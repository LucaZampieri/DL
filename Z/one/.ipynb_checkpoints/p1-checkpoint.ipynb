{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to load the data\n",
    "import dlc_bci as bci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the imported data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n",
      "train --- mean 24.03, std: 41.49 target mean:  0.496835443038\n",
      "test --- mean 21.69, std: 40.83 target mean:  0.51\n",
      "<class 'torch.autograd.variable.Variable'> torch.Size([252, 28, 50])\n",
      "<class 'torch.autograd.variable.Variable'> torch.Size([252])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = bci.load ( root = './data_bci',train=True, download=False, one_khz=False)\n",
    "print( str( type(train_input) ), train_input.size () )\n",
    "print( str( type(train_target) ), train_target.size () )\n",
    "\n",
    "test_input , test_target = bci.load ( root = './data_bci' , train = False, download=False, one_khz=False)\n",
    "print( str( type(test_input) ) , test_input.size () )\n",
    "print( str( type(test_target) ) , test_target.size () )\n",
    "\n",
    "print('train --- mean {:0.2f}, std: {:0.2f}'.format(train_input.mean(),train_input.std()),\\\n",
    "     'target mean: ',train_target.numpy().mean())\n",
    "print('test --- mean {:0.2f}, std: {:0.2f}'.format(test_input.mean(),test_input.std()),\\\n",
    "     'target mean: ',test_target.numpy().mean())\n",
    "\n",
    "# split training into train and validation\n",
    "X = train_input.numpy()\n",
    "y = train_target.numpy()\n",
    "train_input, val_input, train_target, val_target = train_test_split(X, y,test_size= 0.2, random_state=6)\n",
    "\n",
    "# transform into one-hot-encoding\n",
    "one_hot_targets = np.eye(2)[train_target]\n",
    "#train_target = one_hot_targets\n",
    "\n",
    "# Convert them into Variables\n",
    "train_input = Variable(Tensor(train_input))\n",
    "train_target = Variable(torch.LongTensor(train_target))\n",
    "val_input = Variable(Tensor(val_input))\n",
    "val_target = Variable(torch.LongTensor(val_target))\n",
    "test_input = Variable(test_input)\n",
    "test_target = Variable(test_target)\n",
    "\n",
    "# normalise the data (note that the channels differ sometimes a lot)\n",
    "mu, std = train_input.mean(),train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(),test_input.std()\n",
    "test_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(0),test_input.std(0)\n",
    "test_input.sub_(mu).div_(std);\n",
    "\n",
    "print( str( type(train_input) ), train_input.size () )\n",
    "print( str( type(train_target) ), train_target.size () )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 100\n",
    "epochs = 10\n",
    "eta = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = eta)\n",
    "    for e in range(epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(e,':  ',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 28, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(28, 28, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(42*28, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        #self.param = Parameter ( Tensor (123 , 456) )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 42*28)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \"\"\"def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 4*64)))\n",
    "        x = self.fc2(x)\n",
    "        return x\"\"\"\n",
    "\n",
    "def create_model_1():\n",
    "    model = Net(100)\n",
    "    return model\n",
    "    \n",
    "def create_model_3():\n",
    "    hidden = 100\n",
    "    model = nn.Sequential(\n",
    "              nn.Conv1d(28,32,kernel_size=5),\n",
    "              nn.Linear(28*46,64),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(64,2),\n",
    "            )\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def create_model_2():\n",
    "    hidden = 100\n",
    "    model = nn.Sequential(\n",
    "              nn.Conv1d(28,64,kernel_size=5),\n",
    "              nn.ReLU(),\n",
    "              nn.Conv1d(64,128,kernel_size=5),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(128*42,hidden),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden,2),\n",
    "            )\n",
    "    return model\n",
    "    \n",
    "def create_deep_model():\n",
    "    model = nn.Sequential(\n",
    "              nn.Linear(2,4),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(4,8),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(8,16),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(16,32),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(32,64),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(64,128),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(128,2)\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size = mini_batch_size):\n",
    "    nb_errors = 0\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model.forward(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "                                                 \n",
    "        \"\"\"for k in range(0, mini_batch_size):\n",
    "            if data_target.data[b + k] != predicted[k]:\n",
    "                nb_errors = nb_errors + 1    \"\"\"                              \n",
    "        true_val = data_target.data[b:b+mini_batch_size]\n",
    "        nb_errors += torch.sum(predicted!=true_val)\n",
    "    print(output)\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 4: out of range at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensor.c:440",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-c57d06d755b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-a654e6b43440>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target, mini_batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 4: out of range at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensor.c:440"
     ]
    }
   ],
   "source": [
    "for m in [create_model_1]:\n",
    "    model = m()\n",
    "\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "\n",
    "    train_errors = compute_nb_errors(model, data_input=train_input, data_target=train_target)\n",
    "    val_errors = compute_nb_errors(model, data_input=val_input, data_target=val_target)\n",
    "    print(m.__name__,' {:0.2f}'.format(std),\\\n",
    "          'Train: {:0.2f}%'.format( train_errors/train_input.size(0)*100),\\\n",
    "          'Test:  {:0.2f}%'.format(val_errors / val_input.size(0)*100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
