{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "#from torch import LongTensor\n",
    "import torch\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "#import baseline\n",
    "\n",
    "DEBUG = False\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3989422804014327"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/math.sqrt(2*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([1000, 1])\n",
      "torch.Size([1000, 1])\n",
      "\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input_ = Tensor(nb, 2).uniform_(0,1)\n",
    "    disk_center = Tensor(nb, 2).fill_(0.5)\n",
    "    #ones_ = torch.ones(nb,2)\n",
    "    R = 1/math.sqrt(2*math.pi) # Radius of the disk\n",
    "    target = (R - (disk_center - input_).pow(2).sum(1).sqrt()  ).sign()#.long()\n",
    "    target.add_(1).div_(2) # to transform [-1,1] into [0,1]\n",
    "    #target = input.pow(2).sum(1).mul(-1).add(1 / 2/ math.pi).sign().add(1).div(2).long() # prof version\n",
    "    return input_, target\n",
    "\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mu, std = train_input.mean(),train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(),test_input.std()\n",
    "test_input.sub_(mu).div_(std)\n",
    "\n",
    "# one hot?\n",
    "#one_hot_targets = np.eye(2)[train_target]\n",
    "#train_target = one_hot_targets\n",
    "#train_target = Tensor(train_target)\n",
    "\n",
    "\n",
    "mini_batch_size = 100\n",
    "print (train_input.size(), train_target.size())\n",
    "#print(train_input[0:10],train_target[0:10])\n",
    "print(train_target.size())\n",
    "#plt.plot(train_input.where())\n",
    "print(train_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_ori  = train_target.clone()\n",
    "one_hot_targets = torch.cat((train_target,1-train_target),1)\n",
    "one_hot_targets[0]\n",
    "train_target = one_hot_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples:        torch.Size([1000, 2])\n",
      "#true_samples:   torch.Size([488, 2])\n",
      "#false_samples:  torch.Size([512, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAF1CAYAAADr6FECAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUMAXEckJBXwRkZxQwBcRyYn/DxxQclsLNVLgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75d725a6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#third_tensor = torch.cat((first_tensor, second_tensor), 0)\n",
    "def plot_data(input_, target_, figure_size = 6):\n",
    "    input_true = torch.Tensor(0,2)\n",
    "    input_false = torch.Tensor(0,2)\n",
    "    for i,x in enumerate(input_):\n",
    "        if target_[i][0] == 0 :\n",
    "            input_false = torch.cat( (input_false, input_[i,:].view(-1,2)),0 )\n",
    "        else :\n",
    "            input_true = torch.cat( (input_true, input_[i,:].view(-1,2)),0 )\n",
    "    print ('#samples:       ',input_.size())\n",
    "    print ('#true_samples:  ',input_true.size())\n",
    "    print ('#false_samples: ',input_false.size())\n",
    "    p1 = plt.figure(1,figsize=(figure_size,figure_size))\n",
    "    plt.plot(input_true[:,0].numpy(),input_true[:,1].numpy(),'r.',label='1 label')\n",
    "    plt.plot(input_false[:,0].numpy(),input_false[:,1].numpy(),'b.',label='0 labe')\n",
    "    plt.xlim(0,1), plt.ylim(0,1)\n",
    "    plt.legend(fontsize='x-large')\n",
    "    plt.title('Distribution of generated data')\n",
    "plot_data(train_input, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between -1,1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=(train_target*2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 %\n"
     ]
    }
   ],
   "source": [
    "import baseline\n",
    "baseline.baseline_linear_model(train_input, train_target_ori, test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def d_tanh(x):\n",
    "    return (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "\n",
    "def relu(x):\n",
    "    if x>0 : return x\n",
    "    else : return x.fill(0)\n",
    "    \n",
    "def d_relu(x):\n",
    "    if x>0: return x.fill(1)\n",
    "    else : return x.fill(0)\n",
    "\n",
    "def mse(x,t):\n",
    "    if DEBUG == True:\n",
    "        print('mse x.size',x.size())\n",
    "        print('mse target size',t.size())\n",
    "    return (x - t).pow(2).sum()\n",
    "\n",
    "#def dsigma_relu(x):\n",
    "\n",
    "sigma = tanh\n",
    "dsigma = d_tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### suggested structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param ( self ) :\n",
    "        return [] \n",
    "    \n",
    "    def zero_grads ( self ) :\n",
    "        pass\n",
    "    \n",
    "    def reset_params( self ) :\n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "   # self._gradient.add_(d_dy.view(-1,1)*self._input.view(1,-1))        \n",
    "    \n",
    "\"\"\"def backward_pass(w1, b1, w2, b2,\n",
    "              t,\n",
    "              x, s1, x1, s2, x2,\n",
    "              dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    x0 = x\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    dl_ds2 = dsigma(s2) * dl_dx2\n",
    "    dl_dx1 = w2.t().mv(dl_ds2)\n",
    "    dl_ds1 = dsigma(s1) * dl_dx1\n",
    "\n",
    "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
    "    dl_db2.add_(dl_ds2)\n",
    "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db1.add_(dl_ds1)\"\"\"\n",
    "\n",
    "class Tanh(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.input.clone().tanh()\n",
    "    \n",
    "    def backward(self, d_output):\n",
    "        x = self.input\n",
    "        #(1 - self._input.tanh()**2) * d_dy\n",
    "        d_input = (1 - self.input.tanh()**2)*d_output#d_tanh(x) * d_output\n",
    "        return d_input\n",
    "     \n",
    "\n",
    "\n",
    "class LossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,x,t):\n",
    "        self.input=x\n",
    "        self.target = t\n",
    "        d_input = mse(x,t)\n",
    "        return d_input\n",
    "        \n",
    "    def backward(self):\n",
    "        d_output = 2 * (self.input - self.target)\n",
    "        return d_output\n",
    "    \n",
    "class Sequential(Module):\n",
    "\n",
    "    def __init__(self,modules, loss):\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        self.loss = loss\n",
    "        \n",
    "    \n",
    "    #done by luca\n",
    "    def add(self, module):\n",
    "        self.modules.append(module)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        for module in self.modules:\n",
    "            input = module.forward(input) # module.forward?\n",
    "        return input, self.loss.forward(input, target)\n",
    "    \n",
    "    def backward(self):\n",
    "        out = self.loss.backward()# arguments??\n",
    "        n = len(self.modules)-1 # -1 for the loss?\n",
    "        for i in range(0,n):\n",
    "            out = self.modules[n-i].backward(out)\n",
    "        return out\n",
    "    \n",
    "    def zero_grads(self):\n",
    "        for x in self.modules:\n",
    "            x.zero_grads()\n",
    "            \n",
    "    def param ( self ):\n",
    "        params = []\n",
    "        for x in self.modules:\n",
    "            params = params + x.param()\n",
    "        return params\n",
    "            \n",
    "            \n",
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        # num features\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # weigths\n",
    "        self.weight = torch.Tensor(out_features, in_features).normal_(0,1e-6)\n",
    "        self.bias   = torch.Tensor(out_features).fill_(0.0)\n",
    "        # gradients\n",
    "        self.dl_dws = torch.Tensor(out_features, in_features).fill_(0.0)\n",
    "        self.dl_dbias   = torch.Tensor(out_features).fill_(0.0)\n",
    "        self.params = [(self.weight,self.dl_dws), (self.bias, self.dl_dbias)] \n",
    "        if DEBUG == True:\n",
    "            print('weights size: ',self.weight.size())\n",
    "        # initialize the parameters\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1)) # *sqrt(3)?\n",
    "        self.weight.uniform_(-stdv, stdv)\n",
    "        self.bias.uniform_(0, 0)\n",
    "        \n",
    "    def zero_grads(self):\n",
    "        \"\"\"resets the gradients of the module\"\"\"\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.dl_dws.zero_()\n",
    "        self.dl_dbias.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.s = torch.mv(self.weight, input).add(self.bias)\n",
    "        if DEBUG == True:\n",
    "            print(input.size())\n",
    "        #self.input = torch.add(self.input,self.bias)\n",
    "        return self.s.clone()\n",
    "        \n",
    "    def backward ( self ,d_output ) :\n",
    "        if DEBUG == True:\n",
    "            print('input: ',self.input.view(-1,1).size())\n",
    "            print('output: ',d_output.view(-1,1).t().size())\n",
    "        dl_dw = d_output.view(-1,1).mm(self.input.view(-1,1).t())\n",
    "        if DEBUG == True:\n",
    "            print('dl_dw size: ',dl_dw.size())\n",
    "            print('dl_dws size',self.dl_dws.size())\n",
    "        self.dl_dws.add_(dl_dw) \n",
    "        self.dl_dbias.add(d_output)\n",
    "        d_input = self.weight.t().mv(d_output) #mv()\n",
    "        return d_input\n",
    "    \n",
    "    def param ( self ) :\n",
    "        return [[self.weight,self.dl_dws], [self.bias, self.dl_dbias]] \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 20\n",
    "lay1 = Linear(2,hidden)\n",
    "sigma1 = Tanh()\n",
    "lay2 = Linear(hidden,hidden)\n",
    "sigma2 = Tanh()\n",
    "lay3 = Linear(hidden,2)\n",
    "sigma3 = Tanh()\n",
    "layers = [lay1,sigma1, lay2, sigma2, lay3, sigma3]\n",
    "net = Sequential(modules = layers, loss = LossMSE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.6696\n",
      "-1.3786\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "\n",
      " 0.2000\n",
      " 0.3000\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "\n",
      "-1\n",
      " 1\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "\n",
      "-1\n",
      " 1\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0])\n",
    "print(Tensor([0.2 , 0.3]))\n",
    "print(train_target[0])\n",
    "print(Tensor([-1,1]))\n",
    "\n",
    "a = net.forward(Tensor([0.2 , 0.3]),Tensor([-1,1]))\n",
    "a\n",
    "\n",
    "net.backward()\n",
    "net.zero_grads()\n",
    "\n",
    "a = (1,2)\n",
    "a[0]\n",
    "\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 0 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 1 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 2 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 3 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 4 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 5 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 6 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 7 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 8 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 9 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 10 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 11 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 12 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 13 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 14 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 15 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 16 acc_train_loss 2000.00 acc_train_error 51.40%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 17 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 18 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 19 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 20 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 21 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 22 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 23 acc_train_loss 2000.00 acc_train_error 51.50%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 24 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 25 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 26 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 27 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 28 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 29 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 30 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 31 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 32 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 33 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 34 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 35 acc_train_loss 2000.00 acc_train_error 51.70%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 36 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 37 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 38 acc_train_loss 2000.00 acc_train_error 51.60%\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "epoch 39 acc_train_loss 2000.00 acc_train_error 51.60%\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "# training set\n",
    "train_input = train_input\n",
    "train_target = train_target\n",
    "\n",
    "# network parameters\n",
    "model = Sequential(modules = layers, loss= LossMSE())\n",
    "\n",
    "mini_batch_size = 1\n",
    "# training parameters\n",
    "lr = 1\n",
    "nb_epochs = 40\n",
    "train_errors = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    # Back-prop\n",
    "\n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "    \n",
    "    model.zero_grads()\n",
    "    \n",
    "    #for b in range(0,train_input.size(0), mini_batch_size):\n",
    "    for b in range(0,train_input.size(0)):\n",
    "        #output, loss = model.forward(train_input[b:b+mini_batch_size],train_target[b:b+mini_batch_size])\n",
    "        output, loss = model.forward(train_input[b],train_target[b])\n",
    "        acc_loss += loss\n",
    "        model.backward()\n",
    "        #print('OUTPUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUT: ',output)\n",
    "        value_pred, prediction = output.max(0)\n",
    "        #print(prediction)\n",
    "        value_target, target = train_target[b].max(0)\n",
    "        #print(target)\n",
    "        \n",
    "        if target.numpy() != prediction.numpy():\n",
    "            nb_train_errors = nb_train_errors + 1 \n",
    "        \n",
    "    train_errors.append(nb_train_errors)\n",
    "    loss_list.append(acc_loss)\n",
    "    my_parameters = model.param()\n",
    "    if DEBUG == True:\n",
    "        print('length params', len(my_parameters))\n",
    "        print('weigths before',my_parameters[0][0][0:5])\n",
    "        print('DDDweigths before',my_parameters[0][1][0:5])\n",
    "    for i,_ in enumerate(my_parameters):\n",
    "        my_parameters[i][0]-= lr * my_parameters[i][1]\n",
    "    if DEBUG == True:\n",
    "        print('weigths after',my_parameters[0][0][0:5])\n",
    "        print('DDDweigths after',my_parameters[0][1][0:5])\n",
    "    print(model.param()[0][1][0:5])\n",
    "    \n",
    "    print('epoch {:d} acc_train_loss {:.02f} acc_train_error {:.02f}%'.format(epoch,acc_loss,\n",
    "                              (100 * nb_train_errors) / train_input.size(0)))\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQPjqzkadAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75c6285198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOCGYmVnCCcHMzAD4/ydvtKQhaXfFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75c622f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "plt.plot(train_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prof version\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def loss(v, t):\n",
    "    return (v - t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)\n",
    "\n",
    "######################################################################\n",
    "# from F\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "def linear(input, weight, bias=None):\n",
    "    \n",
    "    output = input.matmul(weight.t())\n",
    "    if bias is not None:\n",
    "        output += bias\n",
    "    return output\n",
    "\n",
    "\n",
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "######################################################################\n",
    "################# A first model ######################################\n",
    "def linear_forward(x,w,b):\n",
    "    s = w.mv(x) + b\n",
    "    x = sigma(s)\n",
    "    return s,x\n",
    "\n",
    "def linear_backward(x0, x, dl_ds_prev, dl_dw, dl_db, initial = False):\n",
    "    \n",
    "    dl_dx = w.t().mv(dl_ds_prev)\n",
    "    dl_ds = dsigma(s1) * dl_dx   \n",
    "    dl_dw.add_(dl_ds.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db.add_(dl_ds)\n",
    "\n",
    "def forward_pass(ws, bs, x, test = False):\n",
    "    x0 = x\n",
    "    \n",
    "    s1, x1 = linear_forward(x0,ws[0],bs[0])\n",
    "    s2, x2 = linear_forward(x1,ws[1],bs[1])\n",
    "    \n",
    "    xs = [x1, x2]\n",
    "    ss = [s1, s2]\n",
    "    if test: \n",
    "        return xs[-1]\n",
    "    return x0, xs, ss\n",
    "\n",
    "\n",
    "def backward_pass(ws, bs,\n",
    "                  t,\n",
    "                  x, xs, ss,\n",
    "                  dl_dws, dl_dbs):\n",
    "    x0 = x\n",
    "    \n",
    "    dl_dx2 = dloss(xs[-1], t)\n",
    "    dl_ds2 = dsigma(ss[2-1]) * dl_dx2\n",
    "    dl_dws[2-1].add_(dl_ds2.view(-1, 1).mm(xs[1-1].view(1, -1)))\n",
    "    dl_dbs[2-1].add_(dl_ds2)\n",
    "    \n",
    "    dl_dx1 = ws[2-1].t().mv(dl_ds2) # w2\n",
    "    dl_ds1 = dsigma(ss[1-1]) * dl_dx1   \n",
    "    \n",
    "    dl_dws[1-1].add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_dbs[1-1].add_(dl_ds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.size():  torch.Size([1000, 2])\n",
      "-6.00436487729894e-06\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of non-empty torch.ByteTensor objects is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-33190ad6df85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# check wether the target was 1 or -1 --> verify if positif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mnb_train_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_train_errors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# if == -1 lets say :p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0macc_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         raise RuntimeError(\"bool value of non-empty \" + torch.typename(self) +\n\u001b[0;32m--> 140\u001b[0;31m                            \" objects is ambiguous\")\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of non-empty torch.ByteTensor objects is ambiguous"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "zeta = 0.9\n",
    "train_input = train_input\n",
    "test_input = test_input\n",
    "\n",
    "nb_hidden=50\n",
    "print ('train_input.size(): ', train_input.size())\n",
    "nb_classes = 2 #train_target.size(1) \n",
    "nb_train_samples = train_input.size(0)\n",
    "\n",
    "eta = 0.1 / train_target.size(0)\n",
    "\n",
    "eps = 1e-6\n",
    "\n",
    "# weights and biases\n",
    "w1 = Tensor(nb_hidden, train_input.size(1)).normal_(0,1)\n",
    "b1 = Tensor(nb_hidden).normal_(0,1)\n",
    "w2 = Tensor(nb_classes, nb_hidden).normal_(0,eps)\n",
    "b2 = Tensor(nb_classes).normal_(0,eps)\n",
    "\n",
    "# lists\n",
    "ws = [w1, w2]\n",
    "bs = [b1, b2]\n",
    "# derivatives of the losse wrt weights and biases\n",
    "dl_dws = []\n",
    "dl_dbs = []\n",
    "for w in ws:\n",
    "    dl_dws.append(Tensor(w.size()))\n",
    "for b in bs:\n",
    "    dl_dbs.append(Tensor(b.size()))\n",
    "\n",
    "\n",
    "epochs = 250\n",
    "for k in range (0,epochs):\n",
    "    \n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "    \n",
    "    # set the storage to 0\n",
    "    for i in range(0, len(dl_dws)):\n",
    "        dl_dws[i].zero_()\n",
    "        dl_dbs[i].zero_()\n",
    "    \n",
    "    # for each sample run forward and backward pass\n",
    "    for n in range(0, nb_train_samples):\n",
    "        \n",
    "        # run forward pass\n",
    "        x0, xs, ss = forward_pass(ws, bs, train_input[n])\n",
    "        \n",
    "        # prediction is the maximum predicted class\n",
    "        \n",
    "        predicted = xs[-1].max(dim = 0)[1] # dim is the axis, 1 for taking index, 0 to just select the value\n",
    "        pred = predicted [0]\n",
    "        #print(predicted)\n",
    "        pred = xs[-1][0]\n",
    "        #print(xs[-1])\n",
    "        print(pred)\n",
    "        # check wether the target was 1 or -1 --> verify if positif\n",
    "        if train_target[n] != int(pred) : \n",
    "            nb_train_errors = nb_train_errors + 1 # if == -1 lets say :p \n",
    "        acc_loss += loss(Tensor(1).fill_(pred), train_target[n])\n",
    "        #acc_loss += loss(pred, train_target[n])\n",
    "\n",
    "        # run backward pass\n",
    "        backward_pass(ws, bs,\n",
    "                      train_target[n],\n",
    "                      x0, xs, ss,\n",
    "                      dl_dws, dl_dbs)\n",
    "    \n",
    "    # Gradient step\n",
    "    for i in range(0, len(ws)):\n",
    "        ws[i] = ws[i] - eta * dl_dws[i]\n",
    "        bs[i] = bs[i] - eta * dl_dbs[i]\n",
    "\n",
    "    # Test error\n",
    "    nb_test_errors = 0\n",
    "    for n in range(0, test_input.size(0)):\n",
    "        output = forward_pass(ws, bs, test_input[n], test=True)\n",
    "\n",
    "        pred = output.max(0)[1][0]\n",
    "        if test_target[n] != int(output[0]) : nb_test_errors = nb_test_errors + 1  \n",
    "\n",
    "\n",
    "    print(k,' --> acc_train_loss {:.02f} acc_train_error {:.02f}% test_error {:.02f}%'\n",
    "          .format(acc_loss,\n",
    "                  (100 * nb_train_errors) / train_input.size(0),\n",
    "                  (100 * nb_test_errors) / test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
