{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "#from torch import LongTensor\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3989422804014327"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/math.sqrt(2*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input = Tensor(nb, 2).uniform_(0,1)\n",
    "    R = 1/math.sqrt(2*math.pi) # Radius of the disk\n",
    "    target = (R - input.pow(2).sum(1).sqrt()).sign()#.long()\n",
    "    target.add_(1).div_(2) # to transform [-1,1] into [0,1]\n",
    "    #target = input.pow(2).sum(1).mul(-1).add(1 / 2/ math.pi).sign().add(1).div(2).long() # prof version\n",
    "    return input, target\n",
    "\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mu, std = train_input.mean(0),train_input.std(0)\n",
    "train_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(0),test_input.std(0)\n",
    "test_input.sub_(mu).div_(std)\n",
    "\n",
    "#train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "#test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "# one hot?\n",
    "#one_hot_targets = np.eye(2)[train_target]\n",
    "#train_target = one_hot_targets\n",
    "#train_target = Tensor(train_target)\n",
    "\n",
    "mini_batch_size = 100\n",
    "print (train_input.size(), train_target.size())\n",
    "#print(train_input[0:10],train_target[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma_tanh(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def dsigma_tanh(x):\n",
    "    return (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "\n",
    "def sigma_relu(x):\n",
    "    if x>0 : return x\n",
    "    else : return 0\n",
    "\n",
    "#def dsigma_relu(x):\n",
    "\n",
    "sigma = sigma_tanh\n",
    "dsigma = dsigma_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### suggested structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param ( self ) :\n",
    "        return []\n",
    "    \n",
    "# prof version\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def loss(v, t):\n",
    "    return (v - t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)\n",
    "\n",
    "######################################################################\n",
    "# from F\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "def linear(input, weight, bias=None):\n",
    "    \n",
    "    output = input.matmul(weight.t())\n",
    "    if bias is not None:\n",
    "        output += bias\n",
    "    return output\n",
    "\n",
    "\n",
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "######################################################################\n",
    "def linear_forward(x,w,b):\n",
    "    s = w.mv(x) + b\n",
    "    x = sigma(s)\n",
    "    return s,x\n",
    "\n",
    "def linear_backward(x0, x, dl_ds_prev, dl_dw, dl_db, initial = False):\n",
    "    \n",
    "    dl_dx = w.t().mv(dl_ds_prev)\n",
    "    dl_ds = dsigma(s1) * dl_dx   \n",
    "    dl_dw.add_(dl_ds.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db.add_(dl_ds)\n",
    "\n",
    "def forward_pass(ws, bs, x, test = False):\n",
    "    x0 = x\n",
    "    \n",
    "    s1, x1 = linear_forward(x0,ws[0],bs[0])\n",
    "    s2, x2 = linear_forward(x1,ws[1],bs[1])\n",
    "    \n",
    "    xs = [x1, x2]\n",
    "    ss = [s1, s2]\n",
    "    if test: \n",
    "        return xs[-1]\n",
    "    return x0, xs, ss\n",
    "\n",
    "\n",
    "def backward_pass(ws, bs,\n",
    "                  t,\n",
    "                  x, xs, ss,\n",
    "                  dl_dws, dl_dbs):\n",
    "    x0 = x\n",
    "    \n",
    "    dl_dx2 = dloss(xs[-1], t)\n",
    "    dl_ds2 = dsigma(ss[2-1]) * dl_dx2\n",
    "    dl_dws[2-1].add_(dl_ds2.view(-1, 1).mm(xs[1-1].view(1, -1)))\n",
    "    dl_dbs[2-1].add_(dl_ds2)\n",
    "    \n",
    "    dl_dx1 = ws[2-1].t().mv(dl_ds2) # w2\n",
    "    dl_ds1 = dsigma(ss[1-1]) * dl_dx1   \n",
    "    \n",
    "    dl_dws[1-1].add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_dbs[1-1].add_(dl_ds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.size():  torch.Size([1000, 2])\n",
      "0  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "1  --> acc_train_loss 486.00 acc_train_error 48.60% test_error 12.40%\n",
      "2  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "3  --> acc_train_loss 454.00 acc_train_error 45.40% test_error 12.40%\n",
      "4  --> acc_train_loss 456.00 acc_train_error 45.60% test_error 12.40%\n",
      "5  --> acc_train_loss 452.00 acc_train_error 45.20% test_error 12.40%\n",
      "6  --> acc_train_loss 430.00 acc_train_error 43.00% test_error 12.40%\n",
      "7  --> acc_train_loss 426.00 acc_train_error 42.60% test_error 12.40%\n",
      "8  --> acc_train_loss 426.00 acc_train_error 42.60% test_error 12.40%\n",
      "9  --> acc_train_loss 424.00 acc_train_error 42.40% test_error 12.40%\n",
      "10  --> acc_train_loss 424.00 acc_train_error 42.40% test_error 12.40%\n",
      "11  --> acc_train_loss 428.00 acc_train_error 42.80% test_error 12.40%\n",
      "12  --> acc_train_loss 427.00 acc_train_error 42.70% test_error 12.40%\n",
      "13  --> acc_train_loss 429.00 acc_train_error 42.90% test_error 12.40%\n",
      "14  --> acc_train_loss 425.00 acc_train_error 42.50% test_error 12.40%\n",
      "15  --> acc_train_loss 431.00 acc_train_error 43.10% test_error 12.40%\n",
      "16  --> acc_train_loss 430.00 acc_train_error 43.00% test_error 12.40%\n",
      "17  --> acc_train_loss 433.00 acc_train_error 43.30% test_error 12.40%\n",
      "18  --> acc_train_loss 434.00 acc_train_error 43.40% test_error 12.40%\n",
      "19  --> acc_train_loss 436.00 acc_train_error 43.60% test_error 12.40%\n",
      "20  --> acc_train_loss 438.00 acc_train_error 43.80% test_error 12.40%\n",
      "21  --> acc_train_loss 439.00 acc_train_error 43.90% test_error 12.40%\n",
      "22  --> acc_train_loss 438.00 acc_train_error 43.80% test_error 12.40%\n",
      "23  --> acc_train_loss 439.00 acc_train_error 43.90% test_error 12.40%\n",
      "24  --> acc_train_loss 442.00 acc_train_error 44.20% test_error 12.40%\n",
      "25  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "26  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "27  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "28  --> acc_train_loss 442.00 acc_train_error 44.20% test_error 12.40%\n",
      "29  --> acc_train_loss 443.00 acc_train_error 44.30% test_error 12.40%\n",
      "30  --> acc_train_loss 439.00 acc_train_error 43.90% test_error 12.40%\n",
      "31  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "32  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "33  --> acc_train_loss 440.00 acc_train_error 44.00% test_error 12.40%\n",
      "34  --> acc_train_loss 442.00 acc_train_error 44.20% test_error 12.40%\n",
      "35  --> acc_train_loss 441.00 acc_train_error 44.10% test_error 12.40%\n",
      "36  --> acc_train_loss 440.00 acc_train_error 44.00% test_error 12.40%\n",
      "37  --> acc_train_loss 445.00 acc_train_error 44.50% test_error 12.40%\n",
      "38  --> acc_train_loss 446.00 acc_train_error 44.60% test_error 12.40%\n",
      "39  --> acc_train_loss 452.00 acc_train_error 45.20% test_error 12.40%\n",
      "40  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "41  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "42  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "43  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "44  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "45  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "46  --> acc_train_loss 449.00 acc_train_error 44.90% test_error 12.40%\n",
      "47  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "48  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "49  --> acc_train_loss 453.00 acc_train_error 45.30% test_error 12.40%\n",
      "50  --> acc_train_loss 446.00 acc_train_error 44.60% test_error 12.40%\n",
      "51  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "52  --> acc_train_loss 454.00 acc_train_error 45.40% test_error 12.40%\n",
      "53  --> acc_train_loss 448.00 acc_train_error 44.80% test_error 12.40%\n",
      "54  --> acc_train_loss 449.00 acc_train_error 44.90% test_error 12.40%\n",
      "55  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "56  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "57  --> acc_train_loss 455.00 acc_train_error 45.50% test_error 12.40%\n",
      "58  --> acc_train_loss 453.00 acc_train_error 45.30% test_error 12.40%\n",
      "59  --> acc_train_loss 453.00 acc_train_error 45.30% test_error 12.40%\n",
      "60  --> acc_train_loss 458.00 acc_train_error 45.80% test_error 12.40%\n",
      "61  --> acc_train_loss 447.00 acc_train_error 44.70% test_error 12.40%\n",
      "62  --> acc_train_loss 449.00 acc_train_error 44.90% test_error 12.40%\n",
      "63  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "64  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "65  --> acc_train_loss 446.00 acc_train_error 44.60% test_error 12.40%\n",
      "66  --> acc_train_loss 453.00 acc_train_error 45.30% test_error 12.40%\n",
      "67  --> acc_train_loss 450.00 acc_train_error 45.00% test_error 12.40%\n",
      "68  --> acc_train_loss 452.00 acc_train_error 45.20% test_error 12.40%\n",
      "69  --> acc_train_loss 453.00 acc_train_error 45.30% test_error 12.40%\n",
      "70  --> acc_train_loss 455.00 acc_train_error 45.50% test_error 12.40%\n",
      "71  --> acc_train_loss 451.00 acc_train_error 45.10% test_error 12.40%\n",
      "72  --> acc_train_loss 452.00 acc_train_error 45.20% test_error 12.40%\n",
      "73  --> acc_train_loss 455.00 acc_train_error 45.50% test_error 12.40%\n",
      "74  --> acc_train_loss 457.00 acc_train_error 45.70% test_error 12.40%\n",
      "75  --> acc_train_loss 462.00 acc_train_error 46.20% test_error 12.40%\n",
      "76  --> acc_train_loss 455.00 acc_train_error 45.50% test_error 12.40%\n",
      "77  --> acc_train_loss 463.00 acc_train_error 46.30% test_error 12.40%\n",
      "78  --> acc_train_loss 457.00 acc_train_error 45.70% test_error 12.40%\n",
      "79  --> acc_train_loss 455.00 acc_train_error 45.50% test_error 12.40%\n",
      "80  --> acc_train_loss 456.00 acc_train_error 45.60% test_error 12.40%\n",
      "81  --> acc_train_loss 460.00 acc_train_error 46.00% test_error 12.40%\n",
      "82  --> acc_train_loss 464.00 acc_train_error 46.40% test_error 12.40%\n",
      "83  --> acc_train_loss 459.00 acc_train_error 45.90% test_error 12.40%\n",
      "84  --> acc_train_loss 463.00 acc_train_error 46.30% test_error 12.40%\n",
      "85  --> acc_train_loss 458.00 acc_train_error 45.80% test_error 12.40%\n",
      "86  --> acc_train_loss 467.00 acc_train_error 46.70% test_error 12.40%\n",
      "87  --> acc_train_loss 462.00 acc_train_error 46.20% test_error 12.40%\n",
      "88  --> acc_train_loss 465.00 acc_train_error 46.50% test_error 12.40%\n",
      "89  --> acc_train_loss 467.00 acc_train_error 46.70% test_error 12.40%\n",
      "90  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "91  --> acc_train_loss 465.00 acc_train_error 46.50% test_error 12.40%\n",
      "92  --> acc_train_loss 468.00 acc_train_error 46.80% test_error 12.40%\n",
      "93  --> acc_train_loss 466.00 acc_train_error 46.60% test_error 12.40%\n",
      "94  --> acc_train_loss 466.00 acc_train_error 46.60% test_error 12.40%\n",
      "95  --> acc_train_loss 474.00 acc_train_error 47.40% test_error 12.40%\n",
      "96  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "97  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "98  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "99  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "100  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "101  --> acc_train_loss 466.00 acc_train_error 46.60% test_error 12.40%\n",
      "102  --> acc_train_loss 467.00 acc_train_error 46.70% test_error 12.40%\n",
      "103  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "104  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "105  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "106  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "107  --> acc_train_loss 474.00 acc_train_error 47.40% test_error 12.40%\n",
      "108  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "109  --> acc_train_loss 483.00 acc_train_error 48.30% test_error 12.40%\n",
      "110  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "111  --> acc_train_loss 483.00 acc_train_error 48.30% test_error 12.40%\n",
      "112  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "113  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "114  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "115  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "117  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "118  --> acc_train_loss 481.00 acc_train_error 48.10% test_error 12.40%\n",
      "119  --> acc_train_loss 474.00 acc_train_error 47.40% test_error 12.40%\n",
      "120  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "121  --> acc_train_loss 466.00 acc_train_error 46.60% test_error 12.40%\n",
      "122  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "123  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "124  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "125  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "126  --> acc_train_loss 467.00 acc_train_error 46.70% test_error 12.40%\n",
      "127  --> acc_train_loss 468.00 acc_train_error 46.80% test_error 12.40%\n",
      "128  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "129  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "130  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "131  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "132  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "133  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "134  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "135  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "136  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "137  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "138  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "139  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "140  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "141  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "142  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "143  --> acc_train_loss 469.00 acc_train_error 46.90% test_error 12.40%\n",
      "144  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "145  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "146  --> acc_train_loss 471.00 acc_train_error 47.10% test_error 12.40%\n",
      "147  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "148  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "149  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "150  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "151  --> acc_train_loss 474.00 acc_train_error 47.40% test_error 12.40%\n",
      "152  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "153  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "154  --> acc_train_loss 486.00 acc_train_error 48.60% test_error 12.40%\n",
      "155  --> acc_train_loss 469.00 acc_train_error 46.90% test_error 12.40%\n",
      "156  --> acc_train_loss 469.00 acc_train_error 46.90% test_error 12.40%\n",
      "157  --> acc_train_loss 485.00 acc_train_error 48.50% test_error 12.40%\n",
      "158  --> acc_train_loss 488.00 acc_train_error 48.80% test_error 12.40%\n",
      "159  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "160  --> acc_train_loss 475.00 acc_train_error 47.50% test_error 12.40%\n",
      "161  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "162  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "163  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "164  --> acc_train_loss 468.00 acc_train_error 46.80% test_error 12.40%\n",
      "165  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "166  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "167  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "168  --> acc_train_loss 483.00 acc_train_error 48.30% test_error 12.40%\n",
      "169  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "170  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "171  --> acc_train_loss 467.00 acc_train_error 46.70% test_error 12.40%\n",
      "172  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "173  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "174  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "175  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "176  --> acc_train_loss 469.00 acc_train_error 46.90% test_error 12.40%\n",
      "177  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "178  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "179  --> acc_train_loss 470.00 acc_train_error 47.00% test_error 12.40%\n",
      "180  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "181  --> acc_train_loss 469.00 acc_train_error 46.90% test_error 12.40%\n",
      "182  --> acc_train_loss 476.00 acc_train_error 47.60% test_error 12.40%\n",
      "183  --> acc_train_loss 485.00 acc_train_error 48.50% test_error 12.40%\n",
      "184  --> acc_train_loss 487.00 acc_train_error 48.70% test_error 12.40%\n",
      "185  --> acc_train_loss 481.00 acc_train_error 48.10% test_error 12.40%\n",
      "186  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "187  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "188  --> acc_train_loss 483.00 acc_train_error 48.30% test_error 12.40%\n",
      "189  --> acc_train_loss 485.00 acc_train_error 48.50% test_error 12.40%\n",
      "190  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "191  --> acc_train_loss 472.00 acc_train_error 47.20% test_error 12.40%\n",
      "192  --> acc_train_loss 473.00 acc_train_error 47.30% test_error 12.40%\n",
      "193  --> acc_train_loss 479.00 acc_train_error 47.90% test_error 12.40%\n",
      "194  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "195  --> acc_train_loss 484.00 acc_train_error 48.40% test_error 12.40%\n",
      "196  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "197  --> acc_train_loss 491.00 acc_train_error 49.10% test_error 12.40%\n",
      "198  --> acc_train_loss 485.00 acc_train_error 48.50% test_error 12.40%\n",
      "199  --> acc_train_loss 491.00 acc_train_error 49.10% test_error 12.40%\n",
      "200  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "201  --> acc_train_loss 495.00 acc_train_error 49.50% test_error 12.40%\n",
      "202  --> acc_train_loss 487.00 acc_train_error 48.70% test_error 12.40%\n",
      "203  --> acc_train_loss 481.00 acc_train_error 48.10% test_error 12.40%\n",
      "204  --> acc_train_loss 494.00 acc_train_error 49.40% test_error 12.40%\n",
      "205  --> acc_train_loss 494.00 acc_train_error 49.40% test_error 12.40%\n",
      "206  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "207  --> acc_train_loss 486.00 acc_train_error 48.60% test_error 12.40%\n",
      "208  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "209  --> acc_train_loss 489.00 acc_train_error 48.90% test_error 12.40%\n",
      "210  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "211  --> acc_train_loss 495.00 acc_train_error 49.50% test_error 12.40%\n",
      "212  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "213  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "214  --> acc_train_loss 480.00 acc_train_error 48.00% test_error 12.40%\n",
      "215  --> acc_train_loss 477.00 acc_train_error 47.70% test_error 12.40%\n",
      "216  --> acc_train_loss 484.00 acc_train_error 48.40% test_error 12.40%\n",
      "217  --> acc_train_loss 478.00 acc_train_error 47.80% test_error 12.40%\n",
      "218  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "219  --> acc_train_loss 488.00 acc_train_error 48.80% test_error 12.40%\n",
      "220  --> acc_train_loss 462.00 acc_train_error 46.20% test_error 12.40%\n",
      "221  --> acc_train_loss 487.00 acc_train_error 48.70% test_error 12.40%\n",
      "222  --> acc_train_loss 493.00 acc_train_error 49.30% test_error 12.40%\n",
      "223  --> acc_train_loss 496.00 acc_train_error 49.60% test_error 12.40%\n",
      "224  --> acc_train_loss 488.00 acc_train_error 48.80% test_error 12.40%\n",
      "225  --> acc_train_loss 501.00 acc_train_error 50.10% test_error 12.40%\n",
      "226  --> acc_train_loss 490.00 acc_train_error 49.00% test_error 12.40%\n",
      "227  --> acc_train_loss 486.00 acc_train_error 48.60% test_error 12.40%\n",
      "228  --> acc_train_loss 491.00 acc_train_error 49.10% test_error 12.40%\n",
      "229  --> acc_train_loss 493.00 acc_train_error 49.30% test_error 12.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230  --> acc_train_loss 483.00 acc_train_error 48.30% test_error 12.40%\n",
      "231  --> acc_train_loss 482.00 acc_train_error 48.20% test_error 12.40%\n",
      "232  --> acc_train_loss 493.00 acc_train_error 49.30% test_error 12.40%\n",
      "233  --> acc_train_loss 494.00 acc_train_error 49.40% test_error 12.40%\n",
      "234  --> acc_train_loss 498.00 acc_train_error 49.80% test_error 12.40%\n",
      "235  --> acc_train_loss 488.00 acc_train_error 48.80% test_error 12.40%\n",
      "236  --> acc_train_loss 498.00 acc_train_error 49.80% test_error 12.40%\n",
      "237  --> acc_train_loss 489.00 acc_train_error 48.90% test_error 12.40%\n",
      "238  --> acc_train_loss 492.00 acc_train_error 49.20% test_error 12.40%\n",
      "239  --> acc_train_loss 513.00 acc_train_error 51.30% test_error 12.40%\n",
      "240  --> acc_train_loss 513.00 acc_train_error 51.30% test_error 12.40%\n",
      "241  --> acc_train_loss 497.00 acc_train_error 49.70% test_error 12.40%\n",
      "242  --> acc_train_loss 496.00 acc_train_error 49.60% test_error 12.40%\n",
      "243  --> acc_train_loss 496.00 acc_train_error 49.60% test_error 12.40%\n",
      "244  --> acc_train_loss 512.00 acc_train_error 51.20% test_error 12.40%\n",
      "245  --> acc_train_loss 491.00 acc_train_error 49.10% test_error 12.40%\n",
      "246  --> acc_train_loss 493.00 acc_train_error 49.30% test_error 12.40%\n",
      "247  --> acc_train_loss 495.00 acc_train_error 49.50% test_error 12.40%\n",
      "248  --> acc_train_loss 487.00 acc_train_error 48.70% test_error 12.40%\n",
      "249  --> acc_train_loss 487.00 acc_train_error 48.70% test_error 12.40%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "zeta = 0.9\n",
    "train_input = train_input\n",
    "test_input = test_input\n",
    "\n",
    "nb_hidden=50\n",
    "print ('train_input.size(): ', train_input.size())\n",
    "nb_classes = 2 #train_target.size(1) \n",
    "nb_train_samples = train_input.size(0)\n",
    "\n",
    "eta = 0.1 / train_target.size(0)\n",
    "\n",
    "eps = 1e-6\n",
    "\n",
    "# weights and biases\n",
    "w1 = Tensor(nb_hidden, train_input.size(1)).normal_(0,1)\n",
    "b1 = Tensor(nb_hidden).normal_(0,1)\n",
    "w2 = Tensor(nb_classes, nb_hidden).normal_(0,eps)\n",
    "b2 = Tensor(nb_classes).normal_(0,eps)\n",
    "\n",
    "# lists\n",
    "ws = [w1, w2]\n",
    "bs = [b1, b2]\n",
    "# derivatives of the losse wrt weights and biases\n",
    "dl_dws = []\n",
    "dl_dbs = []\n",
    "for w in ws:\n",
    "    dl_dws.append(Tensor(w.size()))\n",
    "for b in bs:\n",
    "    dl_dbs.append(Tensor(b.size()))\n",
    "\n",
    "\n",
    "epochs = 250\n",
    "for k in range (0,epochs):\n",
    "    \n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "    \n",
    "    # set the storage to 0\n",
    "    for i in range(0, len(dl_dws)):\n",
    "        dl_dws[i].zero_()\n",
    "        dl_dbs[i].zero_()\n",
    "    \n",
    "    # for each sample run forward and backward pass\n",
    "    for n in range(0, nb_train_samples):\n",
    "        \n",
    "        # run forward pass\n",
    "        x0, xs, ss = forward_pass(ws, bs, train_input[n])\n",
    "        \n",
    "        # prediction is the maximum predicted class\n",
    "        \n",
    "        predicted = xs[-1].max(dim = 0)[1] # dim is the axis, 1 for taking index, 0 to just select the value\n",
    "        pred = predicted [0]\n",
    "        #print(predicted)\n",
    "        #pred = xs[-1][0]\n",
    "        #print(xs[-1])\n",
    "        #print(pred)\n",
    "        # check wether the target was 1 or -1 --> verify if positif\n",
    "        if train_target[n] != int(pred) : nb_train_errors = nb_train_errors + 1 # if == -1 lets say :p \n",
    "        acc_loss += loss(Tensor(1).fill_(pred), train_target[n])\n",
    "        #acc_loss += loss(pred, train_target[n])\n",
    "\n",
    "        # run backward pass\n",
    "        backward_pass(ws, bs,\n",
    "                      train_target[n],\n",
    "                      x0, xs, ss,\n",
    "                      dl_dws, dl_dbs)\n",
    "    \n",
    "    # Gradient step\n",
    "    for i in range(0, len(ws)):\n",
    "        ws[i] = ws[i] - eta * dl_dws[i]\n",
    "        bs[i] = bs[i] - eta * dl_dbs[i]\n",
    "\n",
    "    # Test error\n",
    "    nb_test_errors = 0\n",
    "    for n in range(0, test_input.size(0)):\n",
    "        output = forward_pass(ws, bs, test_input[n], test=True)\n",
    "\n",
    "        pred = output.max(0)[1][0]\n",
    "        if test_target[n] != int(output[0]) : nb_test_errors = nb_test_errors + 1  \n",
    "\n",
    "\n",
    "    print(k,' --> acc_train_loss {:.02f} acc_train_error {:.02f}% test_error {:.02f}%'\n",
    "          .format(acc_loss,\n",
    "                  (100 * nb_train_errors) / train_input.size(0),\n",
    "                  (100 * nb_test_errors) / test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
