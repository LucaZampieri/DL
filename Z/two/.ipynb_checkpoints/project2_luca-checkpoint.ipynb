{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input_ = Tensor(nb, 2).uniform_(0,1)\n",
    "    disk_center = Tensor(nb, 2).fill_(0.5)\n",
    "    #ones_ = torch.ones(nb,2)\n",
    "    R = 1/math.sqrt(2*math.pi) # Radius of the disk\n",
    "    target = (R - (disk_center - input_).pow(2).sum(1).sqrt()).sign()#.long()\n",
    "    target.add_(1).div_(2) # to transform [-1,1] into [0,1]\n",
    "    return input_, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mini_batch_size = 100\n",
    "print (train_input.size(), train_target.size())\n",
    "print(train_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples:        torch.Size([1000, 2])\n",
      "#true_samples:   torch.Size([516, 2])\n",
      "#false_samples:  torch.Size([484, 2])\n",
      "torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "def plot_data(input_, target_, figure_size = 6):\n",
    "    input_true = torch.Tensor(0,2)\n",
    "    input_false = torch.Tensor(0,2)\n",
    "    for i,x in enumerate(input_):\n",
    "        if target_[i] == 0 :\n",
    "            input_false = torch.cat((input_false, input_[i,:].view(-1,2)),0 )\n",
    "        else :\n",
    "            input_true = torch.cat( (input_true, input_[i,:].view(-1,2)),0 )\n",
    "    print ('#samples:       ',input_.size())\n",
    "    print ('#true_samples:  ',input_true.size())\n",
    "    print ('#false_samples: ',input_false.size())\n",
    "    p1 = plt.figure(1,figsize=(figure_size,figure_size))\n",
    "    plt.plot(input_true[:,0].numpy(),input_true[:,1].numpy(),'r.',label='within circle')\n",
    "    plt.plot(input_false[:,0].numpy(),input_false[:,1].numpy(),'b.',label='outside circle')\n",
    "    plt.xlim(0,1), plt.ylim(0,1)\n",
    "    plt.legend(fontsize='x-large')\n",
    "    plt.title('Distribution of generated data')\n",
    "    \n",
    "    \n",
    "plot_data(train_input, train_target)\n",
    "train_target = torch.cat((1-train_target.unsqueeze(1), train_target.unsqueeze(1)),1)\n",
    "test_target = torch.cat((1-test_target.unsqueeze(1), test_target.unsqueeze(1)),1)\n",
    "print(train_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1963  1.3479\n",
       " 0.8442 -0.4480\n",
       " 0.4131  1.6285\n",
       "       â‹®        \n",
       " 1.2105  0.7269\n",
       "-0.6424  1.1538\n",
       "-1.5122  0.6772\n",
       "[torch.FloatTensor of size 1000x2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, std = train_input.mean(),train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(),test_input.std()\n",
    "test_input.sub_(mu).div_(std)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param ( self ) :\n",
    "        return [] \n",
    "    \n",
    "    def zero_grad ( self ) :\n",
    "        pass\n",
    "    \n",
    "    def reset_params( self ) :\n",
    "        pass\n",
    "    \n",
    "class SGDOptimizer():\n",
    "    def __init__(self, Sequential, lr):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Sequential = Sequential\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        for param in self.Sequential.params:\n",
    "            param[0][0].add_(- self.lr * param[1][0])\n",
    "            param[0][1].add_(- self.lr * param[1][1])\n",
    "        \n",
    "        self.Sequential.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def find_direction(self, grad_m1, grad, step, inv_hessian):\n",
    "        H = self.inv_hessian\n",
    "        grad_diff = grad - grad_m1\n",
    "        ys = np.inner(grad_diff, step)\n",
    "        Hy = np.dot(H, grad_diff)\n",
    "        yHy = np.inner(grad_diff, Hy)\n",
    "        H += (ys + yHy) * np.outer(step, step) / ys ** 2\n",
    "        H -= (np.outer(Hy, step) + np.outer(step, Hy)) / ys\n",
    "        direction = -np.dot(H, grad)\n",
    "        return direction, {'gradient_diff': grad_diff}\n",
    "\n",
    "    def __iter__(self):\n",
    "        args, kwargs = next(self.args)\n",
    "        grad = self.fprime(self.wrt, *args, **kwargs)\n",
    "        grad_m1 = scipy.zeros(grad.shape)\n",
    "\n",
    "        if self.inv_hessian is None:\n",
    "            self.inv_hessian = scipy.eye(grad.shape[0])\n",
    "\n",
    "        for i, (next_args, next_kwargs) in enumerate(self.args):\n",
    "            if i == 0:\n",
    "                direction, info = -grad, {}\n",
    "            else:\n",
    "                direction, info = self.find_direction(\n",
    "                    grad_m1, grad, step, self.inv_hessian)\n",
    "\n",
    "            if not is_nonzerofinite(direction):\n",
    "                # TODO: inform the user here.\n",
    "                break\n",
    "\n",
    "            step_length = self.line_search.search(\n",
    "                direction, None, args, kwargs)\n",
    "\n",
    "            if step_length != 0:\n",
    "                step = step_length * direction\n",
    "                self.wrt += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for param in self.Sequential.params:\\n    param[0][0].add_(- self.lr * param[1][0])\\n    param[0][1].add_(- self.lr * param[1][1])'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BFGSOptimizer():\n",
    "    \"\"\"implement the BFGS optimizer for weights and SGD for biases\"\"\"\n",
    "    def __init__(self, Sequential, lr):\n",
    "        super().__init__()\n",
    "        self.Sequential = Sequential\n",
    "        self.params = self.Sequential.params # 1 per layer\n",
    "        self.step_size = lr\n",
    "        \n",
    "        self.grads = []\n",
    "        self.hessians_inv = []\n",
    "        self.old_grads = []\n",
    "        self.directions = []\n",
    "        self.w_diff = []\n",
    "        self.grad_diff = []\n",
    "        self.w = []\n",
    "        self.w_old = []\n",
    "        \n",
    "        self._initialize_parameters()\n",
    "        \n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"initialize the parameters of the optimizer\"\"\"\n",
    "        for param in self.params:\n",
    "            my_ones = torch.ones(param[1][0].size())\n",
    "            my_zeros = torch.zeros(param[1][0].size())\n",
    "            \n",
    "            self.grads.append(my_zeros.clone())\n",
    "            self.hessians_inv.append(my_ones.clone())\n",
    "            self.old_grads.append(my_zeros.clone())\n",
    "            self.w_diff.append(my_zeros.clone())\n",
    "            self.w_old.append(my_zeros.clone())\n",
    "            self.w.append(my_zeros.clone())\n",
    "            self.grad_diff.append(my_zeros.clone())\n",
    "            self.directions.append(param[1][0].clone())\n",
    "\n",
    "    def _compute_direction(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            self.directions[i] = self.hessians_inv[i]*self.grads[i]\n",
    "            \n",
    "    def _quasi_update(self):\n",
    "        for i, inv_hess in enumerate(self.hessians_inv):\n",
    "            rho = 1.0/(self.grad_diff[i]*self.w_diff[i]+0.00001)\n",
    "            tmp1 = 1.0 - rho * self.grad_diff[i] * self.w_diff[i]\n",
    "            tmp2 = rho * self.w_diff[i] * self.w_diff[i]\n",
    "            self.hessians_inv[i] = tmp1 * inv_hess * tmp1 + tmp2  # for BFGS update \n",
    "            #self.hessians_inv[i] = inv_hess # for \"SGD\"\n",
    "\n",
    "    def _compute_step_size(self):\n",
    "        #self.step_size = self.step_size\n",
    "        if self.step_size == 0:\n",
    "            print('optimizer step size is 0')\n",
    "        \n",
    "    def _get_new_parameters(self):\n",
    "        for i,param in enumerate(self.params):\n",
    "            self.grads[i] = param[1][0].clone()\n",
    "            self.w[i] = param[0][0].clone()\n",
    "    \n",
    "    def _update_parameters(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            self.w_diff[i] = self.w[i] - self.w_old[i]\n",
    "            self.grad_diff[i] = self.grads[i] - self.old_grads[i]\n",
    "            self.w_old[i] = self.w[i].clone()\n",
    "            self.old_grads[i] = self.grads[i].clone()\n",
    "    \n",
    "    def step(self):\n",
    "        self._get_new_parameters()\n",
    "        self._compute_direction() # update direction\n",
    "        self._compute_step_size() # update step size\n",
    "                                  \n",
    "        for i,param in enumerate(self.Sequential.params):\n",
    "            param[0][0].add_(- self.step_size * self.directions[i])\n",
    "            param[0][1].add_(- self.step_size * param[1][1])\n",
    "                                  \n",
    "        # update optimizer parameters and do quasi-update\n",
    "        self._update_parameters()\n",
    "        self._quasi_update()\n",
    "        \n",
    "        self.Sequential.zero_grad()\n",
    "        \n",
    "\"\"\"for param in self.Sequential.params:\n",
    "    param[0][0].add_(- self.lr * param[1][0])\n",
    "    param[0][1].add_(- self.lr * param[1][1])\"\"\"\n",
    "# lala\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weights = torch.Tensor(out_features, in_features).normal_(mean=0, std = 1)\n",
    "        self.bias = torch.Tensor(out_features).uniform_(0,0)\n",
    "        \n",
    "        self.dl_dw = torch.Tensor(out_features, in_features)\n",
    "        self.dl_db = torch.Tensor(out_features)\n",
    "        self.zero_grad()\n",
    "        \n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        if(x.size()[1]!=self.in_features):\n",
    "            raise TypeError('Size of x should correspond to size of linear module')\n",
    "        return torch.mm(x,self.weights.t()) + self.bias.expand(x.size()[0], self.out_features)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        self.dl_db = torch.mean(d_dx,0)\n",
    "        self.dl_dw = torch.mm(d_dx.t(), self.x)\n",
    "        return torch.mm(d_dx,self.weights)\n",
    "        \n",
    "    def param(self):\n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "        return self.params\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.dl_db.zero_()\n",
    "        self.dl_dw.zero_()\n",
    "        \n",
    "    def reset_params(self):\n",
    "        self.weights.normal_(mean=0, std = 1)\n",
    "        self.bias.uniform_(0,0)\n",
    "        self.zero_grad()\n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "               \n",
    "        \n",
    "class Sequential(Module):\n",
    "    def __init__(self, modules, loss):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.modules = modules\n",
    "        self.loss = loss\n",
    "        self.params = []\n",
    "        self.param()\n",
    "        \n",
    "    def add(self, new_modules):\n",
    "        self.modules.append(new_modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.modules:\n",
    "            x = module.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "        d_dx = self.loss.backward()  \n",
    "        for module in reversed(self.modules):\n",
    "            d_dx = module.backward(d_dx)\n",
    "        self.param()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for module in self.modules:\n",
    "            module.zero_grad()\n",
    "\n",
    "    def param(self):\n",
    "        self.params = []\n",
    "        for module in self.modules:\n",
    "            if(module.params):\n",
    "                self.params.append(module.param())\n",
    "                \n",
    "    def reset_params(self):\n",
    "        for module in self.modules:\n",
    "            module.reset_params()\n",
    "                \n",
    "            \n",
    "class LeakyReLU(Module):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x*((x>0).type(torch.FloatTensor)+self.alpha*(x<0).type(torch.FloatTensor))\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx*((self.x>0).type(torch.FloatTensor)+self.alpha*(self.x<0).type(torch.FloatTensor))\n",
    "        \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x*(x>0).type(torch.FloatTensor)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx*(self.x>0).type(torch.FloatTensor)\n",
    "        \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "    \n",
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return 0.5*(1+x.tanh())\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return 0.5*d_dx*(1-torch.tanh(self.x)**2)\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "class Sigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx * (torch.sigmoid(self.x*(1-torch.sigmoid(self.x))))\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "    \n",
    "class LossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        return torch.dist(y,t,p=2)\n",
    "    \n",
    "    def backward(self):\n",
    "        return 2*(self.y-self.t)\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "    \n",
    "\n",
    "class LossBCE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, y_pred, t):\n",
    "        self.t = t\n",
    "        self.y_pred = y_pred\n",
    "        true_target, true_index = torch.max(t.view(1,-1),1)\n",
    "        y_true = y_pred[true_index]\n",
    "        y_false = y_pred[1-true_index]\n",
    "        self.true_target = true_target\n",
    "        \n",
    "        self.y_true = y_true\n",
    "        self.y_false = y_false\n",
    "        # old way to do it\n",
    "        L_true = -torch.log(y_true)\n",
    "        L_false = -torch.log(1-y_false)\n",
    "        L = torch.cat((L_true,L_false),0)\n",
    "        #L = - (true_target*torch.log(y_pred) + (1-true_target)*torch.log(1-y_pred))\n",
    "        return torch.mean(L)\n",
    "    \n",
    "    def backward(self):\n",
    "        # old way\n",
    "        dL_true = -1/self.y_true\n",
    "        dL_false = -1/self.y_false\n",
    "        dL = torch.cat((dL_true,dL_false),0)\n",
    "        dL = -(self.true_target*1/self.y_pred + (1-self.true_target)*1/(1-self.y_pred))\n",
    "        return torch.mean(dL)\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:  0.5108255743980408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.0833333134651184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = LossBCE()\n",
    "x = Tensor([0.4, 0.6])\n",
    "t = Tensor([0,1])\n",
    "\"\"\"x = Tensor([[-1, -3, 4], [-3,3,-1]])\n",
    "t = torch.LongTensor([0,1])\"\"\"\n",
    "print('LOSS: ',loss.forward(x,t))\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lin1 = Linear(2,25)\n",
    "Lin2 = Linear(25,25)\n",
    "Lin3 = Linear(25,2)\n",
    "act1 = ReLU()\n",
    "act2 = ReLU()\n",
    "act3 = Tanh()\n",
    "act4 = Sigmoid()\n",
    "layers = [\n",
    "    Lin1,\n",
    "    act1,\n",
    "    Lin2,\n",
    "    act2,\n",
    "    Lin3,\n",
    "    act3,\n",
    "    act4]\n",
    "#loss = LossBCE()\n",
    "loss = LossMSE()\n",
    "model = Sequential(layers, loss)\n",
    "#optim = SGDOptimizer(model, 0.002)\n",
    "\n",
    "optim = BFGSOptimizer(model, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0\n",
      "\n",
      "Training accuracy :  0.549\n",
      "\n",
      "Training loss :  103.1509017944336\n",
      "\n",
      " Epoch 1\n",
      "\n",
      "Training accuracy :  0.59\n",
      "\n",
      "Training loss :  102.47934246063232\n",
      "\n",
      " Epoch 2\n",
      "\n",
      "Training accuracy :  0.654\n",
      "\n",
      "Training loss :  101.51071214675903\n",
      "\n",
      " Epoch 3\n",
      "\n",
      "Training accuracy :  0.712\n",
      "\n",
      "Training loss :  100.07044792175293\n",
      "\n",
      " Epoch 4\n",
      "\n",
      "Training accuracy :  0.717\n",
      "\n",
      "Training loss :  97.2277045249939\n",
      "\n",
      " Epoch 5\n",
      "\n",
      "Training accuracy :  0.692\n",
      "\n",
      "Training loss :  95.32110548019409\n",
      "\n",
      " Epoch 6\n",
      "\n",
      "Training accuracy :  0.691\n",
      "\n",
      "Training loss :  94.90163326263428\n",
      "\n",
      " Epoch 7\n",
      "\n",
      "Training accuracy :  0.692\n",
      "\n",
      "Training loss :  94.39208745956421\n",
      "\n",
      " Epoch 8\n",
      "\n",
      "Training accuracy :  0.695\n",
      "\n",
      "Training loss :  93.81578779220581\n",
      "\n",
      " Epoch 9\n",
      "\n",
      "Training accuracy :  0.703\n",
      "\n",
      "Training loss :  93.34569644927979\n",
      "\n",
      " Epoch 10\n",
      "\n",
      "Training accuracy :  0.711\n",
      "\n",
      "Training loss :  92.94626188278198\n",
      "\n",
      " Epoch 11\n",
      "\n",
      "Training accuracy :  0.734\n",
      "\n",
      "Training loss :  92.27664518356323\n",
      "\n",
      " Epoch 12\n",
      "\n",
      "Training accuracy :  0.76\n",
      "\n",
      "Training loss :  91.4561939239502\n",
      "\n",
      " Epoch 13\n",
      "\n",
      "Training accuracy :  0.765\n",
      "\n",
      "Training loss :  91.04231929779053\n",
      "\n",
      " Epoch 14\n",
      "\n",
      "Training accuracy :  0.768\n",
      "\n",
      "Training loss :  90.82199573516846\n",
      "\n",
      " Epoch 15\n",
      "\n",
      "Training accuracy :  0.769\n",
      "\n",
      "Training loss :  90.66663455963135\n",
      "\n",
      " Epoch 16\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  90.53863286972046\n",
      "\n",
      " Epoch 17\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  90.40907430648804\n",
      "\n",
      " Epoch 18\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  90.27505826950073\n",
      "\n",
      " Epoch 19\n",
      "\n",
      "Training accuracy :  0.769\n",
      "\n",
      "Training loss :  90.16028928756714\n",
      "\n",
      " Epoch 20\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  90.06260538101196\n",
      "\n",
      " Epoch 21\n",
      "\n",
      "Training accuracy :  0.771\n",
      "\n",
      "Training loss :  89.98387384414673\n",
      "\n",
      " Epoch 22\n",
      "\n",
      "Training accuracy :  0.774\n",
      "\n",
      "Training loss :  89.91253328323364\n",
      "\n",
      " Epoch 23\n",
      "\n",
      "Training accuracy :  0.775\n",
      "\n",
      "Training loss :  89.85067129135132\n",
      "\n",
      " Epoch 24\n",
      "\n",
      "Training accuracy :  0.772\n",
      "\n",
      "Training loss :  89.79389905929565\n",
      "\n",
      " Epoch 25\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.75129556655884\n",
      "\n",
      " Epoch 26\n",
      "\n",
      "Training accuracy :  0.774\n",
      "\n",
      "Training loss :  89.70759439468384\n",
      "\n",
      " Epoch 27\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.66365480422974\n",
      "\n",
      " Epoch 28\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.62268018722534\n",
      "\n",
      " Epoch 29\n",
      "\n",
      "Training accuracy :  0.772\n",
      "\n",
      "Training loss :  89.57513809204102\n",
      "\n",
      " Epoch 30\n",
      "\n",
      "Training accuracy :  0.771\n",
      "\n",
      "Training loss :  89.5181336402893\n",
      "\n",
      " Epoch 31\n",
      "\n",
      "Training accuracy :  0.769\n",
      "\n",
      "Training loss :  89.45954847335815\n",
      "\n",
      " Epoch 32\n",
      "\n",
      "Training accuracy :  0.771\n",
      "\n",
      "Training loss :  89.40977764129639\n",
      "\n",
      " Epoch 33\n",
      "\n",
      "Training accuracy :  0.772\n",
      "\n",
      "Training loss :  89.37205219268799\n",
      "\n",
      " Epoch 34\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.32594680786133\n",
      "\n",
      " Epoch 35\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.28981447219849\n",
      "\n",
      " Epoch 36\n",
      "\n",
      "Training accuracy :  0.771\n",
      "\n",
      "Training loss :  89.25499439239502\n",
      "\n",
      " Epoch 37\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  89.22190523147583\n",
      "\n",
      " Epoch 38\n",
      "\n",
      "Training accuracy :  0.77\n",
      "\n",
      "Training loss :  89.19113636016846\n",
      "\n",
      " Epoch 39\n",
      "\n",
      "Training accuracy :  0.771\n",
      "\n",
      "Training loss :  89.16332674026489\n",
      "\n",
      " Epoch 40\n",
      "\n",
      "Training accuracy :  0.772\n",
      "\n",
      "Training loss :  89.1394476890564\n",
      "\n",
      " Epoch 41\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.1168155670166\n",
      "\n",
      " Epoch 42\n",
      "\n",
      "Training accuracy :  0.773\n",
      "\n",
      "Training loss :  89.09245824813843\n",
      "\n",
      " Epoch 43\n",
      "\n",
      "Training accuracy :  0.775\n",
      "\n",
      "Training loss :  89.06755638122559\n",
      "\n",
      " Epoch 44\n",
      "\n",
      "Training accuracy :  0.778\n",
      "\n",
      "Training loss :  89.04316902160645\n",
      "\n",
      " Epoch 45\n",
      "\n",
      "Training accuracy :  0.778\n",
      "\n",
      "Training loss :  89.01610851287842\n",
      "\n",
      " Epoch 46\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.99296379089355\n",
      "\n",
      " Epoch 47\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.96792316436768\n",
      "\n",
      " Epoch 48\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.94238233566284\n",
      "\n",
      " Epoch 49\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.91326761245728\n",
      "\n",
      " Epoch 50\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.87951421737671\n",
      "\n",
      " Epoch 51\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.84489679336548\n",
      "\n",
      " Epoch 52\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.81414842605591\n",
      "\n",
      " Epoch 53\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.78521394729614\n",
      "\n",
      " Epoch 54\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.75939607620239\n",
      "\n",
      " Epoch 55\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.74078178405762\n",
      "\n",
      " Epoch 56\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.72331428527832\n",
      "\n",
      " Epoch 57\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.70846271514893\n",
      "\n",
      " Epoch 58\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.69536399841309\n",
      "\n",
      " Epoch 59\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.6807370185852\n",
      "\n",
      " Epoch 60\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.66674518585205\n",
      "\n",
      " Epoch 61\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.6529541015625\n",
      "\n",
      " Epoch 62\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.6438455581665\n",
      "\n",
      " Epoch 63\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.63667488098145\n",
      "\n",
      " Epoch 64\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.62902593612671\n",
      "\n",
      " Epoch 65\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.61974287033081\n",
      "\n",
      " Epoch 66\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.61243677139282\n",
      "\n",
      " Epoch 67\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.60469007492065\n",
      "\n",
      " Epoch 68\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.59417581558228\n",
      "\n",
      " Epoch 69\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.58655595779419\n",
      "\n",
      " Epoch 70\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.5788106918335\n",
      "\n",
      " Epoch 71\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.57128190994263\n",
      "\n",
      " Epoch 72\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.5634913444519\n",
      "\n",
      " Epoch 73\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.55694389343262\n",
      "\n",
      " Epoch 74\n",
      "\n",
      "Training accuracy :  0.779\n",
      "\n",
      "Training loss :  88.55084085464478\n",
      "\n",
      " Epoch 75\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.5439567565918\n",
      "\n",
      " Epoch 76\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.53663349151611\n",
      "\n",
      " Epoch 77\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.53026294708252\n",
      "\n",
      " Epoch 78\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.52128219604492\n",
      "\n",
      " Epoch 79\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.5115327835083\n",
      "\n",
      " Epoch 80\n",
      "\n",
      "Training accuracy :  0.784\n",
      "\n",
      "Training loss :  88.50525140762329\n",
      "\n",
      " Epoch 81\n",
      "\n",
      "Training accuracy :  0.786\n",
      "\n",
      "Training loss :  88.49819469451904\n",
      "\n",
      " Epoch 82\n",
      "\n",
      "Training accuracy :  0.785\n",
      "\n",
      "Training loss :  88.48982381820679\n",
      "\n",
      " Epoch 83\n",
      "\n",
      "Training accuracy :  0.785\n",
      "\n",
      "Training loss :  88.4816484451294\n",
      "\n",
      " Epoch 84\n",
      "\n",
      "Training accuracy :  0.785\n",
      "\n",
      "Training loss :  88.47498559951782\n",
      "\n",
      " Epoch 85\n",
      "\n",
      "Training accuracy :  0.785\n",
      "\n",
      "Training loss :  88.46664190292358\n",
      "\n",
      " Epoch 86\n",
      "\n",
      "Training accuracy :  0.784\n",
      "\n",
      "Training loss :  88.45859050750732\n",
      "\n",
      " Epoch 87\n",
      "\n",
      "Training accuracy :  0.784\n",
      "\n",
      "Training loss :  88.45297718048096\n",
      "\n",
      " Epoch 88\n",
      "\n",
      "Training accuracy :  0.784\n",
      "\n",
      "Training loss :  88.44316911697388\n",
      "\n",
      " Epoch 89\n",
      "\n",
      "Training accuracy :  0.783\n",
      "\n",
      "Training loss :  88.43273305892944\n",
      "\n",
      " Epoch 90\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.42288064956665\n",
      "\n",
      " Epoch 91\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.40963459014893\n",
      "\n",
      " Epoch 92\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.39810800552368\n",
      "\n",
      " Epoch 93\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.38942623138428\n",
      "\n",
      " Epoch 94\n",
      "\n",
      "Training accuracy :  0.783\n",
      "\n",
      "Training loss :  88.37693548202515\n",
      "\n",
      " Epoch 95\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.36794948577881\n",
      "\n",
      " Epoch 96\n",
      "\n",
      "Training accuracy :  0.78\n",
      "\n",
      "Training loss :  88.35129833221436\n",
      "\n",
      " Epoch 97\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.3391523361206\n",
      "\n",
      " Epoch 98\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.3260269165039\n",
      "\n",
      " Epoch 99\n",
      "\n",
      "Training accuracy :  0.781\n",
      "\n",
      "Training loss :  88.31195163726807\n",
      "\n",
      " Epoch 100\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.29601812362671\n",
      "\n",
      " Epoch 101\n",
      "\n",
      "Training accuracy :  0.782\n",
      "\n",
      "Training loss :  88.28086709976196\n",
      "\n",
      " Epoch 102\n",
      "\n",
      "Training accuracy :  0.783\n",
      "\n",
      "Training loss :  88.26259803771973\n",
      "\n",
      " Epoch 103\n",
      "\n",
      "Training accuracy :  0.784\n",
      "\n",
      "Training loss :  88.24675750732422\n",
      "\n",
      " Epoch 104\n",
      "\n",
      "Training accuracy :  0.786\n",
      "\n",
      "Training loss :  88.22573852539062\n",
      "\n",
      " Epoch 105\n",
      "\n",
      "Training accuracy :  0.785\n",
      "\n",
      "Training loss :  88.20317316055298\n",
      "\n",
      " Epoch 106\n",
      "\n",
      "Training accuracy :  0.787\n",
      "\n",
      "Training loss :  88.18081760406494\n",
      "\n",
      " Epoch 107\n",
      "\n",
      "Training accuracy :  0.789\n",
      "\n",
      "Training loss :  88.15101909637451\n",
      "\n",
      " Epoch 108\n",
      "\n",
      "Training accuracy :  0.79\n",
      "\n",
      "Training loss :  88.12313175201416\n",
      "\n",
      " Epoch 109\n",
      "\n",
      "Training accuracy :  0.792\n",
      "\n",
      "Training loss :  88.09786319732666\n",
      "\n",
      " Epoch 110\n",
      "\n",
      "Training accuracy :  0.795\n",
      "\n",
      "Training loss :  88.07015132904053\n",
      "\n",
      " Epoch 111\n",
      "\n",
      "Training accuracy :  0.796\n",
      "\n",
      "Training loss :  88.04564714431763\n",
      "\n",
      " Epoch 112\n",
      "\n",
      "Training accuracy :  0.793\n",
      "\n",
      "Training loss :  88.02375841140747\n",
      "\n",
      " Epoch 113\n",
      "\n",
      "Training accuracy :  0.792\n",
      "\n",
      "Training loss :  87.99731922149658\n",
      "\n",
      " Epoch 114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.796\n",
      "\n",
      "Training loss :  87.96556091308594\n",
      "\n",
      " Epoch 115\n",
      "\n",
      "Training accuracy :  0.798\n",
      "\n",
      "Training loss :  87.93334770202637\n",
      "\n",
      " Epoch 116\n",
      "\n",
      "Training accuracy :  0.799\n",
      "\n",
      "Training loss :  87.89594316482544\n",
      "\n",
      " Epoch 117\n",
      "\n",
      "Training accuracy :  0.801\n",
      "\n",
      "Training loss :  87.86693096160889\n",
      "\n",
      " Epoch 118\n",
      "\n",
      "Training accuracy :  0.801\n",
      "\n",
      "Training loss :  87.84159898757935\n",
      "\n",
      " Epoch 119\n",
      "\n",
      "Training accuracy :  0.802\n",
      "\n",
      "Training loss :  87.81782960891724\n",
      "\n",
      " Epoch 120\n",
      "\n",
      "Training accuracy :  0.804\n",
      "\n",
      "Training loss :  87.7973370552063\n",
      "\n",
      " Epoch 121\n",
      "\n",
      "Training accuracy :  0.805\n",
      "\n",
      "Training loss :  87.7770094871521\n",
      "\n",
      " Epoch 122\n",
      "\n",
      "Training accuracy :  0.806\n",
      "\n",
      "Training loss :  87.75857591629028\n",
      "\n",
      " Epoch 123\n",
      "\n",
      "Training accuracy :  0.806\n",
      "\n",
      "Training loss :  87.74136447906494\n",
      "\n",
      " Epoch 124\n",
      "\n",
      "Training accuracy :  0.808\n",
      "\n",
      "Training loss :  87.72089099884033\n",
      "\n",
      " Epoch 125\n",
      "\n",
      "Training accuracy :  0.81\n",
      "\n",
      "Training loss :  87.70318460464478\n",
      "\n",
      " Epoch 126\n",
      "\n",
      "Training accuracy :  0.811\n",
      "\n",
      "Training loss :  87.68473672866821\n",
      "\n",
      " Epoch 127\n",
      "\n",
      "Training accuracy :  0.812\n",
      "\n",
      "Training loss :  87.66563129425049\n",
      "\n",
      " Epoch 128\n",
      "\n",
      "Training accuracy :  0.813\n",
      "\n",
      "Training loss :  87.64796018600464\n",
      "\n",
      " Epoch 129\n",
      "\n",
      "Training accuracy :  0.814\n",
      "\n",
      "Training loss :  87.6254529953003\n",
      "\n",
      " Epoch 130\n",
      "\n",
      "Training accuracy :  0.815\n",
      "\n",
      "Training loss :  87.60256576538086\n",
      "\n",
      " Epoch 131\n",
      "\n",
      "Training accuracy :  0.817\n",
      "\n",
      "Training loss :  87.58627510070801\n",
      "\n",
      " Epoch 132\n",
      "\n",
      "Training accuracy :  0.822\n",
      "\n",
      "Training loss :  87.5669150352478\n",
      "\n",
      " Epoch 133\n",
      "\n",
      "Training accuracy :  0.833\n",
      "\n",
      "Training loss :  87.54726314544678\n",
      "\n",
      " Epoch 134\n",
      "\n",
      "Training accuracy :  0.843\n",
      "\n",
      "Training loss :  87.53249454498291\n",
      "\n",
      " Epoch 135\n",
      "\n",
      "Training accuracy :  0.868\n",
      "\n",
      "Training loss :  87.48921966552734\n",
      "\n",
      " Epoch 136\n",
      "\n",
      "Training accuracy :  0.882\n",
      "\n",
      "Training loss :  87.10057783126831\n",
      "\n",
      " Epoch 137\n",
      "\n",
      "Training accuracy :  0.891\n",
      "\n",
      "Training loss :  86.70575952529907\n",
      "\n",
      " Epoch 138\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  86.49199342727661\n",
      "\n",
      " Epoch 139\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  86.23731565475464\n",
      "\n",
      " Epoch 140\n",
      "\n",
      "Training accuracy :  0.885\n",
      "\n",
      "Training loss :  86.06151342391968\n",
      "\n",
      " Epoch 141\n",
      "\n",
      "Training accuracy :  0.882\n",
      "\n",
      "Training loss :  85.95213222503662\n",
      "\n",
      " Epoch 142\n",
      "\n",
      "Training accuracy :  0.882\n",
      "\n",
      "Training loss :  85.87428760528564\n",
      "\n",
      " Epoch 143\n",
      "\n",
      "Training accuracy :  0.883\n",
      "\n",
      "Training loss :  85.80879640579224\n",
      "\n",
      " Epoch 144\n",
      "\n",
      "Training accuracy :  0.884\n",
      "\n",
      "Training loss :  85.74515867233276\n",
      "\n",
      " Epoch 145\n",
      "\n",
      "Training accuracy :  0.885\n",
      "\n",
      "Training loss :  85.69065189361572\n",
      "\n",
      " Epoch 146\n",
      "\n",
      "Training accuracy :  0.886\n",
      "\n",
      "Training loss :  85.64081335067749\n",
      "\n",
      " Epoch 147\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.59555721282959\n",
      "\n",
      " Epoch 148\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.55709552764893\n",
      "\n",
      " Epoch 149\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.5235948562622\n",
      "\n",
      " Epoch 150\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.50151205062866\n",
      "\n",
      " Epoch 151\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.47292470932007\n",
      "\n",
      " Epoch 152\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.44733238220215\n",
      "\n",
      " Epoch 153\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.42114877700806\n",
      "\n",
      " Epoch 154\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.3998212814331\n",
      "\n",
      " Epoch 155\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.37003469467163\n",
      "\n",
      " Epoch 156\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.35346937179565\n",
      "\n",
      " Epoch 157\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.33737134933472\n",
      "\n",
      " Epoch 158\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.32378673553467\n",
      "\n",
      " Epoch 159\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.3101863861084\n",
      "\n",
      " Epoch 160\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.29835844039917\n",
      "\n",
      " Epoch 161\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.28371620178223\n",
      "\n",
      " Epoch 162\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.27299928665161\n",
      "\n",
      " Epoch 163\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.25857591629028\n",
      "\n",
      " Epoch 164\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.24763584136963\n",
      "\n",
      " Epoch 165\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.23664045333862\n",
      "\n",
      " Epoch 166\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.22577476501465\n",
      "\n",
      " Epoch 167\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.2142071723938\n",
      "\n",
      " Epoch 168\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.20415592193604\n",
      "\n",
      " Epoch 169\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.19299840927124\n",
      "\n",
      " Epoch 170\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.18373155593872\n",
      "\n",
      " Epoch 171\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.17600154876709\n",
      "\n",
      " Epoch 172\n",
      "\n",
      "Training accuracy :  0.886\n",
      "\n",
      "Training loss :  85.1679515838623\n",
      "\n",
      " Epoch 173\n",
      "\n",
      "Training accuracy :  0.887\n",
      "\n",
      "Training loss :  85.1583800315857\n",
      "\n",
      " Epoch 174\n",
      "\n",
      "Training accuracy :  0.887\n",
      "\n",
      "Training loss :  85.1517243385315\n",
      "\n",
      " Epoch 175\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.14636898040771\n",
      "\n",
      " Epoch 176\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.1384129524231\n",
      "\n",
      " Epoch 177\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.1329870223999\n",
      "\n",
      " Epoch 178\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.12780809402466\n",
      "\n",
      " Epoch 179\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.12156629562378\n",
      "\n",
      " Epoch 180\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.11674547195435\n",
      "\n",
      " Epoch 181\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.11204528808594\n",
      "\n",
      " Epoch 182\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.10573482513428\n",
      "\n",
      " Epoch 183\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.10040521621704\n",
      "\n",
      " Epoch 184\n",
      "\n",
      "Training accuracy :  0.891\n",
      "\n",
      "Training loss :  85.09517192840576\n",
      "\n",
      " Epoch 185\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.09366416931152\n",
      "\n",
      " Epoch 186\n",
      "\n",
      "Training accuracy :  0.891\n",
      "\n",
      "Training loss :  85.08478355407715\n",
      "\n",
      " Epoch 187\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.08398199081421\n",
      "\n",
      " Epoch 188\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.07628107070923\n",
      "\n",
      " Epoch 189\n",
      "\n",
      "Training accuracy :  0.887\n",
      "\n",
      "Training loss :  85.07573890686035\n",
      "\n",
      " Epoch 190\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.06799697875977\n",
      "\n",
      " Epoch 191\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.06748676300049\n",
      "\n",
      " Epoch 192\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.0655665397644\n",
      "\n",
      " Epoch 193\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.05931234359741\n",
      "\n",
      " Epoch 194\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.05713987350464\n",
      "\n",
      " Epoch 195\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.05276918411255\n",
      "\n",
      " Epoch 196\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.05078554153442\n",
      "\n",
      " Epoch 197\n",
      "\n",
      "Training accuracy :  0.889\n",
      "\n",
      "Training loss :  85.04535818099976\n",
      "\n",
      " Epoch 198\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.04338073730469\n",
      "\n",
      " Epoch 199\n",
      "\n",
      "Training accuracy :  0.89\n",
      "\n",
      "Training loss :  85.0385913848877\n",
      "\n",
      " Epoch 200\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  85.035728931427\n",
      "\n",
      " Epoch 201\n",
      "\n",
      "Training accuracy :  0.891\n",
      "\n",
      "Training loss :  85.03097867965698\n",
      "\n",
      " Epoch 202\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  85.02925205230713\n",
      "\n",
      " Epoch 203\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.02476501464844\n",
      "\n",
      " Epoch 204\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.0217113494873\n",
      "\n",
      " Epoch 205\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.01765489578247\n",
      "\n",
      " Epoch 206\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.01434898376465\n",
      "\n",
      " Epoch 207\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.00989007949829\n",
      "\n",
      " Epoch 208\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.00634336471558\n",
      "\n",
      " Epoch 209\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  85.00205755233765\n",
      "\n",
      " Epoch 210\n",
      "\n",
      "Training accuracy :  0.892\n",
      "\n",
      "Training loss :  84.99816226959229\n",
      "\n",
      " Epoch 211\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  84.99649381637573\n",
      "\n",
      " Epoch 212\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  84.99280023574829\n",
      "\n",
      " Epoch 213\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  84.98980808258057\n",
      "\n",
      " Epoch 214\n",
      "\n",
      "Training accuracy :  0.895\n",
      "\n",
      "Training loss :  84.98690509796143\n",
      "\n",
      " Epoch 215\n",
      "\n",
      "Training accuracy :  0.895\n",
      "\n",
      "Training loss :  84.98278379440308\n",
      "\n",
      " Epoch 216\n",
      "\n",
      "Training accuracy :  0.896\n",
      "\n",
      "Training loss :  84.98075866699219\n",
      "\n",
      " Epoch 217\n",
      "\n",
      "Training accuracy :  0.896\n",
      "\n",
      "Training loss :  84.97743225097656\n",
      "\n",
      " Epoch 218\n",
      "\n",
      "Training accuracy :  0.895\n",
      "\n",
      "Training loss :  84.9711709022522\n",
      "\n",
      " Epoch 219\n",
      "\n",
      "Training accuracy :  0.896\n",
      "\n",
      "Training loss :  84.96914577484131\n",
      "\n",
      " Epoch 220\n",
      "\n",
      "Training accuracy :  0.896\n",
      "\n",
      "Training loss :  84.96362733840942\n",
      "\n",
      " Epoch 221\n",
      "\n",
      "Training accuracy :  0.897\n",
      "\n",
      "Training loss :  84.96190881729126\n",
      "\n",
      " Epoch 222\n",
      "\n",
      "Training accuracy :  0.897\n",
      "\n",
      "Training loss :  84.95917987823486\n",
      "\n",
      " Epoch 223\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.95371580123901\n",
      "\n",
      " Epoch 224\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.95029020309448\n",
      "\n",
      " Epoch 225\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.94816541671753\n",
      "\n",
      " Epoch 226\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.94488334655762\n",
      "\n",
      " Epoch 227\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.94195365905762\n",
      "\n",
      " Epoch 228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.93887281417847\n",
      "\n",
      " Epoch 229\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.93584394454956\n",
      "\n",
      " Epoch 230\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.93233489990234\n",
      "\n",
      " Epoch 231\n",
      "\n",
      "Training accuracy :  0.898\n",
      "\n",
      "Training loss :  84.92886114120483\n",
      "\n",
      " Epoch 232\n",
      "\n",
      "Training accuracy :  0.899\n",
      "\n",
      "Training loss :  84.92623376846313\n",
      "\n",
      " Epoch 233\n",
      "\n",
      "Training accuracy :  0.9\n",
      "\n",
      "Training loss :  84.92389583587646\n",
      "\n",
      " Epoch 234\n",
      "\n",
      "Training accuracy :  0.903\n",
      "\n",
      "Training loss :  84.91898012161255\n",
      "\n",
      " Epoch 235\n",
      "\n",
      "Training accuracy :  0.903\n",
      "\n",
      "Training loss :  84.91816520690918\n",
      "\n",
      " Epoch 236\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.91238784790039\n",
      "\n",
      " Epoch 237\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.90876293182373\n",
      "\n",
      " Epoch 238\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.90524673461914\n",
      "\n",
      " Epoch 239\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.90262699127197\n",
      "\n",
      " Epoch 240\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.89808702468872\n",
      "\n",
      " Epoch 241\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.8961591720581\n",
      "\n",
      " Epoch 242\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.89076328277588\n",
      "\n",
      " Epoch 243\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.88671064376831\n",
      "\n",
      " Epoch 244\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.88146495819092\n",
      "\n",
      " Epoch 245\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.87592029571533\n",
      "\n",
      " Epoch 246\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.87347269058228\n",
      "\n",
      " Epoch 247\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.86746978759766\n",
      "\n",
      " Epoch 248\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.86382961273193\n",
      "\n",
      " Epoch 249\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.86111688613892\n",
      "\n",
      " Epoch 250\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.85602569580078\n",
      "\n",
      " Epoch 251\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.85379314422607\n",
      "\n",
      " Epoch 252\n",
      "\n",
      "Training accuracy :  0.903\n",
      "\n",
      "Training loss :  84.84889459609985\n",
      "\n",
      " Epoch 253\n",
      "\n",
      "Training accuracy :  0.903\n",
      "\n",
      "Training loss :  84.84520435333252\n",
      "\n",
      " Epoch 254\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.84126043319702\n",
      "\n",
      " Epoch 255\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.83761882781982\n",
      "\n",
      " Epoch 256\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.83488607406616\n",
      "\n",
      " Epoch 257\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.83126735687256\n",
      "\n",
      " Epoch 258\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.82793092727661\n",
      "\n",
      " Epoch 259\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.82485437393188\n",
      "\n",
      " Epoch 260\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.82265901565552\n",
      "\n",
      " Epoch 261\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.8193416595459\n",
      "\n",
      " Epoch 262\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  84.81381511688232\n",
      "\n",
      " Epoch 263\n",
      "\n",
      "Training accuracy :  0.905\n",
      "\n",
      "Training loss :  84.80842065811157\n",
      "\n",
      " Epoch 264\n",
      "\n",
      "Training accuracy :  0.905\n",
      "\n",
      "Training loss :  84.80204629898071\n",
      "\n",
      " Epoch 265\n",
      "\n",
      "Training accuracy :  0.908\n",
      "\n",
      "Training loss :  84.79351043701172\n",
      "\n",
      " Epoch 266\n",
      "\n",
      "Training accuracy :  0.908\n",
      "\n",
      "Training loss :  84.78532695770264\n",
      "\n",
      " Epoch 267\n",
      "\n",
      "Training accuracy :  0.908\n",
      "\n",
      "Training loss :  84.77746963500977\n",
      "\n",
      " Epoch 268\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.770348072052\n",
      "\n",
      " Epoch 269\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.76452779769897\n",
      "\n",
      " Epoch 270\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.7594256401062\n",
      "\n",
      " Epoch 271\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.75419998168945\n",
      "\n",
      " Epoch 272\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.75038766860962\n",
      "\n",
      " Epoch 273\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.74433708190918\n",
      "\n",
      " Epoch 274\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.73946332931519\n",
      "\n",
      " Epoch 275\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.73508310317993\n",
      "\n",
      " Epoch 276\n",
      "\n",
      "Training accuracy :  0.909\n",
      "\n",
      "Training loss :  84.73265886306763\n",
      "\n",
      " Epoch 277\n",
      "\n",
      "Training accuracy :  0.91\n",
      "\n",
      "Training loss :  84.72741651535034\n",
      "\n",
      " Epoch 278\n",
      "\n",
      "Training accuracy :  0.91\n",
      "\n",
      "Training loss :  84.72513246536255\n",
      "\n",
      " Epoch 279\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.72166347503662\n",
      "\n",
      " Epoch 280\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.71763324737549\n",
      "\n",
      " Epoch 281\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.71421957015991\n",
      "\n",
      " Epoch 282\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.71013975143433\n",
      "\n",
      " Epoch 283\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.70593976974487\n",
      "\n",
      " Epoch 284\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.70164728164673\n",
      "\n",
      " Epoch 285\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.70130586624146\n",
      "\n",
      " Epoch 286\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.69765949249268\n",
      "\n",
      " Epoch 287\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.69367837905884\n",
      "\n",
      " Epoch 288\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.69020652770996\n",
      "\n",
      " Epoch 289\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.685546875\n",
      "\n",
      " Epoch 290\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.67956781387329\n",
      "\n",
      " Epoch 291\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.6748251914978\n",
      "\n",
      " Epoch 292\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.66920280456543\n",
      "\n",
      " Epoch 293\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.66174268722534\n",
      "\n",
      " Epoch 294\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.65770673751831\n",
      "\n",
      " Epoch 295\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.65429544448853\n",
      "\n",
      " Epoch 296\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.64913415908813\n",
      "\n",
      " Epoch 297\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.64437818527222\n",
      "\n",
      " Epoch 298\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.64044284820557\n",
      "\n",
      " Epoch 299\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.63776969909668\n",
      "\n",
      " Epoch 300\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.63320922851562\n",
      "\n",
      " Epoch 301\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.62888717651367\n",
      "\n",
      " Epoch 302\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.62586116790771\n",
      "\n",
      " Epoch 303\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.62331533432007\n",
      "\n",
      " Epoch 304\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.6213846206665\n",
      "\n",
      " Epoch 305\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.61812400817871\n",
      "\n",
      " Epoch 306\n",
      "\n",
      "Training accuracy :  0.91\n",
      "\n",
      "Training loss :  84.61545324325562\n",
      "\n",
      " Epoch 307\n",
      "\n",
      "Training accuracy :  0.91\n",
      "\n",
      "Training loss :  84.61370468139648\n",
      "\n",
      " Epoch 308\n",
      "\n",
      "Training accuracy :  0.91\n",
      "\n",
      "Training loss :  84.6116418838501\n",
      "\n",
      " Epoch 309\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.6100025177002\n",
      "\n",
      " Epoch 310\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.6081428527832\n",
      "\n",
      " Epoch 311\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.60598802566528\n",
      "\n",
      " Epoch 312\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.6044397354126\n",
      "\n",
      " Epoch 313\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.60267496109009\n",
      "\n",
      " Epoch 314\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.60053730010986\n",
      "\n",
      " Epoch 315\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.5986762046814\n",
      "\n",
      " Epoch 316\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.59683799743652\n",
      "\n",
      " Epoch 317\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.59479761123657\n",
      "\n",
      " Epoch 318\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.59318971633911\n",
      "\n",
      " Epoch 319\n",
      "\n",
      "Training accuracy :  0.911\n",
      "\n",
      "Training loss :  84.59205913543701\n",
      "\n",
      " Epoch 320\n",
      "\n",
      "Training accuracy :  0.912\n",
      "\n",
      "Training loss :  84.58987236022949\n",
      "\n",
      " Epoch 321\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  84.58803510665894\n",
      "\n",
      " Epoch 322\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.5865044593811\n",
      "\n",
      " Epoch 323\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.58466386795044\n",
      "\n",
      " Epoch 324\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.58311796188354\n",
      "\n",
      " Epoch 325\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.58147811889648\n",
      "\n",
      " Epoch 326\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.57967376708984\n",
      "\n",
      " Epoch 327\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.57866477966309\n",
      "\n",
      " Epoch 328\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.57708930969238\n",
      "\n",
      " Epoch 329\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.57583999633789\n",
      "\n",
      " Epoch 330\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.57510805130005\n",
      "\n",
      " Epoch 331\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.57389259338379\n",
      "\n",
      " Epoch 332\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.57206678390503\n",
      "\n",
      " Epoch 333\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.56978464126587\n",
      "\n",
      " Epoch 334\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.56828117370605\n",
      "\n",
      " Epoch 335\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.56667280197144\n",
      "\n",
      " Epoch 336\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.56569385528564\n",
      "\n",
      " Epoch 337\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.56412172317505\n",
      "\n",
      " Epoch 338\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.56264638900757\n",
      "\n",
      " Epoch 339\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.56190204620361\n",
      "\n",
      " Epoch 340\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.56025266647339\n",
      "\n",
      " Epoch 341\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.55961894989014\n",
      "\n",
      " Epoch 342\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.558828830719\n",
      "\n",
      " Epoch 343\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.55680561065674\n",
      "\n",
      " Epoch 344\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.55610466003418\n",
      "\n",
      " Epoch 345\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.5534119606018\n",
      "\n",
      " Epoch 346\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.55090665817261\n",
      "\n",
      " Epoch 347\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.54937553405762\n",
      "\n",
      " Epoch 348\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.549307346344\n",
      "\n",
      " Epoch 349\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.54459190368652\n",
      "\n",
      " Epoch 350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.54200077056885\n",
      "\n",
      " Epoch 351\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.53532886505127\n",
      "\n",
      " Epoch 352\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.53436183929443\n",
      "\n",
      " Epoch 353\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.53296947479248\n",
      "\n",
      " Epoch 354\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.5265326499939\n",
      "\n",
      " Epoch 355\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.52399730682373\n",
      "\n",
      " Epoch 356\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.52043056488037\n",
      "\n",
      " Epoch 357\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.51828384399414\n",
      "\n",
      " Epoch 358\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.5154824256897\n",
      "\n",
      " Epoch 359\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.51217555999756\n",
      "\n",
      " Epoch 360\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.51002168655396\n",
      "\n",
      " Epoch 361\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.50800275802612\n",
      "\n",
      " Epoch 362\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.50572729110718\n",
      "\n",
      " Epoch 363\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.50289011001587\n",
      "\n",
      " Epoch 364\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.50041770935059\n",
      "\n",
      " Epoch 365\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.49806547164917\n",
      "\n",
      " Epoch 366\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.49445247650146\n",
      "\n",
      " Epoch 367\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.49093818664551\n",
      "\n",
      " Epoch 368\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.48730707168579\n",
      "\n",
      " Epoch 369\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.48273658752441\n",
      "\n",
      " Epoch 370\n",
      "\n",
      "Training accuracy :  0.919\n",
      "\n",
      "Training loss :  84.47899961471558\n",
      "\n",
      " Epoch 371\n",
      "\n",
      "Training accuracy :  0.92\n",
      "\n",
      "Training loss :  84.47518539428711\n",
      "\n",
      " Epoch 372\n",
      "\n",
      "Training accuracy :  0.92\n",
      "\n",
      "Training loss :  84.47188663482666\n",
      "\n",
      " Epoch 373\n",
      "\n",
      "Training accuracy :  0.919\n",
      "\n",
      "Training loss :  84.46665954589844\n",
      "\n",
      " Epoch 374\n",
      "\n",
      "Training accuracy :  0.92\n",
      "\n",
      "Training loss :  84.46219873428345\n",
      "\n",
      " Epoch 375\n",
      "\n",
      "Training accuracy :  0.918\n",
      "\n",
      "Training loss :  84.45724630355835\n",
      "\n",
      " Epoch 376\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.45703840255737\n",
      "\n",
      " Epoch 377\n",
      "\n",
      "Training accuracy :  0.918\n",
      "\n",
      "Training loss :  84.44777917861938\n",
      "\n",
      " Epoch 378\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.44716215133667\n",
      "\n",
      " Epoch 379\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.44304275512695\n",
      "\n",
      " Epoch 380\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.43482828140259\n",
      "\n",
      " Epoch 381\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.43693399429321\n",
      "\n",
      " Epoch 382\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.43342399597168\n",
      "\n",
      " Epoch 383\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.42339181900024\n",
      "\n",
      " Epoch 384\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  84.42524766921997\n",
      "\n",
      " Epoch 385\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.42354679107666\n",
      "\n",
      " Epoch 386\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.42051267623901\n",
      "\n",
      " Epoch 387\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.41721248626709\n",
      "\n",
      " Epoch 388\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.41522407531738\n",
      "\n",
      " Epoch 389\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.41330003738403\n",
      "\n",
      " Epoch 390\n",
      "\n",
      "Training accuracy :  0.915\n",
      "\n",
      "Training loss :  84.4115571975708\n",
      "\n",
      " Epoch 391\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  84.40988874435425\n",
      "\n",
      " Epoch 392\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.40822219848633\n",
      "\n",
      " Epoch 393\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.40623378753662\n",
      "\n",
      " Epoch 394\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.40411710739136\n",
      "\n",
      " Epoch 395\n",
      "\n",
      "Training accuracy :  0.918\n",
      "\n",
      "Training loss :  84.40224409103394\n",
      "\n",
      " Epoch 396\n",
      "\n",
      "Training accuracy :  0.919\n",
      "\n",
      "Training loss :  84.4001784324646\n",
      "\n",
      " Epoch 397\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.39839124679565\n",
      "\n",
      " Epoch 398\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.396409034729\n",
      "\n",
      " Epoch 399\n",
      "\n",
      "Training accuracy :  0.917\n",
      "\n",
      "Training loss :  84.39481210708618\n",
      "\n",
      " Epoch 400\n",
      "\n",
      "Training accuracy :  0.918\n",
      "\n",
      "Training loss :  84.39304828643799\n",
      "\n",
      " Epoch 401\n",
      "\n",
      "Training accuracy :  0.92\n",
      "\n",
      "Training loss :  84.39112281799316\n",
      "\n",
      " Epoch 402\n",
      "\n",
      "Training accuracy :  0.922\n",
      "\n",
      "Training loss :  84.38921594619751\n",
      "\n",
      " Epoch 403\n",
      "\n",
      "Training accuracy :  0.923\n",
      "\n",
      "Training loss :  84.38726949691772\n",
      "\n",
      " Epoch 404\n",
      "\n",
      "Training accuracy :  0.925\n",
      "\n",
      "Training loss :  84.38568449020386\n",
      "\n",
      " Epoch 405\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.38416719436646\n",
      "\n",
      " Epoch 406\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.3825011253357\n",
      "\n",
      " Epoch 407\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.38110303878784\n",
      "\n",
      " Epoch 408\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.38034343719482\n",
      "\n",
      " Epoch 409\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.37866258621216\n",
      "\n",
      " Epoch 410\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.37760734558105\n",
      "\n",
      " Epoch 411\n",
      "\n",
      "Training accuracy :  0.926\n",
      "\n",
      "Training loss :  84.37616777420044\n",
      "\n",
      " Epoch 412\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.37626934051514\n",
      "\n",
      " Epoch 413\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.37477588653564\n",
      "\n",
      " Epoch 414\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.3735556602478\n",
      "\n",
      " Epoch 415\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.37235450744629\n",
      "\n",
      " Epoch 416\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.37075185775757\n",
      "\n",
      " Epoch 417\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.37074565887451\n",
      "\n",
      " Epoch 418\n",
      "\n",
      "Training accuracy :  0.927\n",
      "\n",
      "Training loss :  84.36831092834473\n",
      "\n",
      " Epoch 419\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36743211746216\n",
      "\n",
      " Epoch 420\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36656904220581\n",
      "\n",
      " Epoch 421\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36536073684692\n",
      "\n",
      " Epoch 422\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36565971374512\n",
      "\n",
      " Epoch 423\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.364333152771\n",
      "\n",
      " Epoch 424\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36333417892456\n",
      "\n",
      " Epoch 425\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36210060119629\n",
      "\n",
      " Epoch 426\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  84.36125040054321\n",
      "\n",
      " Epoch 427\n",
      "\n",
      "Training accuracy :  0.929\n",
      "\n",
      "Training loss :  84.36015844345093\n",
      "\n",
      " Epoch 428\n",
      "\n",
      "Training accuracy :  0.929\n",
      "\n",
      "Training loss :  84.35859680175781\n",
      "\n",
      " Epoch 429\n",
      "\n",
      "Training accuracy :  0.929\n",
      "\n",
      "Training loss :  84.35871839523315\n",
      "\n",
      " Epoch 430\n",
      "\n",
      "Training accuracy :  0.931\n",
      "\n",
      "Training loss :  84.3579454421997\n",
      "\n",
      " Epoch 431\n",
      "\n",
      "Training accuracy :  0.931\n",
      "\n",
      "Training loss :  84.35672426223755\n",
      "\n",
      " Epoch 432\n",
      "\n",
      "Training accuracy :  0.931\n",
      "\n",
      "Training loss :  84.3557538986206\n",
      "\n",
      " Epoch 433\n",
      "\n",
      "Training accuracy :  0.931\n",
      "\n",
      "Training loss :  84.3546552658081\n",
      "\n",
      " Epoch 434\n",
      "\n",
      "Training accuracy :  0.931\n",
      "\n",
      "Training loss :  84.35315990447998\n",
      "\n",
      " Epoch 435\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.3534803390503\n",
      "\n",
      " Epoch 436\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.35201454162598\n",
      "\n",
      " Epoch 437\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.35095071792603\n",
      "\n",
      " Epoch 438\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.35019493103027\n",
      "\n",
      " Epoch 439\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34922409057617\n",
      "\n",
      " Epoch 440\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34809494018555\n",
      "\n",
      " Epoch 441\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34670209884644\n",
      "\n",
      " Epoch 442\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34671258926392\n",
      "\n",
      " Epoch 443\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.3456621170044\n",
      "\n",
      " Epoch 444\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34490537643433\n",
      "\n",
      " Epoch 445\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34379291534424\n",
      "\n",
      " Epoch 446\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  84.34392786026001\n",
      "\n",
      " Epoch 447\n",
      "\n",
      "Training accuracy :  0.934\n",
      "\n",
      "Training loss :  84.34294843673706\n",
      "\n",
      " Epoch 448\n",
      "\n",
      "Training accuracy :  0.933\n",
      "\n",
      "Training loss :  84.34183120727539\n",
      "\n",
      " Epoch 449\n",
      "\n",
      "Training accuracy :  0.933\n",
      "\n",
      "Training loss :  84.34050464630127\n",
      "\n",
      " Epoch 450\n",
      "\n",
      "Training accuracy :  0.934\n",
      "\n",
      "Training loss :  84.34055948257446\n",
      "\n",
      " Epoch 451\n",
      "\n",
      "Training accuracy :  0.934\n",
      "\n",
      "Training loss :  84.34012174606323\n",
      "\n",
      " Epoch 452\n",
      "\n",
      "Training accuracy :  0.934\n",
      "\n",
      "Training loss :  84.34001588821411\n",
      "\n",
      " Epoch 453\n",
      "\n",
      "Training accuracy :  0.934\n",
      "\n",
      "Training loss :  84.33807468414307\n",
      "\n",
      " Epoch 454\n",
      "\n",
      "Training accuracy :  0.936\n",
      "\n",
      "Training loss :  84.33814096450806\n",
      "\n",
      " Epoch 455\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  84.33752489089966\n",
      "\n",
      " Epoch 456\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  84.33598518371582\n",
      "\n",
      " Epoch 457\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  84.3349609375\n",
      "\n",
      " Epoch 458\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.33435010910034\n",
      "\n",
      " Epoch 459\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.333899974823\n",
      "\n",
      " Epoch 460\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.33250427246094\n",
      "\n",
      " Epoch 461\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.33239555358887\n",
      "\n",
      " Epoch 462\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  84.33132648468018\n",
      "\n",
      " Epoch 463\n",
      "\n",
      "Training accuracy :  0.941\n",
      "\n",
      "Training loss :  84.33003044128418\n",
      "\n",
      " Epoch 464\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  84.32946348190308\n",
      "\n",
      " Epoch 465\n",
      "\n",
      "Training accuracy :  0.941\n",
      "\n",
      "Training loss :  84.32835531234741\n",
      "\n",
      " Epoch 466\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  84.32739353179932\n",
      "\n",
      " Epoch 467\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  84.32606029510498\n",
      "\n",
      " Epoch 468\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.32461023330688\n",
      "\n",
      " Epoch 469\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.32373142242432\n",
      "\n",
      " Epoch 470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.32355070114136\n",
      "\n",
      " Epoch 471\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.32276630401611\n",
      "\n",
      " Epoch 472\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  84.32166767120361\n",
      "\n",
      " Epoch 473\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.32112312316895\n",
      "\n",
      " Epoch 474\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.31982278823853\n",
      "\n",
      " Epoch 475\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.31976556777954\n",
      "\n",
      " Epoch 476\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.31865406036377\n",
      "\n",
      " Epoch 477\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.31822443008423\n",
      "\n",
      " Epoch 478\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.31713247299194\n",
      "\n",
      " Epoch 479\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  84.316237449646\n",
      "\n",
      " Epoch 480\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  84.31470680236816\n",
      "\n",
      " Epoch 481\n",
      "\n",
      "Training accuracy :  0.943\n",
      "\n",
      "Training loss :  84.31454515457153\n",
      "\n",
      " Epoch 482\n",
      "\n",
      "Training accuracy :  0.942\n",
      "\n",
      "Training loss :  84.31293869018555\n",
      "\n",
      " Epoch 483\n",
      "\n",
      "Training accuracy :  0.943\n",
      "\n",
      "Training loss :  84.31223058700562\n",
      "\n",
      " Epoch 484\n",
      "\n",
      "Training accuracy :  0.944\n",
      "\n",
      "Training loss :  84.31359767913818\n",
      "\n",
      " Epoch 485\n",
      "\n",
      "Training accuracy :  0.943\n",
      "\n",
      "Training loss :  84.31021881103516\n",
      "\n",
      " Epoch 486\n",
      "\n",
      "Training accuracy :  0.944\n",
      "\n",
      "Training loss :  84.31143760681152\n",
      "\n",
      " Epoch 487\n",
      "\n",
      "Training accuracy :  0.943\n",
      "\n",
      "Training loss :  84.3095350265503\n",
      "\n",
      " Epoch 488\n",
      "\n",
      "Training accuracy :  0.945\n",
      "\n",
      "Training loss :  84.30988311767578\n",
      "\n",
      " Epoch 489\n",
      "\n",
      "Training accuracy :  0.944\n",
      "\n",
      "Training loss :  84.30888748168945\n",
      "\n",
      " Epoch 490\n",
      "\n",
      "Training accuracy :  0.946\n",
      "\n",
      "Training loss :  84.30922031402588\n",
      "\n",
      " Epoch 491\n",
      "\n",
      "Training accuracy :  0.945\n",
      "\n",
      "Training loss :  84.3074402809143\n",
      "\n",
      " Epoch 492\n",
      "\n",
      "Training accuracy :  0.946\n",
      "\n",
      "Training loss :  84.30829095840454\n",
      "\n",
      " Epoch 493\n",
      "\n",
      "Training accuracy :  0.946\n",
      "\n",
      "Training loss :  84.30740070343018\n",
      "\n",
      " Epoch 494\n",
      "\n",
      "Training accuracy :  0.948\n",
      "\n",
      "Training loss :  84.30589962005615\n",
      "\n",
      " Epoch 495\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  84.30481100082397\n",
      "\n",
      " Epoch 496\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  84.3060097694397\n",
      "\n",
      " Epoch 497\n",
      "\n",
      "Training accuracy :  0.948\n",
      "\n",
      "Training loss :  84.30345821380615\n",
      "\n",
      " Epoch 498\n",
      "\n",
      "Training accuracy :  0.948\n",
      "\n",
      "Training loss :  84.30355024337769\n",
      "\n",
      " Epoch 499\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  84.30139446258545\n",
      "\n",
      " Epoch 500\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  84.3003077507019\n",
      "\n",
      " Epoch 501\n",
      "\n",
      "Training accuracy :  0.95\n",
      "\n",
      "Training loss :  84.30066394805908\n",
      "\n",
      " Epoch 502\n",
      "\n",
      "Training accuracy :  0.951\n",
      "\n",
      "Training loss :  84.29723262786865\n",
      "\n",
      " Epoch 503\n",
      "\n",
      "Training accuracy :  0.951\n",
      "\n",
      "Training loss :  84.29719829559326\n",
      "\n",
      " Epoch 504\n",
      "\n",
      "Training accuracy :  0.951\n",
      "\n",
      "Training loss :  84.29640626907349\n",
      "\n",
      " Epoch 505\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.2953896522522\n",
      "\n",
      " Epoch 506\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.29529809951782\n",
      "\n",
      " Epoch 507\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.29468870162964\n",
      "\n",
      " Epoch 508\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.29439306259155\n",
      "\n",
      " Epoch 509\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.29274988174438\n",
      "\n",
      " Epoch 510\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.2920069694519\n",
      "\n",
      " Epoch 511\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.29096221923828\n",
      "\n",
      " Epoch 512\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.28990936279297\n",
      "\n",
      " Epoch 513\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.28887701034546\n",
      "\n",
      " Epoch 514\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.28797245025635\n",
      "\n",
      " Epoch 515\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.2872953414917\n",
      "\n",
      " Epoch 516\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28654766082764\n",
      "\n",
      " Epoch 517\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28583240509033\n",
      "\n",
      " Epoch 518\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28509664535522\n",
      "\n",
      " Epoch 519\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28435230255127\n",
      "\n",
      " Epoch 520\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28358745574951\n",
      "\n",
      " Epoch 521\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28278493881226\n",
      "\n",
      " Epoch 522\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28254890441895\n",
      "\n",
      " Epoch 523\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28170871734619\n",
      "\n",
      " Epoch 524\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28253364562988\n",
      "\n",
      " Epoch 525\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.28068923950195\n",
      "\n",
      " Epoch 526\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27987241744995\n",
      "\n",
      " Epoch 527\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27915287017822\n",
      "\n",
      " Epoch 528\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.2800464630127\n",
      "\n",
      " Epoch 529\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27806282043457\n",
      "\n",
      " Epoch 530\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27702760696411\n",
      "\n",
      " Epoch 531\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27657079696655\n",
      "\n",
      " Epoch 532\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.2760739326477\n",
      "\n",
      " Epoch 533\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27639770507812\n",
      "\n",
      " Epoch 534\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27469253540039\n",
      "\n",
      " Epoch 535\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27414512634277\n",
      "\n",
      " Epoch 536\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27394771575928\n",
      "\n",
      " Epoch 537\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.27409934997559\n",
      "\n",
      " Epoch 538\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.27303886413574\n",
      "\n",
      " Epoch 539\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.2730565071106\n",
      "\n",
      " Epoch 540\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.27190637588501\n",
      "\n",
      " Epoch 541\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.27001762390137\n",
      "\n",
      " Epoch 542\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.26943254470825\n",
      "\n",
      " Epoch 543\n",
      "\n",
      "Training accuracy :  0.952\n",
      "\n",
      "Training loss :  84.26924228668213\n",
      "\n",
      " Epoch 544\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.2684268951416\n",
      "\n",
      " Epoch 545\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.26781845092773\n",
      "\n",
      " Epoch 546\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.2672643661499\n",
      "\n",
      " Epoch 547\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.2667727470398\n",
      "\n",
      " Epoch 548\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.26573371887207\n",
      "\n",
      " Epoch 549\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.26546144485474\n",
      "\n",
      " Epoch 550\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.26432418823242\n",
      "\n",
      " Epoch 551\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.26347541809082\n",
      "\n",
      " Epoch 552\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.26308107376099\n",
      "\n",
      " Epoch 553\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.26179599761963\n",
      "\n",
      " Epoch 554\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.26054048538208\n",
      "\n",
      " Epoch 555\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.25930833816528\n",
      "\n",
      " Epoch 556\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.25650787353516\n",
      "\n",
      " Epoch 557\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.25476455688477\n",
      "\n",
      " Epoch 558\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.25220155715942\n",
      "\n",
      " Epoch 559\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  84.250732421875\n",
      "\n",
      " Epoch 560\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  84.24623250961304\n",
      "\n",
      " Epoch 561\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.24052953720093\n",
      "\n",
      " Epoch 562\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.23697423934937\n",
      "\n",
      " Epoch 563\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.23411893844604\n",
      "\n",
      " Epoch 564\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.23037195205688\n",
      "\n",
      " Epoch 565\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.22827434539795\n",
      "\n",
      " Epoch 566\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.22641658782959\n",
      "\n",
      " Epoch 567\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.2244782447815\n",
      "\n",
      " Epoch 568\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.22313261032104\n",
      "\n",
      " Epoch 569\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.22062492370605\n",
      "\n",
      " Epoch 570\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.21886920928955\n",
      "\n",
      " Epoch 571\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.2166166305542\n",
      "\n",
      " Epoch 572\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.21431636810303\n",
      "\n",
      " Epoch 573\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.21405410766602\n",
      "\n",
      " Epoch 574\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.21294069290161\n",
      "\n",
      " Epoch 575\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.20963907241821\n",
      "\n",
      " Epoch 576\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.2089490890503\n",
      "\n",
      " Epoch 577\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.20735931396484\n",
      "\n",
      " Epoch 578\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.20621538162231\n",
      "\n",
      " Epoch 579\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.20500326156616\n",
      "\n",
      " Epoch 580\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.20261001586914\n",
      "\n",
      " Epoch 581\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.20312833786011\n",
      "\n",
      " Epoch 582\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.2011342048645\n",
      "\n",
      " Epoch 583\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.2001314163208\n",
      "\n",
      " Epoch 584\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19836473464966\n",
      "\n",
      " Epoch 585\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1974048614502\n",
      "\n",
      " Epoch 586\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19542026519775\n",
      "\n",
      " Epoch 587\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19458389282227\n",
      "\n",
      " Epoch 588\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19478511810303\n",
      "\n",
      " Epoch 589\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19383144378662\n",
      "\n",
      " Epoch 590\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19184303283691\n",
      "\n",
      " Epoch 591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.19205808639526\n",
      "\n",
      " Epoch 592\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1900577545166\n",
      "\n",
      " Epoch 593\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1886076927185\n",
      "\n",
      " Epoch 594\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1892499923706\n",
      "\n",
      " Epoch 595\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18839979171753\n",
      "\n",
      " Epoch 596\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18617582321167\n",
      "\n",
      " Epoch 597\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18694496154785\n",
      "\n",
      " Epoch 598\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1851453781128\n",
      "\n",
      " Epoch 599\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18544626235962\n",
      "\n",
      " Epoch 600\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18376588821411\n",
      "\n",
      " Epoch 601\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18309783935547\n",
      "\n",
      " Epoch 602\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18396854400635\n",
      "\n",
      " Epoch 603\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.18238592147827\n",
      "\n",
      " Epoch 604\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.18116998672485\n",
      "\n",
      " Epoch 605\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1816930770874\n",
      "\n",
      " Epoch 606\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.18022918701172\n",
      "\n",
      " Epoch 607\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17917013168335\n",
      "\n",
      " Epoch 608\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17856502532959\n",
      "\n",
      " Epoch 609\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17772006988525\n",
      "\n",
      " Epoch 610\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17735004425049\n",
      "\n",
      " Epoch 611\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17785787582397\n",
      "\n",
      " Epoch 612\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17591762542725\n",
      "\n",
      " Epoch 613\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17538928985596\n",
      "\n",
      " Epoch 614\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17593908309937\n",
      "\n",
      " Epoch 615\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.1742033958435\n",
      "\n",
      " Epoch 616\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17355823516846\n",
      "\n",
      " Epoch 617\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17369937896729\n",
      "\n",
      " Epoch 618\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17172241210938\n",
      "\n",
      " Epoch 619\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.17215919494629\n",
      "\n",
      " Epoch 620\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.17030191421509\n",
      "\n",
      " Epoch 621\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.17086267471313\n",
      "\n",
      " Epoch 622\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16949462890625\n",
      "\n",
      " Epoch 623\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16859245300293\n",
      "\n",
      " Epoch 624\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16919088363647\n",
      "\n",
      " Epoch 625\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16742420196533\n",
      "\n",
      " Epoch 626\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16699647903442\n",
      "\n",
      " Epoch 627\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1664981842041\n",
      "\n",
      " Epoch 628\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.1669979095459\n",
      "\n",
      " Epoch 629\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16545867919922\n",
      "\n",
      " Epoch 630\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16509628295898\n",
      "\n",
      " Epoch 631\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16450119018555\n",
      "\n",
      " Epoch 632\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1653323173523\n",
      "\n",
      " Epoch 633\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16390037536621\n",
      "\n",
      " Epoch 634\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1632571220398\n",
      "\n",
      " Epoch 635\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16293001174927\n",
      "\n",
      " Epoch 636\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16237354278564\n",
      "\n",
      " Epoch 637\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.16321802139282\n",
      "\n",
      " Epoch 638\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.1617636680603\n",
      "\n",
      " Epoch 639\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.1611647605896\n",
      "\n",
      " Epoch 640\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  84.15975666046143\n",
      "\n",
      " Epoch 641\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15972852706909\n",
      "\n",
      " Epoch 642\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15780591964722\n",
      "\n",
      " Epoch 643\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15809297561646\n",
      "\n",
      " Epoch 644\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.15570306777954\n",
      "\n",
      " Epoch 645\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15531492233276\n",
      "\n",
      " Epoch 646\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15552759170532\n",
      "\n",
      " Epoch 647\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15329504013062\n",
      "\n",
      " Epoch 648\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  84.15438652038574\n",
      "\n",
      " Epoch 649\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15267419815063\n",
      "\n",
      " Epoch 650\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15144777297974\n",
      "\n",
      " Epoch 651\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  84.15070056915283\n",
      "\n",
      " Epoch 652\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14998435974121\n",
      "\n",
      " Epoch 653\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14934062957764\n",
      "\n",
      " Epoch 654\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14930200576782\n",
      "\n",
      " Epoch 655\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.1474781036377\n",
      "\n",
      " Epoch 656\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.148681640625\n",
      "\n",
      " Epoch 657\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14695310592651\n",
      "\n",
      " Epoch 658\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14654207229614\n",
      "\n",
      " Epoch 659\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.146963596344\n",
      "\n",
      " Epoch 660\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14556550979614\n",
      "\n",
      " Epoch 661\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.1448392868042\n",
      "\n",
      " Epoch 662\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14661931991577\n",
      "\n",
      " Epoch 663\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14476346969604\n",
      "\n",
      " Epoch 664\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14435195922852\n",
      "\n",
      " Epoch 665\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14435577392578\n",
      "\n",
      " Epoch 666\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14452362060547\n",
      "\n",
      " Epoch 667\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14320945739746\n",
      "\n",
      " Epoch 668\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14303493499756\n",
      "\n",
      " Epoch 669\n",
      "\n",
      "Training accuracy :  0.959\n",
      "\n",
      "Training loss :  84.14246034622192\n",
      "\n",
      " Epoch 670\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  84.14301776885986\n",
      "\n",
      " Epoch 671\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.14129781723022\n",
      "\n",
      " Epoch 672\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.14071989059448\n",
      "\n",
      " Epoch 673\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.14160299301147\n",
      "\n",
      " Epoch 674\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13968992233276\n",
      "\n",
      " Epoch 675\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13940286636353\n",
      "\n",
      " Epoch 676\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13867282867432\n",
      "\n",
      " Epoch 677\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13960647583008\n",
      "\n",
      " Epoch 678\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13816690444946\n",
      "\n",
      " Epoch 679\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13753080368042\n",
      "\n",
      " Epoch 680\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13675022125244\n",
      "\n",
      " Epoch 681\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13663053512573\n",
      "\n",
      " Epoch 682\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  84.13607597351074\n",
      "\n",
      " Epoch 683\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13648509979248\n",
      "\n",
      " Epoch 684\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  84.13551568984985\n",
      "\n",
      " Epoch 685\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.1350679397583\n",
      "\n",
      " Epoch 686\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13488864898682\n",
      "\n",
      " Epoch 687\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13549327850342\n",
      "\n",
      " Epoch 688\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13438415527344\n",
      "\n",
      " Epoch 689\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13380765914917\n",
      "\n",
      " Epoch 690\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13374710083008\n",
      "\n",
      " Epoch 691\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13476133346558\n",
      "\n",
      " Epoch 692\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13345241546631\n",
      "\n",
      " Epoch 693\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.13315486907959\n",
      "\n",
      " Epoch 694\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13278007507324\n",
      "\n",
      " Epoch 695\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  84.1337080001831\n",
      "\n",
      " Epoch 696\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  84.13201522827148\n",
      "\n",
      " Epoch 697\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  84.13180303573608\n",
      "\n",
      " Epoch 698\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  84.13156843185425\n",
      "\n",
      " Epoch 699\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  84.13251972198486\n",
      "\n",
      " Epoch 700\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  84.13115644454956\n",
      "\n",
      " Epoch 701\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  84.13082647323608\n",
      "\n",
      " Epoch 702\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  84.13011360168457\n",
      "\n",
      " Epoch 703\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  84.13117790222168\n",
      "\n",
      " Epoch 704\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.1300220489502\n",
      "\n",
      " Epoch 705\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12947940826416\n",
      "\n",
      " Epoch 706\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  84.1304783821106\n",
      "\n",
      " Epoch 707\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12887573242188\n",
      "\n",
      " Epoch 708\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  84.12866687774658\n",
      "\n",
      " Epoch 709\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12954950332642\n",
      "\n",
      " Epoch 710\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12814521789551\n",
      "\n",
      " Epoch 711\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12769508361816\n",
      "\n",
      " Epoch 712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.1285285949707\n",
      "\n",
      " Epoch 713\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12728309631348\n",
      "\n",
      " Epoch 714\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12694311141968\n",
      "\n",
      " Epoch 715\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.1279125213623\n",
      "\n",
      " Epoch 716\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12622165679932\n",
      "\n",
      " Epoch 717\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12698984146118\n",
      "\n",
      " Epoch 718\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12571334838867\n",
      "\n",
      " Epoch 719\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12549591064453\n",
      "\n",
      " Epoch 720\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12524700164795\n",
      "\n",
      " Epoch 721\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12596273422241\n",
      "\n",
      " Epoch 722\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.1250205039978\n",
      "\n",
      " Epoch 723\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12543487548828\n",
      "\n",
      " Epoch 724\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  84.12436389923096\n",
      "\n",
      " Epoch 725\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12514305114746\n",
      "\n",
      " Epoch 726\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12377452850342\n",
      "\n",
      " Epoch 727\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12324333190918\n",
      "\n",
      " Epoch 728\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.124267578125\n",
      "\n",
      " Epoch 729\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12301063537598\n",
      "\n",
      " Epoch 730\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12344741821289\n",
      "\n",
      " Epoch 731\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12296342849731\n",
      "\n",
      " Epoch 732\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12327098846436\n",
      "\n",
      " Epoch 733\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  84.12180852890015\n",
      "\n",
      " Epoch 734\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12258863449097\n",
      "\n",
      " Epoch 735\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12145948410034\n",
      "\n",
      " Epoch 736\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12084674835205\n",
      "\n",
      " Epoch 737\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.1212477684021\n",
      "\n",
      " Epoch 738\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.1212329864502\n",
      "\n",
      " Epoch 739\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12033796310425\n",
      "\n",
      " Epoch 740\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12093925476074\n",
      "\n",
      " Epoch 741\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.12031698226929\n",
      "\n",
      " Epoch 742\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.1195216178894\n",
      "\n",
      " Epoch 743\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.11975145339966\n",
      "\n",
      " Epoch 744\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11988687515259\n",
      "\n",
      " Epoch 745\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11939287185669\n",
      "\n",
      " Epoch 746\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.11825609207153\n",
      "\n",
      " Epoch 747\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11894273757935\n",
      "\n",
      " Epoch 748\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.1186170578003\n",
      "\n",
      " Epoch 749\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11837100982666\n",
      "\n",
      " Epoch 750\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11792230606079\n",
      "\n",
      " Epoch 751\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11706876754761\n",
      "\n",
      " Epoch 752\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11783838272095\n",
      "\n",
      " Epoch 753\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11746597290039\n",
      "\n",
      " Epoch 754\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  84.11712598800659\n",
      "\n",
      " Epoch 755\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11687326431274\n",
      "\n",
      " Epoch 756\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11672019958496\n",
      "\n",
      " Epoch 757\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11561346054077\n",
      "\n",
      " Epoch 758\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  84.11616802215576\n",
      "\n",
      " Epoch 759\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11580181121826\n",
      "\n",
      " Epoch 760\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11576700210571\n",
      "\n",
      " Epoch 761\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  84.11594247817993\n",
      "\n",
      " Epoch 762\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11527490615845\n",
      "\n",
      " Epoch 763\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  84.11462926864624\n",
      "\n",
      " Epoch 764\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  84.11479091644287\n",
      "\n",
      " Epoch 765\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  84.11382818222046\n",
      "\n",
      " Epoch 766\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11449480056763\n",
      "\n",
      " Epoch 767\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11383199691772\n",
      "\n",
      " Epoch 768\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11383390426636\n",
      "\n",
      " Epoch 769\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11260843276978\n",
      "\n",
      " Epoch 770\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  84.11273908615112\n",
      "\n",
      " Epoch 771\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11312818527222\n",
      "\n",
      " Epoch 772\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.11228227615356\n",
      "\n",
      " Epoch 773\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.11244487762451\n",
      "\n",
      " Epoch 774\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11171293258667\n",
      "\n",
      " Epoch 775\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.1116681098938\n",
      "\n",
      " Epoch 776\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11131525039673\n",
      "\n",
      " Epoch 777\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.11132192611694\n",
      "\n",
      " Epoch 778\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.10941076278687\n",
      "\n",
      " Epoch 779\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11019515991211\n",
      "\n",
      " Epoch 780\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  84.11019897460938\n",
      "\n",
      " Epoch 781\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.1102409362793\n",
      "\n",
      " Epoch 782\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10883569717407\n",
      "\n",
      " Epoch 783\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10883808135986\n",
      "\n",
      " Epoch 784\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.1085057258606\n",
      "\n",
      " Epoch 785\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10816812515259\n",
      "\n",
      " Epoch 786\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.1072678565979\n",
      "\n",
      " Epoch 787\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10709142684937\n",
      "\n",
      " Epoch 788\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.1071228981018\n",
      "\n",
      " Epoch 789\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10673189163208\n",
      "\n",
      " Epoch 790\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10667562484741\n",
      "\n",
      " Epoch 791\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10599613189697\n",
      "\n",
      " Epoch 792\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10594320297241\n",
      "\n",
      " Epoch 793\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10574054718018\n",
      "\n",
      " Epoch 794\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10524797439575\n",
      "\n",
      " Epoch 795\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10480880737305\n",
      "\n",
      " Epoch 796\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10434103012085\n",
      "\n",
      " Epoch 797\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10430717468262\n",
      "\n",
      " Epoch 798\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10374975204468\n",
      "\n",
      " Epoch 799\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10347700119019\n",
      "\n",
      " Epoch 800\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10301494598389\n",
      "\n",
      " Epoch 801\n",
      "\n",
      "Training accuracy :  0.972\n",
      "\n",
      "Training loss :  84.10266447067261\n",
      "\n",
      " Epoch 802\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10298156738281\n",
      "\n",
      " Epoch 803\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.10278511047363\n",
      "\n",
      " Epoch 804\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.1025128364563\n",
      "\n",
      " Epoch 805\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.1021957397461\n",
      "\n",
      " Epoch 806\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.10202407836914\n",
      "\n",
      " Epoch 807\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.10125780105591\n",
      "\n",
      " Epoch 808\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.10067510604858\n",
      "\n",
      " Epoch 809\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.09910583496094\n",
      "\n",
      " Epoch 810\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09948825836182\n",
      "\n",
      " Epoch 811\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.09842872619629\n",
      "\n",
      " Epoch 812\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.09824800491333\n",
      "\n",
      " Epoch 813\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09814739227295\n",
      "\n",
      " Epoch 814\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09803295135498\n",
      "\n",
      " Epoch 815\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09712934494019\n",
      "\n",
      " Epoch 816\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09730577468872\n",
      "\n",
      " Epoch 817\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09633779525757\n",
      "\n",
      " Epoch 818\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.09786796569824\n",
      "\n",
      " Epoch 819\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09571027755737\n",
      "\n",
      " Epoch 820\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09398317337036\n",
      "\n",
      " Epoch 821\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  84.09185028076172\n",
      "\n",
      " Epoch 822\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  84.08949756622314\n",
      "\n",
      " Epoch 823\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  84.08670139312744\n",
      "\n",
      " Epoch 824\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  84.08323049545288\n",
      "\n",
      " Epoch 825\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  84.0789041519165\n",
      "\n",
      " Epoch 826\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  84.07406234741211\n",
      "\n",
      " Epoch 827\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  84.06459379196167\n",
      "\n",
      " Epoch 828\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  84.05224132537842\n",
      "\n",
      " Epoch 829\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  84.03630685806274\n",
      "\n",
      " Epoch 830\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  84.01555490493774\n",
      "\n",
      " Epoch 831\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  83.98047685623169\n",
      "\n",
      " Epoch 832\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  83.94494342803955\n",
      "\n",
      " Epoch 833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  83.89086961746216\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 834\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  83.82353925704956\n",
      "\n",
      " Epoch 835\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  83.75151777267456\n",
      "\n",
      " Epoch 836\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  83.68704223632812\n",
      "\n",
      " Epoch 837\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  83.6292176246643\n",
      "\n",
      " Epoch 838\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  83.57527685165405\n",
      "\n",
      " Epoch 839\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  83.52126598358154\n",
      "\n",
      " Epoch 840\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  83.46788597106934\n",
      "\n",
      " Epoch 841\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  83.39143943786621\n",
      "\n",
      " Epoch 842\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  83.31053638458252\n",
      "\n",
      " Epoch 843\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  83.21720504760742\n",
      "\n",
      " Epoch 844\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  83.13355684280396\n",
      "\n",
      " Epoch 845\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  83.0665545463562\n",
      "\n",
      " Epoch 846\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  83.01213693618774\n",
      "\n",
      " Epoch 847\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  82.96394538879395\n",
      "\n",
      " Epoch 848\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.92735958099365\n",
      "\n",
      " Epoch 849\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  82.89752244949341\n",
      "\n",
      " Epoch 850\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  82.874032497406\n",
      "\n",
      " Epoch 851\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  82.85152244567871\n",
      "\n",
      " Epoch 852\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.83091402053833\n",
      "\n",
      " Epoch 853\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.81349658966064\n",
      "\n",
      " Epoch 854\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.7962441444397\n",
      "\n",
      " Epoch 855\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.78031206130981\n",
      "\n",
      " Epoch 856\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.76563692092896\n",
      "\n",
      " Epoch 857\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  82.75150060653687\n",
      "\n",
      " Epoch 858\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  82.73421716690063\n",
      "\n",
      " Epoch 859\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  82.7208423614502\n",
      "\n",
      " Epoch 860\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  82.71140336990356\n",
      "\n",
      " Epoch 861\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  82.70319509506226\n",
      "\n",
      " Epoch 862\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  82.69596242904663\n",
      "\n",
      " Epoch 863\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  82.69023752212524\n",
      "\n",
      " Epoch 864\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.69277906417847\n",
      "\n",
      " Epoch 865\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.68940591812134\n",
      "\n",
      " Epoch 866\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.68480014801025\n",
      "\n",
      " Epoch 867\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6809811592102\n",
      "\n",
      " Epoch 868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.67711448669434\n",
      "\n",
      " Epoch 869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.674081325531\n",
      "\n",
      " Epoch 870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.67064619064331\n",
      "\n",
      " Epoch 871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.66739845275879\n",
      "\n",
      " Epoch 872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.66587972640991\n",
      "\n",
      " Epoch 873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.66414308547974\n",
      "\n",
      " Epoch 874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.6627197265625\n",
      "\n",
      " Epoch 875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.66090965270996\n",
      "\n",
      " Epoch 876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65985918045044\n",
      "\n",
      " Epoch 877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65837287902832\n",
      "\n",
      " Epoch 878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65713882446289\n",
      "\n",
      " Epoch 879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65560054779053\n",
      "\n",
      " Epoch 880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65467262268066\n",
      "\n",
      " Epoch 881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65376138687134\n",
      "\n",
      " Epoch 882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.65274906158447\n",
      "\n",
      " Epoch 883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.6508994102478\n",
      "\n",
      " Epoch 884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.6493673324585\n",
      "\n",
      " Epoch 885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.64732360839844\n",
      "\n",
      " Epoch 886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.64597082138062\n",
      "\n",
      " Epoch 887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.64344263076782\n",
      "\n",
      " Epoch 888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.6430311203003\n",
      "\n",
      " Epoch 889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.63954257965088\n",
      "\n",
      " Epoch 890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.6384220123291\n",
      "\n",
      " Epoch 891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.63705587387085\n",
      "\n",
      " Epoch 892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.63543510437012\n",
      "\n",
      " Epoch 893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.63353109359741\n",
      "\n",
      " Epoch 894\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.63226222991943\n",
      "\n",
      " Epoch 895\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.63100481033325\n",
      "\n",
      " Epoch 896\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62963819503784\n",
      "\n",
      " Epoch 897\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62902688980103\n",
      "\n",
      " Epoch 898\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6276969909668\n",
      "\n",
      " Epoch 899\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62616539001465\n",
      "\n",
      " Epoch 900\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62550497055054\n",
      "\n",
      " Epoch 901\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6242527961731\n",
      "\n",
      " Epoch 902\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62315845489502\n",
      "\n",
      " Epoch 903\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62222576141357\n",
      "\n",
      " Epoch 904\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.62098264694214\n",
      "\n",
      " Epoch 905\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6194076538086\n",
      "\n",
      " Epoch 906\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61775732040405\n",
      "\n",
      " Epoch 907\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61618041992188\n",
      "\n",
      " Epoch 908\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61529016494751\n",
      "\n",
      " Epoch 909\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61373329162598\n",
      "\n",
      " Epoch 910\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61276817321777\n",
      "\n",
      " Epoch 911\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61121416091919\n",
      "\n",
      " Epoch 912\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.61032342910767\n",
      "\n",
      " Epoch 913\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6089973449707\n",
      "\n",
      " Epoch 914\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60825061798096\n",
      "\n",
      " Epoch 915\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6074628829956\n",
      "\n",
      " Epoch 916\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6064338684082\n",
      "\n",
      " Epoch 917\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60546445846558\n",
      "\n",
      " Epoch 918\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60428619384766\n",
      "\n",
      " Epoch 919\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.6034369468689\n",
      "\n",
      " Epoch 920\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60227966308594\n",
      "\n",
      " Epoch 921\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60128116607666\n",
      "\n",
      " Epoch 922\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.60037469863892\n",
      "\n",
      " Epoch 923\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.599289894104\n",
      "\n",
      " Epoch 924\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5978832244873\n",
      "\n",
      " Epoch 925\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59777069091797\n",
      "\n",
      " Epoch 926\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59701156616211\n",
      "\n",
      " Epoch 927\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59601497650146\n",
      "\n",
      " Epoch 928\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59518527984619\n",
      "\n",
      " Epoch 929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5990514755249\n",
      "\n",
      " Epoch 930\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5958924293518\n",
      "\n",
      " Epoch 931\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59386825561523\n",
      "\n",
      " Epoch 932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.59347772598267\n",
      "\n",
      " Epoch 933\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.59173536300659\n",
      "\n",
      " Epoch 934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.59162473678589\n",
      "\n",
      " Epoch 935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.58891153335571\n",
      "\n",
      " Epoch 936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.58911085128784\n",
      "\n",
      " Epoch 937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.58728885650635\n",
      "\n",
      " Epoch 938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5860333442688\n",
      "\n",
      " Epoch 939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.58515405654907\n",
      "\n",
      " Epoch 940\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.58364534378052\n",
      "\n",
      " Epoch 941\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.58343124389648\n",
      "\n",
      " Epoch 942\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.58263158798218\n",
      "\n",
      " Epoch 943\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.58129024505615\n",
      "\n",
      " Epoch 944\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.58049392700195\n",
      "\n",
      " Epoch 945\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57949686050415\n",
      "\n",
      " Epoch 946\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5785722732544\n",
      "\n",
      " Epoch 947\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5778398513794\n",
      "\n",
      " Epoch 948\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57706785202026\n",
      "\n",
      " Epoch 949\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57580709457397\n",
      "\n",
      " Epoch 950\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57604455947876\n",
      "\n",
      " Epoch 951\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57449626922607\n",
      "\n",
      " Epoch 952\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57440042495728\n",
      "\n",
      " Epoch 953\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57230138778687\n",
      "\n",
      " Epoch 954\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57335424423218\n",
      "\n",
      " Epoch 955\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.57181882858276\n",
      "\n",
      " Epoch 956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5707049369812\n",
      "\n",
      " Epoch 957\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5690746307373\n",
      "\n",
      " Epoch 958\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5689582824707\n",
      "\n",
      " Epoch 959\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56821966171265\n",
      "\n",
      " Epoch 960\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56841230392456\n",
      "\n",
      " Epoch 961\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56612157821655\n",
      "\n",
      " Epoch 962\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5655288696289\n",
      "\n",
      " Epoch 963\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56508684158325\n",
      "\n",
      " Epoch 964\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56382942199707\n",
      "\n",
      " Epoch 965\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56368255615234\n",
      "\n",
      " Epoch 966\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56318616867065\n",
      "\n",
      " Epoch 967\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56385803222656\n",
      "\n",
      " Epoch 968\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5622730255127\n",
      "\n",
      " Epoch 969\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56234312057495\n",
      "\n",
      " Epoch 970\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56145334243774\n",
      "\n",
      " Epoch 971\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.56028318405151\n",
      "\n",
      " Epoch 972\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55988359451294\n",
      "\n",
      " Epoch 973\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55908584594727\n",
      "\n",
      " Epoch 974\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55959129333496\n",
      "\n",
      " Epoch 975\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55945253372192\n",
      "\n",
      " Epoch 976\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55849027633667\n",
      "\n",
      " Epoch 977\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55813550949097\n",
      "\n",
      " Epoch 978\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55785274505615\n",
      "\n",
      " Epoch 979\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55780792236328\n",
      "\n",
      " Epoch 980\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55653476715088\n",
      "\n",
      " Epoch 981\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55710124969482\n",
      "\n",
      " Epoch 982\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55664873123169\n",
      "\n",
      " Epoch 983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55633449554443\n",
      "\n",
      " Epoch 984\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5566291809082\n",
      "\n",
      " Epoch 985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55584573745728\n",
      "\n",
      " Epoch 986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55561780929565\n",
      "\n",
      " Epoch 987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55528593063354\n",
      "\n",
      " Epoch 988\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.55576038360596\n",
      "\n",
      " Epoch 989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5550217628479\n",
      "\n",
      " Epoch 990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5536789894104\n",
      "\n",
      " Epoch 991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55544090270996\n",
      "\n",
      " Epoch 992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55401849746704\n",
      "\n",
      " Epoch 993\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55479526519775\n",
      "\n",
      " Epoch 994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5535159111023\n",
      "\n",
      " Epoch 995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55262470245361\n",
      "\n",
      " Epoch 996\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55406188964844\n",
      "\n",
      " Epoch 997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.55424213409424\n",
      "\n",
      " Epoch 998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5516905784607\n",
      "\n",
      " Epoch 999\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55330324172974\n",
      "\n",
      " Epoch 1000\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55292320251465\n",
      "\n",
      " Epoch 1001\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55233955383301\n",
      "\n",
      " Epoch 1002\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55051803588867\n",
      "\n",
      " Epoch 1003\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55101585388184\n",
      "\n",
      " Epoch 1004\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.55049467086792\n",
      "\n",
      " Epoch 1005\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54996538162231\n",
      "\n",
      " Epoch 1006\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54944181442261\n",
      "\n",
      " Epoch 1007\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54961490631104\n",
      "\n",
      " Epoch 1008\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54860639572144\n",
      "\n",
      " Epoch 1009\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54796552658081\n",
      "\n",
      " Epoch 1010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.54782581329346\n",
      "\n",
      " Epoch 1011\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54767847061157\n",
      "\n",
      " Epoch 1012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5471396446228\n",
      "\n",
      " Epoch 1013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.54701089859009\n",
      "\n",
      " Epoch 1014\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.546950340271\n",
      "\n",
      " Epoch 1015\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5463662147522\n",
      "\n",
      " Epoch 1016\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5463342666626\n",
      "\n",
      " Epoch 1017\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54632568359375\n",
      "\n",
      " Epoch 1018\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54573965072632\n",
      "\n",
      " Epoch 1019\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54551601409912\n",
      "\n",
      " Epoch 1020\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54556894302368\n",
      "\n",
      " Epoch 1021\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54533910751343\n",
      "\n",
      " Epoch 1022\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54503631591797\n",
      "\n",
      " Epoch 1023\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54618406295776\n",
      "\n",
      " Epoch 1024\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54466009140015\n",
      "\n",
      " Epoch 1025\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54598045349121\n",
      "\n",
      " Epoch 1026\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54432344436646\n",
      "\n",
      " Epoch 1027\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54559707641602\n",
      "\n",
      " Epoch 1028\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54417753219604\n",
      "\n",
      " Epoch 1029\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54388904571533\n",
      "\n",
      " Epoch 1030\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5450210571289\n",
      "\n",
      " Epoch 1031\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54360342025757\n",
      "\n",
      " Epoch 1032\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54479789733887\n",
      "\n",
      " Epoch 1033\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54329872131348\n",
      "\n",
      " Epoch 1034\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54451608657837\n",
      "\n",
      " Epoch 1035\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54303312301636\n",
      "\n",
      " Epoch 1036\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54422903060913\n",
      "\n",
      " Epoch 1037\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5426173210144\n",
      "\n",
      " Epoch 1038\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54287099838257\n",
      "\n",
      " Epoch 1039\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54220628738403\n",
      "\n",
      " Epoch 1040\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.542151927948\n",
      "\n",
      " Epoch 1041\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54335498809814\n",
      "\n",
      " Epoch 1042\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54166460037231\n",
      "\n",
      " Epoch 1043\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5429859161377\n",
      "\n",
      " Epoch 1044\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54148626327515\n",
      "\n",
      " Epoch 1045\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54269695281982\n",
      "\n",
      " Epoch 1046\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54133653640747\n",
      "\n",
      " Epoch 1047\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54246711730957\n",
      "\n",
      " Epoch 1048\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54099130630493\n",
      "\n",
      " Epoch 1049\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54230833053589\n",
      "\n",
      " Epoch 1050\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54074287414551\n",
      "\n",
      " Epoch 1051\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5416488647461\n",
      "\n",
      " Epoch 1052\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54051494598389\n",
      "\n",
      " Epoch 1053\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5418062210083\n",
      "\n",
      " Epoch 1054\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54021644592285\n",
      "\n",
      " Epoch 1055\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54135465621948\n",
      "\n",
      " Epoch 1056\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5400857925415\n",
      "\n",
      " Epoch 1057\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54075050354004\n",
      "\n",
      " Epoch 1058\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53977918624878\n",
      "\n",
      " Epoch 1059\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.54046249389648\n",
      "\n",
      " Epoch 1060\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53950357437134\n",
      "\n",
      " Epoch 1061\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5401873588562\n",
      "\n",
      " Epoch 1062\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53927087783813\n",
      "\n",
      " Epoch 1063\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53968095779419\n",
      "\n",
      " Epoch 1064\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53887605667114\n",
      "\n",
      " Epoch 1065\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53976345062256\n",
      "\n",
      " Epoch 1066\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53864192962646\n",
      "\n",
      " Epoch 1067\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53962993621826\n",
      "\n",
      " Epoch 1068\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53945875167847\n",
      "\n",
      " Epoch 1069\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53947639465332\n",
      "\n",
      " Epoch 1070\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.538330078125\n",
      "\n",
      " Epoch 1071\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53904342651367\n",
      "\n",
      " Epoch 1072\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.537682056427\n",
      "\n",
      " Epoch 1073\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53901815414429\n",
      "\n",
      " Epoch 1074\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53745174407959\n",
      "\n",
      " Epoch 1075\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.5385570526123\n",
      "\n",
      " Epoch 1076\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53871250152588\n",
      "\n",
      " Epoch 1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53852033615112\n",
      "\n",
      " Epoch 1078\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53751468658447\n",
      "\n",
      " Epoch 1079\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53829193115234\n",
      "\n",
      " Epoch 1080\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  82.53792428970337\n",
      "\n",
      " Epoch 1081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53703212738037\n",
      "\n",
      " Epoch 1082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53766012191772\n",
      "\n",
      " Epoch 1083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53710651397705\n",
      "\n",
      " Epoch 1084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53718328475952\n",
      "\n",
      " Epoch 1085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53731632232666\n",
      "\n",
      " Epoch 1086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53635263442993\n",
      "\n",
      " Epoch 1087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5372838973999\n",
      "\n",
      " Epoch 1088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53688669204712\n",
      "\n",
      " Epoch 1089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5361065864563\n",
      "\n",
      " Epoch 1090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53699207305908\n",
      "\n",
      " Epoch 1091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53643894195557\n",
      "\n",
      " Epoch 1092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53722476959229\n",
      "\n",
      " Epoch 1093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.536048412323\n",
      "\n",
      " Epoch 1094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5363540649414\n",
      "\n",
      " Epoch 1095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53600740432739\n",
      "\n",
      " Epoch 1096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53591060638428\n",
      "\n",
      " Epoch 1097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53668212890625\n",
      "\n",
      " Epoch 1098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5367078781128\n",
      "\n",
      " Epoch 1099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53526067733765\n",
      "\n",
      " Epoch 1100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53668546676636\n",
      "\n",
      " Epoch 1101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53621339797974\n",
      "\n",
      " Epoch 1102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53621673583984\n",
      "\n",
      " Epoch 1103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53622055053711\n",
      "\n",
      " Epoch 1104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5359787940979\n",
      "\n",
      " Epoch 1105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53604745864868\n",
      "\n",
      " Epoch 1106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53576374053955\n",
      "\n",
      " Epoch 1107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53554677963257\n",
      "\n",
      " Epoch 1108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53593826293945\n",
      "\n",
      " Epoch 1109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53538465499878\n",
      "\n",
      " Epoch 1110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53546905517578\n",
      "\n",
      " Epoch 1111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53562211990356\n",
      "\n",
      " Epoch 1112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53536653518677\n",
      "\n",
      " Epoch 1113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53496217727661\n",
      "\n",
      " Epoch 1114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53528118133545\n",
      "\n",
      " Epoch 1115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53521871566772\n",
      "\n",
      " Epoch 1116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53459405899048\n",
      "\n",
      " Epoch 1117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53474283218384\n",
      "\n",
      " Epoch 1118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53470039367676\n",
      "\n",
      " Epoch 1119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53429651260376\n",
      "\n",
      " Epoch 1120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53478050231934\n",
      "\n",
      " Epoch 1121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53447532653809\n",
      "\n",
      " Epoch 1122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53429079055786\n",
      "\n",
      " Epoch 1123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53391361236572\n",
      "\n",
      " Epoch 1124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53411102294922\n",
      "\n",
      " Epoch 1125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53463077545166\n",
      "\n",
      " Epoch 1126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53386402130127\n",
      "\n",
      " Epoch 1127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53309965133667\n",
      "\n",
      " Epoch 1128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53439092636108\n",
      "\n",
      " Epoch 1129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53355598449707\n",
      "\n",
      " Epoch 1130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5335283279419\n",
      "\n",
      " Epoch 1131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53342390060425\n",
      "\n",
      " Epoch 1132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5339093208313\n",
      "\n",
      " Epoch 1133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53311204910278\n",
      "\n",
      " Epoch 1134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53213930130005\n",
      "\n",
      " Epoch 1135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53346633911133\n",
      "\n",
      " Epoch 1136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53239488601685\n",
      "\n",
      " Epoch 1137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53346824645996\n",
      "\n",
      " Epoch 1138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53139114379883\n",
      "\n",
      " Epoch 1139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53311061859131\n",
      "\n",
      " Epoch 1140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53263759613037\n",
      "\n",
      " Epoch 1141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53173923492432\n",
      "\n",
      " Epoch 1142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53292465209961\n",
      "\n",
      " Epoch 1143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5317735671997\n",
      "\n",
      " Epoch 1144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53269720077515\n",
      "\n",
      " Epoch 1145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53255367279053\n",
      "\n",
      " Epoch 1146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53228855133057\n",
      "\n",
      " Epoch 1147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.531325340271\n",
      "\n",
      " Epoch 1148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53249645233154\n",
      "\n",
      " Epoch 1149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5324592590332\n",
      "\n",
      " Epoch 1150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.531907081604\n",
      "\n",
      " Epoch 1151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53251266479492\n",
      "\n",
      " Epoch 1152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5315809249878\n",
      "\n",
      " Epoch 1153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5308837890625\n",
      "\n",
      " Epoch 1154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5322995185852\n",
      "\n",
      " Epoch 1155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53192043304443\n",
      "\n",
      " Epoch 1156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53098249435425\n",
      "\n",
      " Epoch 1157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53196811676025\n",
      "\n",
      " Epoch 1158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53116464614868\n",
      "\n",
      " Epoch 1159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53036403656006\n",
      "\n",
      " Epoch 1160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53158664703369\n",
      "\n",
      " Epoch 1161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53158473968506\n",
      "\n",
      " Epoch 1162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53135061264038\n",
      "\n",
      " Epoch 1163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52932167053223\n",
      "\n",
      " Epoch 1164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53128290176392\n",
      "\n",
      " Epoch 1165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53119468688965\n",
      "\n",
      " Epoch 1166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53047561645508\n",
      "\n",
      " Epoch 1167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53128957748413\n",
      "\n",
      " Epoch 1168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53130006790161\n",
      "\n",
      " Epoch 1169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53099536895752\n",
      "\n",
      " Epoch 1170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52987670898438\n",
      "\n",
      " Epoch 1171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53098154067993\n",
      "\n",
      " Epoch 1172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53036403656006\n",
      "\n",
      " Epoch 1173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53110027313232\n",
      "\n",
      " Epoch 1174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5309157371521\n",
      "\n",
      " Epoch 1175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53001546859741\n",
      "\n",
      " Epoch 1176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53081607818604\n",
      "\n",
      " Epoch 1177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53090906143188\n",
      "\n",
      " Epoch 1178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53003787994385\n",
      "\n",
      " Epoch 1179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53096389770508\n",
      "\n",
      " Epoch 1180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52986860275269\n",
      "\n",
      " Epoch 1181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53051471710205\n",
      "\n",
      " Epoch 1182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53054332733154\n",
      "\n",
      " Epoch 1183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5304160118103\n",
      "\n",
      " Epoch 1184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52898359298706\n",
      "\n",
      " Epoch 1185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52954578399658\n",
      "\n",
      " Epoch 1186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53088521957397\n",
      "\n",
      " Epoch 1187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53000545501709\n",
      "\n",
      " Epoch 1188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52886247634888\n",
      "\n",
      " Epoch 1189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53119373321533\n",
      "\n",
      " Epoch 1190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52924919128418\n",
      "\n",
      " Epoch 1191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52877044677734\n",
      "\n",
      " Epoch 1192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53033065795898\n",
      "\n",
      " Epoch 1193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5298662185669\n",
      "\n",
      " Epoch 1194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52871227264404\n",
      "\n",
      " Epoch 1195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52986717224121\n",
      "\n",
      " Epoch 1196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53006982803345\n",
      "\n",
      " Epoch 1197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52968120574951\n",
      "\n",
      " Epoch 1198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52974796295166\n",
      "\n",
      " Epoch 1199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53021812438965\n",
      "\n",
      " Epoch 1200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52830743789673\n",
      "\n",
      " Epoch 1201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52972173690796\n",
      "\n",
      " Epoch 1202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5292854309082\n",
      "\n",
      " Epoch 1203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52921533584595\n",
      "\n",
      " Epoch 1204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5294132232666\n",
      "\n",
      " Epoch 1205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52983093261719\n",
      "\n",
      " Epoch 1206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53026390075684\n",
      "\n",
      " Epoch 1207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52774572372437\n",
      "\n",
      " Epoch 1208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52987909317017\n",
      "\n",
      " Epoch 1209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52849912643433\n",
      "\n",
      " Epoch 1210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52979135513306\n",
      "\n",
      " Epoch 1211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.53009748458862\n",
      "\n",
      " Epoch 1212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52886056900024\n",
      "\n",
      " Epoch 1213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5280294418335\n",
      "\n",
      " Epoch 1214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52913236618042\n",
      "\n",
      " Epoch 1215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52874994277954\n",
      "\n",
      " Epoch 1216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52955961227417\n",
      "\n",
      " Epoch 1217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52881193161011\n",
      "\n",
      " Epoch 1218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52950239181519\n",
      "\n",
      " Epoch 1219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52774715423584\n",
      "\n",
      " Epoch 1220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5295557975769\n",
      "\n",
      " Epoch 1221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52767896652222\n",
      "\n",
      " Epoch 1222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52960729598999\n",
      "\n",
      " Epoch 1223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52911424636841\n",
      "\n",
      " Epoch 1224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52678394317627\n",
      "\n",
      " Epoch 1225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5293607711792\n",
      "\n",
      " Epoch 1226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52910423278809\n",
      "\n",
      " Epoch 1227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52893686294556\n",
      "\n",
      " Epoch 1228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52768754959106\n",
      "\n",
      " Epoch 1229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52815008163452\n",
      "\n",
      " Epoch 1230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52871704101562\n",
      "\n",
      " Epoch 1231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52727699279785\n",
      "\n",
      " Epoch 1232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5288724899292\n",
      "\n",
      " Epoch 1233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5289945602417\n",
      "\n",
      " Epoch 1234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52910327911377\n",
      "\n",
      " Epoch 1235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5275616645813\n",
      "\n",
      " Epoch 1236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5289158821106\n",
      "\n",
      " Epoch 1237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5288987159729\n",
      "\n",
      " Epoch 1238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52744007110596\n",
      "\n",
      " Epoch 1239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52829694747925\n",
      "\n",
      " Epoch 1240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52850294113159\n",
      "\n",
      " Epoch 1241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52846479415894\n",
      "\n",
      " Epoch 1242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5275092124939\n",
      "\n",
      " Epoch 1243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52752447128296\n",
      "\n",
      " Epoch 1244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52843236923218\n",
      "\n",
      " Epoch 1245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52789878845215\n",
      "\n",
      " Epoch 1246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52708101272583\n",
      "\n",
      " Epoch 1247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52845573425293\n",
      "\n",
      " Epoch 1248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52742099761963\n",
      "\n",
      " Epoch 1249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52703189849854\n",
      "\n",
      " Epoch 1250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52756357192993\n",
      "\n",
      " Epoch 1251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52667427062988\n",
      "\n",
      " Epoch 1252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52828550338745\n",
      "\n",
      " Epoch 1253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52795314788818\n",
      "\n",
      " Epoch 1254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52742862701416\n",
      "\n",
      " Epoch 1255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5285062789917\n",
      "\n",
      " Epoch 1256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52778434753418\n",
      "\n",
      " Epoch 1257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52799797058105\n",
      "\n",
      " Epoch 1258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.527024269104\n",
      "\n",
      " Epoch 1259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52714109420776\n",
      "\n",
      " Epoch 1260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52807664871216\n",
      "\n",
      " Epoch 1261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52711248397827\n",
      "\n",
      " Epoch 1262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52618598937988\n",
      "\n",
      " Epoch 1263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5276403427124\n",
      "\n",
      " Epoch 1264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52781105041504\n",
      "\n",
      " Epoch 1265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52758598327637\n",
      "\n",
      " Epoch 1266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52718448638916\n",
      "\n",
      " Epoch 1267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52822828292847\n",
      "\n",
      " Epoch 1268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52596712112427\n",
      "\n",
      " Epoch 1269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52774047851562\n",
      "\n",
      " Epoch 1270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52606439590454\n",
      "\n",
      " Epoch 1271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5267014503479\n",
      "\n",
      " Epoch 1272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5278639793396\n",
      "\n",
      " Epoch 1273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5268611907959\n",
      "\n",
      " Epoch 1274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52591562271118\n",
      "\n",
      " Epoch 1275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52704334259033\n",
      "\n",
      " Epoch 1276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52754068374634\n",
      "\n",
      " Epoch 1277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52772426605225\n",
      "\n",
      " Epoch 1278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52735090255737\n",
      "\n",
      " Epoch 1279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52524709701538\n",
      "\n",
      " Epoch 1280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52764654159546\n",
      "\n",
      " Epoch 1281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52765083312988\n",
      "\n",
      " Epoch 1282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52652359008789\n",
      "\n",
      " Epoch 1283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52570247650146\n",
      "\n",
      " Epoch 1284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52754068374634\n",
      "\n",
      " Epoch 1285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52687883377075\n",
      "\n",
      " Epoch 1286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52714109420776\n",
      "\n",
      " Epoch 1287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52667474746704\n",
      "\n",
      " Epoch 1288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52577114105225\n",
      "\n",
      " Epoch 1289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52734470367432\n",
      "\n",
      " Epoch 1290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52707624435425\n",
      "\n",
      " Epoch 1291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52657508850098\n",
      "\n",
      " Epoch 1292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52686929702759\n",
      "\n",
      " Epoch 1293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5267744064331\n",
      "\n",
      " Epoch 1294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5277099609375\n",
      "\n",
      " Epoch 1295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52655553817749\n",
      "\n",
      " Epoch 1296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5258560180664\n",
      "\n",
      " Epoch 1297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52637720108032\n",
      "\n",
      " Epoch 1298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52726173400879\n",
      "\n",
      " Epoch 1299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52737474441528\n",
      "\n",
      " Epoch 1300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52518320083618\n",
      "\n",
      " Epoch 1301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52704668045044\n",
      "\n",
      " Epoch 1302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52605438232422\n",
      "\n",
      " Epoch 1303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52671575546265\n",
      "\n",
      " Epoch 1304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52706098556519\n",
      "\n",
      " Epoch 1305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52627611160278\n",
      "\n",
      " Epoch 1306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52523517608643\n",
      "\n",
      " Epoch 1307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52692604064941\n",
      "\n",
      " Epoch 1308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52625274658203\n",
      "\n",
      " Epoch 1309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52663850784302\n",
      "\n",
      " Epoch 1310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.526047706604\n",
      "\n",
      " Epoch 1311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52637052536011\n",
      "\n",
      " Epoch 1312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52667284011841\n",
      "\n",
      " Epoch 1313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52623748779297\n",
      "\n",
      " Epoch 1314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528762817383\n",
      "\n",
      " Epoch 1315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52669477462769\n",
      "\n",
      " Epoch 1316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5268006324768\n",
      "\n",
      " Epoch 1317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52539348602295\n",
      "\n",
      " Epoch 1318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52627801895142\n",
      "\n",
      " Epoch 1319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52707576751709\n",
      "\n",
      " Epoch 1320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52519512176514\n",
      "\n",
      " Epoch 1321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52682161331177\n",
      "\n",
      " Epoch 1322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52624559402466\n",
      "\n",
      " Epoch 1323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52587175369263\n",
      "\n",
      " Epoch 1324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52583408355713\n",
      "\n",
      " Epoch 1325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52656650543213\n",
      "\n",
      " Epoch 1326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52544927597046\n",
      "\n",
      " Epoch 1327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5266342163086\n",
      "\n",
      " Epoch 1328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52559423446655\n",
      "\n",
      " Epoch 1329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52571964263916\n",
      "\n",
      " Epoch 1330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52681016921997\n",
      "\n",
      " Epoch 1331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52549362182617\n",
      "\n",
      " Epoch 1332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52565574645996\n",
      "\n",
      " Epoch 1333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52656173706055\n",
      "\n",
      " Epoch 1334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52630281448364\n",
      "\n",
      " Epoch 1335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528095245361\n",
      "\n",
      " Epoch 1336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52604818344116\n",
      "\n",
      " Epoch 1337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52581739425659\n",
      "\n",
      " Epoch 1338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52642822265625\n",
      "\n",
      " Epoch 1339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52556276321411\n",
      "\n",
      " Epoch 1340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5259051322937\n",
      "\n",
      " Epoch 1341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52610397338867\n",
      "\n",
      " Epoch 1342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52571535110474\n",
      "\n",
      " Epoch 1343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52563238143921\n",
      "\n",
      " Epoch 1344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52595043182373\n",
      "\n",
      " Epoch 1345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52535581588745\n",
      "\n",
      " Epoch 1346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52668952941895\n",
      "\n",
      " Epoch 1347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52563762664795\n",
      "\n",
      " Epoch 1348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52572631835938\n",
      "\n",
      " Epoch 1349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5258116722107\n",
      "\n",
      " Epoch 1350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52553462982178\n",
      "\n",
      " Epoch 1351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52599906921387\n",
      "\n",
      " Epoch 1352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52500915527344\n",
      "\n",
      " Epoch 1353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52613878250122\n",
      "\n",
      " Epoch 1354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52535247802734\n",
      "\n",
      " Epoch 1355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52586936950684\n",
      "\n",
      " Epoch 1356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52651357650757\n",
      "\n",
      " Epoch 1357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5260419845581\n",
      "\n",
      " Epoch 1358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5255217552185\n",
      "\n",
      " Epoch 1359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52613639831543\n",
      "\n",
      " Epoch 1360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5254578590393\n",
      "\n",
      " Epoch 1361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5254578590393\n",
      "\n",
      " Epoch 1362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52630376815796\n",
      "\n",
      " Epoch 1363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52631759643555\n",
      "\n",
      " Epoch 1364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52538919448853\n",
      "\n",
      " Epoch 1365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52552461624146\n",
      "\n",
      " Epoch 1366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52543687820435\n",
      "\n",
      " Epoch 1367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52544498443604\n",
      "\n",
      " Epoch 1368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52636289596558\n",
      "\n",
      " Epoch 1369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52619504928589\n",
      "\n",
      " Epoch 1370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52468061447144\n",
      "\n",
      " Epoch 1371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52605199813843\n",
      "\n",
      " Epoch 1372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528953552246\n",
      "\n",
      " Epoch 1373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528619766235\n",
      "\n",
      " Epoch 1374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5260534286499\n",
      "\n",
      " Epoch 1375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5252776145935\n",
      "\n",
      " Epoch 1376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5250735282898\n",
      "\n",
      " Epoch 1377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52531337738037\n",
      "\n",
      " Epoch 1378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52624654769897\n",
      "\n",
      " Epoch 1379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52600574493408\n",
      "\n",
      " Epoch 1380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5245771408081\n",
      "\n",
      " Epoch 1381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52594661712646\n",
      "\n",
      " Epoch 1382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52581834793091\n",
      "\n",
      " Epoch 1383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52450942993164\n",
      "\n",
      " Epoch 1384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52618837356567\n",
      "\n",
      " Epoch 1385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52605962753296\n",
      "\n",
      " Epoch 1386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5245041847229\n",
      "\n",
      " Epoch 1387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52582025527954\n",
      "\n",
      " Epoch 1388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52581548690796\n",
      "\n",
      " Epoch 1389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52503204345703\n",
      "\n",
      " Epoch 1390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52547979354858\n",
      "\n",
      " Epoch 1391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52600908279419\n",
      "\n",
      " Epoch 1392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52516651153564\n",
      "\n",
      " Epoch 1393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52516651153564\n",
      "\n",
      " Epoch 1394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52547597885132\n",
      "\n",
      " Epoch 1395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52525901794434\n",
      "\n",
      " Epoch 1396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52549982070923\n",
      "\n",
      " Epoch 1397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52540826797485\n",
      "\n",
      " Epoch 1398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52567720413208\n",
      "\n",
      " Epoch 1399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52442073822021\n",
      "\n",
      " Epoch 1400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5260705947876\n",
      "\n",
      " Epoch 1401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5258412361145\n",
      "\n",
      " Epoch 1402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52505159378052\n",
      "\n",
      " Epoch 1403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52505302429199\n",
      "\n",
      " Epoch 1404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52537441253662\n",
      "\n",
      " Epoch 1405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52510070800781\n",
      "\n",
      " Epoch 1406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52536344528198\n",
      "\n",
      " Epoch 1407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52583932876587\n",
      "\n",
      " Epoch 1408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52495050430298\n",
      "\n",
      " Epoch 1409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52498483657837\n",
      "\n",
      " Epoch 1410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52555561065674\n",
      "\n",
      " Epoch 1411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52475261688232\n",
      "\n",
      " Epoch 1412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52529096603394\n",
      "\n",
      " Epoch 1413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52577686309814\n",
      "\n",
      " Epoch 1414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5248966217041\n",
      "\n",
      " Epoch 1415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52493906021118\n",
      "\n",
      " Epoch 1416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52519607543945\n",
      "\n",
      " Epoch 1417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52489995956421\n",
      "\n",
      " Epoch 1418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52583074569702\n",
      "\n",
      " Epoch 1419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52463483810425\n",
      "\n",
      " Epoch 1420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52504110336304\n",
      "\n",
      " Epoch 1421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52549600601196\n",
      "\n",
      " Epoch 1422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52478885650635\n",
      "\n",
      " Epoch 1423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52475786209106\n",
      "\n",
      " Epoch 1424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52533912658691\n",
      "\n",
      " Epoch 1425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52476835250854\n",
      "\n",
      " Epoch 1426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52395534515381\n",
      "\n",
      " Epoch 1427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52555513381958\n",
      "\n",
      " Epoch 1428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528381347656\n",
      "\n",
      " Epoch 1429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52388954162598\n",
      "\n",
      " Epoch 1430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52531719207764\n",
      "\n",
      " Epoch 1431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52394771575928\n",
      "\n",
      " Epoch 1432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52541828155518\n",
      "\n",
      " Epoch 1433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52475023269653\n",
      "\n",
      " Epoch 1434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5245099067688\n",
      "\n",
      " Epoch 1435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52475357055664\n",
      "\n",
      " Epoch 1436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52459239959717\n",
      "\n",
      " Epoch 1437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52469825744629\n",
      "\n",
      " Epoch 1438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5251898765564\n",
      "\n",
      " Epoch 1439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52352094650269\n",
      "\n",
      " Epoch 1440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52509832382202\n",
      "\n",
      " Epoch 1441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52487373352051\n",
      "\n",
      " Epoch 1442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52480697631836\n",
      "\n",
      " Epoch 1443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5245304107666\n",
      "\n",
      " Epoch 1444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5238881111145\n",
      "\n",
      " Epoch 1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52534484863281\n",
      "\n",
      " Epoch 1446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52475357055664\n",
      "\n",
      " Epoch 1447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52399110794067\n",
      "\n",
      " Epoch 1448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52527284622192\n",
      "\n",
      " Epoch 1449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5243444442749\n",
      "\n",
      " Epoch 1450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52468299865723\n",
      "\n",
      " Epoch 1451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52537775039673\n",
      "\n",
      " Epoch 1452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5248646736145\n",
      "\n",
      " Epoch 1453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52447414398193\n",
      "\n",
      " Epoch 1454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52450895309448\n",
      "\n",
      " Epoch 1455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52531003952026\n",
      "\n",
      " Epoch 1456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52405595779419\n",
      "\n",
      " Epoch 1457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5251317024231\n",
      "\n",
      " Epoch 1458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52529191970825\n",
      "\n",
      " Epoch 1459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52340936660767\n",
      "\n",
      " Epoch 1460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52532243728638\n",
      "\n",
      " Epoch 1461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52480459213257\n",
      "\n",
      " Epoch 1462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52456331253052\n",
      "\n",
      " Epoch 1463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52542877197266\n",
      "\n",
      " Epoch 1464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52418518066406\n",
      "\n",
      " Epoch 1465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52456855773926\n",
      "\n",
      " Epoch 1466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5252594947815\n",
      "\n",
      " Epoch 1467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52518939971924\n",
      "\n",
      " Epoch 1468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52419853210449\n",
      "\n",
      " Epoch 1469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52468967437744\n",
      "\n",
      " Epoch 1470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52518939971924\n",
      "\n",
      " Epoch 1471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52359342575073\n",
      "\n",
      " Epoch 1472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5248703956604\n",
      "\n",
      " Epoch 1473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52491188049316\n",
      "\n",
      " Epoch 1474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52406024932861\n",
      "\n",
      " Epoch 1475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52485799789429\n",
      "\n",
      " Epoch 1476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52485370635986\n",
      "\n",
      " Epoch 1477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52540159225464\n",
      "\n",
      " Epoch 1478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5236120223999\n",
      "\n",
      " Epoch 1479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52421998977661\n",
      "\n",
      " Epoch 1480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52493906021118\n",
      "\n",
      " Epoch 1481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52383613586426\n",
      "\n",
      " Epoch 1482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52493524551392\n",
      "\n",
      " Epoch 1483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52481412887573\n",
      "\n",
      " Epoch 1484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52389335632324\n",
      "\n",
      " Epoch 1485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52528285980225\n",
      "\n",
      " Epoch 1486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52453804016113\n",
      "\n",
      " Epoch 1487\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5236554145813\n",
      "\n",
      " Epoch 1488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52470254898071\n",
      "\n",
      " Epoch 1489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5246467590332\n",
      "\n",
      " Epoch 1490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52415084838867\n",
      "\n",
      " Epoch 1491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52510738372803\n",
      "\n",
      " Epoch 1492\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52436876296997\n",
      "\n",
      " Epoch 1493\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5233907699585\n",
      "\n",
      " Epoch 1494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52488279342651\n",
      "\n",
      " Epoch 1495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52441644668579\n",
      "\n",
      " Epoch 1496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52372694015503\n",
      "\n",
      " Epoch 1497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52493858337402\n",
      "\n",
      " Epoch 1498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52514171600342\n",
      "\n",
      " Epoch 1499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52396202087402\n",
      "\n",
      " Epoch 1500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52454853057861\n",
      "\n",
      " Epoch 1501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5246934890747\n",
      "\n",
      " Epoch 1502\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52369737625122\n",
      "\n",
      " Epoch 1503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52471685409546\n",
      "\n",
      " Epoch 1504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52463817596436\n",
      "\n",
      " Epoch 1505\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52415466308594\n",
      "\n",
      " Epoch 1506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52465200424194\n",
      "\n",
      " Epoch 1507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52439832687378\n",
      "\n",
      " Epoch 1508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52418804168701\n",
      "\n",
      " Epoch 1509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52482557296753\n",
      "\n",
      " Epoch 1510\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5240683555603\n",
      "\n",
      " Epoch 1511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52383995056152\n",
      "\n",
      " Epoch 1512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52441501617432\n",
      "\n",
      " Epoch 1513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52411937713623\n",
      "\n",
      " Epoch 1514\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52473545074463\n",
      "\n",
      " Epoch 1515\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52426624298096\n",
      "\n",
      " Epoch 1516\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5238995552063\n",
      "\n",
      " Epoch 1517\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52448463439941\n",
      "\n",
      " Epoch 1518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52420425415039\n",
      "\n",
      " Epoch 1519\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52434206008911\n",
      "\n",
      " Epoch 1520\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52395677566528\n",
      "\n",
      " Epoch 1521\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52375507354736\n",
      "\n",
      " Epoch 1522\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52448797225952\n",
      "\n",
      " Epoch 1523\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52497482299805\n",
      "\n",
      " Epoch 1524\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52329921722412\n",
      "\n",
      " Epoch 1525\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5247163772583\n",
      "\n",
      " Epoch 1526\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52444982528687\n",
      "\n",
      " Epoch 1527\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5249514579773\n",
      "\n",
      " Epoch 1528\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52374839782715\n",
      "\n",
      " Epoch 1529\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52417230606079\n",
      "\n",
      " Epoch 1530\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52374362945557\n",
      "\n",
      " Epoch 1531\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52464962005615\n",
      "\n",
      " Epoch 1532\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5239930152893\n",
      "\n",
      " Epoch 1533\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5244140625\n",
      "\n",
      " Epoch 1534\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52393341064453\n",
      "\n",
      " Epoch 1535\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52438259124756\n",
      "\n",
      " Epoch 1536\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52401208877563\n",
      "\n",
      " Epoch 1537\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52374792098999\n",
      "\n",
      " Epoch 1538\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52460241317749\n",
      "\n",
      " Epoch 1539\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52426528930664\n",
      "\n",
      " Epoch 1540\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52329015731812\n",
      "\n",
      " Epoch 1541\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52420473098755\n",
      "\n",
      " Epoch 1542\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52422666549683\n",
      "\n",
      " Epoch 1543\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52454566955566\n",
      "\n",
      " Epoch 1544\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52305030822754\n",
      "\n",
      " Epoch 1545\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52436256408691\n",
      "\n",
      " Epoch 1546\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52344369888306\n",
      "\n",
      " Epoch 1547\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52345180511475\n",
      "\n",
      " Epoch 1548\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5243444442749\n",
      "\n",
      " Epoch 1549\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52386665344238\n",
      "\n",
      " Epoch 1550\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52364444732666\n",
      "\n",
      " Epoch 1551\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5245475769043\n",
      "\n",
      " Epoch 1552\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52317190170288\n",
      "\n",
      " Epoch 1553\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52410745620728\n",
      "\n",
      " Epoch 1554\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52363729476929\n",
      "\n",
      " Epoch 1555\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52361297607422\n",
      "\n",
      " Epoch 1556\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52424049377441\n",
      "\n",
      " Epoch 1557\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5233211517334\n",
      "\n",
      " Epoch 1558\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52428817749023\n",
      "\n",
      " Epoch 1559\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52379083633423\n",
      "\n",
      " Epoch 1560\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52353382110596\n",
      "\n",
      " Epoch 1561\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52443027496338\n",
      "\n",
      " Epoch 1562\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52306032180786\n",
      "\n",
      " Epoch 1563\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52399206161499\n",
      "\n",
      " Epoch 1564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52349805831909\n",
      "\n",
      " Epoch 1565\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52349519729614\n",
      "\n",
      " Epoch 1566\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52414846420288\n",
      "\n",
      " Epoch 1567\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52300262451172\n",
      "\n",
      " Epoch 1568\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52321434020996\n",
      "\n",
      " Epoch 1569\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5241346359253\n",
      "\n",
      " Epoch 1570\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52354145050049\n",
      "\n",
      " Epoch 1571\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52413749694824\n",
      "\n",
      " Epoch 1572\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52352380752563\n",
      "\n",
      " Epoch 1573\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52418041229248\n",
      "\n",
      " Epoch 1574\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52318859100342\n",
      "\n",
      " Epoch 1575\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52388286590576\n",
      "\n",
      " Epoch 1576\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52359199523926\n",
      "\n",
      " Epoch 1577\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52384853363037\n",
      "\n",
      " Epoch 1578\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52342557907104\n",
      "\n",
      " Epoch 1579\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52387285232544\n",
      "\n",
      " Epoch 1580\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52338457107544\n",
      "\n",
      " Epoch 1581\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52335834503174\n",
      "\n",
      " Epoch 1582\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5240044593811\n",
      "\n",
      " Epoch 1583\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52339887619019\n",
      "\n",
      " Epoch 1584\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52406454086304\n",
      "\n",
      " Epoch 1585\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52325010299683\n",
      "\n",
      " Epoch 1586\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52407550811768\n",
      "\n",
      " Epoch 1587\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52263069152832\n",
      "\n",
      " Epoch 1588\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52398490905762\n",
      "\n",
      " Epoch 1589\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52373313903809\n",
      "\n",
      " Epoch 1590\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52306938171387\n",
      "\n",
      " Epoch 1591\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52290391921997\n",
      "\n",
      " Epoch 1592\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5231785774231\n",
      "\n",
      " Epoch 1593\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52388620376587\n",
      "\n",
      " Epoch 1594\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52327060699463\n",
      "\n",
      " Epoch 1595\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52397346496582\n",
      "\n",
      " Epoch 1596\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52297782897949\n",
      "\n",
      " Epoch 1597\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52367544174194\n",
      "\n",
      " Epoch 1598\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52318143844604\n",
      "\n",
      " Epoch 1599\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52338123321533\n",
      "\n",
      " Epoch 1600\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52365016937256\n",
      "\n",
      " Epoch 1601\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52320957183838\n",
      "\n",
      " Epoch 1602\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52392816543579\n",
      "\n",
      " Epoch 1603\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52295255661011\n",
      "\n",
      " Epoch 1604\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52383422851562\n",
      "\n",
      " Epoch 1605\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52316045761108\n",
      "\n",
      " Epoch 1606\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5232048034668\n",
      "\n",
      " Epoch 1607\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52363348007202\n",
      "\n",
      " Epoch 1608\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52305221557617\n",
      "\n",
      " Epoch 1609\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52383327484131\n",
      "\n",
      " Epoch 1610\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52305459976196\n",
      "\n",
      " Epoch 1611\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52362728118896\n",
      "\n",
      " Epoch 1612\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52312517166138\n",
      "\n",
      " Epoch 1613\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52313613891602\n",
      "\n",
      " Epoch 1614\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52350997924805\n",
      "\n",
      " Epoch 1615\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52305555343628\n",
      "\n",
      " Epoch 1616\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52306842803955\n",
      "\n",
      " Epoch 1617\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52366399765015\n",
      "\n",
      " Epoch 1618\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5233063697815\n",
      "\n",
      " Epoch 1619\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52301788330078\n",
      "\n",
      " Epoch 1620\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52305221557617\n",
      "\n",
      " Epoch 1621\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52327728271484\n",
      "\n",
      " Epoch 1622\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52343988418579\n",
      "\n",
      " Epoch 1623\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52297639846802\n",
      "\n",
      " Epoch 1624\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52368021011353\n",
      "\n",
      " Epoch 1625\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52374076843262\n",
      "\n",
      " Epoch 1626\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52290916442871\n",
      "\n",
      " Epoch 1627\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52320575714111\n",
      "\n",
      " Epoch 1628\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52287530899048\n",
      "\n",
      " Epoch 1629\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52362442016602\n",
      "\n",
      " Epoch 1630\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52268648147583\n",
      "\n",
      " Epoch 1631\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52335596084595\n",
      "\n",
      " Epoch 1632\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52388954162598\n",
      "\n",
      " Epoch 1633\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52263402938843\n",
      "\n",
      " Epoch 1634\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52361631393433\n",
      "\n",
      " Epoch 1635\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52334117889404\n",
      "\n",
      " Epoch 1636\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52298021316528\n",
      "\n",
      " Epoch 1637\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52339839935303\n",
      "\n",
      " Epoch 1638\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52287149429321\n",
      "\n",
      " Epoch 1639\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52374935150146\n",
      "\n",
      " Epoch 1640\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52233266830444\n",
      "\n",
      " Epoch 1641\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52304983139038\n",
      "\n",
      " Epoch 1642\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.523521900177\n",
      "\n",
      " Epoch 1643\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52279043197632\n",
      "\n",
      " Epoch 1644\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52274513244629\n",
      "\n",
      " Epoch 1645\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52323818206787\n",
      "\n",
      " Epoch 1646\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52373743057251\n",
      "\n",
      " Epoch 1647\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52305555343628\n",
      "\n",
      " Epoch 1648\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52259492874146\n",
      "\n",
      " Epoch 1649\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5224838256836\n",
      "\n",
      " Epoch 1650\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52340316772461\n",
      "\n",
      " Epoch 1651\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52345848083496\n",
      "\n",
      " Epoch 1652\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52371072769165\n",
      "\n",
      " Epoch 1653\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5222430229187\n",
      "\n",
      " Epoch 1654\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52245855331421\n",
      "\n",
      " Epoch 1655\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52337169647217\n",
      "\n",
      " Epoch 1656\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52270555496216\n",
      "\n",
      " Epoch 1657\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52287340164185\n",
      "\n",
      " Epoch 1658\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52357006072998\n",
      "\n",
      " Epoch 1659\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52238893508911\n",
      "\n",
      " Epoch 1660\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5226182937622\n",
      "\n",
      " Epoch 1661\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52310705184937\n",
      "\n",
      " Epoch 1662\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52343940734863\n",
      "\n",
      " Epoch 1663\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52307081222534\n",
      "\n",
      " Epoch 1664\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52189493179321\n",
      "\n",
      " Epoch 1665\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5230450630188\n",
      "\n",
      " Epoch 1666\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52346849441528\n",
      "\n",
      " Epoch 1667\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52272939682007\n",
      "\n",
      " Epoch 1668\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52264499664307\n",
      "\n",
      " Epoch 1669\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52226066589355\n",
      "\n",
      " Epoch 1670\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52322959899902\n",
      "\n",
      " Epoch 1671\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52331113815308\n",
      "\n",
      " Epoch 1672\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52256441116333\n",
      "\n",
      " Epoch 1673\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52146196365356\n",
      "\n",
      " Epoch 1674\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52287864685059\n",
      "\n",
      " Epoch 1675\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52337646484375\n",
      "\n",
      " Epoch 1676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52272701263428\n",
      "\n",
      " Epoch 1677\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5224781036377\n",
      "\n",
      " Epoch 1678\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52278232574463\n",
      "\n",
      " Epoch 1679\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52252340316772\n",
      "\n",
      " Epoch 1680\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52321338653564\n",
      "\n",
      " Epoch 1681\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52320289611816\n",
      "\n",
      " Epoch 1682\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52241516113281\n",
      "\n",
      " Epoch 1683\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52244806289673\n",
      "\n",
      " Epoch 1684\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52207279205322\n",
      "\n",
      " Epoch 1685\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5230827331543\n",
      "\n",
      " Epoch 1686\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52213048934937\n",
      "\n",
      " Epoch 1687\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52203941345215\n",
      "\n",
      " Epoch 1688\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5230622291565\n",
      "\n",
      " Epoch 1689\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5230188369751\n",
      "\n",
      " Epoch 1690\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52240133285522\n",
      "\n",
      " Epoch 1691\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52213478088379\n",
      "\n",
      " Epoch 1692\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52256441116333\n",
      "\n",
      " Epoch 1693\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52226066589355\n",
      "\n",
      " Epoch 1694\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52305364608765\n",
      "\n",
      " Epoch 1695\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.522047996521\n",
      "\n",
      " Epoch 1696\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52201509475708\n",
      "\n",
      " Epoch 1697\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52298927307129\n",
      "\n",
      " Epoch 1698\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5229263305664\n",
      "\n",
      " Epoch 1699\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52232837677002\n",
      "\n",
      " Epoch 1700\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52206230163574\n",
      "\n",
      " Epoch 1701\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52242517471313\n",
      "\n",
      " Epoch 1702\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52218437194824\n",
      "\n",
      " Epoch 1703\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5222339630127\n",
      "\n",
      " Epoch 1704\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52242755889893\n",
      "\n",
      " Epoch 1705\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52214050292969\n",
      "\n",
      " Epoch 1706\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52288436889648\n",
      "\n",
      " Epoch 1707\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52294826507568\n",
      "\n",
      " Epoch 1708\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52189779281616\n",
      "\n",
      " Epoch 1709\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5219898223877\n",
      "\n",
      " Epoch 1710\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52233552932739\n",
      "\n",
      " Epoch 1711\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52208757400513\n",
      "\n",
      " Epoch 1712\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5228762626648\n",
      "\n",
      " Epoch 1713\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52263164520264\n",
      "\n",
      " Epoch 1714\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52143335342407\n",
      "\n",
      " Epoch 1715\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52255868911743\n",
      "\n",
      " Epoch 1716\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52273368835449\n",
      "\n",
      " Epoch 1717\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52109289169312\n",
      "\n",
      " Epoch 1718\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52206754684448\n",
      "\n",
      " Epoch 1719\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52281141281128\n",
      "\n",
      " Epoch 1720\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5220742225647\n",
      "\n",
      " Epoch 1721\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5228328704834\n",
      "\n",
      " Epoch 1722\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52133417129517\n",
      "\n",
      " Epoch 1723\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52195835113525\n",
      "\n",
      " Epoch 1724\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52270269393921\n",
      "\n",
      " Epoch 1725\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52129602432251\n",
      "\n",
      " Epoch 1726\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5221381187439\n",
      "\n",
      " Epoch 1727\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5224437713623\n",
      "\n",
      " Epoch 1728\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52126026153564\n",
      "\n",
      " Epoch 1729\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52201557159424\n",
      "\n",
      " Epoch 1730\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52237939834595\n",
      "\n",
      " Epoch 1731\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52239656448364\n",
      "\n",
      " Epoch 1732\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52191352844238\n",
      "\n",
      " Epoch 1733\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52201795578003\n",
      "\n",
      " Epoch 1734\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52218818664551\n",
      "\n",
      " Epoch 1735\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52173137664795\n",
      "\n",
      " Epoch 1736\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52244234085083\n",
      "\n",
      " Epoch 1737\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52233505249023\n",
      "\n",
      " Epoch 1738\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52176237106323\n",
      "\n",
      " Epoch 1739\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52196073532104\n",
      "\n",
      " Epoch 1740\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52166700363159\n",
      "\n",
      " Epoch 1741\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52193546295166\n",
      "\n",
      " Epoch 1742\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52219820022583\n",
      "\n",
      " Epoch 1743\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52182912826538\n",
      "\n",
      " Epoch 1744\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52101516723633\n",
      "\n",
      " Epoch 1745\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52211236953735\n",
      "\n",
      " Epoch 1746\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52239561080933\n",
      "\n",
      " Epoch 1747\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52093982696533\n",
      "\n",
      " Epoch 1748\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5221037864685\n",
      "\n",
      " Epoch 1749\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52213287353516\n",
      "\n",
      " Epoch 1750\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52221345901489\n",
      "\n",
      " Epoch 1751\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52174711227417\n",
      "\n",
      " Epoch 1752\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52161693572998\n",
      "\n",
      " Epoch 1753\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52177238464355\n",
      "\n",
      " Epoch 1754\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5214467048645\n",
      "\n",
      " Epoch 1755\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52152395248413\n",
      "\n",
      " Epoch 1756\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52199029922485\n",
      "\n",
      " Epoch 1757\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5207781791687\n",
      "\n",
      " Epoch 1758\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52193260192871\n",
      "\n",
      " Epoch 1759\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5222716331482\n",
      "\n",
      " Epoch 1760\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52081441879272\n",
      "\n",
      " Epoch 1761\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52189683914185\n",
      "\n",
      " Epoch 1762\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52218961715698\n",
      "\n",
      " Epoch 1763\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52094888687134\n",
      "\n",
      " Epoch 1764\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5216875076294\n",
      "\n",
      " Epoch 1765\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52136898040771\n",
      "\n",
      " Epoch 1766\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52149438858032\n",
      "\n",
      " Epoch 1767\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52171611785889\n",
      "\n",
      " Epoch 1768\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52176475524902\n",
      "\n",
      " Epoch 1769\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5206151008606\n",
      "\n",
      " Epoch 1770\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52183485031128\n",
      "\n",
      " Epoch 1771\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52205419540405\n",
      "\n",
      " Epoch 1772\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52055978775024\n",
      "\n",
      " Epoch 1773\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52175426483154\n",
      "\n",
      " Epoch 1774\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52202796936035\n",
      "\n",
      " Epoch 1775\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5208625793457\n",
      "\n",
      " Epoch 1776\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52140045166016\n",
      "\n",
      " Epoch 1777\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52203416824341\n",
      "\n",
      " Epoch 1778\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52100372314453\n",
      "\n",
      " Epoch 1779\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5203070640564\n",
      "\n",
      " Epoch 1780\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52159833908081\n",
      "\n",
      " Epoch 1781\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52209377288818\n",
      "\n",
      " Epoch 1782\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52137565612793\n",
      "\n",
      " Epoch 1783\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52105379104614\n",
      "\n",
      " Epoch 1784\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52108860015869\n",
      "\n",
      " Epoch 1785\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52172136306763\n",
      "\n",
      " Epoch 1786\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52061653137207\n",
      "\n",
      " Epoch 1787\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52165174484253\n",
      "\n",
      " Epoch 1788\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52168607711792\n",
      "\n",
      " Epoch 1789\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52055311203003\n",
      "\n",
      " Epoch 1790\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52178955078125\n",
      "\n",
      " Epoch 1791\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52099180221558\n",
      "\n",
      " Epoch 1792\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52061891555786\n",
      "\n",
      " Epoch 1793\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52093124389648\n",
      "\n",
      " Epoch 1794\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52192211151123\n",
      "\n",
      " Epoch 1795\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52228212356567\n",
      "\n",
      " Epoch 1796\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51992654800415\n",
      "\n",
      " Epoch 1797\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52171754837036\n",
      "\n",
      " Epoch 1798\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss :  82.52099943161011\n",
      "\n",
      " Epoch 1799\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52131271362305\n",
      "\n",
      " Epoch 1800\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52030849456787\n",
      "\n",
      " Epoch 1801\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52160978317261\n",
      "\n",
      " Epoch 1802\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5217342376709\n",
      "\n",
      " Epoch 1803\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52045488357544\n",
      "\n",
      " Epoch 1804\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52076864242554\n",
      "\n",
      " Epoch 1805\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51994705200195\n",
      "\n",
      " Epoch 1806\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52169370651245\n",
      "\n",
      " Epoch 1807\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5213303565979\n",
      "\n",
      " Epoch 1808\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52083110809326\n",
      "\n",
      " Epoch 1809\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52075576782227\n",
      "\n",
      " Epoch 1810\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52095079421997\n",
      "\n",
      " Epoch 1811\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52132081985474\n",
      "\n",
      " Epoch 1812\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52052021026611\n",
      "\n",
      " Epoch 1813\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52118349075317\n",
      "\n",
      " Epoch 1814\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5211763381958\n",
      "\n",
      " Epoch 1815\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52081298828125\n",
      "\n",
      " Epoch 1816\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52102565765381\n",
      "\n",
      " Epoch 1817\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52109241485596\n",
      "\n",
      " Epoch 1818\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52006721496582\n",
      "\n",
      " Epoch 1819\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52128601074219\n",
      "\n",
      " Epoch 1820\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52132987976074\n",
      "\n",
      " Epoch 1821\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52001476287842\n",
      "\n",
      " Epoch 1822\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52107000350952\n",
      "\n",
      " Epoch 1823\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5215516090393\n",
      "\n",
      " Epoch 1824\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52017259597778\n",
      "\n",
      " Epoch 1825\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5210771560669\n",
      "\n",
      " Epoch 1826\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5205192565918\n",
      "\n",
      " Epoch 1827\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52049922943115\n",
      "\n",
      " Epoch 1828\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52146244049072\n",
      "\n",
      " Epoch 1829\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52154922485352\n",
      "\n",
      " Epoch 1830\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51980543136597\n",
      "\n",
      " Epoch 1831\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52103662490845\n",
      "\n",
      " Epoch 1832\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52078342437744\n",
      "\n",
      " Epoch 1833\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52046871185303\n",
      "\n",
      " Epoch 1834\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52069568634033\n",
      "\n",
      " Epoch 1835\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52038478851318\n",
      "\n",
      " Epoch 1836\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52137327194214\n",
      "\n",
      " Epoch 1837\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52126455307007\n",
      "\n",
      " Epoch 1838\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51967477798462\n",
      "\n",
      " Epoch 1839\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52113580703735\n",
      "\n",
      " Epoch 1840\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52042961120605\n",
      "\n",
      " Epoch 1841\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52039051055908\n",
      "\n",
      " Epoch 1842\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52135610580444\n",
      "\n",
      " Epoch 1843\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52052927017212\n",
      "\n",
      " Epoch 1844\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52006959915161\n",
      "\n",
      " Epoch 1845\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52061367034912\n",
      "\n",
      " Epoch 1846\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52101373672485\n",
      "\n",
      " Epoch 1847\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52061462402344\n",
      "\n",
      " Epoch 1848\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52070617675781\n",
      "\n",
      " Epoch 1849\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52032661437988\n",
      "\n",
      " Epoch 1850\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52128887176514\n",
      "\n",
      " Epoch 1851\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52120447158813\n",
      "\n",
      " Epoch 1852\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51964473724365\n",
      "\n",
      " Epoch 1853\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5208067893982\n",
      "\n",
      " Epoch 1854\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5213041305542\n",
      "\n",
      " Epoch 1855\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51994037628174\n",
      "\n",
      " Epoch 1856\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52094030380249\n",
      "\n",
      " Epoch 1857\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52110576629639\n",
      "\n",
      " Epoch 1858\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51960849761963\n",
      "\n",
      " Epoch 1859\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52076435089111\n",
      "\n",
      " Epoch 1860\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52056169509888\n",
      "\n",
      " Epoch 1861\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.520272731781\n",
      "\n",
      " Epoch 1862\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52120876312256\n",
      "\n",
      " Epoch 1863\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51980304718018\n",
      "\n",
      " Epoch 1864\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52066230773926\n",
      "\n",
      " Epoch 1865\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5213851928711\n",
      "\n",
      " Epoch 1866\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51957941055298\n",
      "\n",
      " Epoch 1867\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52078247070312\n",
      "\n",
      " Epoch 1868\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5209174156189\n",
      "\n",
      " Epoch 1869\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51954889297485\n",
      "\n",
      " Epoch 1870\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52097272872925\n",
      "\n",
      " Epoch 1871\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51965570449829\n",
      "\n",
      " Epoch 1872\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52090501785278\n",
      "\n",
      " Epoch 1873\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52093648910522\n",
      "\n",
      " Epoch 1874\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51960849761963\n",
      "\n",
      " Epoch 1875\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52067184448242\n",
      "\n",
      " Epoch 1876\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5208625793457\n",
      "\n",
      " Epoch 1877\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5197401046753\n",
      "\n",
      " Epoch 1878\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52091693878174\n",
      "\n",
      " Epoch 1879\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52090787887573\n",
      "\n",
      " Epoch 1880\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51937484741211\n",
      "\n",
      " Epoch 1881\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52093887329102\n",
      "\n",
      " Epoch 1882\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52026891708374\n",
      "\n",
      " Epoch 1883\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51982069015503\n",
      "\n",
      " Epoch 1884\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52107000350952\n",
      "\n",
      " Epoch 1885\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51964902877808\n",
      "\n",
      " Epoch 1886\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52190685272217\n",
      "\n",
      " Epoch 1887\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52154445648193\n",
      "\n",
      " Epoch 1888\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52139234542847\n",
      "\n",
      " Epoch 1889\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52108764648438\n",
      "\n",
      " Epoch 1890\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52213621139526\n",
      "\n",
      " Epoch 1891\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52192687988281\n",
      "\n",
      " Epoch 1892\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52088689804077\n",
      "\n",
      " Epoch 1893\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5216236114502\n",
      "\n",
      " Epoch 1894\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52173233032227\n",
      "\n",
      " Epoch 1895\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52161455154419\n",
      "\n",
      " Epoch 1896\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52135944366455\n",
      "\n",
      " Epoch 1897\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5208649635315\n",
      "\n",
      " Epoch 1898\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52210664749146\n",
      "\n",
      " Epoch 1899\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52104473114014\n",
      "\n",
      " Epoch 1900\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52108001708984\n",
      "\n",
      " Epoch 1901\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52147054672241\n",
      "\n",
      " Epoch 1902\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52162790298462\n",
      "\n",
      " Epoch 1903\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52055931091309\n",
      "\n",
      " Epoch 1904\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52083158493042\n",
      "\n",
      " Epoch 1905\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52126550674438\n",
      "\n",
      " Epoch 1906\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52077674865723\n",
      "\n",
      " Epoch 1907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.52160930633545\n",
      "\n",
      " Epoch 1908\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52088499069214\n",
      "\n",
      " Epoch 1909\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52099180221558\n",
      "\n",
      " Epoch 1910\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52103519439697\n",
      "\n",
      " Epoch 1911\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52052545547485\n",
      "\n",
      " Epoch 1912\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52112197875977\n",
      "\n",
      " Epoch 1913\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52100706100464\n",
      "\n",
      " Epoch 1914\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5202956199646\n",
      "\n",
      " Epoch 1915\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52059936523438\n",
      "\n",
      " Epoch 1916\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52105760574341\n",
      "\n",
      " Epoch 1917\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52056884765625\n",
      "\n",
      " Epoch 1918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.521409034729\n",
      "\n",
      " Epoch 1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5204668045044\n",
      "\n",
      " Epoch 1920\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5205807685852\n",
      "\n",
      " Epoch 1921\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52051877975464\n",
      "\n",
      " Epoch 1922\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52053499221802\n",
      "\n",
      " Epoch 1923\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52080965042114\n",
      "\n",
      " Epoch 1924\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52011156082153\n",
      "\n",
      " Epoch 1925\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52099323272705\n",
      "\n",
      " Epoch 1926\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5199384689331\n",
      "\n",
      " Epoch 1927\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52201843261719\n",
      "\n",
      " Epoch 1928\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51995420455933\n",
      "\n",
      " Epoch 1929\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52102184295654\n",
      "\n",
      " Epoch 1930\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5204210281372\n",
      "\n",
      " Epoch 1931\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52022552490234\n",
      "\n",
      " Epoch 1932\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5200686454773\n",
      "\n",
      " Epoch 1933\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52003335952759\n",
      "\n",
      " Epoch 1934\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52017450332642\n",
      "\n",
      " Epoch 1935\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52022933959961\n",
      "\n",
      " Epoch 1936\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52105665206909\n",
      "\n",
      " Epoch 1937\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52013397216797\n",
      "\n",
      " Epoch 1938\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5204758644104\n",
      "\n",
      " Epoch 1939\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52031373977661\n",
      "\n",
      " Epoch 1940\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52135276794434\n",
      "\n",
      " Epoch 1941\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5199294090271\n",
      "\n",
      " Epoch 1942\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52033567428589\n",
      "\n",
      " Epoch 1943\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52055406570435\n",
      "\n",
      " Epoch 1944\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51999473571777\n",
      "\n",
      " Epoch 1945\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.520751953125\n",
      "\n",
      " Epoch 1946\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51969575881958\n",
      "\n",
      " Epoch 1947\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52020645141602\n",
      "\n",
      " Epoch 1948\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52112245559692\n",
      "\n",
      " Epoch 1949\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5206208229065\n",
      "\n",
      " Epoch 1950\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52096366882324\n",
      "\n",
      " Epoch 1951\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51934337615967\n",
      "\n",
      " Epoch 1952\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51985931396484\n",
      "\n",
      " Epoch 1953\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52023887634277\n",
      "\n",
      " Epoch 1954\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52078676223755\n",
      "\n",
      " Epoch 1955\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5202145576477\n",
      "\n",
      " Epoch 1956\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5197343826294\n",
      "\n",
      " Epoch 1957\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52153253555298\n",
      "\n",
      " Epoch 1958\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51986408233643\n",
      "\n",
      " Epoch 1959\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52005386352539\n",
      "\n",
      " Epoch 1960\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51919794082642\n",
      "\n",
      " Epoch 1961\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52065420150757\n",
      "\n",
      " Epoch 1962\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51942253112793\n",
      "\n",
      " Epoch 1963\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52083396911621\n",
      "\n",
      " Epoch 1964\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52088737487793\n",
      "\n",
      " Epoch 1965\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51916885375977\n",
      "\n",
      " Epoch 1966\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52058410644531\n",
      "\n",
      " Epoch 1967\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5190110206604\n",
      "\n",
      " Epoch 1968\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52001523971558\n",
      "\n",
      " Epoch 1969\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52052879333496\n",
      "\n",
      " Epoch 1970\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51939582824707\n",
      "\n",
      " Epoch 1971\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52034378051758\n",
      "\n",
      " Epoch 1972\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51968765258789\n",
      "\n",
      " Epoch 1973\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52056312561035\n",
      "\n",
      " Epoch 1974\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51922750473022\n",
      "\n",
      " Epoch 1975\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52027368545532\n",
      "\n",
      " Epoch 1976\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51969194412231\n",
      "\n",
      " Epoch 1977\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52051830291748\n",
      "\n",
      " Epoch 1978\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51985788345337\n",
      "\n",
      " Epoch 1979\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51916313171387\n",
      "\n",
      " Epoch 1980\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52043199539185\n",
      "\n",
      " Epoch 1981\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51880311965942\n",
      "\n",
      " Epoch 1982\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52035760879517\n",
      "\n",
      " Epoch 1983\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52005004882812\n",
      "\n",
      " Epoch 1984\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52092790603638\n",
      "\n",
      " Epoch 1985\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52023124694824\n",
      "\n",
      " Epoch 1986\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51879835128784\n",
      "\n",
      " Epoch 1987\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51970911026001\n",
      "\n",
      " Epoch 1988\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52050399780273\n",
      "\n",
      " Epoch 1989\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5203161239624\n",
      "\n",
      " Epoch 1990\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.518967628479\n",
      "\n",
      " Epoch 1991\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52016353607178\n",
      "\n",
      " Epoch 1992\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51968669891357\n",
      "\n",
      " Epoch 1993\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52092838287354\n",
      "\n",
      " Epoch 1994\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51921463012695\n",
      "\n",
      " Epoch 1995\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.519540309906\n",
      "\n",
      " Epoch 1996\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52015161514282\n",
      "\n",
      " Epoch 1997\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5190315246582\n",
      "\n",
      " Epoch 1998\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.52014589309692\n",
      "\n",
      " Epoch 1999\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51922225952148\n",
      "\n",
      " Epoch 2000\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5208044052124\n",
      "\n",
      " Epoch 2001\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51941871643066\n",
      "\n",
      " Epoch 2002\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.52004480361938\n",
      "\n",
      " Epoch 2003\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51963090896606\n",
      "\n",
      " Epoch 2004\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51910161972046\n",
      "\n",
      " Epoch 2005\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51978397369385\n",
      "\n",
      " Epoch 2006\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51944828033447\n",
      "\n",
      " Epoch 2007\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51929044723511\n",
      "\n",
      " Epoch 2008\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51891708374023\n",
      "\n",
      " Epoch 2009\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51928758621216\n",
      "\n",
      " Epoch 2010\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51873302459717\n",
      "\n",
      " Epoch 2011\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51960182189941\n",
      "\n",
      " Epoch 2012\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51887130737305\n",
      "\n",
      " Epoch 2013\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51869440078735\n",
      "\n",
      " Epoch 2014\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51937055587769\n",
      "\n",
      " Epoch 2015\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51855373382568\n",
      "\n",
      " Epoch 2016\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51869916915894\n",
      "\n",
      " Epoch 2017\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51924419403076\n",
      "\n",
      " Epoch 2018\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51833868026733\n",
      "\n",
      " Epoch 2019\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.518630027771\n",
      "\n",
      " Epoch 2020\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51845788955688\n",
      "\n",
      " Epoch 2021\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51910257339478\n",
      "\n",
      " Epoch 2022\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51807117462158\n",
      "\n",
      " Epoch 2023\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51899909973145\n",
      "\n",
      " Epoch 2024\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51770496368408\n",
      "\n",
      " Epoch 2025\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51913738250732\n",
      "\n",
      " Epoch 2026\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51822137832642\n",
      "\n",
      " Epoch 2027\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51789712905884\n",
      "\n",
      " Epoch 2028\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51887655258179\n",
      "\n",
      " Epoch 2029\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51818227767944\n",
      "\n",
      " Epoch 2030\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51815271377563\n",
      "\n",
      " Epoch 2031\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51872777938843\n",
      "\n",
      " Epoch 2032\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51714515686035\n",
      "\n",
      " Epoch 2033\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51891469955444\n",
      "\n",
      " Epoch 2034\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51800203323364\n",
      "\n",
      " Epoch 2035\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5180311203003\n",
      "\n",
      " Epoch 2036\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51808214187622\n",
      "\n",
      " Epoch 2037\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51862716674805\n",
      "\n",
      " Epoch 2038\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51752614974976\n",
      "\n",
      " Epoch 2039\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51791191101074\n",
      "\n",
      " Epoch 2040\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51793813705444\n",
      "\n",
      " Epoch 2041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5185751914978\n",
      "\n",
      " Epoch 2042\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51767635345459\n",
      "\n",
      " Epoch 2043\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51748514175415\n",
      "\n",
      " Epoch 2044\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51790714263916\n",
      "\n",
      " Epoch 2045\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.518479347229\n",
      "\n",
      " Epoch 2046\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51764917373657\n",
      "\n",
      " Epoch 2047\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51767778396606\n",
      "\n",
      " Epoch 2048\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51781463623047\n",
      "\n",
      " Epoch 2049\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51836681365967\n",
      "\n",
      " Epoch 2050\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51726150512695\n",
      "\n",
      " Epoch 2051\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51766586303711\n",
      "\n",
      " Epoch 2052\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51693058013916\n",
      "\n",
      " Epoch 2053\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51726627349854\n",
      "\n",
      " Epoch 2054\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51774311065674\n",
      "\n",
      " Epoch 2055\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51819086074829\n",
      "\n",
      " Epoch 2056\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51757383346558\n",
      "\n",
      " Epoch 2057\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51751184463501\n",
      "\n",
      " Epoch 2058\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51747512817383\n",
      "\n",
      " Epoch 2059\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51810455322266\n",
      "\n",
      " Epoch 2060\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51709365844727\n",
      "\n",
      " Epoch 2061\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51750135421753\n",
      "\n",
      " Epoch 2062\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51651763916016\n",
      "\n",
      " Epoch 2063\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51697826385498\n",
      "\n",
      " Epoch 2064\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51763105392456\n",
      "\n",
      " Epoch 2065\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5180926322937\n",
      "\n",
      " Epoch 2066\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51717805862427\n",
      "\n",
      " Epoch 2067\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51732635498047\n",
      "\n",
      " Epoch 2068\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51732206344604\n",
      "\n",
      " Epoch 2069\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51803016662598\n",
      "\n",
      " Epoch 2070\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51712894439697\n",
      "\n",
      " Epoch 2071\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51612901687622\n",
      "\n",
      " Epoch 2072\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51737928390503\n",
      "\n",
      " Epoch 2073\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5172905921936\n",
      "\n",
      " Epoch 2074\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5170841217041\n",
      "\n",
      " Epoch 2075\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51801443099976\n",
      "\n",
      " Epoch 2076\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51703643798828\n",
      "\n",
      " Epoch 2077\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51599740982056\n",
      "\n",
      " Epoch 2078\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51707363128662\n",
      "\n",
      " Epoch 2079\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51726818084717\n",
      "\n",
      " Epoch 2080\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51777076721191\n",
      "\n",
      " Epoch 2081\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51697587966919\n",
      "\n",
      " Epoch 2082\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51699304580688\n",
      "\n",
      " Epoch 2083\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51703453063965\n",
      "\n",
      " Epoch 2084\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51766157150269\n",
      "\n",
      " Epoch 2085\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51695823669434\n",
      "\n",
      " Epoch 2086\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51694393157959\n",
      "\n",
      " Epoch 2087\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51624059677124\n",
      "\n",
      " Epoch 2088\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51660776138306\n",
      "\n",
      " Epoch 2089\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51697492599487\n",
      "\n",
      " Epoch 2090\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51762056350708\n",
      "\n",
      " Epoch 2091\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51675653457642\n",
      "\n",
      " Epoch 2092\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51699733734131\n",
      "\n",
      " Epoch 2093\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51682233810425\n",
      "\n",
      " Epoch 2094\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51598739624023\n",
      "\n",
      " Epoch 2095\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5165228843689\n",
      "\n",
      " Epoch 2096\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5169415473938\n",
      "\n",
      " Epoch 2097\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51755285263062\n",
      "\n",
      " Epoch 2098\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51665925979614\n",
      "\n",
      " Epoch 2099\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51672315597534\n",
      "\n",
      " Epoch 2100\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51740026473999\n",
      "\n",
      " Epoch 2101\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51676225662231\n",
      "\n",
      " Epoch 2102\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51677513122559\n",
      "\n",
      " Epoch 2103\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51592445373535\n",
      "\n",
      " Epoch 2104\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51638555526733\n",
      "\n",
      " Epoch 2105\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51688146591187\n",
      "\n",
      " Epoch 2106\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51740312576294\n",
      "\n",
      " Epoch 2107\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51654577255249\n",
      "\n",
      " Epoch 2108\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5166220664978\n",
      "\n",
      " Epoch 2109\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51579284667969\n",
      "\n",
      " Epoch 2110\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.5163722038269\n",
      "\n",
      " Epoch 2111\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51733350753784\n",
      "\n",
      " Epoch 2112\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51646900177002\n",
      "\n",
      " Epoch 2113\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51666831970215\n",
      "\n",
      " Epoch 2114\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5157618522644\n",
      "\n",
      " Epoch 2115\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51616859436035\n",
      "\n",
      " Epoch 2116\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51655626296997\n",
      "\n",
      " Epoch 2117\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51732349395752\n",
      "\n",
      " Epoch 2118\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51634883880615\n",
      "\n",
      " Epoch 2119\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51562309265137\n",
      "\n",
      " Epoch 2120\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51606893539429\n",
      "\n",
      " Epoch 2121\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51734256744385\n",
      "\n",
      " Epoch 2122\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51635265350342\n",
      "\n",
      " Epoch 2123\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51558113098145\n",
      "\n",
      " Epoch 2124\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51616525650024\n",
      "\n",
      " Epoch 2125\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.516441822052\n",
      "\n",
      " Epoch 2126\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5171160697937\n",
      "\n",
      " Epoch 2127\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51619005203247\n",
      "\n",
      " Epoch 2128\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51564359664917\n",
      "\n",
      " Epoch 2129\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51599216461182\n",
      "\n",
      " Epoch 2130\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51633930206299\n",
      "\n",
      " Epoch 2131\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51703548431396\n",
      "\n",
      " Epoch 2132\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51611423492432\n",
      "\n",
      " Epoch 2133\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51560544967651\n",
      "\n",
      " Epoch 2134\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51627111434937\n",
      "\n",
      " Epoch 2135\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5171389579773\n",
      "\n",
      " Epoch 2136\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51569700241089\n",
      "\n",
      " Epoch 2137\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51546669006348\n",
      "\n",
      " Epoch 2138\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51584815979004\n",
      "\n",
      " Epoch 2139\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51719427108765\n",
      "\n",
      " Epoch 2140\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51614570617676\n",
      "\n",
      " Epoch 2141\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51540184020996\n",
      "\n",
      " Epoch 2142\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51613664627075\n",
      "\n",
      " Epoch 2143\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5170464515686\n",
      "\n",
      " Epoch 2144\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51564693450928\n",
      "\n",
      " Epoch 2145\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51543617248535\n",
      "\n",
      " Epoch 2146\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51582956314087\n",
      "\n",
      " Epoch 2147\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51706600189209\n",
      "\n",
      " Epoch 2148\n",
      "\n",
      "Training accuracy :  0.984\n",
      "\n",
      "Training loss :  82.51608324050903\n",
      "\n",
      " Epoch 2149\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51539182662964\n",
      "\n",
      " Epoch 2150\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51612710952759\n",
      "\n",
      " Epoch 2151\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51623868942261\n",
      "\n",
      " Epoch 2152\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51533699035645\n",
      "\n",
      " Epoch 2153\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51571416854858\n",
      "\n",
      " Epoch 2154\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51686191558838\n",
      "\n",
      " Epoch 2155\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5160322189331\n",
      "\n",
      " Epoch 2156\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51610136032104\n",
      "\n",
      " Epoch 2157\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51742839813232\n",
      "\n",
      " Epoch 2158\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51689386367798\n",
      "\n",
      " Epoch 2159\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51646709442139\n",
      "\n",
      " Epoch 2160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51573038101196\n",
      "\n",
      " Epoch 2161\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.516432762146\n",
      "\n",
      " Epoch 2162\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51733207702637\n",
      "\n",
      " Epoch 2163\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51570129394531\n",
      "\n",
      " Epoch 2164\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51531219482422\n",
      "\n",
      " Epoch 2165\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51525735855103\n",
      "\n",
      " Epoch 2166\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5157880783081\n",
      "\n",
      " Epoch 2167\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51504802703857\n",
      "\n",
      " Epoch 2168\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51575231552124\n",
      "\n",
      " Epoch 2169\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51596164703369\n",
      "\n",
      " Epoch 2170\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5149278640747\n",
      "\n",
      " Epoch 2171\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51591110229492\n",
      "\n",
      " Epoch 2172\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51655769348145\n",
      "\n",
      " Epoch 2173\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51536321640015\n",
      "\n",
      " Epoch 2174\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51578998565674\n",
      "\n",
      " Epoch 2175\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51738595962524\n",
      "\n",
      " Epoch 2176\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51654863357544\n",
      "\n",
      " Epoch 2177\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51662635803223\n",
      "\n",
      " Epoch 2178\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51704216003418\n",
      "\n",
      " Epoch 2179\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51653289794922\n",
      "\n",
      " Epoch 2180\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51611137390137\n",
      "\n",
      " Epoch 2181\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5152177810669\n",
      "\n",
      " Epoch 2182\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5168228149414\n",
      "\n",
      " Epoch 2183\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51630067825317\n",
      "\n",
      " Epoch 2184\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5159010887146\n",
      "\n",
      " Epoch 2185\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51485967636108\n",
      "\n",
      " Epoch 2186\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51652717590332\n",
      "\n",
      " Epoch 2187\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51580953598022\n",
      "\n",
      " Epoch 2188\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51632690429688\n",
      "\n",
      " Epoch 2189\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51417350769043\n",
      "\n",
      " Epoch 2190\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51619005203247\n",
      "\n",
      " Epoch 2191\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5155930519104\n",
      "\n",
      " Epoch 2192\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51612091064453\n",
      "\n",
      " Epoch 2193\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5138669013977\n",
      "\n",
      " Epoch 2194\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51592779159546\n",
      "\n",
      " Epoch 2195\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5150146484375\n",
      "\n",
      " Epoch 2196\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51599836349487\n",
      "\n",
      " Epoch 2197\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51494598388672\n",
      "\n",
      " Epoch 2198\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51422595977783\n",
      "\n",
      " Epoch 2199\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51556396484375\n",
      "\n",
      " Epoch 2200\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51519250869751\n",
      "\n",
      " Epoch 2201\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51482105255127\n",
      "\n",
      " Epoch 2202\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51391506195068\n",
      "\n",
      " Epoch 2203\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51554250717163\n",
      "\n",
      " Epoch 2204\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51505136489868\n",
      "\n",
      " Epoch 2205\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51451539993286\n",
      "\n",
      " Epoch 2206\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51373767852783\n",
      "\n",
      " Epoch 2207\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51523494720459\n",
      "\n",
      " Epoch 2208\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51470708847046\n",
      "\n",
      " Epoch 2209\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5145034790039\n",
      "\n",
      " Epoch 2210\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5128345489502\n",
      "\n",
      " Epoch 2211\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5138292312622\n",
      "\n",
      " Epoch 2212\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51203107833862\n",
      "\n",
      " Epoch 2213\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51204538345337\n",
      "\n",
      " Epoch 2214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51285696029663\n",
      "\n",
      " Epoch 2215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51531505584717\n",
      "\n",
      " Epoch 2216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51159286499023\n",
      "\n",
      " Epoch 2217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5118761062622\n",
      "\n",
      " Epoch 2218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51140403747559\n",
      "\n",
      " Epoch 2219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51183462142944\n",
      "\n",
      " Epoch 2220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51427268981934\n",
      "\n",
      " Epoch 2221\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51366996765137\n",
      "\n",
      " Epoch 2222\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51349401473999\n",
      "\n",
      " Epoch 2223\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51126909255981\n",
      "\n",
      " Epoch 2224\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51306772232056\n",
      "\n",
      " Epoch 2225\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51331186294556\n",
      "\n",
      " Epoch 2226\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51284217834473\n",
      "\n",
      " Epoch 2227\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51390552520752\n",
      "\n",
      " Epoch 2228\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51168632507324\n",
      "\n",
      " Epoch 2229\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51101160049438\n",
      "\n",
      " Epoch 2230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51275157928467\n",
      "\n",
      " Epoch 2231\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51192378997803\n",
      "\n",
      " Epoch 2232\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51197290420532\n",
      "\n",
      " Epoch 2233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51259803771973\n",
      "\n",
      " Epoch 2234\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51139211654663\n",
      "\n",
      " Epoch 2235\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51157140731812\n",
      "\n",
      " Epoch 2236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51175498962402\n",
      "\n",
      " Epoch 2237\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5112738609314\n",
      "\n",
      " Epoch 2238\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51063966751099\n",
      "\n",
      " Epoch 2239\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5108790397644\n",
      "\n",
      " Epoch 2240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51159286499023\n",
      "\n",
      " Epoch 2241\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5099983215332\n",
      "\n",
      " Epoch 2242\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5106430053711\n",
      "\n",
      " Epoch 2243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51115608215332\n",
      "\n",
      " Epoch 2244\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.5094985961914\n",
      "\n",
      " Epoch 2245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5107946395874\n",
      "\n",
      " Epoch 2246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51090431213379\n",
      "\n",
      " Epoch 2247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51167440414429\n",
      "\n",
      " Epoch 2248\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.51006937026978\n",
      "\n",
      " Epoch 2249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51131200790405\n",
      "\n",
      " Epoch 2250\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.50981283187866\n",
      "\n",
      " Epoch 2251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51133680343628\n",
      "\n",
      " Epoch 2252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51014804840088\n",
      "\n",
      " Epoch 2253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51004886627197\n",
      "\n",
      " Epoch 2254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51022434234619\n",
      "\n",
      " Epoch 2255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50992393493652\n",
      "\n",
      " Epoch 2256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51040983200073\n",
      "\n",
      " Epoch 2257\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.50914812088013\n",
      "\n",
      " Epoch 2258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51060676574707\n",
      "\n",
      " Epoch 2259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50969982147217\n",
      "\n",
      " Epoch 2260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5093994140625\n",
      "\n",
      " Epoch 2261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50966453552246\n",
      "\n",
      " Epoch 2262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50949907302856\n",
      "\n",
      " Epoch 2263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50991916656494\n",
      "\n",
      " Epoch 2264\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.50855922698975\n",
      "\n",
      " Epoch 2265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.51034593582153\n",
      "\n",
      " Epoch 2266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50888347625732\n",
      "\n",
      " Epoch 2267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50910234451294\n",
      "\n",
      " Epoch 2268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50980997085571\n",
      "\n",
      " Epoch 2269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50832605361938\n",
      "\n",
      " Epoch 2270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50905418395996\n",
      "\n",
      " Epoch 2271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50962972640991\n",
      "\n",
      " Epoch 2272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50874471664429\n",
      "\n",
      " Epoch 2273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5086817741394\n",
      "\n",
      " Epoch 2274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50854206085205\n",
      "\n",
      " Epoch 2275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50843906402588\n",
      "\n",
      " Epoch 2276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50864791870117\n",
      "\n",
      " Epoch 2277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50928068161011\n",
      "\n",
      " Epoch 2278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50730085372925\n",
      "\n",
      " Epoch 2279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50836563110352\n",
      "\n",
      " Epoch 2280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50904893875122\n",
      "\n",
      " Epoch 2281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50754308700562\n",
      "\n",
      " Epoch 2282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50834846496582\n",
      "\n",
      " Epoch 2283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50787878036499\n",
      "\n",
      " Epoch 2284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5076060295105\n",
      "\n",
      " Epoch 2285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50875902175903\n",
      "\n",
      " Epoch 2286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5071930885315\n",
      "\n",
      " Epoch 2287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50818729400635\n",
      "\n",
      " Epoch 2288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50729990005493\n",
      "\n",
      " Epoch 2289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50771617889404\n",
      "\n",
      " Epoch 2290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50716304779053\n",
      "\n",
      " Epoch 2291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50794315338135\n",
      "\n",
      " Epoch 2292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50669193267822\n",
      "\n",
      " Epoch 2293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5071930885315\n",
      "\n",
      " Epoch 2294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50738382339478\n",
      "\n",
      " Epoch 2295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50638103485107\n",
      "\n",
      " Epoch 2296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50849103927612\n",
      "\n",
      " Epoch 2297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50669431686401\n",
      "\n",
      " Epoch 2298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50738859176636\n",
      "\n",
      " Epoch 2299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50730752944946\n",
      "\n",
      " Epoch 2300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50678586959839\n",
      "\n",
      " Epoch 2301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5065975189209\n",
      "\n",
      " Epoch 2302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50696516036987\n",
      "\n",
      " Epoch 2303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50727128982544\n",
      "\n",
      " Epoch 2304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50788116455078\n",
      "\n",
      " Epoch 2305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50610637664795\n",
      "\n",
      " Epoch 2306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50676155090332\n",
      "\n",
      " Epoch 2307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50745248794556\n",
      "\n",
      " Epoch 2308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50671339035034\n",
      "\n",
      " Epoch 2309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50696992874146\n",
      "\n",
      " Epoch 2310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50653171539307\n",
      "\n",
      " Epoch 2311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50708293914795\n",
      "\n",
      " Epoch 2312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50698184967041\n",
      "\n",
      " Epoch 2313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50673627853394\n",
      "\n",
      " Epoch 2314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50689220428467\n",
      "\n",
      " Epoch 2315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50588703155518\n",
      "\n",
      " Epoch 2316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50696754455566\n",
      "\n",
      " Epoch 2317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50721263885498\n",
      "\n",
      " Epoch 2318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50636053085327\n",
      "\n",
      " Epoch 2319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50667953491211\n",
      "\n",
      " Epoch 2320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50623559951782\n",
      "\n",
      " Epoch 2321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50776243209839\n",
      "\n",
      " Epoch 2322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50695514678955\n",
      "\n",
      " Epoch 2323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50407075881958\n",
      "\n",
      " Epoch 2324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50776672363281\n",
      "\n",
      " Epoch 2325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50656747817993\n",
      "\n",
      " Epoch 2326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50658226013184\n",
      "\n",
      " Epoch 2327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5045280456543\n",
      "\n",
      " Epoch 2328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50670766830444\n",
      "\n",
      " Epoch 2329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50560140609741\n",
      "\n",
      " Epoch 2330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50689125061035\n",
      "\n",
      " Epoch 2331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50542879104614\n",
      "\n",
      " Epoch 2332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5041127204895\n",
      "\n",
      " Epoch 2333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50672674179077\n",
      "\n",
      " Epoch 2334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50495862960815\n",
      "\n",
      " Epoch 2335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50596570968628\n",
      "\n",
      " Epoch 2336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50384998321533\n",
      "\n",
      " Epoch 2337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50606060028076\n",
      "\n",
      " Epoch 2338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50469827651978\n",
      "\n",
      " Epoch 2339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50363969802856\n",
      "\n",
      " Epoch 2340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50628805160522\n",
      "\n",
      " Epoch 2341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5055103302002\n",
      "\n",
      " Epoch 2342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50601243972778\n",
      "\n",
      " Epoch 2343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50499963760376\n",
      "\n",
      " Epoch 2344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50534915924072\n",
      "\n",
      " Epoch 2345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50316429138184\n",
      "\n",
      " Epoch 2346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50500440597534\n",
      "\n",
      " Epoch 2347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50454425811768\n",
      "\n",
      " Epoch 2348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50250625610352\n",
      "\n",
      " Epoch 2349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50541114807129\n",
      "\n",
      " Epoch 2350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50467824935913\n",
      "\n",
      " Epoch 2351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50339221954346\n",
      "\n",
      " Epoch 2352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50468683242798\n",
      "\n",
      " Epoch 2353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5046763420105\n",
      "\n",
      " Epoch 2354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50288772583008\n",
      "\n",
      " Epoch 2355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50513458251953\n",
      "\n",
      " Epoch 2356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50384330749512\n",
      "\n",
      " Epoch 2357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50385761260986\n",
      "\n",
      " Epoch 2358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50451898574829\n",
      "\n",
      " Epoch 2359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50342321395874\n",
      "\n",
      " Epoch 2360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50395154953003\n",
      "\n",
      " Epoch 2361\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.501718044281\n",
      "\n",
      " Epoch 2362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50525903701782\n",
      "\n",
      " Epoch 2363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50362586975098\n",
      "\n",
      " Epoch 2364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50639057159424\n",
      "\n",
      " Epoch 2365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5044641494751\n",
      "\n",
      " Epoch 2366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50455331802368\n",
      "\n",
      " Epoch 2367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50448751449585\n",
      "\n",
      " Epoch 2368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50441598892212\n",
      "\n",
      " Epoch 2369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50218868255615\n",
      "\n",
      " Epoch 2370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50398254394531\n",
      "\n",
      " Epoch 2371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50406169891357\n",
      "\n",
      " Epoch 2372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50100660324097\n",
      "\n",
      " Epoch 2373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5043716430664\n",
      "\n",
      " Epoch 2374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50360202789307\n",
      "\n",
      " Epoch 2375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50292825698853\n",
      "\n",
      " Epoch 2376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50320816040039\n",
      "\n",
      " Epoch 2377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50020790100098\n",
      "\n",
      " Epoch 2378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5027060508728\n",
      "\n",
      " Epoch 2379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50246238708496\n",
      "\n",
      " Epoch 2380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50219964981079\n",
      "\n",
      " Epoch 2381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50232696533203\n",
      "\n",
      " Epoch 2382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4999737739563\n",
      "\n",
      " Epoch 2383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50228834152222\n",
      "\n",
      " Epoch 2384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50173902511597\n",
      "\n",
      " Epoch 2385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50176239013672\n",
      "\n",
      " Epoch 2386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49971294403076\n",
      "\n",
      " Epoch 2387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49933671951294\n",
      "\n",
      " Epoch 2388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50137853622437\n",
      "\n",
      " Epoch 2389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50106954574585\n",
      "\n",
      " Epoch 2390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50055503845215\n",
      "\n",
      " Epoch 2391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49916458129883\n",
      "\n",
      " Epoch 2392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50103378295898\n",
      "\n",
      " Epoch 2393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49974918365479\n",
      "\n",
      " Epoch 2394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50108051300049\n",
      "\n",
      " Epoch 2395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49986219406128\n",
      "\n",
      " Epoch 2396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50021457672119\n",
      "\n",
      " Epoch 2397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50095844268799\n",
      "\n",
      " Epoch 2398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49954986572266\n",
      "\n",
      " Epoch 2399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5009274482727\n",
      "\n",
      " Epoch 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4998369216919\n",
      "\n",
      " Epoch 2401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49988746643066\n",
      "\n",
      " Epoch 2402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50033617019653\n",
      "\n",
      " Epoch 2403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49989748001099\n",
      "\n",
      " Epoch 2404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50067663192749\n",
      "\n",
      " Epoch 2405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49932861328125\n",
      "\n",
      " Epoch 2406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50063180923462\n",
      "\n",
      " Epoch 2407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49952602386475\n",
      "\n",
      " Epoch 2408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49992322921753\n",
      "\n",
      " Epoch 2409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49962902069092\n",
      "\n",
      " Epoch 2410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.5001368522644\n",
      "\n",
      " Epoch 2411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49952554702759\n",
      "\n",
      " Epoch 2412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50045967102051\n",
      "\n",
      " Epoch 2413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49911737442017\n",
      "\n",
      " Epoch 2414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50038385391235\n",
      "\n",
      " Epoch 2415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49931240081787\n",
      "\n",
      " Epoch 2416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50015163421631\n",
      "\n",
      " Epoch 2417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49930620193481\n",
      "\n",
      " Epoch 2418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49948215484619\n",
      "\n",
      " Epoch 2419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50024509429932\n",
      "\n",
      " Epoch 2420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49917840957642\n",
      "\n",
      " Epoch 2421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49939107894897\n",
      "\n",
      " Epoch 2422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49997758865356\n",
      "\n",
      " Epoch 2423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49891662597656\n",
      "\n",
      " Epoch 2424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50010824203491\n",
      "\n",
      " Epoch 2425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49920797348022\n",
      "\n",
      " Epoch 2426\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4978575706482\n",
      "\n",
      " Epoch 2427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49874353408813\n",
      "\n",
      " Epoch 2428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49983930587769\n",
      "\n",
      " Epoch 2429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49860858917236\n",
      "\n",
      " Epoch 2430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4998426437378\n",
      "\n",
      " Epoch 2431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4984769821167\n",
      "\n",
      " Epoch 2432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4995665550232\n",
      "\n",
      " Epoch 2433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4982500076294\n",
      "\n",
      " Epoch 2434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49930381774902\n",
      "\n",
      " Epoch 2435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49878072738647\n",
      "\n",
      " Epoch 2436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49921941757202\n",
      "\n",
      " Epoch 2437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49868059158325\n",
      "\n",
      " Epoch 2438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49918413162231\n",
      "\n",
      " Epoch 2439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49821758270264\n",
      "\n",
      " Epoch 2440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49908208847046\n",
      "\n",
      " Epoch 2441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4985842704773\n",
      "\n",
      " Epoch 2442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49901151657104\n",
      "\n",
      " Epoch 2443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49851703643799\n",
      "\n",
      " Epoch 2444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49898862838745\n",
      "\n",
      " Epoch 2445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49768543243408\n",
      "\n",
      " Epoch 2446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49948406219482\n",
      "\n",
      " Epoch 2447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49890279769897\n",
      "\n",
      " Epoch 2448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4985842704773\n",
      "\n",
      " Epoch 2449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49894046783447\n",
      "\n",
      " Epoch 2450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49845266342163\n",
      "\n",
      " Epoch 2451\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49702835083008\n",
      "\n",
      " Epoch 2452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4992241859436\n",
      "\n",
      " Epoch 2453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49890279769897\n",
      "\n",
      " Epoch 2454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49852657318115\n",
      "\n",
      " Epoch 2455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49826860427856\n",
      "\n",
      " Epoch 2456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49941539764404\n",
      "\n",
      " Epoch 2457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4987440109253\n",
      "\n",
      " Epoch 2458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49817705154419\n",
      "\n",
      " Epoch 2459\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49617576599121\n",
      "\n",
      " Epoch 2460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4989881515503\n",
      "\n",
      " Epoch 2461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49885749816895\n",
      "\n",
      " Epoch 2462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49871873855591\n",
      "\n",
      " Epoch 2463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49886703491211\n",
      "\n",
      " Epoch 2464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49917221069336\n",
      "\n",
      " Epoch 2465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49892950057983\n",
      "\n",
      " Epoch 2466\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49673795700073\n",
      "\n",
      " Epoch 2467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49940824508667\n",
      "\n",
      " Epoch 2468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49977397918701\n",
      "\n",
      " Epoch 2469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49949502944946\n",
      "\n",
      " Epoch 2470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49914360046387\n",
      "\n",
      " Epoch 2471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49957942962646\n",
      "\n",
      " Epoch 2472\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49725008010864\n",
      "\n",
      " Epoch 2473\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49838495254517\n",
      "\n",
      " Epoch 2474\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49753522872925\n",
      "\n",
      " Epoch 2475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49992799758911\n",
      "\n",
      " Epoch 2476\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49703121185303\n",
      "\n",
      " Epoch 2477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50017213821411\n",
      "\n",
      " Epoch 2478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49877595901489\n",
      "\n",
      " Epoch 2479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49882364273071\n",
      "\n",
      " Epoch 2480\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49669885635376\n",
      "\n",
      " Epoch 2481\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49727439880371\n",
      "\n",
      " Epoch 2482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.50008535385132\n",
      "\n",
      " Epoch 2483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49895668029785\n",
      "\n",
      " Epoch 2484\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49646949768066\n",
      "\n",
      " Epoch 2485\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4978461265564\n",
      "\n",
      " Epoch 2486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49902772903442\n",
      "\n",
      " Epoch 2487\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49678945541382\n",
      "\n",
      " Epoch 2488\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4968638420105\n",
      "\n",
      " Epoch 2489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49909925460815\n",
      "\n",
      " Epoch 2490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49828481674194\n",
      "\n",
      " Epoch 2491\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49563646316528\n",
      "\n",
      " Epoch 2492\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49695444107056\n",
      "\n",
      " Epoch 2493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4994740486145\n",
      "\n",
      " Epoch 2494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49718379974365\n",
      "\n",
      " Epoch 2495\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49566602706909\n",
      "\n",
      " Epoch 2496\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4968991279602\n",
      "\n",
      " Epoch 2497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49843645095825\n",
      "\n",
      " Epoch 2498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49855852127075\n",
      "\n",
      " Epoch 2499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49690294265747\n",
      "\n",
      " Epoch 2500\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49575519561768\n",
      "\n",
      " Epoch 2501\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49464225769043\n",
      "\n",
      " Epoch 2502\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49689388275146\n",
      "\n",
      " Epoch 2503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49803066253662\n",
      "\n",
      " Epoch 2504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49625492095947\n",
      "\n",
      " Epoch 2505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49722957611084\n",
      "\n",
      " Epoch 2506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49708414077759\n",
      "\n",
      " Epoch 2507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49606370925903\n",
      "\n",
      " Epoch 2508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49537134170532\n",
      "\n",
      " Epoch 2509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4974274635315\n",
      "\n",
      " Epoch 2510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49683046340942\n",
      "\n",
      " Epoch 2511\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49406433105469\n",
      "\n",
      " Epoch 2512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49773359298706\n",
      "\n",
      " Epoch 2513\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49408674240112\n",
      "\n",
      " Epoch 2514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49794626235962\n",
      "\n",
      " Epoch 2515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4956750869751\n",
      "\n",
      " Epoch 2516\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49371671676636\n",
      "\n",
      " Epoch 2517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49704027175903\n",
      "\n",
      " Epoch 2518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49621772766113\n",
      "\n",
      " Epoch 2519\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49418783187866\n",
      "\n",
      " Epoch 2520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49711608886719\n",
      "\n",
      " Epoch 2521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49535369873047\n",
      "\n",
      " Epoch 2522\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4934492111206\n",
      "\n",
      " Epoch 2523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49688863754272\n",
      "\n",
      " Epoch 2524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49607801437378\n",
      "\n",
      " Epoch 2525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4944109916687\n",
      "\n",
      " Epoch 2526\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49375009536743\n",
      "\n",
      " Epoch 2527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49623537063599\n",
      "\n",
      " Epoch 2528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4946551322937\n",
      "\n",
      " Epoch 2529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4958610534668\n",
      "\n",
      " Epoch 2530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49475479125977\n",
      "\n",
      " Epoch 2531\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49291038513184\n",
      "\n",
      " Epoch 2532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49493789672852\n",
      "\n",
      " Epoch 2533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49466037750244\n",
      "\n",
      " Epoch 2534\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49209022521973\n",
      "\n",
      " Epoch 2535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49602222442627\n",
      "\n",
      " Epoch 2536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49504804611206\n",
      "\n",
      " Epoch 2537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49335432052612\n",
      "\n",
      " Epoch 2538\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49288654327393\n",
      "\n",
      " Epoch 2539\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49343681335449\n",
      "\n",
      " Epoch 2540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49566698074341\n",
      "\n",
      " Epoch 2541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49334955215454\n",
      "\n",
      " Epoch 2542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49488735198975\n",
      "\n",
      " Epoch 2543\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49387693405151\n",
      "\n",
      " Epoch 2544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49374389648438\n",
      "\n",
      " Epoch 2545\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49212503433228\n",
      "\n",
      " Epoch 2546\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49206686019897\n",
      "\n",
      " Epoch 2547\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49435329437256\n",
      "\n",
      " Epoch 2548\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.494788646698\n",
      "\n",
      " Epoch 2549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4933352470398\n",
      "\n",
      " Epoch 2550\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49349451065063\n",
      "\n",
      " Epoch 2551\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49229574203491\n",
      "\n",
      " Epoch 2552\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49402093887329\n",
      "\n",
      " Epoch 2553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49257135391235\n",
      "\n",
      " Epoch 2554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4922947883606\n",
      "\n",
      " Epoch 2555\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49002361297607\n",
      "\n",
      " Epoch 2556\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49227809906006\n",
      "\n",
      " Epoch 2557\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4919548034668\n",
      "\n",
      " Epoch 2558\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.49050664901733\n",
      "\n",
      " Epoch 2559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4935417175293\n",
      "\n",
      " Epoch 2560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49104356765747\n",
      "\n",
      " Epoch 2561\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48985433578491\n",
      "\n",
      " Epoch 2562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49229955673218\n",
      "\n",
      " Epoch 2563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49143743515015\n",
      "\n",
      " Epoch 2564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49279832839966\n",
      "\n",
      " Epoch 2565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49136543273926\n",
      "\n",
      " Epoch 2566\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48941326141357\n",
      "\n",
      " Epoch 2567\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48962688446045\n",
      "\n",
      " Epoch 2568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4926872253418\n",
      "\n",
      " Epoch 2569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49060869216919\n",
      "\n",
      " Epoch 2570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49230718612671\n",
      "\n",
      " Epoch 2571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49083805084229\n",
      "\n",
      " Epoch 2572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49078464508057\n",
      "\n",
      " Epoch 2573\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48890686035156\n",
      "\n",
      " Epoch 2574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49122428894043\n",
      "\n",
      " Epoch 2575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49068212509155\n",
      "\n",
      " Epoch 2576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49161720275879\n",
      "\n",
      " Epoch 2577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49077701568604\n",
      "\n",
      " Epoch 2578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49129486083984\n",
      "\n",
      " Epoch 2579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49057197570801\n",
      "\n",
      " Epoch 2580\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48832130432129\n",
      "\n",
      " Epoch 2581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49081563949585\n",
      "\n",
      " Epoch 2582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48991823196411\n",
      "\n",
      " Epoch 2583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49120044708252\n",
      "\n",
      " Epoch 2584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49008893966675\n",
      "\n",
      " Epoch 2585\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48725175857544\n",
      "\n",
      " Epoch 2586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4904842376709\n",
      "\n",
      " Epoch 2587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48991250991821\n",
      "\n",
      " Epoch 2588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48985767364502\n",
      "\n",
      " Epoch 2589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49101781845093\n",
      "\n",
      " Epoch 2590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48953342437744\n",
      "\n",
      " Epoch 2591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48990964889526\n",
      "\n",
      " Epoch 2592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49075889587402\n",
      "\n",
      " Epoch 2593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48948097229004\n",
      "\n",
      " Epoch 2594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48980236053467\n",
      "\n",
      " Epoch 2595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48912334442139\n",
      "\n",
      " Epoch 2596\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48582649230957\n",
      "\n",
      " Epoch 2597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49070692062378\n",
      "\n",
      " Epoch 2598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49081945419312\n",
      "\n",
      " Epoch 2599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48813199996948\n",
      "\n",
      " Epoch 2600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4904932975769\n",
      "\n",
      " Epoch 2601\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48611879348755\n",
      "\n",
      " Epoch 2602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48978853225708\n",
      "\n",
      " Epoch 2603\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4862585067749\n",
      "\n",
      " Epoch 2604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48959159851074\n",
      "\n",
      " Epoch 2605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.49042272567749\n",
      "\n",
      " Epoch 2606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48811101913452\n",
      "\n",
      " Epoch 2607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48931837081909\n",
      "\n",
      " Epoch 2608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48895406723022\n",
      "\n",
      " Epoch 2609\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48587465286255\n",
      "\n",
      " Epoch 2610\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48795652389526\n",
      "\n",
      " Epoch 2611\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48798704147339\n",
      "\n",
      " Epoch 2612\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48662614822388\n",
      "\n",
      " Epoch 2613\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48711109161377\n",
      "\n",
      " Epoch 2614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48771572113037\n",
      "\n",
      " Epoch 2615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48591232299805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48716974258423\n",
      "\n",
      " Epoch 2617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48670768737793\n",
      "\n",
      " Epoch 2618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48587036132812\n",
      "\n",
      " Epoch 2619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48687076568604\n",
      "\n",
      " Epoch 2620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48628044128418\n",
      "\n",
      " Epoch 2621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48555088043213\n",
      "\n",
      " Epoch 2622\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48711919784546\n",
      "\n",
      " Epoch 2623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48578977584839\n",
      "\n",
      " Epoch 2624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48705911636353\n",
      "\n",
      " Epoch 2625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48541593551636\n",
      "\n",
      " Epoch 2626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48621368408203\n",
      "\n",
      " Epoch 2627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4867434501648\n",
      "\n",
      " Epoch 2628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48628091812134\n",
      "\n",
      " Epoch 2629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48628330230713\n",
      "\n",
      " Epoch 2630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48545980453491\n",
      "\n",
      " Epoch 2631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48679685592651\n",
      "\n",
      " Epoch 2632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48637628555298\n",
      "\n",
      " Epoch 2633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48566436767578\n",
      "\n",
      " Epoch 2634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48521518707275\n",
      "\n",
      " Epoch 2635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48634147644043\n",
      "\n",
      " Epoch 2636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48618745803833\n",
      "\n",
      " Epoch 2637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48559951782227\n",
      "\n",
      " Epoch 2638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48623895645142\n",
      "\n",
      " Epoch 2639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48471164703369\n",
      "\n",
      " Epoch 2640\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48590517044067\n",
      "\n",
      " Epoch 2641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48549461364746\n",
      "\n",
      " Epoch 2642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48604488372803\n",
      "\n",
      " Epoch 2643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48557329177856\n",
      "\n",
      " Epoch 2644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4858512878418\n",
      "\n",
      " Epoch 2645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48461103439331\n",
      "\n",
      " Epoch 2646\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48511266708374\n",
      "\n",
      " Epoch 2647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48576354980469\n",
      "\n",
      " Epoch 2648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48566436767578\n",
      "\n",
      " Epoch 2649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48539447784424\n",
      "\n",
      " Epoch 2650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48566627502441\n",
      "\n",
      " Epoch 2651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48433589935303\n",
      "\n",
      " Epoch 2652\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48541498184204\n",
      "\n",
      " Epoch 2653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48556995391846\n",
      "\n",
      " Epoch 2654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4846715927124\n",
      "\n",
      " Epoch 2655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48544454574585\n",
      "\n",
      " Epoch 2656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48534822463989\n",
      "\n",
      " Epoch 2657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48504209518433\n",
      "\n",
      " Epoch 2658\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48533344268799\n",
      "\n",
      " Epoch 2659\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48400831222534\n",
      "\n",
      " Epoch 2660\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48507833480835\n",
      "\n",
      " Epoch 2661\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48521566390991\n",
      "\n",
      " Epoch 2662\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48490619659424\n",
      "\n",
      " Epoch 2663\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4848895072937\n",
      "\n",
      " Epoch 2664\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48437738418579\n",
      "\n",
      " Epoch 2665\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48503732681274\n",
      "\n",
      " Epoch 2666\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48485946655273\n",
      "\n",
      " Epoch 2667\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48345232009888\n",
      "\n",
      " Epoch 2668\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48449945449829\n",
      "\n",
      " Epoch 2669\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4843578338623\n",
      "\n",
      " Epoch 2670\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48381567001343\n",
      "\n",
      " Epoch 2671\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48452138900757\n",
      "\n",
      " Epoch 2672\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48434734344482\n",
      "\n",
      " Epoch 2673\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48292827606201\n",
      "\n",
      " Epoch 2674\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48378801345825\n",
      "\n",
      " Epoch 2675\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48431301116943\n",
      "\n",
      " Epoch 2676\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48388338088989\n",
      "\n",
      " Epoch 2677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48394727706909\n",
      "\n",
      " Epoch 2678\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4840087890625\n",
      "\n",
      " Epoch 2679\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48225450515747\n",
      "\n",
      " Epoch 2680\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48380517959595\n",
      "\n",
      " Epoch 2681\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48397541046143\n",
      "\n",
      " Epoch 2682\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48355722427368\n",
      "\n",
      " Epoch 2683\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48367643356323\n",
      "\n",
      " Epoch 2684\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48154878616333\n",
      "\n",
      " Epoch 2685\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48335933685303\n",
      "\n",
      " Epoch 2686\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48341369628906\n",
      "\n",
      " Epoch 2687\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4826922416687\n",
      "\n",
      " Epoch 2688\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4831051826477\n",
      "\n",
      " Epoch 2689\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48287200927734\n",
      "\n",
      " Epoch 2690\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48133087158203\n",
      "\n",
      " Epoch 2691\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48287439346313\n",
      "\n",
      " Epoch 2692\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48224687576294\n",
      "\n",
      " Epoch 2693\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48257875442505\n",
      "\n",
      " Epoch 2694\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48269367218018\n",
      "\n",
      " Epoch 2695\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48032903671265\n",
      "\n",
      " Epoch 2696\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48184823989868\n",
      "\n",
      " Epoch 2697\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48087167739868\n",
      "\n",
      " Epoch 2698\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48121118545532\n",
      "\n",
      " Epoch 2699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4821228981018\n",
      "\n",
      " Epoch 2700\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47964906692505\n",
      "\n",
      " Epoch 2701\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48193979263306\n",
      "\n",
      " Epoch 2702\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4806432723999\n",
      "\n",
      " Epoch 2703\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4816541671753\n",
      "\n",
      " Epoch 2704\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48008298873901\n",
      "\n",
      " Epoch 2705\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48149156570435\n",
      "\n",
      " Epoch 2706\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48043298721313\n",
      "\n",
      " Epoch 2707\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48084926605225\n",
      "\n",
      " Epoch 2708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.48001956939697\n",
      "\n",
      " Epoch 2709\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48064184188843\n",
      "\n",
      " Epoch 2710\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48036241531372\n",
      "\n",
      " Epoch 2711\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48007917404175\n",
      "\n",
      " Epoch 2712\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.480224609375\n",
      "\n",
      " Epoch 2713\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.480064868927\n",
      "\n",
      " Epoch 2714\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47996091842651\n",
      "\n",
      " Epoch 2715\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.48006629943848\n",
      "\n",
      " Epoch 2716\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47967576980591\n",
      "\n",
      " Epoch 2717\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.478675365448\n",
      "\n",
      " Epoch 2718\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47968101501465\n",
      "\n",
      " Epoch 2719\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47918510437012\n",
      "\n",
      " Epoch 2720\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4785361289978\n",
      "\n",
      " Epoch 2721\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47982931137085\n",
      "\n",
      " Epoch 2722\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47903251647949\n",
      "\n",
      " Epoch 2723\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4793930053711\n",
      "\n",
      " Epoch 2724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.478280544281\n",
      "\n",
      " Epoch 2725\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47920799255371\n",
      "\n",
      " Epoch 2726\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47813081741333\n",
      "\n",
      " Epoch 2727\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47897958755493\n",
      "\n",
      " Epoch 2728\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47867631912231\n",
      "\n",
      " Epoch 2729\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47875928878784\n",
      "\n",
      " Epoch 2730\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47788858413696\n",
      "\n",
      " Epoch 2731\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47874402999878\n",
      "\n",
      " Epoch 2732\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47841691970825\n",
      "\n",
      " Epoch 2733\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47752285003662\n",
      "\n",
      " Epoch 2734\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47899007797241\n",
      "\n",
      " Epoch 2735\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47838401794434\n",
      "\n",
      " Epoch 2736\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4777159690857\n",
      "\n",
      " Epoch 2737\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47857475280762\n",
      "\n",
      " Epoch 2738\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47812843322754\n",
      "\n",
      " Epoch 2739\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4772458076477\n",
      "\n",
      " Epoch 2740\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47894525527954\n",
      "\n",
      " Epoch 2741\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47709655761719\n",
      "\n",
      " Epoch 2742\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47669506072998\n",
      "\n",
      " Epoch 2743\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47746133804321\n",
      "\n",
      " Epoch 2744\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47769689559937\n",
      "\n",
      " Epoch 2745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47787570953369\n",
      "\n",
      " Epoch 2746\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47641849517822\n",
      "\n",
      " Epoch 2747\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47821998596191\n",
      "\n",
      " Epoch 2748\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47707176208496\n",
      "\n",
      " Epoch 2749\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47647666931152\n",
      "\n",
      " Epoch 2750\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47679615020752\n",
      "\n",
      " Epoch 2751\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47709846496582\n",
      "\n",
      " Epoch 2752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47761487960815\n",
      "\n",
      " Epoch 2753\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47619295120239\n",
      "\n",
      " Epoch 2754\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4766993522644\n",
      "\n",
      " Epoch 2755\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47696685791016\n",
      "\n",
      " Epoch 2756\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47773218154907\n",
      "\n",
      " Epoch 2757\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47597694396973\n",
      "\n",
      " Epoch 2758\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47764921188354\n",
      "\n",
      " Epoch 2759\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47616958618164\n",
      "\n",
      " Epoch 2760\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47618770599365\n",
      "\n",
      " Epoch 2761\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47641468048096\n",
      "\n",
      " Epoch 2762\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47526931762695\n",
      "\n",
      " Epoch 2763\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4761266708374\n",
      "\n",
      " Epoch 2764\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47625398635864\n",
      "\n",
      " Epoch 2765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47686767578125\n",
      "\n",
      " Epoch 2766\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47520685195923\n",
      "\n",
      " Epoch 2767\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4758620262146\n",
      "\n",
      " Epoch 2768\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4760422706604\n",
      "\n",
      " Epoch 2769\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47518634796143\n",
      "\n",
      " Epoch 2770\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47591638565063\n",
      "\n",
      " Epoch 2771\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47554349899292\n",
      "\n",
      " Epoch 2772\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4753737449646\n",
      "\n",
      " Epoch 2773\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47553586959839\n",
      "\n",
      " Epoch 2774\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4757513999939\n",
      "\n",
      " Epoch 2775\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47632169723511\n",
      "\n",
      " Epoch 2776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47616481781006\n",
      "\n",
      " Epoch 2777\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47459030151367\n",
      "\n",
      " Epoch 2778\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47525644302368\n",
      "\n",
      " Epoch 2779\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47523546218872\n",
      "\n",
      " Epoch 2780\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47530508041382\n",
      "\n",
      " Epoch 2781\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47538661956787\n",
      "\n",
      " Epoch 2782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4758095741272\n",
      "\n",
      " Epoch 2783\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47428035736084\n",
      "\n",
      " Epoch 2784\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47608232498169\n",
      "\n",
      " Epoch 2785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47506856918335\n",
      "\n",
      " Epoch 2786\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47458791732788\n",
      "\n",
      " Epoch 2787\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47474145889282\n",
      "\n",
      " Epoch 2788\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47472095489502\n",
      "\n",
      " Epoch 2789\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47437858581543\n",
      "\n",
      " Epoch 2790\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47543907165527\n",
      "\n",
      " Epoch 2791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4750394821167\n",
      "\n",
      " Epoch 2792\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4741792678833\n",
      "\n",
      " Epoch 2793\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47434854507446\n",
      "\n",
      " Epoch 2794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47457504272461\n",
      "\n",
      " Epoch 2795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47370147705078\n",
      "\n",
      " Epoch 2796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47472476959229\n",
      "\n",
      " Epoch 2797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4745135307312\n",
      "\n",
      " Epoch 2798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47448635101318\n",
      "\n",
      " Epoch 2799\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47334623336792\n",
      "\n",
      " Epoch 2800\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47415256500244\n",
      "\n",
      " Epoch 2801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4742660522461\n",
      "\n",
      " Epoch 2802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47453451156616\n",
      "\n",
      " Epoch 2803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47353792190552\n",
      "\n",
      " Epoch 2804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47429466247559\n",
      "\n",
      " Epoch 2805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47351551055908\n",
      "\n",
      " Epoch 2806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47402858734131\n",
      "\n",
      " Epoch 2807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47305822372437\n",
      "\n",
      " Epoch 2808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47395133972168\n",
      "\n",
      " Epoch 2809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47356033325195\n",
      "\n",
      " Epoch 2810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47451162338257\n",
      "\n",
      " Epoch 2811\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47353219985962\n",
      "\n",
      " Epoch 2812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4740195274353\n",
      "\n",
      " Epoch 2813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.473867893219\n",
      "\n",
      " Epoch 2814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47300434112549\n",
      "\n",
      " Epoch 2815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47385787963867\n",
      "\n",
      " Epoch 2816\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47361516952515\n",
      "\n",
      " Epoch 2817\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47225093841553\n",
      "\n",
      " Epoch 2818\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4742784500122\n",
      "\n",
      " Epoch 2819\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47311305999756\n",
      "\n",
      " Epoch 2820\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4722318649292\n",
      "\n",
      " Epoch 2821\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47404670715332\n",
      "\n",
      " Epoch 2822\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4730772972107\n",
      "\n",
      " Epoch 2823\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47253322601318\n",
      "\n",
      " Epoch 2824\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47263097763062\n",
      "\n",
      " Epoch 2825\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4731650352478\n",
      "\n",
      " Epoch 2826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47346019744873\n",
      "\n",
      " Epoch 2827\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47127342224121\n",
      "\n",
      " Epoch 2828\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.473548412323\n",
      "\n",
      " Epoch 2829\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47316026687622\n",
      "\n",
      " Epoch 2830\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47124910354614\n",
      "\n",
      " Epoch 2831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47250890731812\n",
      "\n",
      " Epoch 2832\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47119045257568\n",
      "\n",
      " Epoch 2833\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47264003753662\n",
      "\n",
      " Epoch 2834\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47254228591919\n",
      "\n",
      " Epoch 2835\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47135639190674\n",
      "\n",
      " Epoch 2836\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47130060195923\n",
      "\n",
      " Epoch 2837\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47239112854004\n",
      "\n",
      " Epoch 2838\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4719614982605\n",
      "\n",
      " Epoch 2839\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4713773727417\n",
      "\n",
      " Epoch 2840\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47226619720459\n",
      "\n",
      " Epoch 2841\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47229719161987\n",
      "\n",
      " Epoch 2842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47234010696411\n",
      "\n",
      " Epoch 2843\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47164011001587\n",
      "\n",
      " Epoch 2844\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47174787521362\n",
      "\n",
      " Epoch 2845\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47013711929321\n",
      "\n",
      " Epoch 2846\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47129344940186\n",
      "\n",
      " Epoch 2847\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47145795822144\n",
      "\n",
      " Epoch 2848\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47133874893188\n",
      "\n",
      " Epoch 2849\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47133874893188\n",
      "\n",
      " Epoch 2850\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47137880325317\n",
      "\n",
      " Epoch 2851\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47152757644653\n",
      "\n",
      " Epoch 2852\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47080707550049\n",
      "\n",
      " Epoch 2853\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47149705886841\n",
      "\n",
      " Epoch 2854\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47071647644043\n",
      "\n",
      " Epoch 2855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47100591659546\n",
      "\n",
      " Epoch 2856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4713864326477\n",
      "\n",
      " Epoch 2857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47047901153564\n",
      "\n",
      " Epoch 2858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47204923629761\n",
      "\n",
      " Epoch 2859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47134637832642\n",
      "\n",
      " Epoch 2860\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47011137008667\n",
      "\n",
      " Epoch 2861\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47051763534546\n",
      "\n",
      " Epoch 2862\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47102546691895\n",
      "\n",
      " Epoch 2863\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47073650360107\n",
      "\n",
      " Epoch 2864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47076606750488\n",
      "\n",
      " Epoch 2865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47145175933838\n",
      "\n",
      " Epoch 2866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47097969055176\n",
      "\n",
      " Epoch 2867\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47029209136963\n",
      "\n",
      " Epoch 2868\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47011947631836\n",
      "\n",
      " Epoch 2869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47081708908081\n",
      "\n",
      " Epoch 2870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46973609924316\n",
      "\n",
      " Epoch 2871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47098731994629\n",
      "\n",
      " Epoch 2872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47014617919922\n",
      "\n",
      " Epoch 2873\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.47036933898926\n",
      "\n",
      " Epoch 2874\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.46953868865967\n",
      "\n",
      " Epoch 2875\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.4709119796753\n",
      "\n",
      " Epoch 2876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46983098983765\n",
      "\n",
      " Epoch 2877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47013473510742\n",
      "\n",
      " Epoch 2878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47036552429199\n",
      "\n",
      " Epoch 2879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46965885162354\n",
      "\n",
      " Epoch 2880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47025918960571\n",
      "\n",
      " Epoch 2881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46979904174805\n",
      "\n",
      " Epoch 2882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46997594833374\n",
      "\n",
      " Epoch 2883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46914386749268\n",
      "\n",
      " Epoch 2884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47029209136963\n",
      "\n",
      " Epoch 2885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46959447860718\n",
      "\n",
      " Epoch 2886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47008085250854\n",
      "\n",
      " Epoch 2887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46965551376343\n",
      "\n",
      " Epoch 2888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46995687484741\n",
      "\n",
      " Epoch 2889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4687967300415\n",
      "\n",
      " Epoch 2890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46915102005005\n",
      "\n",
      " Epoch 2891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46970272064209\n",
      "\n",
      " Epoch 2892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4695520401001\n",
      "\n",
      " Epoch 2893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.47042417526245\n",
      "\n",
      " Epoch 2894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46988296508789\n",
      "\n",
      " Epoch 2895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46884202957153\n",
      "\n",
      " Epoch 2896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46928119659424\n",
      "\n",
      " Epoch 2897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4691481590271\n",
      "\n",
      " Epoch 2898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46971035003662\n",
      "\n",
      " Epoch 2899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46917295455933\n",
      "\n",
      " Epoch 2900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4698576927185\n",
      "\n",
      " Epoch 2901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46836376190186\n",
      "\n",
      " Epoch 2902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4690670967102\n",
      "\n",
      " Epoch 2903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46999025344849\n",
      "\n",
      " Epoch 2904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46898365020752\n",
      "\n",
      " Epoch 2905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46864557266235\n",
      "\n",
      " Epoch 2906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46884107589722\n",
      "\n",
      " Epoch 2907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46943712234497\n",
      "\n",
      " Epoch 2908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46872472763062\n",
      "\n",
      " Epoch 2909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46928405761719\n",
      "\n",
      " Epoch 2910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46813488006592\n",
      "\n",
      " Epoch 2911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46875143051147\n",
      "\n",
      " Epoch 2912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4693455696106\n",
      "\n",
      " Epoch 2913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46854877471924\n",
      "\n",
      " Epoch 2914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46837186813354\n",
      "\n",
      " Epoch 2915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46912384033203\n",
      "\n",
      " Epoch 2916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46869277954102\n",
      "\n",
      " Epoch 2917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46922254562378\n",
      "\n",
      " Epoch 2918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46840524673462\n",
      "\n",
      " Epoch 2919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46893358230591\n",
      "\n",
      " Epoch 2920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46778345108032\n",
      "\n",
      " Epoch 2921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46839094161987\n",
      "\n",
      " Epoch 2922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4686336517334\n",
      "\n",
      " Epoch 2923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46823978424072\n",
      "\n",
      " Epoch 2924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46847486495972\n",
      "\n",
      " Epoch 2925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46873712539673\n",
      "\n",
      " Epoch 2926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4680495262146\n",
      "\n",
      " Epoch 2927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46910905838013\n",
      "\n",
      " Epoch 2928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46959590911865\n",
      "\n",
      " Epoch 2929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46919012069702\n",
      "\n",
      " Epoch 2930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46958255767822\n",
      "\n",
      " Epoch 2931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46876907348633\n",
      "\n",
      " Epoch 2932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4694356918335\n",
      "\n",
      " Epoch 2933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46783447265625\n",
      "\n",
      " Epoch 2934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4683780670166\n",
      "\n",
      " Epoch 2935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46919250488281\n",
      "\n",
      " Epoch 2936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46859550476074\n",
      "\n",
      " Epoch 2937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46885871887207\n",
      "\n",
      " Epoch 2938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46908378601074\n",
      "\n",
      " Epoch 2939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46825122833252\n",
      "\n",
      " Epoch 2940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46815156936646\n",
      "\n",
      " Epoch 2941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46909523010254\n",
      "\n",
      " Epoch 2942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46788024902344\n",
      "\n",
      " Epoch 2943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46848344802856\n",
      "\n",
      " Epoch 2944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46902704238892\n",
      "\n",
      " Epoch 2945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4690170288086\n",
      "\n",
      " Epoch 2946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46771574020386\n",
      "\n",
      " Epoch 2947\n",
      "\n",
      "Training accuracy :  0.983\n",
      "\n",
      "Training loss :  82.46790075302124\n",
      "\n",
      " Epoch 2948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46885585784912\n",
      "\n",
      " Epoch 2949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46926164627075\n",
      "\n",
      " Epoch 2950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46876764297485\n",
      "\n",
      " Epoch 2951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46787786483765\n",
      "\n",
      " Epoch 2952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46819829940796\n",
      "\n",
      " Epoch 2953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46869802474976\n",
      "\n",
      " Epoch 2954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46751594543457\n",
      "\n",
      " Epoch 2955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46809005737305\n",
      "\n",
      " Epoch 2956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46860265731812\n",
      "\n",
      " Epoch 2957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46737146377563\n",
      "\n",
      " Epoch 2958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46915817260742\n",
      "\n",
      " Epoch 2959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46732234954834\n",
      "\n",
      " Epoch 2960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4678225517273\n",
      "\n",
      " Epoch 2961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4678111076355\n",
      "\n",
      " Epoch 2962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46838331222534\n",
      "\n",
      " Epoch 2963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46732997894287\n",
      "\n",
      " Epoch 2964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46756649017334\n",
      "\n",
      " Epoch 2965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46809101104736\n",
      "\n",
      " Epoch 2966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46711254119873\n",
      "\n",
      " Epoch 2967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46750783920288\n",
      "\n",
      " Epoch 2968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46795082092285\n",
      "\n",
      " Epoch 2969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46804475784302\n",
      "\n",
      " Epoch 2970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46697235107422\n",
      "\n",
      " Epoch 2971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46723508834839\n",
      "\n",
      " Epoch 2972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4679388999939\n",
      "\n",
      " Epoch 2973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4672794342041\n",
      "\n",
      " Epoch 2974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46779203414917\n",
      "\n",
      " Epoch 2975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46684789657593\n",
      "\n",
      " Epoch 2976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46721315383911\n",
      "\n",
      " Epoch 2977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46767473220825\n",
      "\n",
      " Epoch 2978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46667671203613\n",
      "\n",
      " Epoch 2979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46837854385376\n",
      "\n",
      " Epoch 2980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46747732162476\n",
      "\n",
      " Epoch 2981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46654462814331\n",
      "\n",
      " Epoch 2982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46735382080078\n",
      "\n",
      " Epoch 2983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46706008911133\n",
      "\n",
      " Epoch 2984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4676718711853\n",
      "\n",
      " Epoch 2985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46636247634888\n",
      "\n",
      " Epoch 2986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46726417541504\n",
      "\n",
      " Epoch 2987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.467538356781\n",
      "\n",
      " Epoch 2988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46730136871338\n",
      "\n",
      " Epoch 2989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46637058258057\n",
      "\n",
      " Epoch 2990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46711921691895\n",
      "\n",
      " Epoch 2991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46735000610352\n",
      "\n",
      " Epoch 2992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46630144119263\n",
      "\n",
      " Epoch 2993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46663570404053\n",
      "\n",
      " Epoch 2994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46602821350098\n",
      "\n",
      " Epoch 2995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46694469451904\n",
      "\n",
      " Epoch 2996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46730041503906\n",
      "\n",
      " Epoch 2997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4660816192627\n",
      "\n",
      " Epoch 2998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46649503707886\n",
      "\n",
      " Epoch 2999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46583461761475\n",
      "\n",
      " Epoch 3000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46678113937378\n",
      "\n",
      " Epoch 3001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46710681915283\n",
      "\n",
      " Epoch 3002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4666919708252\n",
      "\n",
      " Epoch 3003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46590852737427\n",
      "\n",
      " Epoch 3004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46678686141968\n",
      "\n",
      " Epoch 3005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46652412414551\n",
      "\n",
      " Epoch 3006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46590089797974\n",
      "\n",
      " Epoch 3007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46677112579346\n",
      "\n",
      " Epoch 3008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4664945602417\n",
      "\n",
      " Epoch 3009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46665477752686\n",
      "\n",
      " Epoch 3010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4666576385498\n",
      "\n",
      " Epoch 3011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46632671356201\n",
      "\n",
      " Epoch 3012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46594190597534\n",
      "\n",
      " Epoch 3013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.466543674469\n",
      "\n",
      " Epoch 3014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46637344360352\n",
      "\n",
      " Epoch 3015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46583986282349\n",
      "\n",
      " Epoch 3016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46648502349854\n",
      "\n",
      " Epoch 3017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46633672714233\n",
      "\n",
      " Epoch 3018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4656434059143\n",
      "\n",
      " Epoch 3019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46654605865479\n",
      "\n",
      " Epoch 3020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4660792350769\n",
      "\n",
      " Epoch 3021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46572828292847\n",
      "\n",
      " Epoch 3022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46628522872925\n",
      "\n",
      " Epoch 3023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46615219116211\n",
      "\n",
      " Epoch 3024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46561002731323\n",
      "\n",
      " Epoch 3025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46624088287354\n",
      "\n",
      " Epoch 3026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4660873413086\n",
      "\n",
      " Epoch 3027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46538162231445\n",
      "\n",
      " Epoch 3028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46628189086914\n",
      "\n",
      " Epoch 3029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4658203125\n",
      "\n",
      " Epoch 3030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4654221534729\n",
      "\n",
      " Epoch 3031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46610498428345\n",
      "\n",
      " Epoch 3032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4658374786377\n",
      "\n",
      " Epoch 3033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4652452468872\n",
      "\n",
      " Epoch 3034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46610450744629\n",
      "\n",
      " Epoch 3035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46566867828369\n",
      "\n",
      " Epoch 3036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46532964706421\n",
      "\n",
      " Epoch 3037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46589517593384\n",
      "\n",
      " Epoch 3038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46571969985962\n",
      "\n",
      " Epoch 3039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46506834030151\n",
      "\n",
      " Epoch 3040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46578931808472\n",
      "\n",
      " Epoch 3041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46563959121704\n",
      "\n",
      " Epoch 3042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46498250961304\n",
      "\n",
      " Epoch 3043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46584177017212\n",
      "\n",
      " Epoch 3044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4654541015625\n",
      "\n",
      " Epoch 3045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46503734588623\n",
      "\n",
      " Epoch 3046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46564960479736\n",
      "\n",
      " Epoch 3047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46549034118652\n",
      "\n",
      " Epoch 3048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46485757827759\n",
      "\n",
      " Epoch 3049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46555233001709\n",
      "\n",
      " Epoch 3050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46539354324341\n",
      "\n",
      " Epoch 3051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46475553512573\n",
      "\n",
      " Epoch 3052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46546840667725\n",
      "\n",
      " Epoch 3053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46462345123291\n",
      "\n",
      " Epoch 3054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46542882919312\n",
      "\n",
      " Epoch 3055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4650650024414\n",
      "\n",
      " Epoch 3056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4646987915039\n",
      "\n",
      " Epoch 3057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4653582572937\n",
      "\n",
      " Epoch 3058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46515798568726\n",
      "\n",
      " Epoch 3059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46452379226685\n",
      "\n",
      " Epoch 3060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46530818939209\n",
      "\n",
      " Epoch 3061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46512413024902\n",
      "\n",
      " Epoch 3062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46440076828003\n",
      "\n",
      " Epoch 3063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46516275405884\n",
      "\n",
      " Epoch 3064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4650297164917\n",
      "\n",
      " Epoch 3065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46442079544067\n",
      "\n",
      " Epoch 3066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46516847610474\n",
      "\n",
      " Epoch 3067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46497774124146\n",
      "\n",
      " Epoch 3068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.464280128479\n",
      "\n",
      " Epoch 3069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46518659591675\n",
      "\n",
      " Epoch 3070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46484327316284\n",
      "\n",
      " Epoch 3071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46428442001343\n",
      "\n",
      " Epoch 3072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46501588821411\n",
      "\n",
      " Epoch 3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46484088897705\n",
      "\n",
      " Epoch 3074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46427869796753\n",
      "\n",
      " Epoch 3075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46494722366333\n",
      "\n",
      " Epoch 3076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46405506134033\n",
      "\n",
      " Epoch 3077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46492719650269\n",
      "\n",
      " Epoch 3078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46463584899902\n",
      "\n",
      " Epoch 3079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4639778137207\n",
      "\n",
      " Epoch 3080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46485424041748\n",
      "\n",
      " Epoch 3081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46466398239136\n",
      "\n",
      " Epoch 3082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46399068832397\n",
      "\n",
      " Epoch 3083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46479225158691\n",
      "\n",
      " Epoch 3084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46446418762207\n",
      "\n",
      " Epoch 3085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46386480331421\n",
      "\n",
      " Epoch 3086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46508312225342\n",
      "\n",
      " Epoch 3087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46472930908203\n",
      "\n",
      " Epoch 3088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46465492248535\n",
      "\n",
      " Epoch 3089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46401357650757\n",
      "\n",
      " Epoch 3090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4655385017395\n",
      "\n",
      " Epoch 3091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46438312530518\n",
      "\n",
      " Epoch 3092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46438694000244\n",
      "\n",
      " Epoch 3093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46432542800903\n",
      "\n",
      " Epoch 3094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46438264846802\n",
      "\n",
      " Epoch 3095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46369218826294\n",
      "\n",
      " Epoch 3096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46415996551514\n",
      "\n",
      " Epoch 3097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46410131454468\n",
      "\n",
      " Epoch 3098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46430683135986\n",
      "\n",
      " Epoch 3099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46344757080078\n",
      "\n",
      " Epoch 3100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46486473083496\n",
      "\n",
      " Epoch 3101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46407890319824\n",
      "\n",
      " Epoch 3102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46374464035034\n",
      "\n",
      " Epoch 3103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4640121459961\n",
      "\n",
      " Epoch 3104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46395778656006\n",
      "\n",
      " Epoch 3105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46322059631348\n",
      "\n",
      " Epoch 3106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4639344215393\n",
      "\n",
      " Epoch 3107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46389102935791\n",
      "\n",
      " Epoch 3108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46370601654053\n",
      "\n",
      " Epoch 3109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46323490142822\n",
      "\n",
      " Epoch 3110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4638557434082\n",
      "\n",
      " Epoch 3111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46367931365967\n",
      "\n",
      " Epoch 3112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46347188949585\n",
      "\n",
      " Epoch 3113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46366214752197\n",
      "\n",
      " Epoch 3114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46292924880981\n",
      "\n",
      " Epoch 3115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46367120742798\n",
      "\n",
      " Epoch 3116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46342849731445\n",
      "\n",
      " Epoch 3117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4635534286499\n",
      "\n",
      " Epoch 3118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46336507797241\n",
      "\n",
      " Epoch 3119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46291780471802\n",
      "\n",
      " Epoch 3120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46355676651001\n",
      "\n",
      " Epoch 3121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46337985992432\n",
      "\n",
      " Epoch 3122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46318626403809\n",
      "\n",
      " Epoch 3123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4631986618042\n",
      "\n",
      " Epoch 3124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46271991729736\n",
      "\n",
      " Epoch 3125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4633641242981\n",
      "\n",
      " Epoch 3126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4632077217102\n",
      "\n",
      " Epoch 3127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46325731277466\n",
      "\n",
      " Epoch 3128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46290683746338\n",
      "\n",
      " Epoch 3129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46258497238159\n",
      "\n",
      " Epoch 3130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46414470672607\n",
      "\n",
      " Epoch 3131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4620771408081\n",
      "\n",
      " Epoch 3132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46392488479614\n",
      "\n",
      " Epoch 3133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46305751800537\n",
      "\n",
      " Epoch 3134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46340703964233\n",
      "\n",
      " Epoch 3135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46306276321411\n",
      "\n",
      " Epoch 3136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46314287185669\n",
      "\n",
      " Epoch 3137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46209192276001\n",
      "\n",
      " Epoch 3138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46304225921631\n",
      "\n",
      " Epoch 3139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46266841888428\n",
      "\n",
      " Epoch 3140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46215677261353\n",
      "\n",
      " Epoch 3141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46282386779785\n",
      "\n",
      " Epoch 3142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46252822875977\n",
      "\n",
      " Epoch 3143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46199798583984\n",
      "\n",
      " Epoch 3144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4627537727356\n",
      "\n",
      " Epoch 3145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46267795562744\n",
      "\n",
      " Epoch 3146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46256256103516\n",
      "\n",
      " Epoch 3147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46174478530884\n",
      "\n",
      " Epoch 3148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46361684799194\n",
      "\n",
      " Epoch 3149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46253108978271\n",
      "\n",
      " Epoch 3150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46304893493652\n",
      "\n",
      " Epoch 3151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46299505233765\n",
      "\n",
      " Epoch 3152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46295928955078\n",
      "\n",
      " Epoch 3153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46184062957764\n",
      "\n",
      " Epoch 3154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46272373199463\n",
      "\n",
      " Epoch 3155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46184873580933\n",
      "\n",
      " Epoch 3156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46266841888428\n",
      "\n",
      " Epoch 3157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46252155303955\n",
      "\n",
      " Epoch 3158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46169710159302\n",
      "\n",
      " Epoch 3159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46265172958374\n",
      "\n",
      " Epoch 3160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46250486373901\n",
      "\n",
      " Epoch 3161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4618592262268\n",
      "\n",
      " Epoch 3162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46261262893677\n",
      "\n",
      " Epoch 3163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46230506896973\n",
      "\n",
      " Epoch 3164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4618091583252\n",
      "\n",
      " Epoch 3165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46255826950073\n",
      "\n",
      " Epoch 3166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46239233016968\n",
      "\n",
      " Epoch 3167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46164226531982\n",
      "\n",
      " Epoch 3168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46203660964966\n",
      "\n",
      " Epoch 3169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46171522140503\n",
      "\n",
      " Epoch 3170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46245098114014\n",
      "\n",
      " Epoch 3171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46217727661133\n",
      "\n",
      " Epoch 3172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.461678981781\n",
      "\n",
      " Epoch 3173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46189260482788\n",
      "\n",
      " Epoch 3174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46234464645386\n",
      "\n",
      " Epoch 3175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46189403533936\n",
      "\n",
      " Epoch 3176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46229696273804\n",
      "\n",
      " Epoch 3177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46164417266846\n",
      "\n",
      " Epoch 3178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46184396743774\n",
      "\n",
      " Epoch 3179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46225547790527\n",
      "\n",
      " Epoch 3180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46143913269043\n",
      "\n",
      " Epoch 3181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46179389953613\n",
      "\n",
      " Epoch 3182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46221685409546\n",
      "\n",
      " Epoch 3183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4613709449768\n",
      "\n",
      " Epoch 3184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46175527572632\n",
      "\n",
      " Epoch 3185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46215772628784\n",
      "\n",
      " Epoch 3186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46152687072754\n",
      "\n",
      " Epoch 3187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46173095703125\n",
      "\n",
      " Epoch 3188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46199703216553\n",
      "\n",
      " Epoch 3189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46140623092651\n",
      "\n",
      " Epoch 3190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46164226531982\n",
      "\n",
      " Epoch 3191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46209812164307\n",
      "\n",
      " Epoch 3192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46114110946655\n",
      "\n",
      " Epoch 3193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46167039871216\n",
      "\n",
      " Epoch 3194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46193647384644\n",
      "\n",
      " Epoch 3195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46138143539429\n",
      "\n",
      " Epoch 3196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46154308319092\n",
      "\n",
      " Epoch 3197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46184778213501\n",
      "\n",
      " Epoch 3198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4616904258728\n",
      "\n",
      " Epoch 3199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46190738677979\n",
      "\n",
      " Epoch 3200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46111965179443\n",
      "\n",
      " Epoch 3201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46155309677124\n",
      "\n",
      " Epoch 3202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46116924285889\n",
      "\n",
      " Epoch 3203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4611587524414\n",
      "\n",
      " Epoch 3204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46141386032104\n",
      "\n",
      " Epoch 3205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46188259124756\n",
      "\n",
      " Epoch 3206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46165418624878\n",
      "\n",
      " Epoch 3207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4610652923584\n",
      "\n",
      " Epoch 3208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46137571334839\n",
      "\n",
      " Epoch 3209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46179294586182\n",
      "\n",
      " Epoch 3210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032476425171\n",
      "\n",
      " Epoch 3211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46147727966309\n",
      "\n",
      " Epoch 3212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46179246902466\n",
      "\n",
      " Epoch 3213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073913574219\n",
      "\n",
      " Epoch 3214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46142101287842\n",
      "\n",
      " Epoch 3215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46161699295044\n",
      "\n",
      " Epoch 3216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46098184585571\n",
      "\n",
      " Epoch 3217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46128368377686\n",
      "\n",
      " Epoch 3218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46152925491333\n",
      "\n",
      " Epoch 3219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46095848083496\n",
      "\n",
      " Epoch 3220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46168899536133\n",
      "\n",
      " Epoch 3221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031618118286\n",
      "\n",
      " Epoch 3222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46110105514526\n",
      "\n",
      " Epoch 3223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46157646179199\n",
      "\n",
      " Epoch 3224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46147918701172\n",
      "\n",
      " Epoch 3225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067094802856\n",
      "\n",
      " Epoch 3226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46099805831909\n",
      "\n",
      " Epoch 3227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46145725250244\n",
      "\n",
      " Epoch 3228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602918624878\n",
      "\n",
      " Epoch 3229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46109580993652\n",
      "\n",
      " Epoch 3230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46133470535278\n",
      "\n",
      " Epoch 3231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46066904067993\n",
      "\n",
      " Epoch 3232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46110534667969\n",
      "\n",
      " Epoch 3233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065521240234\n",
      "\n",
      " Epoch 3234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46075487136841\n",
      "\n",
      " Epoch 3235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46098852157593\n",
      "\n",
      " Epoch 3236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073007583618\n",
      "\n",
      " Epoch 3237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072483062744\n",
      "\n",
      " Epoch 3238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46097183227539\n",
      "\n",
      " Epoch 3239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46138715744019\n",
      "\n",
      " Epoch 3240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042919158936\n",
      "\n",
      " Epoch 3241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092224121094\n",
      "\n",
      " Epoch 3242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080207824707\n",
      "\n",
      " Epoch 3243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46088075637817\n",
      "\n",
      " Epoch 3244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606876373291\n",
      "\n",
      " Epoch 3245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46138954162598\n",
      "\n",
      " Epoch 3246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067476272583\n",
      "\n",
      " Epoch 3247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46090459823608\n",
      "\n",
      " Epoch 3248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065616607666\n",
      "\n",
      " Epoch 3249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053457260132\n",
      "\n",
      " Epoch 3250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46097183227539\n",
      "\n",
      " Epoch 3251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46058750152588\n",
      "\n",
      " Epoch 3252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017646789551\n",
      "\n",
      " Epoch 3253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46091413497925\n",
      "\n",
      " Epoch 3254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46103572845459\n",
      "\n",
      " Epoch 3255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019506454468\n",
      "\n",
      " Epoch 3256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085357666016\n",
      "\n",
      " Epoch 3257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061038970947\n",
      "\n",
      " Epoch 3258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46062564849854\n",
      "\n",
      " Epoch 3259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072721481323\n",
      "\n",
      " Epoch 3260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064567565918\n",
      "\n",
      " Epoch 3261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605622291565\n",
      "\n",
      " Epoch 3262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46081113815308\n",
      "\n",
      " Epoch 3263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46117448806763\n",
      "\n",
      " Epoch 3264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019411087036\n",
      "\n",
      " Epoch 3265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080684661865\n",
      "\n",
      " Epoch 3266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055793762207\n",
      "\n",
      " Epoch 3267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080780029297\n",
      "\n",
      " Epoch 3268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604082107544\n",
      "\n",
      " Epoch 3269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46125364303589\n",
      "\n",
      " Epoch 3270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45992803573608\n",
      "\n",
      " Epoch 3271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46086168289185\n",
      "\n",
      " Epoch 3272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604082107544\n",
      "\n",
      " Epoch 3273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46057510375977\n",
      "\n",
      " Epoch 3274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46069431304932\n",
      "\n",
      " Epoch 3275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604697227478\n",
      "\n",
      " Epoch 3276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46047687530518\n",
      "\n",
      " Epoch 3277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064281463623\n",
      "\n",
      " Epoch 3278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034955978394\n",
      "\n",
      " Epoch 3279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001815795898\n",
      "\n",
      " Epoch 3280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46070194244385\n",
      "\n",
      " Epoch 3281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035432815552\n",
      "\n",
      " Epoch 3282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053981781006\n",
      "\n",
      " Epoch 3283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46056842803955\n",
      "\n",
      " Epoch 3284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604058265686\n",
      "\n",
      " Epoch 3285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46108818054199\n",
      "\n",
      " Epoch 3286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993947982788\n",
      "\n",
      " Epoch 3287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46076393127441\n",
      "\n",
      " Epoch 3288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023082733154\n",
      "\n",
      " Epoch 3289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044111251831\n",
      "\n",
      " Epoch 3290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605131149292\n",
      "\n",
      " Epoch 3291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035861968994\n",
      "\n",
      " Epoch 3292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46102857589722\n",
      "\n",
      " Epoch 3293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45959234237671\n",
      "\n",
      " Epoch 3294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061944961548\n",
      "\n",
      " Epoch 3295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045064926147\n",
      "\n",
      " Epoch 3296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45963382720947\n",
      "\n",
      " Epoch 3297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059942245483\n",
      "\n",
      " Epoch 3298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055746078491\n",
      "\n",
      " Epoch 3299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46068096160889\n",
      "\n",
      " Epoch 3300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985174179077\n",
      "\n",
      " Epoch 3301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055364608765\n",
      "\n",
      " Epoch 3302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020078659058\n",
      "\n",
      " Epoch 3303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984220504761\n",
      "\n",
      " Epoch 3304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46056270599365\n",
      "\n",
      " Epoch 3305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021699905396\n",
      "\n",
      " Epoch 3306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46094942092896\n",
      "\n",
      " Epoch 3307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950031280518\n",
      "\n",
      " Epoch 3308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065902709961\n",
      "\n",
      " Epoch 3309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031141281128\n",
      "\n",
      " Epoch 3310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46071910858154\n",
      "\n",
      " Epoch 3311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459792137146\n",
      "\n",
      " Epoch 3312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46049642562866\n",
      "\n",
      " Epoch 3313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601902961731\n",
      "\n",
      " Epoch 3314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014165878296\n",
      "\n",
      " Epoch 3315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053314208984\n",
      "\n",
      " Epoch 3316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013355255127\n",
      "\n",
      " Epoch 3317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596300125122\n",
      "\n",
      " Epoch 3318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46057605743408\n",
      "\n",
      " Epoch 3319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46016836166382\n",
      "\n",
      " Epoch 3320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080541610718\n",
      "\n",
      " Epoch 3321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951461791992\n",
      "\n",
      " Epoch 3322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033573150635\n",
      "\n",
      " Epoch 3323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042442321777\n",
      "\n",
      " Epoch 3324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954895019531\n",
      "\n",
      " Epoch 3325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026182174683\n",
      "\n",
      " Epoch 3326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043252944946\n",
      "\n",
      " Epoch 3327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46068954467773\n",
      "\n",
      " Epoch 3328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953607559204\n",
      "\n",
      " Epoch 3329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044921875\n",
      "\n",
      " Epoch 3330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600567817688\n",
      "\n",
      " Epoch 3331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46084833145142\n",
      "\n",
      " Epoch 3332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594235420227\n",
      "\n",
      " Epoch 3333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048641204834\n",
      "\n",
      " Epoch 3334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460533618927\n",
      "\n",
      " Epoch 3335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595856666565\n",
      "\n",
      " Epoch 3336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605827331543\n",
      "\n",
      " Epoch 3337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4613127708435\n",
      "\n",
      " Epoch 3338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061992645264\n",
      "\n",
      " Epoch 3339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607400894165\n",
      "\n",
      " Epoch 3340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085691452026\n",
      "\n",
      " Epoch 3341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072292327881\n",
      "\n",
      " Epoch 3342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46138000488281\n",
      "\n",
      " Epoch 3343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999097824097\n",
      "\n",
      " Epoch 3344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46110534667969\n",
      "\n",
      " Epoch 3345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46150732040405\n",
      "\n",
      " Epoch 3346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002388000488\n",
      "\n",
      " Epoch 3347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46099376678467\n",
      "\n",
      " Epoch 3348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46149349212646\n",
      "\n",
      " Epoch 3349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605803489685\n",
      "\n",
      " Epoch 3350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067714691162\n",
      "\n",
      " Epoch 3351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46134233474731\n",
      "\n",
      " Epoch 3352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46103811264038\n",
      "\n",
      " Epoch 3353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46122455596924\n",
      "\n",
      " Epoch 3354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005821228027\n",
      "\n",
      " Epoch 3355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46107006072998\n",
      "\n",
      " Epoch 3356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4610161781311\n",
      "\n",
      " Epoch 3357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46143579483032\n",
      "\n",
      " Epoch 3358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032571792603\n",
      "\n",
      " Epoch 3359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46124172210693\n",
      "\n",
      " Epoch 3360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46094989776611\n",
      "\n",
      " Epoch 3361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46139860153198\n",
      "\n",
      " Epoch 3362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008682250977\n",
      "\n",
      " Epoch 3363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46103858947754\n",
      "\n",
      " Epoch 3364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605507850647\n",
      "\n",
      " Epoch 3365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46118927001953\n",
      "\n",
      " Epoch 3366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4610047340393\n",
      "\n",
      " Epoch 3367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46133041381836\n",
      "\n",
      " Epoch 3368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995044708252\n",
      "\n",
      " Epoch 3369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46112298965454\n",
      "\n",
      " Epoch 3370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46162748336792\n",
      "\n",
      " Epoch 3371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025371551514\n",
      "\n",
      " Epoch 3372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46145868301392\n",
      "\n",
      " Epoch 3373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46132040023804\n",
      "\n",
      " Epoch 3374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998334884644\n",
      "\n",
      " Epoch 3375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46108436584473\n",
      "\n",
      " Epoch 3376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46119403839111\n",
      "\n",
      " Epoch 3377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060085296631\n",
      "\n",
      " Epoch 3378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46137046813965\n",
      "\n",
      " Epoch 3379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46126699447632\n",
      "\n",
      " Epoch 3380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993375778198\n",
      "\n",
      " Epoch 3381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46112823486328\n",
      "\n",
      " Epoch 3382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092319488525\n",
      "\n",
      " Epoch 3383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026515960693\n",
      "\n",
      " Epoch 3384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4613995552063\n",
      "\n",
      " Epoch 3385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46097755432129\n",
      "\n",
      " Epoch 3386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46077060699463\n",
      "\n",
      " Epoch 3387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025609970093\n",
      "\n",
      " Epoch 3388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4610047340393\n",
      "\n",
      " Epoch 3389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46100282669067\n",
      "\n",
      " Epoch 3390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.461181640625\n",
      "\n",
      " Epoch 3391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014547348022\n",
      "\n",
      " Epoch 3392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46133518218994\n",
      "\n",
      " Epoch 3393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46095752716064\n",
      "\n",
      " Epoch 3394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46126079559326\n",
      "\n",
      " Epoch 3395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006870269775\n",
      "\n",
      " Epoch 3396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46097803115845\n",
      "\n",
      " Epoch 3397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032047271729\n",
      "\n",
      " Epoch 3398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46135091781616\n",
      "\n",
      " Epoch 3399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46095991134644\n",
      "\n",
      " Epoch 3400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073532104492\n",
      "\n",
      " Epoch 3401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46063423156738\n",
      "\n",
      " Epoch 3402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46129369735718\n",
      "\n",
      " Epoch 3403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46117973327637\n",
      "\n",
      " Epoch 3404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605360031128\n",
      "\n",
      " Epoch 3405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605484008789\n",
      "\n",
      " Epoch 3406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46121120452881\n",
      "\n",
      " Epoch 3407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46097612380981\n",
      "\n",
      " Epoch 3408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601993560791\n",
      "\n",
      " Epoch 3409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46124410629272\n",
      "\n",
      " Epoch 3410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085214614868\n",
      "\n",
      " Epoch 3411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46118545532227\n",
      "\n",
      " Epoch 3412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002054214478\n",
      "\n",
      " Epoch 3413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609694480896\n",
      "\n",
      " Epoch 3414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46122550964355\n",
      "\n",
      " Epoch 3415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46105098724365\n",
      "\n",
      " Epoch 3416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018648147583\n",
      "\n",
      " Epoch 3417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46086025238037\n",
      "\n",
      " Epoch 3418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608736038208\n",
      "\n",
      " Epoch 3419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46116352081299\n",
      "\n",
      " Epoch 3420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46016454696655\n",
      "\n",
      " Epoch 3421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46088552474976\n",
      "\n",
      " Epoch 3422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603853225708\n",
      "\n",
      " Epoch 3423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46198606491089\n",
      "\n",
      " Epoch 3424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46140670776367\n",
      "\n",
      " Epoch 3425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46101570129395\n",
      "\n",
      " Epoch 3426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064758300781\n",
      "\n",
      " Epoch 3427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46117401123047\n",
      "\n",
      " Epoch 3428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46090602874756\n",
      "\n",
      " Epoch 3429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46079635620117\n",
      "\n",
      " Epoch 3430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46071910858154\n",
      "\n",
      " Epoch 3431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46120929718018\n",
      "\n",
      " Epoch 3432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092224121094\n",
      "\n",
      " Epoch 3433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46098327636719\n",
      "\n",
      " Epoch 3434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053647994995\n",
      "\n",
      " Epoch 3435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4620943069458\n",
      "\n",
      " Epoch 3436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46154308319092\n",
      "\n",
      " Epoch 3437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46161985397339\n",
      "\n",
      " Epoch 3438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46118021011353\n",
      "\n",
      " Epoch 3439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043968200684\n",
      "\n",
      " Epoch 3440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46107244491577\n",
      "\n",
      " Epoch 3441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604606628418\n",
      "\n",
      " Epoch 3442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46197271347046\n",
      "\n",
      " Epoch 3443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4614896774292\n",
      "\n",
      " Epoch 3444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4612283706665\n",
      "\n",
      " Epoch 3445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.461021900177\n",
      "\n",
      " Epoch 3446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037197113037\n",
      "\n",
      " Epoch 3447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092557907104\n",
      "\n",
      " Epoch 3448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46108722686768\n",
      "\n",
      " Epoch 3449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46120500564575\n",
      "\n",
      " Epoch 3450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034049987793\n",
      "\n",
      " Epoch 3451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46141052246094\n",
      "\n",
      " Epoch 3452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46082878112793\n",
      "\n",
      " Epoch 3453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025228500366\n",
      "\n",
      " Epoch 3454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46142768859863\n",
      "\n",
      " Epoch 3455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609751701355\n",
      "\n",
      " Epoch 3456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023321151733\n",
      "\n",
      " Epoch 3457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46157550811768\n",
      "\n",
      " Epoch 3458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073961257935\n",
      "\n",
      " Epoch 3459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602952003479\n",
      "\n",
      " Epoch 3460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46159839630127\n",
      "\n",
      " Epoch 3461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46105337142944\n",
      "\n",
      " Epoch 3462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036624908447\n",
      "\n",
      " Epoch 3463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46068620681763\n",
      "\n",
      " Epoch 3464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072340011597\n",
      "\n",
      " Epoch 3465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46110677719116\n",
      "\n",
      " Epoch 3466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46054220199585\n",
      "\n",
      " Epoch 3467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855379104614\n",
      "\n",
      " Epoch 3468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46070194244385\n",
      "\n",
      " Epoch 3469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46136522293091\n",
      "\n",
      " Epoch 3470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080732345581\n",
      "\n",
      " Epoch 3471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053218841553\n",
      "\n",
      " Epoch 3472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46130800247192\n",
      "\n",
      " Epoch 3473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092557907104\n",
      "\n",
      " Epoch 3474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028423309326\n",
      "\n",
      " Epoch 3475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46124219894409\n",
      "\n",
      " Epoch 3476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46081686019897\n",
      "\n",
      " Epoch 3477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609580039978\n",
      "\n",
      " Epoch 3478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46040105819702\n",
      "\n",
      " Epoch 3479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060800552368\n",
      "\n",
      " Epoch 3480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46127557754517\n",
      "\n",
      " Epoch 3481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46069383621216\n",
      "\n",
      " Epoch 3482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46047925949097\n",
      "\n",
      " Epoch 3483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841360092163\n",
      "\n",
      " Epoch 3484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46088075637817\n",
      "\n",
      " Epoch 3485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609785079956\n",
      "\n",
      " Epoch 3486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46089458465576\n",
      "\n",
      " Epoch 3487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027565002441\n",
      "\n",
      " Epoch 3488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46142530441284\n",
      "\n",
      " Epoch 3489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064043045044\n",
      "\n",
      " Epoch 3490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092367172241\n",
      "\n",
      " Epoch 3491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608302116394\n",
      "\n",
      " Epoch 3492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46219968795776\n",
      "\n",
      " Epoch 3493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46100091934204\n",
      "\n",
      " Epoch 3494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085834503174\n",
      "\n",
      " Epoch 3495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986557006836\n",
      "\n",
      " Epoch 3496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46107244491577\n",
      "\n",
      " Epoch 3497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46099138259888\n",
      "\n",
      " Epoch 3498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002340316772\n",
      "\n",
      " Epoch 3499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46108055114746\n",
      "\n",
      " Epoch 3500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067810058594\n",
      "\n",
      " Epoch 3501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028327941895\n",
      "\n",
      " Epoch 3502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582109451294\n",
      "\n",
      " Epoch 3503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46172714233398\n",
      "\n",
      " Epoch 3504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46104192733765\n",
      "\n",
      " Epoch 3505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609022140503\n",
      "\n",
      " Epoch 3506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607424736023\n",
      "\n",
      " Epoch 3507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602632522583\n",
      "\n",
      " Epoch 3508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46103572845459\n",
      "\n",
      " Epoch 3509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46052312850952\n",
      "\n",
      " Epoch 3510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022367477417\n",
      "\n",
      " Epoch 3511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822191238403\n",
      "\n",
      " Epoch 3512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061277389526\n",
      "\n",
      " Epoch 3513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606261253357\n",
      "\n",
      " Epoch 3514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605860710144\n",
      "\n",
      " Epoch 3515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603476524353\n",
      "\n",
      " Epoch 3516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4615330696106\n",
      "\n",
      " Epoch 3517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4611005783081\n",
      "\n",
      " Epoch 3518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46092987060547\n",
      "\n",
      " Epoch 3519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037292480469\n",
      "\n",
      " Epoch 3520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036529541016\n",
      "\n",
      " Epoch 3521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46090316772461\n",
      "\n",
      " Epoch 3522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060228347778\n",
      "\n",
      " Epoch 3523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017503738403\n",
      "\n",
      " Epoch 3524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46154308319092\n",
      "\n",
      " Epoch 3525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46091365814209\n",
      "\n",
      " Epoch 3526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46078062057495\n",
      "\n",
      " Epoch 3527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975589752197\n",
      "\n",
      " Epoch 3528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46078824996948\n",
      "\n",
      " Epoch 3529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604320526123\n",
      "\n",
      " Epoch 3530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993232727051\n",
      "\n",
      " Epoch 3531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609112739563\n",
      "\n",
      " Epoch 3532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608211517334\n",
      "\n",
      " Epoch 3533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599061012268\n",
      "\n",
      " Epoch 3534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46069955825806\n",
      "\n",
      " Epoch 3535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46091890335083\n",
      "\n",
      " Epoch 3536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974636077881\n",
      "\n",
      " Epoch 3537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46156024932861\n",
      "\n",
      " Epoch 3538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4609956741333\n",
      "\n",
      " Epoch 3539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608473777771\n",
      "\n",
      " Epoch 3540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598937034607\n",
      "\n",
      " Epoch 3541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067476272583\n",
      "\n",
      " Epoch 3542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072435379028\n",
      "\n",
      " Epoch 3543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019744873047\n",
      "\n",
      " Epoch 3544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46088314056396\n",
      "\n",
      " Epoch 3545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607343673706\n",
      "\n",
      " Epoch 3546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017646789551\n",
      "\n",
      " Epoch 3547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46070432662964\n",
      "\n",
      " Epoch 3548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46086406707764\n",
      "\n",
      " Epoch 3549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989084243774\n",
      "\n",
      " Epoch 3550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795392990112\n",
      "\n",
      " Epoch 3551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045064926147\n",
      "\n",
      " Epoch 3552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059942245483\n",
      "\n",
      " Epoch 3553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46078491210938\n",
      "\n",
      " Epoch 3554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004486083984\n",
      "\n",
      " Epoch 3555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46156740188599\n",
      "\n",
      " Epoch 3556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085405349731\n",
      "\n",
      " Epoch 3557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46077060699463\n",
      "\n",
      " Epoch 3558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976209640503\n",
      "\n",
      " Epoch 3559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059846878052\n",
      "\n",
      " Epoch 3560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065330505371\n",
      "\n",
      " Epoch 3561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014642715454\n",
      "\n",
      " Epoch 3562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46128511428833\n",
      "\n",
      " Epoch 3563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46104288101196\n",
      "\n",
      " Epoch 3564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606122970581\n",
      "\n",
      " Epoch 3565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993089675903\n",
      "\n",
      " Epoch 3566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060085296631\n",
      "\n",
      " Epoch 3567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46068716049194\n",
      "\n",
      " Epoch 3568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997476577759\n",
      "\n",
      " Epoch 3569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789432525635\n",
      "\n",
      " Epoch 3570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46142578125\n",
      "\n",
      " Epoch 3571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080780029297\n",
      "\n",
      " Epoch 3572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606499671936\n",
      "\n",
      " Epoch 3573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996141433716\n",
      "\n",
      " Epoch 3574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46145486831665\n",
      "\n",
      " Epoch 3575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46090459823608\n",
      "\n",
      " Epoch 3576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073913574219\n",
      "\n",
      " Epoch 3577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953559875488\n",
      "\n",
      " Epoch 3578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46077632904053\n",
      "\n",
      " Epoch 3579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603214263916\n",
      "\n",
      " Epoch 3580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993423461914\n",
      "\n",
      " Epoch 3581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064043045044\n",
      "\n",
      " Epoch 3582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020364761353\n",
      "\n",
      " Epoch 3583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045064926147\n",
      "\n",
      " Epoch 3584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960330963135\n",
      "\n",
      " Epoch 3585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46081209182739\n",
      "\n",
      " Epoch 3586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033430099487\n",
      "\n",
      " Epoch 3587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993041992188\n",
      "\n",
      " Epoch 3588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46088123321533\n",
      "\n",
      " Epoch 3589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037340164185\n",
      "\n",
      " Epoch 3590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997953414917\n",
      "\n",
      " Epoch 3591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801830291748\n",
      "\n",
      " Epoch 3592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020746231079\n",
      "\n",
      " Epoch 3593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46076345443726\n",
      "\n",
      " Epoch 3594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46046018600464\n",
      "\n",
      " Epoch 3595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599928855896\n",
      "\n",
      " Epoch 3596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46151304244995\n",
      "\n",
      " Epoch 3597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46071767807007\n",
      "\n",
      " Epoch 3598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605188369751\n",
      "\n",
      " Epoch 3599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994281768799\n",
      "\n",
      " Epoch 3600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085977554321\n",
      "\n",
      " Epoch 3601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026611328125\n",
      "\n",
      " Epoch 3602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460036277771\n",
      "\n",
      " Epoch 3603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46128940582275\n",
      "\n",
      " Epoch 3604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46054220199585\n",
      "\n",
      " Epoch 3605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46071863174438\n",
      "\n",
      " Epoch 3606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596815109253\n",
      "\n",
      " Epoch 3607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067953109741\n",
      "\n",
      " Epoch 3608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009588241577\n",
      "\n",
      " Epoch 3609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006536483765\n",
      "\n",
      " Epoch 3610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804119110107\n",
      "\n",
      " Epoch 3611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014022827148\n",
      "\n",
      " Epoch 3612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46049356460571\n",
      "\n",
      " Epoch 3613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072435379028\n",
      "\n",
      " Epoch 3614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598069190979\n",
      "\n",
      " Epoch 3615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46133852005005\n",
      "\n",
      " Epoch 3616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46057176589966\n",
      "\n",
      " Epoch 3617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46051692962646\n",
      "\n",
      " Epoch 3618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45959568023682\n",
      "\n",
      " Epoch 3619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46050262451172\n",
      "\n",
      " Epoch 3620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045064926147\n",
      "\n",
      " Epoch 3621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972013473511\n",
      "\n",
      " Epoch 3622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055793762207\n",
      "\n",
      " Epoch 3623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602918624878\n",
      "\n",
      " Epoch 3624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603157043457\n",
      "\n",
      " Epoch 3625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995759963989\n",
      "\n",
      " Epoch 3626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605975151062\n",
      "\n",
      " Epoch 3627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032476425171\n",
      "\n",
      " Epoch 3628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45978021621704\n",
      "\n",
      " Epoch 3629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789813995361\n",
      "\n",
      " Epoch 3630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604663848877\n",
      "\n",
      " Epoch 3631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46049070358276\n",
      "\n",
      " Epoch 3632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976734161377\n",
      "\n",
      " Epoch 3633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46126079559326\n",
      "\n",
      " Epoch 3634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059370040894\n",
      "\n",
      " Epoch 3635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46057367324829\n",
      "\n",
      " Epoch 3636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975351333618\n",
      "\n",
      " Epoch 3637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46066904067993\n",
      "\n",
      " Epoch 3638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021938323975\n",
      "\n",
      " Epoch 3639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968818664551\n",
      "\n",
      " Epoch 3640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788764953613\n",
      "\n",
      " Epoch 3641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012783050537\n",
      "\n",
      " Epoch 3642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044969558716\n",
      "\n",
      " Epoch 3643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600133895874\n",
      "\n",
      " Epoch 3644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595718383789\n",
      "\n",
      " Epoch 3645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033525466919\n",
      "\n",
      " Epoch 3646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022748947144\n",
      "\n",
      " Epoch 3647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034717559814\n",
      "\n",
      " Epoch 3648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46163892745972\n",
      "\n",
      " Epoch 3649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020555496216\n",
      "\n",
      " Epoch 3650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015167236328\n",
      "\n",
      " Epoch 3651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598445892334\n",
      "\n",
      " Epoch 3652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787906646729\n",
      "\n",
      " Epoch 3653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598913192749\n",
      "\n",
      " Epoch 3654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021842956543\n",
      "\n",
      " Epoch 3655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946931838989\n",
      "\n",
      " Epoch 3656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46039199829102\n",
      "\n",
      " Epoch 3657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602632522583\n",
      "\n",
      " Epoch 3658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951271057129\n",
      "\n",
      " Epoch 3659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46128129959106\n",
      "\n",
      " Epoch 3660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604811668396\n",
      "\n",
      " Epoch 3661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036624908447\n",
      "\n",
      " Epoch 3662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595513343811\n",
      "\n",
      " Epoch 3663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818996429443\n",
      "\n",
      " Epoch 3664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600133895874\n",
      "\n",
      " Epoch 3665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46158361434937\n",
      "\n",
      " Epoch 3666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023035049438\n",
      "\n",
      " Epoch 3667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45963430404663\n",
      "\n",
      " Epoch 3668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46070861816406\n",
      "\n",
      " Epoch 3669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751333236694\n",
      "\n",
      " Epoch 3670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595136642456\n",
      "\n",
      " Epoch 3671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044540405273\n",
      "\n",
      " Epoch 3672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967960357666\n",
      "\n",
      " Epoch 3673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46052503585815\n",
      "\n",
      " Epoch 3674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595537185669\n",
      "\n",
      " Epoch 3675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766592025757\n",
      "\n",
      " Epoch 3676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46051549911499\n",
      "\n",
      " Epoch 3677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053266525269\n",
      "\n",
      " Epoch 3678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807361602783\n",
      "\n",
      " Epoch 3679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038341522217\n",
      "\n",
      " Epoch 3680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460524559021\n",
      "\n",
      " Epoch 3681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974731445312\n",
      "\n",
      " Epoch 3682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46063709259033\n",
      "\n",
      " Epoch 3683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921277999878\n",
      "\n",
      " Epoch 3684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798015594482\n",
      "\n",
      " Epoch 3685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019983291626\n",
      "\n",
      " Epoch 3686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46183586120605\n",
      "\n",
      " Epoch 3687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020221710205\n",
      "\n",
      " Epoch 3688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46049547195435\n",
      "\n",
      " Epoch 3689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805025100708\n",
      "\n",
      " Epoch 3690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974349975586\n",
      "\n",
      " Epoch 3691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46096563339233\n",
      "\n",
      " Epoch 3692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044778823853\n",
      "\n",
      " Epoch 3693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821619033813\n",
      "\n",
      " Epoch 3694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459951877594\n",
      "\n",
      " Epoch 3695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607195854187\n",
      "\n",
      " Epoch 3696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960187911987\n",
      "\n",
      " Epoch 3697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580569267273\n",
      "\n",
      " Epoch 3698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042251586914\n",
      "\n",
      " Epoch 3699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059608459473\n",
      "\n",
      " Epoch 3700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972776412964\n",
      "\n",
      " Epoch 3701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784950256348\n",
      "\n",
      " Epoch 3702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059274673462\n",
      "\n",
      " Epoch 3703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061277389526\n",
      "\n",
      " Epoch 3704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46153783798218\n",
      "\n",
      " Epoch 3705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602689743042\n",
      "\n",
      " Epoch 3706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598388671875\n",
      "\n",
      " Epoch 3707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579873085022\n",
      "\n",
      " Epoch 3708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045970916748\n",
      "\n",
      " Epoch 3709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038627624512\n",
      "\n",
      " Epoch 3710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46051979064941\n",
      "\n",
      " Epoch 3711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846366882324\n",
      "\n",
      " Epoch 3712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043062210083\n",
      "\n",
      " Epoch 3713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46052598953247\n",
      "\n",
      " Epoch 3714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979166030884\n",
      "\n",
      " Epoch 3715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811557769775\n",
      "\n",
      " Epoch 3716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603796005249\n",
      "\n",
      " Epoch 3717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000051498413\n",
      "\n",
      " Epoch 3718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783805847168\n",
      "\n",
      " Epoch 3719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042728424072\n",
      "\n",
      " Epoch 3720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048498153687\n",
      "\n",
      " Epoch 3721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997762680054\n",
      "\n",
      " Epoch 3722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770645141602\n",
      "\n",
      " Epoch 3723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031475067139\n",
      "\n",
      " Epoch 3724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46046543121338\n",
      "\n",
      " Epoch 3725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46208238601685\n",
      "\n",
      " Epoch 3726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037101745605\n",
      "\n",
      " Epoch 3727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46058654785156\n",
      "\n",
      " Epoch 3728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972442626953\n",
      "\n",
      " Epoch 3729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806646347046\n",
      "\n",
      " Epoch 3730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019172668457\n",
      "\n",
      " Epoch 3731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042156219482\n",
      "\n",
      " Epoch 3732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991373062134\n",
      "\n",
      " Epoch 3733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608383178711\n",
      "\n",
      " Epoch 3734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786905288696\n",
      "\n",
      " Epoch 3735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043109893799\n",
      "\n",
      " Epoch 3736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46079969406128\n",
      "\n",
      " Epoch 3737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011686325073\n",
      "\n",
      " Epoch 3738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002531051636\n",
      "\n",
      " Epoch 3739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787858963013\n",
      "\n",
      " Epoch 3740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46041440963745\n",
      "\n",
      " Epoch 3741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044206619263\n",
      "\n",
      " Epoch 3742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986080169678\n",
      "\n",
      " Epoch 3743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46074295043945\n",
      "\n",
      " Epoch 3744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579005241394\n",
      "\n",
      " Epoch 3745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46041202545166\n",
      "\n",
      " Epoch 3746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46206617355347\n",
      "\n",
      " Epoch 3747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607424736023\n",
      "\n",
      " Epoch 3748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460524559021\n",
      "\n",
      " Epoch 3749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984315872192\n",
      "\n",
      " Epoch 3750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608063697815\n",
      "\n",
      " Epoch 3751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787525177002\n",
      "\n",
      " Epoch 3752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967435836792\n",
      "\n",
      " Epoch 3753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791339874268\n",
      "\n",
      " Epoch 3754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46052551269531\n",
      "\n",
      " Epoch 3755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031284332275\n",
      "\n",
      " Epoch 3756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987367630005\n",
      "\n",
      " Epoch 3757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608907699585\n",
      "\n",
      " Epoch 3758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026706695557\n",
      "\n",
      " Epoch 3759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830631256104\n",
      "\n",
      " Epoch 3760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46024465560913\n",
      "\n",
      " Epoch 3761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035957336426\n",
      "\n",
      " Epoch 3762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987176895142\n",
      "\n",
      " Epoch 3763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810985565186\n",
      "\n",
      " Epoch 3764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601697921753\n",
      "\n",
      " Epoch 3765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038293838501\n",
      "\n",
      " Epoch 3766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986318588257\n",
      "\n",
      " Epoch 3767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458083152771\n",
      "\n",
      " Epoch 3768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46039247512817\n",
      "\n",
      " Epoch 3769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018648147583\n",
      "\n",
      " Epoch 3770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985460281372\n",
      "\n",
      " Epoch 3771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46090936660767\n",
      "\n",
      " Epoch 3772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46046257019043\n",
      "\n",
      " Epoch 3773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579176902771\n",
      "\n",
      " Epoch 3774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025705337524\n",
      "\n",
      " Epoch 3775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46050453186035\n",
      "\n",
      " Epoch 3776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45977878570557\n",
      "\n",
      " Epoch 3777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786666870117\n",
      "\n",
      " Epoch 3778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603681564331\n",
      "\n",
      " Epoch 3779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017265319824\n",
      "\n",
      " Epoch 3780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45982360839844\n",
      "\n",
      " Epoch 3781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803213119507\n",
      "\n",
      " Epoch 3782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035623550415\n",
      "\n",
      " Epoch 3783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036529541016\n",
      "\n",
      " Epoch 3784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46174907684326\n",
      "\n",
      " Epoch 3785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46069955825806\n",
      "\n",
      " Epoch 3786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038007736206\n",
      "\n",
      " Epoch 3787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972537994385\n",
      "\n",
      " Epoch 3788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790529251099\n",
      "\n",
      " Epoch 3789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034288406372\n",
      "\n",
      " Epoch 3790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034526824951\n",
      "\n",
      " Epoch 3791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986032485962\n",
      "\n",
      " Epoch 3792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46067428588867\n",
      "\n",
      " Epoch 3793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795440673828\n",
      "\n",
      " Epoch 3794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038866043091\n",
      "\n",
      " Epoch 3795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46191930770874\n",
      "\n",
      " Epoch 3796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46066331863403\n",
      "\n",
      " Epoch 3797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45977115631104\n",
      "\n",
      " Epoch 3798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791244506836\n",
      "\n",
      " Epoch 3799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028327941895\n",
      "\n",
      " Epoch 3800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031522750854\n",
      "\n",
      " Epoch 3801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984077453613\n",
      "\n",
      " Epoch 3802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581036567688\n",
      "\n",
      " Epoch 3803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010637283325\n",
      "\n",
      " Epoch 3804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46030902862549\n",
      "\n",
      " Epoch 3805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981121063232\n",
      "\n",
      " Epoch 3806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807552337646\n",
      "\n",
      " Epoch 3807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031856536865\n",
      "\n",
      " Epoch 3808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033143997192\n",
      "\n",
      " Epoch 3809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46169900894165\n",
      "\n",
      " Epoch 3810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46066665649414\n",
      "\n",
      " Epoch 3811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018171310425\n",
      "\n",
      " Epoch 3812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45982360839844\n",
      "\n",
      " Epoch 3813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784187316895\n",
      "\n",
      " Epoch 3814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027946472168\n",
      "\n",
      " Epoch 3815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45977973937988\n",
      "\n",
      " Epoch 3816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790910720825\n",
      "\n",
      " Epoch 3817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603123664856\n",
      "\n",
      " Epoch 3818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46029901504517\n",
      "\n",
      " Epoch 3819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986890792847\n",
      "\n",
      " Epoch 3820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780849456787\n",
      "\n",
      " Epoch 3821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46030330657959\n",
      "\n",
      " Epoch 3822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601378440857\n",
      "\n",
      " Epoch 3823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45978212356567\n",
      "\n",
      " Epoch 3824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781326293945\n",
      "\n",
      " Epoch 3825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036529541016\n",
      "\n",
      " Epoch 3826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032810211182\n",
      "\n",
      " Epoch 3827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46168088912964\n",
      "\n",
      " Epoch 3828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034002304077\n",
      "\n",
      " Epoch 3829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988988876343\n",
      "\n",
      " Epoch 3830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45982551574707\n",
      "\n",
      " Epoch 3831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772552490234\n",
      "\n",
      " Epoch 3832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020126342773\n",
      "\n",
      " Epoch 3833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042251586914\n",
      "\n",
      " Epoch 3834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596209526062\n",
      "\n",
      " Epoch 3835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46078968048096\n",
      "\n",
      " Epoch 3836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762825012207\n",
      "\n",
      " Epoch 3837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043252944946\n",
      "\n",
      " Epoch 3838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46180772781372\n",
      "\n",
      " Epoch 3839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46056270599365\n",
      "\n",
      " Epoch 3840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028709411621\n",
      "\n",
      " Epoch 3841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966339111328\n",
      "\n",
      " Epoch 3842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778560638428\n",
      "\n",
      " Epoch 3843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021890640259\n",
      "\n",
      " Epoch 3844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45969152450562\n",
      "\n",
      " Epoch 3845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580454826355\n",
      "\n",
      " Epoch 3846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026802062988\n",
      "\n",
      " Epoch 3847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027994155884\n",
      "\n",
      " Epoch 3848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951557159424\n",
      "\n",
      " Epoch 3849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789909362793\n",
      "\n",
      " Epoch 3850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602108001709\n",
      "\n",
      " Epoch 3851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46029567718506\n",
      "\n",
      " Epoch 3852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46180438995361\n",
      "\n",
      " Epoch 3853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604926109314\n",
      "\n",
      " Epoch 3854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596004486084\n",
      "\n",
      " Epoch 3855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036005020142\n",
      "\n",
      " Epoch 3856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036911010742\n",
      "\n",
      " Epoch 3857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45959424972534\n",
      "\n",
      " Epoch 3858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799255371094\n",
      "\n",
      " Epoch 3859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019887924194\n",
      "\n",
      " Epoch 3860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023035049438\n",
      "\n",
      " Epoch 3861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46158123016357\n",
      "\n",
      " Epoch 3862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026420593262\n",
      "\n",
      " Epoch 3863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009302139282\n",
      "\n",
      " Epoch 3864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968055725098\n",
      "\n",
      " Epoch 3865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790386199951\n",
      "\n",
      " Epoch 3866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46040678024292\n",
      "\n",
      " Epoch 3867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017599105835\n",
      "\n",
      " Epoch 3868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991659164429\n",
      "\n",
      " Epoch 3869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765686035156\n",
      "\n",
      " Epoch 3870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009159088135\n",
      "\n",
      " Epoch 3871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028804779053\n",
      "\n",
      " Epoch 3872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46154069900513\n",
      "\n",
      " Epoch 3873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46039342880249\n",
      "\n",
      " Epoch 3874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956993103027\n",
      "\n",
      " Epoch 3875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784664154053\n",
      "\n",
      " Epoch 3876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46024227142334\n",
      "\n",
      " Epoch 3877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954418182373\n",
      "\n",
      " Epoch 3878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792818069458\n",
      "\n",
      " Epoch 3879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998239517212\n",
      "\n",
      " Epoch 3880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008205413818\n",
      "\n",
      " Epoch 3881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961618423462\n",
      "\n",
      " Epoch 3882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46047925949097\n",
      "\n",
      " Epoch 3883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027708053589\n",
      "\n",
      " Epoch 3884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939111709595\n",
      "\n",
      " Epoch 3885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768594741821\n",
      "\n",
      " Epoch 3886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602632522583\n",
      "\n",
      " Epoch 3887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045255661011\n",
      "\n",
      " Epoch 3888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822095870972\n",
      "\n",
      " Epoch 3889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46084880828857\n",
      "\n",
      " Epoch 3890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46075963973999\n",
      "\n",
      " Epoch 3891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032619476318\n",
      "\n",
      " Epoch 3892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958185195923\n",
      "\n",
      " Epoch 3893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579029083252\n",
      "\n",
      " Epoch 3894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012830734253\n",
      "\n",
      " Epoch 3895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015644073486\n",
      "\n",
      " Epoch 3896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45978450775146\n",
      "\n",
      " Epoch 3897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578537940979\n",
      "\n",
      " Epoch 3898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45992088317871\n",
      "\n",
      " Epoch 3899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022891998291\n",
      "\n",
      " Epoch 3900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46168088912964\n",
      "\n",
      " Epoch 3901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043729782104\n",
      "\n",
      " Epoch 3902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919990539551\n",
      "\n",
      " Epoch 3903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031284332275\n",
      "\n",
      " Epoch 3904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014833450317\n",
      "\n",
      " Epoch 3905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809555053711\n",
      "\n",
      " Epoch 3906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000528335571\n",
      "\n",
      " Epoch 3907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013832092285\n",
      "\n",
      " Epoch 3908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596152305603\n",
      "\n",
      " Epoch 3909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768070220947\n",
      "\n",
      " Epoch 3910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019506454468\n",
      "\n",
      " Epoch 3911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014451980591\n",
      "\n",
      " Epoch 3912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4617018699646\n",
      "\n",
      " Epoch 3913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46072959899902\n",
      "\n",
      " Epoch 3914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955562591553\n",
      "\n",
      " Epoch 3915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773696899414\n",
      "\n",
      " Epoch 3916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46029567718506\n",
      "\n",
      " Epoch 3917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034097671509\n",
      "\n",
      " Epoch 3918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968103408813\n",
      "\n",
      " Epoch 3919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778274536133\n",
      "\n",
      " Epoch 3920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022510528564\n",
      "\n",
      " Epoch 3921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45963144302368\n",
      "\n",
      " Epoch 3922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605565071106\n",
      "\n",
      " Epoch 3923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010160446167\n",
      "\n",
      " Epoch 3924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46096515655518\n",
      "\n",
      " Epoch 3925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45965242385864\n",
      "\n",
      " Epoch 3926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796585083008\n",
      "\n",
      " Epoch 3927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601035118103\n",
      "\n",
      " Epoch 3928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004390716553\n",
      "\n",
      " Epoch 3929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46093273162842\n",
      "\n",
      " Epoch 3930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020603179932\n",
      "\n",
      " Epoch 3931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4615478515625\n",
      "\n",
      " Epoch 3932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060609817505\n",
      "\n",
      " Epoch 3933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596266746521\n",
      "\n",
      " Epoch 3934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035194396973\n",
      "\n",
      " Epoch 3935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46045303344727\n",
      "\n",
      " Epoch 3936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011018753052\n",
      "\n",
      " Epoch 3937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932483673096\n",
      "\n",
      " Epoch 3938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46032428741455\n",
      "\n",
      " Epoch 3939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944833755493\n",
      "\n",
      " Epoch 3940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578447341919\n",
      "\n",
      " Epoch 3941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008062362671\n",
      "\n",
      " Epoch 3942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945310592651\n",
      "\n",
      " Epoch 3943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46041965484619\n",
      "\n",
      " Epoch 3944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825481414795\n",
      "\n",
      " Epoch 3945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46082830429077\n",
      "\n",
      " Epoch 3946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46059226989746\n",
      "\n",
      " Epoch 3947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010112762451\n",
      "\n",
      " Epoch 3948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973062515259\n",
      "\n",
      " Epoch 3949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759868621826\n",
      "\n",
      " Epoch 3950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011972427368\n",
      "\n",
      " Epoch 3951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459547996521\n",
      "\n",
      " Epoch 3952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46047973632812\n",
      "\n",
      " Epoch 3953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602484703064\n",
      "\n",
      " Epoch 3954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46096420288086\n",
      "\n",
      " Epoch 3955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599175453186\n",
      "\n",
      " Epoch 3956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46134948730469\n",
      "\n",
      " Epoch 3957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023225784302\n",
      "\n",
      " Epoch 3958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961999893188\n",
      "\n",
      " Epoch 3959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602952003479\n",
      "\n",
      " Epoch 3960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604959487915\n",
      "\n",
      " Epoch 3961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764017105103\n",
      "\n",
      " Epoch 3962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993757247925\n",
      "\n",
      " Epoch 3963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951557159424\n",
      "\n",
      " Epoch 3964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034526824951\n",
      "\n",
      " Epoch 3965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593620300293\n",
      "\n",
      " Epoch 3966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781421661377\n",
      "\n",
      " Epoch 3967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001482009888\n",
      "\n",
      " Epoch 3968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949792861938\n",
      "\n",
      " Epoch 3969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4603476524353\n",
      "\n",
      " Epoch 3970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002244949341\n",
      "\n",
      " Epoch 3971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810508728027\n",
      "\n",
      " Epoch 3972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460684299469\n",
      "\n",
      " Epoch 3973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065187454224\n",
      "\n",
      " Epoch 3974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46016883850098\n",
      "\n",
      " Epoch 3975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46078538894653\n",
      "\n",
      " Epoch 3976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009969711304\n",
      "\n",
      " Epoch 3977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941400527954\n",
      "\n",
      " Epoch 3978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031427383423\n",
      "\n",
      " Epoch 3979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931339263916\n",
      "\n",
      " Epoch 3980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771169662476\n",
      "\n",
      " Epoch 3981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000242233276\n",
      "\n",
      " Epoch 3982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594841003418\n",
      "\n",
      " Epoch 3983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033334732056\n",
      "\n",
      " Epoch 3984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994472503662\n",
      "\n",
      " Epoch 3985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806312561035\n",
      "\n",
      " Epoch 3986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987510681152\n",
      "\n",
      " Epoch 3987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943117141724\n",
      "\n",
      " Epoch 3988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46114301681519\n",
      "\n",
      " Epoch 3989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46044778823853\n",
      "\n",
      " Epoch 3990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018171310425\n",
      "\n",
      " Epoch 3991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46068143844604\n",
      "\n",
      " Epoch 3992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600601196289\n",
      "\n",
      " Epoch 3993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927095413208\n",
      "\n",
      " Epoch 3994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576563835144\n",
      "\n",
      " Epoch 3995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995855331421\n",
      "\n",
      " Epoch 3996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945882797241\n",
      "\n",
      " Epoch 3997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46030855178833\n",
      "\n",
      " Epoch 3998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019458770752\n",
      "\n",
      " Epoch 3999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812225341797\n",
      "\n",
      " Epoch 4000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975017547607\n",
      "\n",
      " Epoch 4001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935678482056\n",
      "\n",
      " Epoch 4002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46110725402832\n",
      "\n",
      " Epoch 4003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46052360534668\n",
      "\n",
      " Epoch 4004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014404296875\n",
      "\n",
      " Epoch 4005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060848236084\n",
      "\n",
      " Epoch 4006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997858047485\n",
      "\n",
      " Epoch 4007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930004119873\n",
      "\n",
      " Epoch 4008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783615112305\n",
      "\n",
      " Epoch 4009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921230316162\n",
      "\n",
      " Epoch 4010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46102046966553\n",
      "\n",
      " Epoch 4011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061325073242\n",
      "\n",
      " Epoch 4012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013021469116\n",
      "\n",
      " Epoch 4013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607458114624\n",
      "\n",
      " Epoch 4014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986461639404\n",
      "\n",
      " Epoch 4015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593095779419\n",
      "\n",
      " Epoch 4016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782804489136\n",
      "\n",
      " Epoch 4017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994472503662\n",
      "\n",
      " Epoch 4018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944213867188\n",
      "\n",
      " Epoch 4019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46046733856201\n",
      "\n",
      " Epoch 4020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004724502563\n",
      "\n",
      " Epoch 4021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801401138306\n",
      "\n",
      " Epoch 4022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45980453491211\n",
      "\n",
      " Epoch 4023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939111709595\n",
      "\n",
      " Epoch 4024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776319503784\n",
      "\n",
      " Epoch 4025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006631851196\n",
      "\n",
      " Epoch 4026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46003866195679\n",
      "\n",
      " Epoch 4027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46155405044556\n",
      "\n",
      " Epoch 4028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601263999939\n",
      "\n",
      " Epoch 4029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968198776245\n",
      "\n",
      " Epoch 4030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747423171997\n",
      "\n",
      " Epoch 4031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990467071533\n",
      "\n",
      " Epoch 4032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989656448364\n",
      "\n",
      " Epoch 4033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960235595703\n",
      "\n",
      " Epoch 4034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015787124634\n",
      "\n",
      " Epoch 4035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022939682007\n",
      "\n",
      " Epoch 4036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606409072876\n",
      "\n",
      " Epoch 4037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001148223877\n",
      "\n",
      " Epoch 4038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995712280273\n",
      "\n",
      " Epoch 4039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46070861816406\n",
      "\n",
      " Epoch 4040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764112472534\n",
      "\n",
      " Epoch 4041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936393737793\n",
      "\n",
      " Epoch 4042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755052566528\n",
      "\n",
      " Epoch 4043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999670028687\n",
      "\n",
      " Epoch 4044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993089675903\n",
      "\n",
      " Epoch 4045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960140228271\n",
      "\n",
      " Epoch 4046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576768875122\n",
      "\n",
      " Epoch 4047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993566513062\n",
      "\n",
      " Epoch 4048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991659164429\n",
      "\n",
      " Epoch 4049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46158790588379\n",
      "\n",
      " Epoch 4050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46034097671509\n",
      "\n",
      " Epoch 4051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949745178223\n",
      "\n",
      " Epoch 4052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757722854614\n",
      "\n",
      " Epoch 4053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995473861694\n",
      "\n",
      " Epoch 4054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995330810547\n",
      "\n",
      " Epoch 4055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594373703003\n",
      "\n",
      " Epoch 4056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786905288696\n",
      "\n",
      " Epoch 4057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001625061035\n",
      "\n",
      " Epoch 4058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598650932312\n",
      "\n",
      " Epoch 4059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055316925049\n",
      "\n",
      " Epoch 4060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987939834595\n",
      "\n",
      " Epoch 4061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958375930786\n",
      "\n",
      " Epoch 4062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749235153198\n",
      "\n",
      " Epoch 4063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600658416748\n",
      "\n",
      " Epoch 4064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989036560059\n",
      "\n",
      " Epoch 4065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46157884597778\n",
      "\n",
      " Epoch 4066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996189117432\n",
      "\n",
      " Epoch 4067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954418182373\n",
      "\n",
      " Epoch 4068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45731115341187\n",
      "\n",
      " Epoch 4069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996189117432\n",
      "\n",
      " Epoch 4070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995759963989\n",
      "\n",
      " Epoch 4071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596061706543\n",
      "\n",
      " Epoch 4072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745706558228\n",
      "\n",
      " Epoch 4073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006917953491\n",
      "\n",
      " Epoch 4074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006155014038\n",
      "\n",
      " Epoch 4075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949029922485\n",
      "\n",
      " Epoch 4076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576325416565\n",
      "\n",
      " Epoch 4077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601092338562\n",
      "\n",
      " Epoch 4078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600567817688\n",
      "\n",
      " Epoch 4079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46155738830566\n",
      "\n",
      " Epoch 4080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601616859436\n",
      "\n",
      " Epoch 4081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950937271118\n",
      "\n",
      " Epoch 4082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747756958008\n",
      "\n",
      " Epoch 4083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997476577759\n",
      "\n",
      " Epoch 4084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014833450317\n",
      "\n",
      " Epoch 4085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943450927734\n",
      "\n",
      " Epoch 4086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575662612915\n",
      "\n",
      " Epoch 4087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002912521362\n",
      "\n",
      " Epoch 4088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018600463867\n",
      "\n",
      " Epoch 4089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797872543335\n",
      "\n",
      " Epoch 4090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46065855026245\n",
      "\n",
      " Epoch 4091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011018753052\n",
      "\n",
      " Epoch 4092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006917953491\n",
      "\n",
      " Epoch 4093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935487747192\n",
      "\n",
      " Epoch 4094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763778686523\n",
      "\n",
      " Epoch 4095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995283126831\n",
      "\n",
      " Epoch 4096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999574661255\n",
      "\n",
      " Epoch 4097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946645736694\n",
      "\n",
      " Epoch 4098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762395858765\n",
      "\n",
      " Epoch 4099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000242233276\n",
      "\n",
      " Epoch 4100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005392074585\n",
      "\n",
      " Epoch 4101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594349861145\n",
      "\n",
      " Epoch 4102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762634277344\n",
      "\n",
      " Epoch 4103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999574661255\n",
      "\n",
      " Epoch 4104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005439758301\n",
      "\n",
      " Epoch 4105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46058988571167\n",
      "\n",
      " Epoch 4106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988893508911\n",
      "\n",
      " Epoch 4107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922088623047\n",
      "\n",
      " Epoch 4108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766115188599\n",
      "\n",
      " Epoch 4109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985984802246\n",
      "\n",
      " Epoch 4110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006536483765\n",
      "\n",
      " Epoch 4111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45794105529785\n",
      "\n",
      " Epoch 4112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46056127548218\n",
      "\n",
      " Epoch 4113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46024322509766\n",
      "\n",
      " Epoch 4114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990753173828\n",
      "\n",
      " Epoch 4115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927381515503\n",
      "\n",
      " Epoch 4116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755100250244\n",
      "\n",
      " Epoch 4117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000385284424\n",
      "\n",
      " Epoch 4118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993661880493\n",
      "\n",
      " Epoch 4119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944881439209\n",
      "\n",
      " Epoch 4120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764780044556\n",
      "\n",
      " Epoch 4121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005582809448\n",
      "\n",
      " Epoch 4122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999097824097\n",
      "\n",
      " Epoch 4123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4605884552002\n",
      "\n",
      " Epoch 4124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45725202560425\n",
      "\n",
      " Epoch 4125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991039276123\n",
      "\n",
      " Epoch 4126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996522903442\n",
      "\n",
      " Epoch 4127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055603027344\n",
      "\n",
      " Epoch 4128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984077453613\n",
      "\n",
      " Epoch 4129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592661857605\n",
      "\n",
      " Epoch 4130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574842453003\n",
      "\n",
      " Epoch 4131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985269546509\n",
      "\n",
      " Epoch 4132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005582809448\n",
      "\n",
      " Epoch 4133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579267501831\n",
      "\n",
      " Epoch 4134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974779129028\n",
      "\n",
      " Epoch 4135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918369293213\n",
      "\n",
      " Epoch 4136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46105432510376\n",
      "\n",
      " Epoch 4137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019554138184\n",
      "\n",
      " Epoch 4138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999193191528\n",
      "\n",
      " Epoch 4139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907735824585\n",
      "\n",
      " Epoch 4140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765018463135\n",
      "\n",
      " Epoch 4141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988130569458\n",
      "\n",
      " Epoch 4142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934438705444\n",
      "\n",
      " Epoch 4143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574842453003\n",
      "\n",
      " Epoch 4144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999193191528\n",
      "\n",
      " Epoch 4145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943355560303\n",
      "\n",
      " Epoch 4146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747947692871\n",
      "\n",
      " Epoch 4147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45977449417114\n",
      "\n",
      " Epoch 4148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999097824097\n",
      "\n",
      " Epoch 4149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914888381958\n",
      "\n",
      " Epoch 4150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768070220947\n",
      "\n",
      " Epoch 4151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45977115631104\n",
      "\n",
      " Epoch 4152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998907089233\n",
      "\n",
      " Epoch 4153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780086517334\n",
      "\n",
      " Epoch 4154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053504943848\n",
      "\n",
      " Epoch 4155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013498306274\n",
      "\n",
      " Epoch 4156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45980930328369\n",
      "\n",
      " Epoch 4157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931911468506\n",
      "\n",
      " Epoch 4158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732927322388\n",
      "\n",
      " Epoch 4159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989942550659\n",
      "\n",
      " Epoch 4160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983791351318\n",
      "\n",
      " Epoch 4161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048927307129\n",
      "\n",
      " Epoch 4162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45982933044434\n",
      "\n",
      " Epoch 4163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923566818237\n",
      "\n",
      " Epoch 4164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749521255493\n",
      "\n",
      " Epoch 4165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990037918091\n",
      "\n",
      " Epoch 4166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598913192749\n",
      "\n",
      " Epoch 4167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798540115356\n",
      "\n",
      " Epoch 4168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956611633301\n",
      "\n",
      " Epoch 4169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908117294312\n",
      "\n",
      " Epoch 4170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741319656372\n",
      "\n",
      " Epoch 4171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979881286621\n",
      "\n",
      " Epoch 4172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599838256836\n",
      "\n",
      " Epoch 4173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920753479004\n",
      "\n",
      " Epoch 4174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753574371338\n",
      "\n",
      " Epoch 4175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986700057983\n",
      "\n",
      " Epoch 4176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981311798096\n",
      "\n",
      " Epoch 4177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46133852005005\n",
      "\n",
      " Epoch 4178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011781692505\n",
      "\n",
      " Epoch 4179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972776412964\n",
      "\n",
      " Epoch 4180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919466018677\n",
      "\n",
      " Epoch 4181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747900009155\n",
      "\n",
      " Epoch 4182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459641456604\n",
      "\n",
      " Epoch 4183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921897888184\n",
      "\n",
      " Epoch 4184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743703842163\n",
      "\n",
      " Epoch 4185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979690551758\n",
      "\n",
      " Epoch 4186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004581451416\n",
      "\n",
      " Epoch 4187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776796340942\n",
      "\n",
      " Epoch 4188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055269241333\n",
      "\n",
      " Epoch 4189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010828018188\n",
      "\n",
      " Epoch 4190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986366271973\n",
      "\n",
      " Epoch 4191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899057388306\n",
      "\n",
      " Epoch 4192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759010314941\n",
      "\n",
      " Epoch 4193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967817306519\n",
      "\n",
      " Epoch 4194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915031433105\n",
      "\n",
      " Epoch 4195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988893508911\n",
      "\n",
      " Epoch 4196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990705490112\n",
      "\n",
      " Epoch 4197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768117904663\n",
      "\n",
      " Epoch 4198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596734046936\n",
      "\n",
      " Epoch 4199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987892150879\n",
      "\n",
      " Epoch 4200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918655395508\n",
      "\n",
      " Epoch 4201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45731258392334\n",
      "\n",
      " Epoch 4202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974731445312\n",
      "\n",
      " Epoch 4203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920276641846\n",
      "\n",
      " Epoch 4204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573621749878\n",
      "\n",
      " Epoch 4205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960283279419\n",
      "\n",
      " Epoch 4206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990562438965\n",
      "\n",
      " Epoch 4207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46108627319336\n",
      "\n",
      " Epoch 4208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989465713501\n",
      "\n",
      " Epoch 4209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4597487449646\n",
      "\n",
      " Epoch 4210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908498764038\n",
      "\n",
      " Epoch 4211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45733213424683\n",
      "\n",
      " Epoch 4212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971918106079\n",
      "\n",
      " Epoch 4213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924282073975\n",
      "\n",
      " Epoch 4214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728635787964\n",
      "\n",
      " Epoch 4215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596495628357\n",
      "\n",
      " Epoch 4216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985174179077\n",
      "\n",
      " Epoch 4217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46128416061401\n",
      "\n",
      " Epoch 4218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006393432617\n",
      "\n",
      " Epoch 4219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925760269165\n",
      "\n",
      " Epoch 4220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571270942688\n",
      "\n",
      " Epoch 4221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966911315918\n",
      "\n",
      " Epoch 4222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599199295044\n",
      "\n",
      " Epoch 4223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779657363892\n",
      "\n",
      " Epoch 4224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45970249176025\n",
      "\n",
      " Epoch 4225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981311798096\n",
      "\n",
      " Epoch 4226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878076553345\n",
      "\n",
      " Epoch 4227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010303497314\n",
      "\n",
      " Epoch 4228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901250839233\n",
      "\n",
      " Epoch 4229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732307434082\n",
      "\n",
      " Epoch 4230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966863632202\n",
      "\n",
      " Epoch 4231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918369293213\n",
      "\n",
      " Epoch 4232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946884155273\n",
      "\n",
      " Epoch 4233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976448059082\n",
      "\n",
      " Epoch 4234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576005935669\n",
      "\n",
      " Epoch 4235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955181121826\n",
      "\n",
      " Epoch 4236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878839492798\n",
      "\n",
      " Epoch 4237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995235443115\n",
      "\n",
      " Epoch 4238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884275436401\n",
      "\n",
      " Epoch 4239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571180343628\n",
      "\n",
      " Epoch 4240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955896377563\n",
      "\n",
      " Epoch 4241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888137817383\n",
      "\n",
      " Epoch 4242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960474014282\n",
      "\n",
      " Epoch 4243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966958999634\n",
      "\n",
      " Epoch 4244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745277404785\n",
      "\n",
      " Epoch 4245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927667617798\n",
      "\n",
      " Epoch 4246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881748199463\n",
      "\n",
      " Epoch 4247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988035202026\n",
      "\n",
      " Epoch 4248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867919921875\n",
      "\n",
      " Epoch 4249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010446548462\n",
      "\n",
      " Epoch 4250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881748199463\n",
      "\n",
      " Epoch 4251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726108551025\n",
      "\n",
      " Epoch 4252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892477035522\n",
      "\n",
      " Epoch 4253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073722839355\n",
      "\n",
      " Epoch 4254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973348617554\n",
      "\n",
      " Epoch 4255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884227752686\n",
      "\n",
      " Epoch 4256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571008682251\n",
      "\n",
      " Epoch 4257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874118804932\n",
      "\n",
      " Epoch 4258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035289764404\n",
      "\n",
      " Epoch 4259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45970153808594\n",
      "\n",
      " Epoch 4260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893859863281\n",
      "\n",
      " Epoch 4261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940399169922\n",
      "\n",
      " Epoch 4262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4570894241333\n",
      "\n",
      " Epoch 4263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946407318115\n",
      "\n",
      " Epoch 4264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940637588501\n",
      "\n",
      " Epoch 4265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599461555481\n",
      "\n",
      " Epoch 4266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882081985474\n",
      "\n",
      " Epoch 4267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987176895142\n",
      "\n",
      " Epoch 4268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893144607544\n",
      "\n",
      " Epoch 4269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45699310302734\n",
      "\n",
      " Epoch 4270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596381187439\n",
      "\n",
      " Epoch 4271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902061462402\n",
      "\n",
      " Epoch 4272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962047576904\n",
      "\n",
      " Epoch 4273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876407623291\n",
      "\n",
      " Epoch 4274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017932891846\n",
      "\n",
      " Epoch 4275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770502090454\n",
      "\n",
      " Epoch 4276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459481716156\n",
      "\n",
      " Epoch 4277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866823196411\n",
      "\n",
      " Epoch 4278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45959663391113\n",
      "\n",
      " Epoch 4279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884275436401\n",
      "\n",
      " Epoch 4280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993757247925\n",
      "\n",
      " Epoch 4281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745706558228\n",
      "\n",
      " Epoch 4282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46026086807251\n",
      "\n",
      " Epoch 4283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961332321167\n",
      "\n",
      " Epoch 4284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587836265564\n",
      "\n",
      " Epoch 4285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46003198623657\n",
      "\n",
      " Epoch 4286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886039733887\n",
      "\n",
      " Epoch 4287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723533630371\n",
      "\n",
      " Epoch 4288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952320098877\n",
      "\n",
      " Epoch 4289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589614868164\n",
      "\n",
      " Epoch 4290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931148529053\n",
      "\n",
      " Epoch 4291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962810516357\n",
      "\n",
      " Epoch 4292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759534835815\n",
      "\n",
      " Epoch 4293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933628082275\n",
      "\n",
      " Epoch 4294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880079269409\n",
      "\n",
      " Epoch 4295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989084243774\n",
      "\n",
      " Epoch 4296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886945724487\n",
      "\n",
      " Epoch 4297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45696353912354\n",
      "\n",
      " Epoch 4298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928192138672\n",
      "\n",
      " Epoch 4299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884561538696\n",
      "\n",
      " Epoch 4300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459707736969\n",
      "\n",
      " Epoch 4301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877504348755\n",
      "\n",
      " Epoch 4302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598331451416\n",
      "\n",
      " Epoch 4303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756483078003\n",
      "\n",
      " Epoch 4304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919466018677\n",
      "\n",
      " Epoch 4305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954608917236\n",
      "\n",
      " Epoch 4306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870447158813\n",
      "\n",
      " Epoch 4307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45705699920654\n",
      "\n",
      " Epoch 4308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930528640747\n",
      "\n",
      " Epoch 4309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882177352905\n",
      "\n",
      " Epoch 4310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981693267822\n",
      "\n",
      " Epoch 4311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002006530762\n",
      "\n",
      " Epoch 4312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929956436157\n",
      "\n",
      " Epoch 4313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941066741943\n",
      "\n",
      " Epoch 4314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45737266540527\n",
      "\n",
      " Epoch 4315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932149887085\n",
      "\n",
      " Epoch 4316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875215530396\n",
      "\n",
      " Epoch 4317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946264266968\n",
      "\n",
      " Epoch 4318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601879119873\n",
      "\n",
      " Epoch 4319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937252044678\n",
      "\n",
      " Epoch 4320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872211456299\n",
      "\n",
      " Epoch 4321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599814414978\n",
      "\n",
      " Epoch 4322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45575380325317\n",
      "\n",
      " Epoch 4323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934343338013\n",
      "\n",
      " Epoch 4324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013355255127\n",
      "\n",
      " Epoch 4325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979928970337\n",
      "\n",
      " Epoch 4326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880079269409\n",
      "\n",
      " Epoch 4327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927047729492\n",
      "\n",
      " Epoch 4328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4570665359497\n",
      "\n",
      " Epoch 4329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923471450806\n",
      "\n",
      " Epoch 4330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593276977539\n",
      "\n",
      " Epoch 4331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998191833496\n",
      "\n",
      " Epoch 4332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924854278564\n",
      "\n",
      " Epoch 4333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858097076416\n",
      "\n",
      " Epoch 4334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020364761353\n",
      "\n",
      " Epoch 4335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744609832764\n",
      "\n",
      " Epoch 4336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931434631348\n",
      "\n",
      " Epoch 4337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869731903076\n",
      "\n",
      " Epoch 4338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943212509155\n",
      "\n",
      " Epoch 4339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858192443848\n",
      "\n",
      " Epoch 4340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005153656006\n",
      "\n",
      " Epoch 4341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45582008361816\n",
      "\n",
      " Epoch 4342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926237106323\n",
      "\n",
      " Epoch 4343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458815574646\n",
      "\n",
      " Epoch 4344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013593673706\n",
      "\n",
      " Epoch 4345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45739459991455\n",
      "\n",
      " Epoch 4346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924186706543\n",
      "\n",
      " Epoch 4347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951890945435\n",
      "\n",
      " Epoch 4348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849275588989\n",
      "\n",
      " Epoch 4349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997333526611\n",
      "\n",
      " Epoch 4350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46082210540771\n",
      "\n",
      " Epoch 4351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45970630645752\n",
      "\n",
      " Epoch 4352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868349075317\n",
      "\n",
      " Epoch 4353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988941192627\n",
      "\n",
      " Epoch 4354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873641967773\n",
      "\n",
      " Epoch 4355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460045337677\n",
      "\n",
      " Epoch 4356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45588541030884\n",
      "\n",
      " Epoch 4357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924091339111\n",
      "\n",
      " Epoch 4358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967149734497\n",
      "\n",
      " Epoch 4359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908212661743\n",
      "\n",
      " Epoch 4360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45686054229736\n",
      "\n",
      " Epoch 4361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939540863037\n",
      "\n",
      " Epoch 4362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595160484314\n",
      "\n",
      " Epoch 4363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997428894043\n",
      "\n",
      " Epoch 4364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924758911133\n",
      "\n",
      " Epoch 4365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853757858276\n",
      "\n",
      " Epoch 4366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995569229126\n",
      "\n",
      " Epoch 4367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45737743377686\n",
      "\n",
      " Epoch 4368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926284790039\n",
      "\n",
      " Epoch 4369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866298675537\n",
      "\n",
      " Epoch 4370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960521697998\n",
      "\n",
      " Epoch 4371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853567123413\n",
      "\n",
      " Epoch 4372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45980787277222\n",
      "\n",
      " Epoch 4373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742225646973\n",
      "\n",
      " Epoch 4374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018552780151\n",
      "\n",
      " Epoch 4375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974445343018\n",
      "\n",
      " Epoch 4376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941400527954\n",
      "\n",
      " Epoch 4377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873403549194\n",
      "\n",
      " Epoch 4378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926666259766\n",
      "\n",
      " Epoch 4379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675277709961\n",
      "\n",
      " Epoch 4380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924758911133\n",
      "\n",
      " Epoch 4381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946979522705\n",
      "\n",
      " Epoch 4382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45965576171875\n",
      "\n",
      " Epoch 4383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925712585449\n",
      "\n",
      " Epoch 4384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865869522095\n",
      "\n",
      " Epoch 4385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004486083984\n",
      "\n",
      " Epoch 4386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572868347168\n",
      "\n",
      " Epoch 4387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917749404907\n",
      "\n",
      " Epoch 4388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 4389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941114425659\n",
      "\n",
      " Epoch 4390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835971832275\n",
      "\n",
      " Epoch 4391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857810974121\n",
      "\n",
      " Epoch 4392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017408370972\n",
      "\n",
      " Epoch 4393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45739030838013\n",
      "\n",
      " Epoch 4394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013879776001\n",
      "\n",
      " Epoch 4395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972347259521\n",
      "\n",
      " Epoch 4396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864057540894\n",
      "\n",
      " Epoch 4397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599461555481\n",
      "\n",
      " Epoch 4398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861577987671\n",
      "\n",
      " Epoch 4399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723724365234\n",
      "\n",
      " Epoch 4400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930099487305\n",
      "\n",
      " Epoch 4401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880270004272\n",
      "\n",
      " Epoch 4402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981311798096\n",
      "\n",
      " Epoch 4403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873689651489\n",
      "\n",
      " Epoch 4404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958375930786\n",
      "\n",
      " Epoch 4405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839023590088\n",
      "\n",
      " Epoch 4406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726776123047\n",
      "\n",
      " Epoch 4407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928955078125\n",
      "\n",
      " Epoch 4408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947694778442\n",
      "\n",
      " Epoch 4409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587140083313\n",
      "\n",
      " Epoch 4410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998525619507\n",
      "\n",
      " Epoch 4411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599781036377\n",
      "\n",
      " Epoch 4412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45670986175537\n",
      "\n",
      " Epoch 4413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927047729492\n",
      "\n",
      " Epoch 4414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586877822876\n",
      "\n",
      " Epoch 4415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949649810791\n",
      "\n",
      " Epoch 4416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914268493652\n",
      "\n",
      " Epoch 4417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457435131073\n",
      "\n",
      " Epoch 4418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907592773438\n",
      "\n",
      " Epoch 4419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851802825928\n",
      "\n",
      " Epoch 4420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4597373008728\n",
      "\n",
      " Epoch 4421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849323272705\n",
      "\n",
      " Epoch 4422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596676826477\n",
      "\n",
      " Epoch 4423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45719957351685\n",
      "\n",
      " Epoch 4424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46007251739502\n",
      "\n",
      " Epoch 4425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941352844238\n",
      "\n",
      " Epoch 4426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901823043823\n",
      "\n",
      " Epoch 4427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952701568604\n",
      "\n",
      " Epoch 4428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847129821777\n",
      "\n",
      " Epoch 4429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008682250977\n",
      "\n",
      " Epoch 4430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572982788086\n",
      "\n",
      " Epoch 4431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009874343872\n",
      "\n",
      " Epoch 4432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585633277893\n",
      "\n",
      " Epoch 4433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891332626343\n",
      "\n",
      " Epoch 4434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595742225647\n",
      "\n",
      " Epoch 4435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592604637146\n",
      "\n",
      " Epoch 4436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854139328003\n",
      "\n",
      " Epoch 4437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593014717102\n",
      "\n",
      " Epoch 4438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45705652236938\n",
      "\n",
      " Epoch 4439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934295654297\n",
      "\n",
      " Epoch 4440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939350128174\n",
      "\n",
      " Epoch 4441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46080303192139\n",
      "\n",
      " Epoch 4442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946216583252\n",
      "\n",
      " Epoch 4443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906496047974\n",
      "\n",
      " Epoch 4444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942068099976\n",
      "\n",
      " Epoch 4445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858383178711\n",
      "\n",
      " Epoch 4446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459951877594\n",
      "\n",
      " Epoch 4447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743703842163\n",
      "\n",
      " Epoch 4448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910310745239\n",
      "\n",
      " Epoch 4449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853090286255\n",
      "\n",
      " Epoch 4450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984601974487\n",
      "\n",
      " Epoch 4451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862865447998\n",
      "\n",
      " Epoch 4452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45698595046997\n",
      "\n",
      " Epoch 4453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912837982178\n",
      "\n",
      " Epoch 4454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962381362915\n",
      "\n",
      " Epoch 4455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46073961257935\n",
      "\n",
      " Epoch 4456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952892303467\n",
      "\n",
      " Epoch 4457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936059951782\n",
      "\n",
      " Epoch 4458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011638641357\n",
      "\n",
      " Epoch 4459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587984085083\n",
      "\n",
      " Epoch 4460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951175689697\n",
      "\n",
      " Epoch 4461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991563796997\n",
      "\n",
      " Epoch 4462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882415771484\n",
      "\n",
      " Epoch 4463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45948219299316\n",
      "\n",
      " Epoch 4464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583511352539\n",
      "\n",
      " Epoch 4465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598536491394\n",
      "\n",
      " Epoch 4466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45570421218872\n",
      "\n",
      " Epoch 4467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920753479004\n",
      "\n",
      " Epoch 4468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877742767334\n",
      "\n",
      " Epoch 4469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949745178223\n",
      "\n",
      " Epoch 4470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4568510055542\n",
      "\n",
      " Epoch 4471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867204666138\n",
      "\n",
      " Epoch 4472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037197113037\n",
      "\n",
      " Epoch 4473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855808258057\n",
      "\n",
      " Epoch 4474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590482711792\n",
      "\n",
      " Epoch 4475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979595184326\n",
      "\n",
      " Epoch 4476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45735263824463\n",
      "\n",
      " Epoch 4477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986461639404\n",
      "\n",
      " Epoch 4478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979833602905\n",
      "\n",
      " Epoch 4479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870590209961\n",
      "\n",
      " Epoch 4480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971298217773\n",
      "\n",
      " Epoch 4481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848035812378\n",
      "\n",
      " Epoch 4482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945644378662\n",
      "\n",
      " Epoch 4483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45679950714111\n",
      "\n",
      " Epoch 4484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926856994629\n",
      "\n",
      " Epoch 4485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972490310669\n",
      "\n",
      " Epoch 4486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891571044922\n",
      "\n",
      " Epoch 4487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593768119812\n",
      "\n",
      " Epoch 4488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584755897522\n",
      "\n",
      " Epoch 4489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45707321166992\n",
      "\n",
      " Epoch 4490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589114189148\n",
      "\n",
      " Epoch 4491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865249633789\n",
      "\n",
      " Epoch 4492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983171463013\n",
      "\n",
      " Epoch 4493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608998298645\n",
      "\n",
      " Epoch 4494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592137336731\n",
      "\n",
      " Epoch 4495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589204788208\n",
      "\n",
      " Epoch 4496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45948362350464\n",
      "\n",
      " Epoch 4497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843076705933\n",
      "\n",
      " Epoch 4498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006393432617\n",
      "\n",
      " Epoch 4499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45559644699097\n",
      "\n",
      " Epoch 4500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912027359009\n",
      "\n",
      " Epoch 4501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872259140015\n",
      "\n",
      " Epoch 4502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993614196777\n",
      "\n",
      " Epoch 4503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722150802612\n",
      "\n",
      " Epoch 4504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902061462402\n",
      "\n",
      " Epoch 4505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933818817139\n",
      "\n",
      " Epoch 4506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846033096313\n",
      "\n",
      " Epoch 4507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954275131226\n",
      "\n",
      " Epoch 4508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582667350769\n",
      "\n",
      " Epoch 4509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598503112793\n",
      "\n",
      " Epoch 4510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734786987305\n",
      "\n",
      " Epoch 4511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590835571289\n",
      "\n",
      " Epoch 4512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916700363159\n",
      "\n",
      " Epoch 4513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46077489852905\n",
      "\n",
      " Epoch 4514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926141738892\n",
      "\n",
      " Epoch 4515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915842056274\n",
      "\n",
      " Epoch 4516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45664119720459\n",
      "\n",
      " Epoch 4517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905303955078\n",
      "\n",
      " Epoch 4518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861864089966\n",
      "\n",
      " Epoch 4519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856952667236\n",
      "\n",
      " Epoch 4520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825433731079\n",
      "\n",
      " Epoch 4521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994663238525\n",
      "\n",
      " Epoch 4522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46060800552368\n",
      "\n",
      " Epoch 4523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968580245972\n",
      "\n",
      " Epoch 4524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880556106567\n",
      "\n",
      " Epoch 4525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45687675476074\n",
      "\n",
      " Epoch 4526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916652679443\n",
      "\n",
      " Epoch 4527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926713943481\n",
      "\n",
      " Epoch 4528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979261398315\n",
      "\n",
      " Epoch 4529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898675918579\n",
      "\n",
      " Epoch 4530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848369598389\n",
      "\n",
      " Epoch 4531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984411239624\n",
      "\n",
      " Epoch 4532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45717096328735\n",
      "\n",
      " Epoch 4533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985126495361\n",
      "\n",
      " Epoch 4534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844841003418\n",
      "\n",
      " Epoch 4535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895767211914\n",
      "\n",
      " Epoch 4536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593505859375\n",
      "\n",
      " Epoch 4537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880889892578\n",
      "\n",
      " Epoch 4538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955562591553\n",
      "\n",
      " Epoch 4539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458411693573\n",
      "\n",
      " Epoch 4540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45707416534424\n",
      "\n",
      " Epoch 4541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907926559448\n",
      "\n",
      " Epoch 4542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844173431396\n",
      "\n",
      " Epoch 4543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595742225647\n",
      "\n",
      " Epoch 4544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000528335571\n",
      "\n",
      " Epoch 4545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949411392212\n",
      "\n",
      " Epoch 4546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46079969406128\n",
      "\n",
      " Epoch 4547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946073532104\n",
      "\n",
      " Epoch 4548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939922332764\n",
      "\n",
      " Epoch 4549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858335494995\n",
      "\n",
      " Epoch 4550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971822738647\n",
      "\n",
      " Epoch 4551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840311050415\n",
      "\n",
      " Epoch 4552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45602989196777\n",
      "\n",
      " Epoch 4553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906114578247\n",
      "\n",
      " Epoch 4554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871210098267\n",
      "\n",
      " Epoch 4555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593653678894\n",
      "\n",
      " Epoch 4556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928144454956\n",
      "\n",
      " Epoch 4557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964860916138\n",
      "\n",
      " Epoch 4558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968198776245\n",
      "\n",
      " Epoch 4559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964813232422\n",
      "\n",
      " Epoch 4560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911931991577\n",
      "\n",
      " Epoch 4561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45691394805908\n",
      "\n",
      " Epoch 4562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911455154419\n",
      "\n",
      " Epoch 4563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851564407349\n",
      "\n",
      " Epoch 4564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45687866210938\n",
      "\n",
      " Epoch 4565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923471450806\n",
      "\n",
      " Epoch 4566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935678482056\n",
      "\n",
      " Epoch 4567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910787582397\n",
      "\n",
      " Epoch 4568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45719242095947\n",
      "\n",
      " Epoch 4569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909690856934\n",
      "\n",
      " Epoch 4570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848655700684\n",
      "\n",
      " Epoch 4571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986127853394\n",
      "\n",
      " Epoch 4572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048498153687\n",
      "\n",
      " Epoch 4573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945358276367\n",
      "\n",
      " Epoch 4574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874786376953\n",
      "\n",
      " Epoch 4575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940160751343\n",
      "\n",
      " Epoch 4576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829391479492\n",
      "\n",
      " Epoch 4577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45992279052734\n",
      "\n",
      " Epoch 4578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45547485351562\n",
      "\n",
      " Epoch 4579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836019515991\n",
      "\n",
      " Epoch 4580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947170257568\n",
      "\n",
      " Epoch 4581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844745635986\n",
      "\n",
      " Epoch 4582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971488952637\n",
      "\n",
      " Epoch 4583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46085691452026\n",
      "\n",
      " Epoch 4584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45957088470459\n",
      "\n",
      " Epoch 4585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891284942627\n",
      "\n",
      " Epoch 4586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947456359863\n",
      "\n",
      " Epoch 4587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4597487449646\n",
      "\n",
      " Epoch 4588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591588973999\n",
      "\n",
      " Epoch 4589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591555595398\n",
      "\n",
      " Epoch 4590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975017547607\n",
      "\n",
      " Epoch 4591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880365371704\n",
      "\n",
      " Epoch 4592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939493179321\n",
      "\n",
      " Epoch 4593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45668697357178\n",
      "\n",
      " Epoch 4594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843648910522\n",
      "\n",
      " Epoch 4595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019172668457\n",
      "\n",
      " Epoch 4596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842456817627\n",
      "\n",
      " Epoch 4597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891571044922\n",
      "\n",
      " Epoch 4598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967435836792\n",
      "\n",
      " Epoch 4599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46063470840454\n",
      "\n",
      " Epoch 4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595274925232\n",
      "\n",
      " Epoch 4601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906496047974\n",
      "\n",
      " Epoch 4602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4568419456482\n",
      "\n",
      " Epoch 4603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899772644043\n",
      "\n",
      " Epoch 4604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859050750732\n",
      "\n",
      " Epoch 4605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928716659546\n",
      "\n",
      " Epoch 4606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585542678833\n",
      "\n",
      " Epoch 4607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984363555908\n",
      "\n",
      " Epoch 4608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45720481872559\n",
      "\n",
      " Epoch 4609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887851715088\n",
      "\n",
      " Epoch 4610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922517776489\n",
      "\n",
      " Epoch 4611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887613296509\n",
      "\n",
      " Epoch 4612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715951919556\n",
      "\n",
      " Epoch 4613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882797241211\n",
      "\n",
      " Epoch 4614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830345153809\n",
      "\n",
      " Epoch 4615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953607559204\n",
      "\n",
      " Epoch 4616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849561691284\n",
      "\n",
      " Epoch 4617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45681858062744\n",
      "\n",
      " Epoch 4618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916175842285\n",
      "\n",
      " Epoch 4619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922994613647\n",
      "\n",
      " Epoch 4620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837259292603\n",
      "\n",
      " Epoch 4621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852375030518\n",
      "\n",
      " Epoch 4622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839595794678\n",
      "\n",
      " Epoch 4623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985507965088\n",
      "\n",
      " Epoch 4624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732069015503\n",
      "\n",
      " Epoch 4625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981693267822\n",
      "\n",
      " Epoch 4626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940637588501\n",
      "\n",
      " Epoch 4627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585189819336\n",
      "\n",
      " Epoch 4628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964908599854\n",
      "\n",
      " Epoch 4629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849847793579\n",
      "\n",
      " Epoch 4630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983028411865\n",
      "\n",
      " Epoch 4631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45558261871338\n",
      "\n",
      " Epoch 4632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830154418945\n",
      "\n",
      " Epoch 4633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028327941895\n",
      "\n",
      " Epoch 4634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944118499756\n",
      "\n",
      " Epoch 4635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589581489563\n",
      "\n",
      " Epoch 4636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950365066528\n",
      "\n",
      " Epoch 4637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45708179473877\n",
      "\n",
      " Epoch 4638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45990896224976\n",
      "\n",
      " Epoch 4639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974111557007\n",
      "\n",
      " Epoch 4640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928621292114\n",
      "\n",
      " Epoch 4641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834875106812\n",
      "\n",
      " Epoch 4642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984888076782\n",
      "\n",
      " Epoch 4643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45706272125244\n",
      "\n",
      " Epoch 4644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899963378906\n",
      "\n",
      " Epoch 4645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583740234375\n",
      "\n",
      " Epoch 4646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976305007935\n",
      "\n",
      " Epoch 4647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887088775635\n",
      "\n",
      " Epoch 4648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789670944214\n",
      "\n",
      " Epoch 4649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004152297974\n",
      "\n",
      " Epoch 4650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922565460205\n",
      "\n",
      " Epoch 4651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850419998169\n",
      "\n",
      " Epoch 4652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985174179077\n",
      "\n",
      " Epoch 4653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715856552124\n",
      "\n",
      " Epoch 4654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896434783936\n",
      "\n",
      " Epoch 4655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838403701782\n",
      "\n",
      " Epoch 4656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971775054932\n",
      "\n",
      " Epoch 4657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849943161011\n",
      "\n",
      " Epoch 4658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45685958862305\n",
      "\n",
      " Epoch 4659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896911621094\n",
      "\n",
      " Epoch 4660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858335494995\n",
      "\n",
      " Epoch 4661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945644378662\n",
      "\n",
      " Epoch 4662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46091079711914\n",
      "\n",
      " Epoch 4663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813226699829\n",
      "\n",
      " Epoch 4664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864963531494\n",
      "\n",
      " Epoch 4665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932579040527\n",
      "\n",
      " Epoch 4666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829153060913\n",
      "\n",
      " Epoch 4667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993661880493\n",
      "\n",
      " Epoch 4668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45713901519775\n",
      "\n",
      " Epoch 4669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988750457764\n",
      "\n",
      " Epoch 4670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951128005981\n",
      "\n",
      " Epoch 4671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909214019775\n",
      "\n",
      " Epoch 4672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844602584839\n",
      "\n",
      " Epoch 4673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899391174316\n",
      "\n",
      " Epoch 4674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660352706909\n",
      "\n",
      " Epoch 4675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894622802734\n",
      "\n",
      " Epoch 4676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920896530151\n",
      "\n",
      " Epoch 4677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884561538696\n",
      "\n",
      " Epoch 4678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956945419312\n",
      "\n",
      " Epoch 4679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878314971924\n",
      "\n",
      " Epoch 4680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933818817139\n",
      "\n",
      " Epoch 4681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906209945679\n",
      "\n",
      " Epoch 4682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726203918457\n",
      "\n",
      " Epoch 4683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894050598145\n",
      "\n",
      " Epoch 4684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832633972168\n",
      "\n",
      " Epoch 4685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972490310669\n",
      "\n",
      " Epoch 4686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606294631958\n",
      "\n",
      " Epoch 4687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946311950684\n",
      "\n",
      " Epoch 4688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877122879028\n",
      "\n",
      " Epoch 4689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937156677246\n",
      "\n",
      " Epoch 4690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829200744629\n",
      "\n",
      " Epoch 4691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966386795044\n",
      "\n",
      " Epoch 4692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45558071136475\n",
      "\n",
      " Epoch 4693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821285247803\n",
      "\n",
      " Epoch 4694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952796936035\n",
      "\n",
      " Epoch 4695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916986465454\n",
      "\n",
      " Epoch 4696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048736572266\n",
      "\n",
      " Epoch 4697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958375930786\n",
      "\n",
      " Epoch 4698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874738693237\n",
      "\n",
      " Epoch 4699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4568133354187\n",
      "\n",
      " Epoch 4700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841789245605\n",
      "\n",
      " Epoch 4701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006917953491\n",
      "\n",
      " Epoch 4702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929956436157\n",
      "\n",
      " Epoch 4703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880079269409\n",
      "\n",
      " Epoch 4704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933771133423\n",
      "\n",
      " Epoch 4705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821619033813\n",
      "\n",
      " Epoch 4706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983982086182\n",
      "\n",
      " Epoch 4707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45542764663696\n",
      "\n",
      " Epoch 4708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830583572388\n",
      "\n",
      " Epoch 4709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940399169922\n",
      "\n",
      " Epoch 4710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837688446045\n",
      "\n",
      " Epoch 4711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964336395264\n",
      "\n",
      " Epoch 4712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4607801437378\n",
      "\n",
      " Epoch 4713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951223373413\n",
      "\n",
      " Epoch 4714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882844924927\n",
      "\n",
      " Epoch 4715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45688676834106\n",
      "\n",
      " Epoch 4716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895051956177\n",
      "\n",
      " Epoch 4717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854711532593\n",
      "\n",
      " Epoch 4718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944547653198\n",
      "\n",
      " Epoch 4719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4608507156372\n",
      "\n",
      " Epoch 4720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813226699829\n",
      "\n",
      " Epoch 4721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865154266357\n",
      "\n",
      " Epoch 4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930528640747\n",
      "\n",
      " Epoch 4723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832538604736\n",
      "\n",
      " Epoch 4724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975351333618\n",
      "\n",
      " Epoch 4725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45720481872559\n",
      "\n",
      " Epoch 4726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45969486236572\n",
      "\n",
      " Epoch 4727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593300819397\n",
      "\n",
      " Epoch 4728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912504196167\n",
      "\n",
      " Epoch 4729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846509933472\n",
      "\n",
      " Epoch 4730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898246765137\n",
      "\n",
      " Epoch 4731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663499832153\n",
      "\n",
      " Epoch 4732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900249481201\n",
      "\n",
      " Epoch 4733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904350280762\n",
      "\n",
      " Epoch 4734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459632396698\n",
      "\n",
      " Epoch 4735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903730392456\n",
      "\n",
      " Epoch 4736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584059715271\n",
      "\n",
      " Epoch 4737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595890045166\n",
      "\n",
      " Epoch 4738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45700645446777\n",
      "\n",
      " Epoch 4739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891094207764\n",
      "\n",
      " Epoch 4740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831441879272\n",
      "\n",
      " Epoch 4741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936107635498\n",
      "\n",
      " Epoch 4742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588942527771\n",
      "\n",
      " Epoch 4743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950174331665\n",
      "\n",
      " Epoch 4744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936393737793\n",
      "\n",
      " Epoch 4745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981550216675\n",
      "\n",
      " Epoch 4746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 4747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926761627197\n",
      "\n",
      " Epoch 4748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581208229065\n",
      "\n",
      " Epoch 4749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960569381714\n",
      "\n",
      " Epoch 4750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45555448532104\n",
      "\n",
      " Epoch 4751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904541015625\n",
      "\n",
      " Epoch 4752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854806900024\n",
      "\n",
      " Epoch 4753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953273773193\n",
      "\n",
      " Epoch 4754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606499671936\n",
      "\n",
      " Epoch 4755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944547653198\n",
      "\n",
      " Epoch 4756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879936218262\n",
      "\n",
      " Epoch 4757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933961868286\n",
      "\n",
      " Epoch 4758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823764801025\n",
      "\n",
      " Epoch 4759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979404449463\n",
      "\n",
      " Epoch 4760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822286605835\n",
      "\n",
      " Epoch 4761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45667123794556\n",
      "\n",
      " Epoch 4762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590048789978\n",
      "\n",
      " Epoch 4763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46051979064941\n",
      "\n",
      " Epoch 4764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594087600708\n",
      "\n",
      " Epoch 4765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873594284058\n",
      "\n",
      " Epoch 4766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593243598938\n",
      "\n",
      " Epoch 4767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582405090332\n",
      "\n",
      " Epoch 4768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987844467163\n",
      "\n",
      " Epoch 4769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45543670654297\n",
      "\n",
      " Epoch 4770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894813537598\n",
      "\n",
      " Epoch 4771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064710617065\n",
      "\n",
      " Epoch 4772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935773849487\n",
      "\n",
      " Epoch 4773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591293334961\n",
      "\n",
      " Epoch 4774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998573303223\n",
      "\n",
      " Epoch 4775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917701721191\n",
      "\n",
      " Epoch 4776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817852020264\n",
      "\n",
      " Epoch 4777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904541015625\n",
      "\n",
      " Epoch 4778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940160751343\n",
      "\n",
      " Epoch 4779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989227294922\n",
      "\n",
      " Epoch 4780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649290084839\n",
      "\n",
      " Epoch 4781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900917053223\n",
      "\n",
      " Epoch 4782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820236206055\n",
      "\n",
      " Epoch 4783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834636688232\n",
      "\n",
      " Epoch 4784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827865600586\n",
      "\n",
      " Epoch 4785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972061157227\n",
      "\n",
      " Epoch 4786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715093612671\n",
      "\n",
      " Epoch 4787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971918106079\n",
      "\n",
      " Epoch 4788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941686630249\n",
      "\n",
      " Epoch 4789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897197723389\n",
      "\n",
      " Epoch 4790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835590362549\n",
      "\n",
      " Epoch 4791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882940292358\n",
      "\n",
      " Epoch 4792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45682144165039\n",
      "\n",
      " Epoch 4793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889329910278\n",
      "\n",
      " Epoch 4794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846128463745\n",
      "\n",
      " Epoch 4795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594349861145\n",
      "\n",
      " Epoch 4796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46063613891602\n",
      "\n",
      " Epoch 4797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901775360107\n",
      "\n",
      " Epoch 4798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876979827881\n",
      "\n",
      " Epoch 4799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591007232666\n",
      "\n",
      " Epoch 4800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810413360596\n",
      "\n",
      " Epoch 4801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45686769485474\n",
      "\n",
      " Epoch 4802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891237258911\n",
      "\n",
      " Epoch 4803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848321914673\n",
      "\n",
      " Epoch 4804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926666259766\n",
      "\n",
      " Epoch 4805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45551204681396\n",
      "\n",
      " Epoch 4806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910501480103\n",
      "\n",
      " Epoch 4807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910310745239\n",
      "\n",
      " Epoch 4808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964622497559\n",
      "\n",
      " Epoch 4809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894050598145\n",
      "\n",
      " Epoch 4810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45700788497925\n",
      "\n",
      " Epoch 4811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886707305908\n",
      "\n",
      " Epoch 4812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830059051514\n",
      "\n",
      " Epoch 4813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955228805542\n",
      "\n",
      " Epoch 4814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893001556396\n",
      "\n",
      " Epoch 4815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45702266693115\n",
      "\n",
      " Epoch 4816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979595184326\n",
      "\n",
      " Epoch 4817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583740234375\n",
      "\n",
      " Epoch 4818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586820602417\n",
      "\n",
      " Epoch 4819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593014717102\n",
      "\n",
      " Epoch 4820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827865600586\n",
      "\n",
      " Epoch 4821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45963764190674\n",
      "\n",
      " Epoch 4822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604926109314\n",
      "\n",
      " Epoch 4823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939207077026\n",
      "\n",
      " Epoch 4824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874404907227\n",
      "\n",
      " Epoch 4825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930862426758\n",
      "\n",
      " Epoch 4826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 4827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967483520508\n",
      "\n",
      " Epoch 4828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45717144012451\n",
      "\n",
      " Epoch 4829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874404907227\n",
      "\n",
      " Epoch 4830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812749862671\n",
      "\n",
      " Epoch 4831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928525924683\n",
      "\n",
      " Epoch 4832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588131904602\n",
      "\n",
      " Epoch 4833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811367034912\n",
      "\n",
      " Epoch 4834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961141586304\n",
      "\n",
      " Epoch 4835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889616012573\n",
      "\n",
      " Epoch 4836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960569381714\n",
      "\n",
      " Epoch 4837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571704864502\n",
      "\n",
      " Epoch 4838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869874954224\n",
      "\n",
      " Epoch 4839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904970169067\n",
      "\n",
      " Epoch 4840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837688446045\n",
      "\n",
      " Epoch 4841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929861068726\n",
      "\n",
      " Epoch 4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819330215454\n",
      "\n",
      " Epoch 4843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598069190979\n",
      "\n",
      " Epoch 4844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45687341690063\n",
      "\n",
      " Epoch 4845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881032943726\n",
      "\n",
      " Epoch 4846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590106010437\n",
      "\n",
      " Epoch 4847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820379257202\n",
      "\n",
      " Epoch 4848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975875854492\n",
      "\n",
      " Epoch 4849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45537662506104\n",
      "\n",
      " Epoch 4850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458984375\n",
      "\n",
      " Epoch 4851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46066474914551\n",
      "\n",
      " Epoch 4852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931816101074\n",
      "\n",
      " Epoch 4853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907163619995\n",
      "\n",
      " Epoch 4854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979738235474\n",
      "\n",
      " Epoch 4855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918369293213\n",
      "\n",
      " Epoch 4856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581561088562\n",
      "\n",
      " Epoch 4857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903730392456\n",
      "\n",
      " Epoch 4858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593710899353\n",
      "\n",
      " Epoch 4859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984983444214\n",
      "\n",
      " Epoch 4860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890188217163\n",
      "\n",
      " Epoch 4861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896911621094\n",
      "\n",
      " Epoch 4862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676612854004\n",
      "\n",
      " Epoch 4863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867395401001\n",
      "\n",
      " Epoch 4864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892572402954\n",
      "\n",
      " Epoch 4865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817708969116\n",
      "\n",
      " Epoch 4866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973634719849\n",
      "\n",
      " Epoch 4867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45538091659546\n",
      "\n",
      " Epoch 4868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825147628784\n",
      "\n",
      " Epoch 4869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931911468506\n",
      "\n",
      " Epoch 4870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827198028564\n",
      "\n",
      " Epoch 4871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45966720581055\n",
      "\n",
      " Epoch 4872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45693349838257\n",
      "\n",
      " Epoch 4873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877647399902\n",
      "\n",
      " Epoch 4874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896863937378\n",
      "\n",
      " Epoch 4875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832395553589\n",
      "\n",
      " Epoch 4876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972061157227\n",
      "\n",
      " Epoch 4877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45674705505371\n",
      "\n",
      " Epoch 4878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587869644165\n",
      "\n",
      " Epoch 4879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589991569519\n",
      "\n",
      " Epoch 4880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814800262451\n",
      "\n",
      " Epoch 4881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971918106079\n",
      "\n",
      " Epoch 4882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778799057007\n",
      "\n",
      " Epoch 4883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715570449829\n",
      "\n",
      " Epoch 4884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875358581543\n",
      "\n",
      " Epoch 4885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824384689331\n",
      "\n",
      " Epoch 4886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949459075928\n",
      "\n",
      " Epoch 4887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46061944961548\n",
      "\n",
      " Epoch 4888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935249328613\n",
      "\n",
      " Epoch 4889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867490768433\n",
      "\n",
      " Epoch 4890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592514038086\n",
      "\n",
      " Epoch 4891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816659927368\n",
      "\n",
      " Epoch 4892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939922332764\n",
      "\n",
      " Epoch 4893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896625518799\n",
      "\n",
      " Epoch 4894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45548439025879\n",
      "\n",
      " Epoch 4895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811176300049\n",
      "\n",
      " Epoch 4896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954036712646\n",
      "\n",
      " Epoch 4897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46050262451172\n",
      "\n",
      " Epoch 4898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949745178223\n",
      "\n",
      " Epoch 4899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861959457397\n",
      "\n",
      " Epoch 4900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921659469604\n",
      "\n",
      " Epoch 4901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583215713501\n",
      "\n",
      " Epoch 4902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566798210144\n",
      "\n",
      " Epoch 4903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877408981323\n",
      "\n",
      " Epoch 4904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46055698394775\n",
      "\n",
      " Epoch 4905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592170715332\n",
      "\n",
      " Epoch 4906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870447158813\n",
      "\n",
      " Epoch 4907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911931991577\n",
      "\n",
      " Epoch 4908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821142196655\n",
      "\n",
      " Epoch 4909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930528640747\n",
      "\n",
      " Epoch 4910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45531129837036\n",
      "\n",
      " Epoch 4911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893716812134\n",
      "\n",
      " Epoch 4912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46054649353027\n",
      "\n",
      " Epoch 4913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922231674194\n",
      "\n",
      " Epoch 4914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999002456665\n",
      "\n",
      " Epoch 4915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867156982422\n",
      "\n",
      " Epoch 4916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900630950928\n",
      "\n",
      " Epoch 4917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871114730835\n",
      "\n",
      " Epoch 4918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833158493042\n",
      "\n",
      " Epoch 4919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960140228271\n",
      "\n",
      " Epoch 4920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45711898803711\n",
      "\n",
      " Epoch 4921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587516784668\n",
      "\n",
      " Epoch 4922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807123184204\n",
      "\n",
      " Epoch 4923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925283432007\n",
      "\n",
      " Epoch 4924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823621749878\n",
      "\n",
      " Epoch 4925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945835113525\n",
      "\n",
      " Epoch 4926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45557451248169\n",
      "\n",
      " Epoch 4927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588737487793\n",
      "\n",
      " Epoch 4928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45693731307983\n",
      "\n",
      " Epoch 4929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588189125061\n",
      "\n",
      " Epoch 4930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916223526001\n",
      "\n",
      " Epoch 4931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829153060913\n",
      "\n",
      " Epoch 4932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967483520508\n",
      "\n",
      " Epoch 4933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875597000122\n",
      "\n",
      " Epoch 4934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45699453353882\n",
      "\n",
      " Epoch 4935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884323120117\n",
      "\n",
      " Epoch 4936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821332931519\n",
      "\n",
      " Epoch 4937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45963764190674\n",
      "\n",
      " Epoch 4938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877504348755\n",
      "\n",
      " Epoch 4939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782423019409\n",
      "\n",
      " Epoch 4940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998477935791\n",
      "\n",
      " Epoch 4941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897960662842\n",
      "\n",
      " Epoch 4942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45697498321533\n",
      "\n",
      " Epoch 4943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866870880127\n",
      "\n",
      " Epoch 4944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807075500488\n",
      "\n",
      " Epoch 4945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953512191772\n",
      "\n",
      " Epoch 4946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042394638062\n",
      "\n",
      " Epoch 4947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927286148071\n",
      "\n",
      " Epoch 4948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585976600647\n",
      "\n",
      " Epoch 4949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921039581299\n",
      "\n",
      " Epoch 4950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811796188354\n",
      "\n",
      " Epoch 4951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951700210571\n",
      "\n",
      " Epoch 4952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818519592285\n",
      "\n",
      " Epoch 4953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45574188232422\n",
      "\n",
      " Epoch 4954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881938934326\n",
      "\n",
      " Epoch 4955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842933654785\n",
      "\n",
      " Epoch 4956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947265625\n",
      "\n",
      " Epoch 4957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46064758300781\n",
      "\n",
      " Epoch 4958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906734466553\n",
      "\n",
      " Epoch 4959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860147476196\n",
      "\n",
      " Epoch 4960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920753479004\n",
      "\n",
      " Epoch 4961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814895629883\n",
      "\n",
      " Epoch 4962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45680141448975\n",
      "\n",
      " Epoch 4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883989334106\n",
      "\n",
      " Epoch 4964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846223831177\n",
      "\n",
      " Epoch 4965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935201644897\n",
      "\n",
      " Epoch 4966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571042060852\n",
      "\n",
      " Epoch 4967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866441726685\n",
      "\n",
      " Epoch 4968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895290374756\n",
      "\n",
      " Epoch 4969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883464813232\n",
      "\n",
      " Epoch 4970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578218460083\n",
      "\n",
      " Epoch 4971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981025695801\n",
      "\n",
      " Epoch 4972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908832550049\n",
      "\n",
      " Epoch 4973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45695543289185\n",
      "\n",
      " Epoch 4974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875787734985\n",
      "\n",
      " Epoch 4975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814561843872\n",
      "\n",
      " Epoch 4976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955324172974\n",
      "\n",
      " Epoch 4977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839214324951\n",
      "\n",
      " Epoch 4978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45653915405273\n",
      "\n",
      " Epoch 4979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586615562439\n",
      "\n",
      " Epoch 4980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822095870972\n",
      "\n",
      " Epoch 4981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918035507202\n",
      "\n",
      " Epoch 4982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46054935455322\n",
      "\n",
      " Epoch 4983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803356170654\n",
      "\n",
      " Epoch 4984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857191085815\n",
      "\n",
      " Epoch 4985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645904541016\n",
      "\n",
      " Epoch 4986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886850357056\n",
      "\n",
      " Epoch 4987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914363861084\n",
      "\n",
      " Epoch 4988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46037006378174\n",
      "\n",
      " Epoch 4989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927143096924\n",
      "\n",
      " Epoch 4990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860195159912\n",
      "\n",
      " Epoch 4991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918607711792\n",
      "\n",
      " Epoch 4992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810079574585\n",
      "\n",
      " Epoch 4993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950174331665\n",
      "\n",
      " Epoch 4994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813083648682\n",
      "\n",
      " Epoch 4995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45572900772095\n",
      "\n",
      " Epoch 4996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879936218262\n",
      "\n",
      " Epoch 4997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838928222656\n",
      "\n",
      " Epoch 4998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946550369263\n",
      "\n",
      " Epoch 4999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4606261253357\n",
      "\n",
      " Epoch 5000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903968811035\n",
      "\n",
      " Epoch 5001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857191085815\n",
      "\n",
      " Epoch 5002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591851234436\n",
      "\n",
      " Epoch 5003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581298828125\n",
      "\n",
      " Epoch 5004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45678329467773\n",
      "\n",
      " Epoch 5005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881462097168\n",
      "\n",
      " Epoch 5006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842599868774\n",
      "\n",
      " Epoch 5007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933628082275\n",
      "\n",
      " Epoch 5008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45710039138794\n",
      "\n",
      " Epoch 5009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863962173462\n",
      "\n",
      " Epoch 5010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892095565796\n",
      "\n",
      " Epoch 5011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880174636841\n",
      "\n",
      " Epoch 5012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778894424438\n",
      "\n",
      " Epoch 5013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979309082031\n",
      "\n",
      " Epoch 5014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590654373169\n",
      "\n",
      " Epoch 5015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45693445205688\n",
      "\n",
      " Epoch 5016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873308181763\n",
      "\n",
      " Epoch 5017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811891555786\n",
      "\n",
      " Epoch 5018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952892303467\n",
      "\n",
      " Epoch 5019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836544036865\n",
      "\n",
      " Epoch 5020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651578903198\n",
      "\n",
      " Epoch 5021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864009857178\n",
      "\n",
      " Epoch 5022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819902420044\n",
      "\n",
      " Epoch 5023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916032791138\n",
      "\n",
      " Epoch 5024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.460533618927\n",
      "\n",
      " Epoch 5025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799922943115\n",
      "\n",
      " Epoch 5026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872163772583\n",
      "\n",
      " Epoch 5027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926427841187\n",
      "\n",
      " Epoch 5028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582781791687\n",
      "\n",
      " Epoch 5029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566535949707\n",
      "\n",
      " Epoch 5030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883989334106\n",
      "\n",
      " Epoch 5031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910549163818\n",
      "\n",
      " Epoch 5032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027994155884\n",
      "\n",
      " Epoch 5033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916700363159\n",
      "\n",
      " Epoch 5034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859336853027\n",
      "\n",
      " Epoch 5035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590744972229\n",
      "\n",
      " Epoch 5036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809507369995\n",
      "\n",
      " Epoch 5037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951795578003\n",
      "\n",
      " Epoch 5038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45708179473877\n",
      "\n",
      " Epoch 5039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864677429199\n",
      "\n",
      " Epoch 5040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886564254761\n",
      "\n",
      " Epoch 5041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806121826172\n",
      "\n",
      " Epoch 5042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45569276809692\n",
      "\n",
      " Epoch 5043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588074684143\n",
      "\n",
      " Epoch 5044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908498764038\n",
      "\n",
      " Epoch 5045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028661727905\n",
      "\n",
      " Epoch 5046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940923690796\n",
      "\n",
      " Epoch 5047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869779586792\n",
      "\n",
      " Epoch 5048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899724960327\n",
      "\n",
      " Epoch 5049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595947265625\n",
      "\n",
      " Epoch 5050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910263061523\n",
      "\n",
      " Epoch 5051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582257270813\n",
      "\n",
      " Epoch 5052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669317245483\n",
      "\n",
      " Epoch 5053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872688293457\n",
      "\n",
      " Epoch 5054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829153060913\n",
      "\n",
      " Epoch 5055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591498374939\n",
      "\n",
      " Epoch 5056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45515632629395\n",
      "\n",
      " Epoch 5057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880508422852\n",
      "\n",
      " Epoch 5058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836687088013\n",
      "\n",
      " Epoch 5059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595217704773\n",
      "\n",
      " Epoch 5060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46043157577515\n",
      "\n",
      " Epoch 5061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910835266113\n",
      "\n",
      " Epoch 5062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586410522461\n",
      "\n",
      " Epoch 5063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640325546265\n",
      "\n",
      " Epoch 5064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889186859131\n",
      "\n",
      " Epoch 5065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890426635742\n",
      "\n",
      " Epoch 5066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811367034912\n",
      "\n",
      " Epoch 5067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877885818481\n",
      "\n",
      " Epoch 5068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592113494873\n",
      "\n",
      " Epoch 5069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45670890808105\n",
      "\n",
      " Epoch 5070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962429046631\n",
      "\n",
      " Epoch 5071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818614959717\n",
      "\n",
      " Epoch 5072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846700668335\n",
      "\n",
      " Epoch 5073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919275283813\n",
      "\n",
      " Epoch 5074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587550163269\n",
      "\n",
      " Epoch 5075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45685291290283\n",
      "\n",
      " Epoch 5076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586501121521\n",
      "\n",
      " Epoch 5077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888471603394\n",
      "\n",
      " Epoch 5078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862197875977\n",
      "\n",
      " Epoch 5079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960283279419\n",
      "\n",
      " Epoch 5080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923280715942\n",
      "\n",
      " Epoch 5081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937442779541\n",
      "\n",
      " Epoch 5082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832538604736\n",
      "\n",
      " Epoch 5083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941305160522\n",
      "\n",
      " Epoch 5084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604377746582\n",
      "\n",
      " Epoch 5085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887422561646\n",
      "\n",
      " Epoch 5086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848560333252\n",
      "\n",
      " Epoch 5087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906734466553\n",
      "\n",
      " Epoch 5088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803308486938\n",
      "\n",
      " Epoch 5089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945644378662\n",
      "\n",
      " Epoch 5090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45530891418457\n",
      "\n",
      " Epoch 5091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798063278198\n",
      "\n",
      " Epoch 5092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000242233276\n",
      "\n",
      " Epoch 5093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934867858887\n",
      "\n",
      " Epoch 5094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868158340454\n",
      "\n",
      " Epoch 5095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917177200317\n",
      "\n",
      " Epoch 5096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808267593384\n",
      "\n",
      " Epoch 5097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952415466309\n",
      "\n",
      " Epoch 5098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45704221725464\n",
      "\n",
      " Epoch 5099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874357223511\n",
      "\n",
      " Epoch 5100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868158340454\n",
      "\n",
      " Epoch 5101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820617675781\n",
      "\n",
      " Epoch 5102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945262908936\n",
      "\n",
      " Epoch 5103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577865600586\n",
      "\n",
      " Epoch 5104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45679092407227\n",
      "\n",
      " Epoch 5105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950126647949\n",
      "\n",
      " Epoch 5106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944499969482\n",
      "\n",
      " Epoch 5107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582028388977\n",
      "\n",
      " Epoch 5108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877933502197\n",
      "\n",
      " Epoch 5109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636749267578\n",
      "\n",
      " Epoch 5110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878219604492\n",
      "\n",
      " Epoch 5111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882654190063\n",
      "\n",
      " Epoch 5112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799922943115\n",
      "\n",
      " Epoch 5113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939111709595\n",
      "\n",
      " Epoch 5114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955228805542\n",
      "\n",
      " Epoch 5115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857334136963\n",
      "\n",
      " Epoch 5116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985794067383\n",
      "\n",
      " Epoch 5117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800113677979\n",
      "\n",
      " Epoch 5118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863008499146\n",
      "\n",
      " Epoch 5119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565691947937\n",
      "\n",
      " Epoch 5120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873403549194\n",
      "\n",
      " Epoch 5121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830154418945\n",
      "\n",
      " Epoch 5122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594464302063\n",
      "\n",
      " Epoch 5123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46053266525269\n",
      "\n",
      " Epoch 5124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893383026123\n",
      "\n",
      " Epoch 5125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849895477295\n",
      "\n",
      " Epoch 5126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910549163818\n",
      "\n",
      " Epoch 5127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798969268799\n",
      "\n",
      " Epoch 5128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567461013794\n",
      "\n",
      " Epoch 5129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878648757935\n",
      "\n",
      " Epoch 5130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835781097412\n",
      "\n",
      " Epoch 5131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915031433105\n",
      "\n",
      " Epoch 5132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791482925415\n",
      "\n",
      " Epoch 5133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676946640015\n",
      "\n",
      " Epoch 5134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45957899093628\n",
      "\n",
      " Epoch 5135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926713943481\n",
      "\n",
      " Epoch 5136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586124420166\n",
      "\n",
      " Epoch 5137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911264419556\n",
      "\n",
      " Epoch 5138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805883407593\n",
      "\n",
      " Epoch 5139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960283279419\n",
      "\n",
      " Epoch 5140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799970626831\n",
      "\n",
      " Epoch 5141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941734313965\n",
      "\n",
      " Epoch 5142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45698308944702\n",
      "\n",
      " Epoch 5143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859098434448\n",
      "\n",
      " Epoch 5144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894432067871\n",
      "\n",
      " Epoch 5145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46017074584961\n",
      "\n",
      " Epoch 5146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932817459106\n",
      "\n",
      " Epoch 5147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844173431396\n",
      "\n",
      " Epoch 5148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908308029175\n",
      "\n",
      " Epoch 5149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579725265503\n",
      "\n",
      " Epoch 5150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953464508057\n",
      "\n",
      " Epoch 5151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45520734786987\n",
      "\n",
      " Epoch 5152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879554748535\n",
      "\n",
      " Epoch 5153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604229927063\n",
      "\n",
      " Epoch 5154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891618728638\n",
      "\n",
      " Epoch 5155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855474472046\n",
      "\n",
      " Epoch 5156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910024642944\n",
      "\n",
      " Epoch 5157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810604095459\n",
      "\n",
      " Epoch 5158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947933197021\n",
      "\n",
      " Epoch 5159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45695686340332\n",
      "\n",
      " Epoch 5160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586067199707\n",
      "\n",
      " Epoch 5161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798587799072\n",
      "\n",
      " Epoch 5162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591326713562\n",
      "\n",
      " Epoch 5163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865440368652\n",
      "\n",
      " Epoch 5164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45677518844604\n",
      "\n",
      " Epoch 5165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943546295166\n",
      "\n",
      " Epoch 5166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580512046814\n",
      "\n",
      " Epoch 5167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839500427246\n",
      "\n",
      " Epoch 5168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898389816284\n",
      "\n",
      " Epoch 5169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584264755249\n",
      "\n",
      " Epoch 5170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926237106323\n",
      "\n",
      " Epoch 5171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45674467086792\n",
      "\n",
      " Epoch 5172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961046218872\n",
      "\n",
      " Epoch 5173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923089981079\n",
      "\n",
      " Epoch 5174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855045318604\n",
      "\n",
      " Epoch 5175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908308029175\n",
      "\n",
      " Epoch 5176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800733566284\n",
      "\n",
      " Epoch 5177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45957088470459\n",
      "\n",
      " Epoch 5178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797157287598\n",
      "\n",
      " Epoch 5179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936870574951\n",
      "\n",
      " Epoch 5180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45570659637451\n",
      "\n",
      " Epoch 5181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877742767334\n",
      "\n",
      " Epoch 5182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036672592163\n",
      "\n",
      " Epoch 5183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924091339111\n",
      "\n",
      " Epoch 5184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861768722534\n",
      "\n",
      " Epoch 5185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895957946777\n",
      "\n",
      " Epoch 5186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803689956665\n",
      "\n",
      " Epoch 5187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944499969482\n",
      "\n",
      " Epoch 5188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807266235352\n",
      "\n",
      " Epoch 5189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592514038086\n",
      "\n",
      " Epoch 5190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45969104766846\n",
      "\n",
      " Epoch 5191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620822906494\n",
      "\n",
      " Epoch 5192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881128311157\n",
      "\n",
      " Epoch 5193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582347869873\n",
      "\n",
      " Epoch 5194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655679702759\n",
      "\n",
      " Epoch 5195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852613449097\n",
      "\n",
      " Epoch 5196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908498764038\n",
      "\n",
      " Epoch 5197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864629745483\n",
      "\n",
      " Epoch 5198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910978317261\n",
      "\n",
      " Epoch 5199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813274383545\n",
      "\n",
      " Epoch 5200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935726165771\n",
      "\n",
      " Epoch 5201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45685291290283\n",
      "\n",
      " Epoch 5202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595513343811\n",
      "\n",
      " Epoch 5203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918941497803\n",
      "\n",
      " Epoch 5204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878410339355\n",
      "\n",
      " Epoch 5205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807027816772\n",
      "\n",
      " Epoch 5206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871305465698\n",
      "\n",
      " Epoch 5207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643711090088\n",
      "\n",
      " Epoch 5208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458740234375\n",
      "\n",
      " Epoch 5209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590573310852\n",
      "\n",
      " Epoch 5210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765399932861\n",
      "\n",
      " Epoch 5211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593915939331\n",
      "\n",
      " Epoch 5212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864200592041\n",
      "\n",
      " Epoch 5213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892715454102\n",
      "\n",
      " Epoch 5214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813941955566\n",
      "\n",
      " Epoch 5215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651483535767\n",
      "\n",
      " Epoch 5216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865440368652\n",
      "\n",
      " Epoch 5217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46042394638062\n",
      "\n",
      " Epoch 5218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907878875732\n",
      "\n",
      " Epoch 5219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884418487549\n",
      "\n",
      " Epoch 5220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45957136154175\n",
      "\n",
      " Epoch 5221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895528793335\n",
      "\n",
      " Epoch 5222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787572860718\n",
      "\n",
      " Epoch 5223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458655834198\n",
      "\n",
      " Epoch 5224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592342376709\n",
      "\n",
      " Epoch 5225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45511865615845\n",
      "\n",
      " Epoch 5226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871019363403\n",
      "\n",
      " Epoch 5227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830869674683\n",
      "\n",
      " Epoch 5228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590311050415\n",
      "\n",
      " Epoch 5229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676374435425\n",
      "\n",
      " Epoch 5230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856142044067\n",
      "\n",
      " Epoch 5231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587984085083\n",
      "\n",
      " Epoch 5232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858097076416\n",
      "\n",
      " Epoch 5233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938396453857\n",
      "\n",
      " Epoch 5234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837831497192\n",
      "\n",
      " Epoch 5235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930194854736\n",
      "\n",
      " Epoch 5236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45694065093994\n",
      "\n",
      " Epoch 5237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458664894104\n",
      "\n",
      " Epoch 5238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881271362305\n",
      "\n",
      " Epoch 5239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866203308105\n",
      "\n",
      " Epoch 5240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45666885375977\n",
      "\n",
      " Epoch 5241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868873596191\n",
      "\n",
      " Epoch 5242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878505706787\n",
      "\n",
      " Epoch 5243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595136642456\n",
      "\n",
      " Epoch 5244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899677276611\n",
      "\n",
      " Epoch 5245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581937789917\n",
      "\n",
      " Epoch 5246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811939239502\n",
      "\n",
      " Epoch 5247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579849243164\n",
      "\n",
      " Epoch 5248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941972732544\n",
      "\n",
      " Epoch 5249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46029615402222\n",
      "\n",
      " Epoch 5250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459153175354\n",
      "\n",
      " Epoch 5251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849609375\n",
      "\n",
      " Epoch 5252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909404754639\n",
      "\n",
      " Epoch 5253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4560399055481\n",
      "\n",
      " Epoch 5254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756340026855\n",
      "\n",
      " Epoch 5255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803356170654\n",
      "\n",
      " Epoch 5256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45948362350464\n",
      "\n",
      " Epoch 5257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675325393677\n",
      "\n",
      " Epoch 5258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872735977173\n",
      "\n",
      " Epoch 5259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882797241211\n",
      "\n",
      " Epoch 5260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815372467041\n",
      "\n",
      " Epoch 5261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915222167969\n",
      "\n",
      " Epoch 5262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567289352417\n",
      "\n",
      " Epoch 5263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954942703247\n",
      "\n",
      " Epoch 5264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810985565186\n",
      "\n",
      " Epoch 5265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839595794678\n",
      "\n",
      " Epoch 5266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903587341309\n",
      "\n",
      " Epoch 5267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798540115356\n",
      "\n",
      " Epoch 5268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938539505005\n",
      "\n",
      " Epoch 5269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587812423706\n",
      "\n",
      " Epoch 5270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45682430267334\n",
      "\n",
      " Epoch 5271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853519439697\n",
      "\n",
      " Epoch 5272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800590515137\n",
      "\n",
      " Epoch 5273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936727523804\n",
      "\n",
      " Epoch 5274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876932144165\n",
      "\n",
      " Epoch 5275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567756652832\n",
      "\n",
      " Epoch 5276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949792861938\n",
      "\n",
      " Epoch 5277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581151008606\n",
      "\n",
      " Epoch 5278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458571434021\n",
      "\n",
      " Epoch 5279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892477035522\n",
      "\n",
      " Epoch 5280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 5281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45954322814941\n",
      "\n",
      " Epoch 5282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584903717041\n",
      "\n",
      " Epoch 5283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45654773712158\n",
      "\n",
      " Epoch 5284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868158340454\n",
      "\n",
      " Epoch 5285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898485183716\n",
      "\n",
      " Epoch 5286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861721038818\n",
      "\n",
      " Epoch 5287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941686630249\n",
      "\n",
      " Epoch 5288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 5289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822715759277\n",
      "\n",
      " Epoch 5290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808172225952\n",
      "\n",
      " Epoch 5291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943784713745\n",
      "\n",
      " Epoch 5292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805358886719\n",
      "\n",
      " Epoch 5293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946264266968\n",
      "\n",
      " Epoch 5294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45701122283936\n",
      "\n",
      " Epoch 5295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852708816528\n",
      "\n",
      " Epoch 5296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588360786438\n",
      "\n",
      " Epoch 5297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028184890747\n",
      "\n",
      " Epoch 5298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925426483154\n",
      "\n",
      " Epoch 5299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809078216553\n",
      "\n",
      " Epoch 5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925760269165\n",
      "\n",
      " Epoch 5301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799922943115\n",
      "\n",
      " Epoch 5302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663213729858\n",
      "\n",
      " Epoch 5303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868444442749\n",
      "\n",
      " Epoch 5304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822668075562\n",
      "\n",
      " Epoch 5305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821475982666\n",
      "\n",
      " Epoch 5306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 5307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4569296836853\n",
      "\n",
      " Epoch 5308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866823196411\n",
      "\n",
      " Epoch 5309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878839492798\n",
      "\n",
      " Epoch 5310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567379951477\n",
      "\n",
      " Epoch 5311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860862731934\n",
      "\n",
      " Epoch 5312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880508422852\n",
      "\n",
      " Epoch 5313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806455612183\n",
      "\n",
      " Epoch 5314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917844772339\n",
      "\n",
      " Epoch 5315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45683431625366\n",
      "\n",
      " Epoch 5316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585976600647\n",
      "\n",
      " Epoch 5317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882844924927\n",
      "\n",
      " Epoch 5318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862531661987\n",
      "\n",
      " Epoch 5319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766258239746\n",
      "\n",
      " Epoch 5320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598126411438\n",
      "\n",
      " Epoch 5321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861196517944\n",
      "\n",
      " Epoch 5322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924234390259\n",
      "\n",
      " Epoch 5323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46048545837402\n",
      "\n",
      " Epoch 5324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887041091919\n",
      "\n",
      " Epoch 5325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863914489746\n",
      "\n",
      " Epoch 5326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894002914429\n",
      "\n",
      " Epoch 5327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579439163208\n",
      "\n",
      " Epoch 5328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951080322266\n",
      "\n",
      " Epoch 5329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790433883667\n",
      "\n",
      " Epoch 5330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662069320679\n",
      "\n",
      " Epoch 5331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878171920776\n",
      "\n",
      " Epoch 5332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576678276062\n",
      "\n",
      " Epoch 5333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660924911499\n",
      "\n",
      " Epoch 5334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586672782898\n",
      "\n",
      " Epoch 5335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880222320557\n",
      "\n",
      " Epoch 5336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813989639282\n",
      "\n",
      " Epoch 5337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935916900635\n",
      "\n",
      " Epoch 5338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45702648162842\n",
      "\n",
      " Epoch 5339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851373672485\n",
      "\n",
      " Epoch 5340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882225036621\n",
      "\n",
      " Epoch 5341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849466323853\n",
      "\n",
      " Epoch 5342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941305160522\n",
      "\n",
      " Epoch 5343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865440368652\n",
      "\n",
      " Epoch 5344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813179016113\n",
      "\n",
      " Epoch 5345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580340385437\n",
      "\n",
      " Epoch 5346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944166183472\n",
      "\n",
      " Epoch 5347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882225036621\n",
      "\n",
      " Epoch 5348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45686435699463\n",
      "\n",
      " Epoch 5349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861291885376\n",
      "\n",
      " Epoch 5350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808172225952\n",
      "\n",
      " Epoch 5351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645713806152\n",
      "\n",
      " Epoch 5352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883464813232\n",
      "\n",
      " Epoch 5353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591932296753\n",
      "\n",
      " Epoch 5354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033048629761\n",
      "\n",
      " Epoch 5355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906400680542\n",
      "\n",
      " Epoch 5356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586730003357\n",
      "\n",
      " Epoch 5357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892286300659\n",
      "\n",
      " Epoch 5358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885515213013\n",
      "\n",
      " Epoch 5359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842742919922\n",
      "\n",
      " Epoch 5360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857048034668\n",
      "\n",
      " Epoch 5361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564118385315\n",
      "\n",
      " Epoch 5362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859098434448\n",
      "\n",
      " Epoch 5363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893907546997\n",
      "\n",
      " Epoch 5364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853471755981\n",
      "\n",
      " Epoch 5365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952415466309\n",
      "\n",
      " Epoch 5366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850133895874\n",
      "\n",
      " Epoch 5367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817184448242\n",
      "\n",
      " Epoch 5368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806121826172\n",
      "\n",
      " Epoch 5369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45946407318115\n",
      "\n",
      " Epoch 5370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883464813232\n",
      "\n",
      " Epoch 5371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45689582824707\n",
      "\n",
      " Epoch 5372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864677429199\n",
      "\n",
      " Epoch 5373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810127258301\n",
      "\n",
      " Epoch 5374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648241043091\n",
      "\n",
      " Epoch 5375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884466171265\n",
      "\n",
      " Epoch 5376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902156829834\n",
      "\n",
      " Epoch 5377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002531051636\n",
      "\n",
      " Epoch 5378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907878875732\n",
      "\n",
      " Epoch 5379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983123779297\n",
      "\n",
      " Epoch 5380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876884460449\n",
      "\n",
      " Epoch 5381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809173583984\n",
      "\n",
      " Epoch 5382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910453796387\n",
      "\n",
      " Epoch 5383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955085754395\n",
      "\n",
      " Epoch 5384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905685424805\n",
      "\n",
      " Epoch 5385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820713043213\n",
      "\n",
      " Epoch 5386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811033248901\n",
      "\n",
      " Epoch 5387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45603704452515\n",
      "\n",
      " Epoch 5388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810651779175\n",
      "\n",
      " Epoch 5389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915031433105\n",
      "\n",
      " Epoch 5390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810890197754\n",
      "\n",
      " Epoch 5391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929336547852\n",
      "\n",
      " Epoch 5392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4568362236023\n",
      "\n",
      " Epoch 5393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854187011719\n",
      "\n",
      " Epoch 5394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873737335205\n",
      "\n",
      " Epoch 5395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586615562439\n",
      "\n",
      " Epoch 5396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45501041412354\n",
      "\n",
      " Epoch 5397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868492126465\n",
      "\n",
      " Epoch 5398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46038389205933\n",
      "\n",
      " Epoch 5399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591007232666\n",
      "\n",
      " Epoch 5400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45981407165527\n",
      "\n",
      " Epoch 5401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850133895874\n",
      "\n",
      " Epoch 5402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971059799194\n",
      "\n",
      " Epoch 5403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912551879883\n",
      "\n",
      " Epoch 5404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585075378418\n",
      "\n",
      " Epoch 5405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904397964478\n",
      "\n",
      " Epoch 5406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793390274048\n",
      "\n",
      " Epoch 5407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949268341064\n",
      "\n",
      " Epoch 5408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660018920898\n",
      "\n",
      " Epoch 5409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856475830078\n",
      "\n",
      " Epoch 5410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877265930176\n",
      "\n",
      " Epoch 5411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776748657227\n",
      "\n",
      " Epoch 5412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822238922119\n",
      "\n",
      " Epoch 5413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792818069458\n",
      "\n",
      " Epoch 5414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952701568604\n",
      "\n",
      " Epoch 5415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4568223953247\n",
      "\n",
      " Epoch 5416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873069763184\n",
      "\n",
      " Epoch 5417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884084701538\n",
      "\n",
      " Epoch 5418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46030855178833\n",
      "\n",
      " Epoch 5419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880794525146\n",
      "\n",
      " Epoch 5420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844984054565\n",
      "\n",
      " Epoch 5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902967453003\n",
      "\n",
      " Epoch 5422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789909362793\n",
      "\n",
      " Epoch 5423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950269699097\n",
      "\n",
      " Epoch 5424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790529251099\n",
      "\n",
      " Epoch 5425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45575046539307\n",
      "\n",
      " Epoch 5426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867776870728\n",
      "\n",
      " Epoch 5427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892810821533\n",
      "\n",
      " Epoch 5428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947456359863\n",
      "\n",
      " Epoch 5429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609283447266\n",
      "\n",
      " Epoch 5430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587230682373\n",
      "\n",
      " Epoch 5431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583044052124\n",
      "\n",
      " Epoch 5432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590163230896\n",
      "\n",
      " Epoch 5433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675802230835\n",
      "\n",
      " Epoch 5434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855760574341\n",
      "\n",
      " Epoch 5435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458909034729\n",
      "\n",
      " Epoch 5436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586272239685\n",
      "\n",
      " Epoch 5437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567141532898\n",
      "\n",
      " Epoch 5438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862770080566\n",
      "\n",
      " Epoch 5439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797061920166\n",
      "\n",
      " Epoch 5440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594612121582\n",
      "\n",
      " Epoch 5441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758819580078\n",
      "\n",
      " Epoch 5442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45959854125977\n",
      "\n",
      " Epoch 5443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918035507202\n",
      "\n",
      " Epoch 5444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594259262085\n",
      "\n",
      " Epoch 5445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881986618042\n",
      "\n",
      " Epoch 5446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802116394043\n",
      "\n",
      " Epoch 5447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901250839233\n",
      "\n",
      " Epoch 5448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45530223846436\n",
      "\n",
      " Epoch 5449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579062461853\n",
      "\n",
      " Epoch 5450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592604637146\n",
      "\n",
      " Epoch 5451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025848388672\n",
      "\n",
      " Epoch 5452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915842056274\n",
      "\n",
      " Epoch 5453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582371711731\n",
      "\n",
      " Epoch 5454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916557312012\n",
      "\n",
      " Epoch 5455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866346359253\n",
      "\n",
      " Epoch 5456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45686149597168\n",
      "\n",
      " Epoch 5457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862674713135\n",
      "\n",
      " Epoch 5458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805978775024\n",
      "\n",
      " Epoch 5459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972776412964\n",
      "\n",
      " Epoch 5460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901203155518\n",
      "\n",
      " Epoch 5461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856189727783\n",
      "\n",
      " Epoch 5462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906162261963\n",
      "\n",
      " Epoch 5463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45717191696167\n",
      "\n",
      " Epoch 5464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874309539795\n",
      "\n",
      " Epoch 5465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649290084839\n",
      "\n",
      " Epoch 5466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874500274658\n",
      "\n",
      " Epoch 5467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589695930481\n",
      "\n",
      " Epoch 5468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45657253265381\n",
      "\n",
      " Epoch 5469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865201950073\n",
      "\n",
      " Epoch 5470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458824634552\n",
      "\n",
      " Epoch 5471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808267593384\n",
      "\n",
      " Epoch 5472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940399169922\n",
      "\n",
      " Epoch 5473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773363113403\n",
      "\n",
      " Epoch 5474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45666980743408\n",
      "\n",
      " Epoch 5475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459481716156\n",
      "\n",
      " Epoch 5476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919895172119\n",
      "\n",
      " Epoch 5477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854806900024\n",
      "\n",
      " Epoch 5478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907831192017\n",
      "\n",
      " Epoch 5479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798063278198\n",
      "\n",
      " Epoch 5480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961332321167\n",
      "\n",
      " Epoch 5481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45516872406006\n",
      "\n",
      " Epoch 5482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803308486938\n",
      "\n",
      " Epoch 5483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985746383667\n",
      "\n",
      " Epoch 5484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920133590698\n",
      "\n",
      " Epoch 5485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867967605591\n",
      "\n",
      " Epoch 5486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563660621643\n",
      "\n",
      " Epoch 5487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870113372803\n",
      "\n",
      " Epoch 5488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46039485931396\n",
      "\n",
      " Epoch 5489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887899398804\n",
      "\n",
      " Epoch 5490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851802825928\n",
      "\n",
      " Epoch 5491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890808105469\n",
      "\n",
      " Epoch 5492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580283164978\n",
      "\n",
      " Epoch 5493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943260192871\n",
      "\n",
      " Epoch 5494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45671081542969\n",
      "\n",
      " Epoch 5495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842695236206\n",
      "\n",
      " Epoch 5496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872259140015\n",
      "\n",
      " Epoch 5497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860052108765\n",
      "\n",
      " Epoch 5498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669794082642\n",
      "\n",
      " Epoch 5499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864534378052\n",
      "\n",
      " Epoch 5500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800113677979\n",
      "\n",
      " Epoch 5501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943450927734\n",
      "\n",
      " Epoch 5502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759153366089\n",
      "\n",
      " Epoch 5503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46024513244629\n",
      "\n",
      " Epoch 5504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907020568848\n",
      "\n",
      " Epoch 5505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856952667236\n",
      "\n",
      " Epoch 5506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907211303711\n",
      "\n",
      " Epoch 5507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944118499756\n",
      "\n",
      " Epoch 5508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857048034668\n",
      "\n",
      " Epoch 5509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791244506836\n",
      "\n",
      " Epoch 5510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871019363403\n",
      "\n",
      " Epoch 5511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563660621643\n",
      "\n",
      " Epoch 5512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867967605591\n",
      "\n",
      " Epoch 5513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892858505249\n",
      "\n",
      " Epoch 5514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763635635376\n",
      "\n",
      " Epoch 5515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956993103027\n",
      "\n",
      " Epoch 5516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850419998169\n",
      "\n",
      " Epoch 5517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909070968628\n",
      "\n",
      " Epoch 5518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790481567383\n",
      "\n",
      " Epoch 5519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951843261719\n",
      "\n",
      " Epoch 5520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45661640167236\n",
      "\n",
      " Epoch 5521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585771560669\n",
      "\n",
      " Epoch 5522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885944366455\n",
      "\n",
      " Epoch 5523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585337638855\n",
      "\n",
      " Epoch 5524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45685958862305\n",
      "\n",
      " Epoch 5525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857191085815\n",
      "\n",
      " Epoch 5526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804214477539\n",
      "\n",
      " Epoch 5527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934009552002\n",
      "\n",
      " Epoch 5528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768404006958\n",
      "\n",
      " Epoch 5529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45672273635864\n",
      "\n",
      " Epoch 5530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951890945435\n",
      "\n",
      " Epoch 5531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919895172119\n",
      "\n",
      " Epoch 5532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585633277893\n",
      "\n",
      " Epoch 5533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890426635742\n",
      "\n",
      " Epoch 5534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807790756226\n",
      "\n",
      " Epoch 5535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937919616699\n",
      "\n",
      " Epoch 5536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860052108765\n",
      "\n",
      " Epoch 5537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4553894996643\n",
      "\n",
      " Epoch 5538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793771743774\n",
      "\n",
      " Epoch 5539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593391418457\n",
      "\n",
      " Epoch 5540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035385131836\n",
      "\n",
      " Epoch 5541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917987823486\n",
      "\n",
      " Epoch 5542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867538452148\n",
      "\n",
      " Epoch 5543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589672088623\n",
      "\n",
      " Epoch 5544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797920227051\n",
      "\n",
      " Epoch 5545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936822891235\n",
      "\n",
      " Epoch 5546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662450790405\n",
      "\n",
      " Epoch 5547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585280418396\n",
      "\n",
      " Epoch 5548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882654190063\n",
      "\n",
      " Epoch 5549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015357971191\n",
      "\n",
      " Epoch 5550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928478240967\n",
      "\n",
      " Epoch 5551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832920074463\n",
      "\n",
      " Epoch 5552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894622802734\n",
      "\n",
      " Epoch 5553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798397064209\n",
      "\n",
      " Epoch 5554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45556211471558\n",
      "\n",
      " Epoch 5555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863723754883\n",
      "\n",
      " Epoch 5556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888328552246\n",
      "\n",
      " Epoch 5557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787239074707\n",
      "\n",
      " Epoch 5558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879364013672\n",
      "\n",
      " Epoch 5559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634078979492\n",
      "\n",
      " Epoch 5560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865058898926\n",
      "\n",
      " Epoch 5561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46033382415771\n",
      "\n",
      " Epoch 5562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880126953125\n",
      "\n",
      " Epoch 5563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583945274353\n",
      "\n",
      " Epoch 5564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902490615845\n",
      "\n",
      " Epoch 5565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797061920166\n",
      "\n",
      " Epoch 5566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936346054077\n",
      "\n",
      " Epoch 5567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45528268814087\n",
      "\n",
      " Epoch 5568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858764648438\n",
      "\n",
      " Epoch 5569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46029233932495\n",
      "\n",
      " Epoch 5570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918560028076\n",
      "\n",
      " Epoch 5571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845317840576\n",
      "\n",
      " Epoch 5572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589524269104\n",
      "\n",
      " Epoch 5573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798969268799\n",
      "\n",
      " Epoch 5574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923805236816\n",
      "\n",
      " Epoch 5575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45505857467651\n",
      "\n",
      " Epoch 5576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865678787231\n",
      "\n",
      " Epoch 5577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941400527954\n",
      "\n",
      " Epoch 5578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906829833984\n",
      "\n",
      " Epoch 5579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595513343811\n",
      "\n",
      " Epoch 5580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832824707031\n",
      "\n",
      " Epoch 5581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903301239014\n",
      "\n",
      " Epoch 5582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840787887573\n",
      "\n",
      " Epoch 5583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45673322677612\n",
      "\n",
      " Epoch 5584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847988128662\n",
      "\n",
      " Epoch 5585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863962173462\n",
      "\n",
      " Epoch 5586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813179016113\n",
      "\n",
      " Epoch 5587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913410186768\n",
      "\n",
      " Epoch 5588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45524168014526\n",
      "\n",
      " Epoch 5589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865869522095\n",
      "\n",
      " Epoch 5590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45673942565918\n",
      "\n",
      " Epoch 5591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861339569092\n",
      "\n",
      " Epoch 5592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895051956177\n",
      "\n",
      " Epoch 5593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859575271606\n",
      "\n",
      " Epoch 5594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931005477905\n",
      "\n",
      " Epoch 5595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857238769531\n",
      "\n",
      " Epoch 5596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922660827637\n",
      "\n",
      " Epoch 5597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036958694458\n",
      "\n",
      " Epoch 5598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882320404053\n",
      "\n",
      " Epoch 5599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837545394897\n",
      "\n",
      " Epoch 5600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898151397705\n",
      "\n",
      " Epoch 5601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583888053894\n",
      "\n",
      " Epoch 5602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45507860183716\n",
      "\n",
      " Epoch 5603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786762237549\n",
      "\n",
      " Epoch 5604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900630950928\n",
      "\n",
      " Epoch 5605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958948135376\n",
      "\n",
      " Epoch 5606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875024795532\n",
      "\n",
      " Epoch 5607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813751220703\n",
      "\n",
      " Epoch 5608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595160484314\n",
      "\n",
      " Epoch 5609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655345916748\n",
      "\n",
      " Epoch 5610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848035812378\n",
      "\n",
      " Epoch 5611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876932144165\n",
      "\n",
      " Epoch 5612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002388000488\n",
      "\n",
      " Epoch 5613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921993255615\n",
      "\n",
      " Epoch 5614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851755142212\n",
      "\n",
      " Epoch 5615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885181427002\n",
      "\n",
      " Epoch 5616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583568572998\n",
      "\n",
      " Epoch 5617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4552640914917\n",
      "\n",
      " Epoch 5618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791339874268\n",
      "\n",
      " Epoch 5619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592957496643\n",
      "\n",
      " Epoch 5620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935344696045\n",
      "\n",
      " Epoch 5621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874071121216\n",
      "\n",
      " Epoch 5622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567666053772\n",
      "\n",
      " Epoch 5623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845079421997\n",
      "\n",
      " Epoch 5624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578971862793\n",
      "\n",
      " Epoch 5625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932722091675\n",
      "\n",
      " Epoch 5626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868015289307\n",
      "\n",
      " Epoch 5627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45499849319458\n",
      "\n",
      " Epoch 5628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791721343994\n",
      "\n",
      " Epoch 5629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949792861938\n",
      "\n",
      " Epoch 5630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861625671387\n",
      "\n",
      " Epoch 5631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941734313965\n",
      "\n",
      " Epoch 5632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581880569458\n",
      "\n",
      " Epoch 5633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895957946777\n",
      "\n",
      " Epoch 5634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45684146881104\n",
      "\n",
      " Epoch 5635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842123031616\n",
      "\n",
      " Epoch 5636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878267288208\n",
      "\n",
      " Epoch 5637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847272872925\n",
      "\n",
      " Epoch 5638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45674133300781\n",
      "\n",
      " Epoch 5639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850801467896\n",
      "\n",
      " Epoch 5640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789241790771\n",
      "\n",
      " Epoch 5641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933151245117\n",
      "\n",
      " Epoch 5642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766115188599\n",
      "\n",
      " Epoch 5643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947742462158\n",
      "\n",
      " Epoch 5644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908546447754\n",
      "\n",
      " Epoch 5645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937442779541\n",
      "\n",
      " Epoch 5646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873308181763\n",
      "\n",
      " Epoch 5647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579553604126\n",
      "\n",
      " Epoch 5648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908403396606\n",
      "\n",
      " Epoch 5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45510339736938\n",
      "\n",
      " Epoch 5650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807456970215\n",
      "\n",
      " Epoch 5651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459228515625\n",
      "\n",
      " Epoch 5652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885610580444\n",
      "\n",
      " Epoch 5653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675802230835\n",
      "\n",
      " Epoch 5654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45948505401611\n",
      "\n",
      " Epoch 5655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808601379395\n",
      "\n",
      " Epoch 5656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836734771729\n",
      "\n",
      " Epoch 5657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897817611694\n",
      "\n",
      " Epoch 5658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792007446289\n",
      "\n",
      " Epoch 5659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45957469940186\n",
      "\n",
      " Epoch 5660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676231384277\n",
      "\n",
      " Epoch 5661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951509475708\n",
      "\n",
      " Epoch 5662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914316177368\n",
      "\n",
      " Epoch 5663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870208740234\n",
      "\n",
      " Epoch 5664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807552337646\n",
      "\n",
      " Epoch 5665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926904678345\n",
      "\n",
      " Epoch 5666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942687988281\n",
      "\n",
      " Epoch 5667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902061462402\n",
      "\n",
      " Epoch 5668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595251083374\n",
      "\n",
      " Epoch 5669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825481414795\n",
      "\n",
      " Epoch 5670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897006988525\n",
      "\n",
      " Epoch 5671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830488204956\n",
      "\n",
      " Epoch 5672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45512104034424\n",
      "\n",
      " Epoch 5673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788335800171\n",
      "\n",
      " Epoch 5674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938348770142\n",
      "\n",
      " Epoch 5675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602484703064\n",
      "\n",
      " Epoch 5676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936870574951\n",
      "\n",
      " Epoch 5677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815372467041\n",
      "\n",
      " Epoch 5678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930004119873\n",
      "\n",
      " Epoch 5679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867395401001\n",
      "\n",
      " Epoch 5680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567141532898\n",
      "\n",
      " Epoch 5681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846843719482\n",
      "\n",
      " Epoch 5682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792293548584\n",
      "\n",
      " Epoch 5683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930862426758\n",
      "\n",
      " Epoch 5684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764446258545\n",
      "\n",
      " Epoch 5685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45593023300171\n",
      "\n",
      " Epoch 5686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801830291748\n",
      "\n",
      " Epoch 5687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906448364258\n",
      "\n",
      " Epoch 5688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802879333496\n",
      "\n",
      " Epoch 5689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459228515625\n",
      "\n",
      " Epoch 5690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45670461654663\n",
      "\n",
      " Epoch 5691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585828781128\n",
      "\n",
      " Epoch 5692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879745483398\n",
      "\n",
      " Epoch 5693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855283737183\n",
      "\n",
      " Epoch 5694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45492696762085\n",
      "\n",
      " Epoch 5695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789575576782\n",
      "\n",
      " Epoch 5696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594783782959\n",
      "\n",
      " Epoch 5697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018409729004\n",
      "\n",
      " Epoch 5698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934629440308\n",
      "\n",
      " Epoch 5699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841121673584\n",
      "\n",
      " Epoch 5700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900201797485\n",
      "\n",
      " Epoch 5701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839405059814\n",
      "\n",
      " Epoch 5702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45682907104492\n",
      "\n",
      " Epoch 5703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843172073364\n",
      "\n",
      " Epoch 5704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785760879517\n",
      "\n",
      " Epoch 5705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594464302063\n",
      "\n",
      " Epoch 5706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 5707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45521068572998\n",
      "\n",
      " Epoch 5708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784854888916\n",
      "\n",
      " Epoch 5709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900630950928\n",
      "\n",
      " Epoch 5710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4604926109314\n",
      "\n",
      " Epoch 5711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943117141724\n",
      "\n",
      " Epoch 5712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458167552948\n",
      "\n",
      " Epoch 5713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931005477905\n",
      "\n",
      " Epoch 5714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863485336304\n",
      "\n",
      " Epoch 5715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45670890808105\n",
      "\n",
      " Epoch 5716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585223197937\n",
      "\n",
      " Epoch 5717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579529762268\n",
      "\n",
      " Epoch 5718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894861221313\n",
      "\n",
      " Epoch 5719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782661437988\n",
      "\n",
      " Epoch 5720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584379196167\n",
      "\n",
      " Epoch 5721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941305160522\n",
      "\n",
      " Epoch 5722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844888687134\n",
      "\n",
      " Epoch 5723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871210098267\n",
      "\n",
      " Epoch 5724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628309249878\n",
      "\n",
      " Epoch 5725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860290527344\n",
      "\n",
      " Epoch 5726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886421203613\n",
      "\n",
      " Epoch 5727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644903182983\n",
      "\n",
      " Epoch 5728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843839645386\n",
      "\n",
      " Epoch 5729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458749294281\n",
      "\n",
      " Epoch 5730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842266082764\n",
      "\n",
      " Epoch 5731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45693826675415\n",
      "\n",
      " Epoch 5732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913791656494\n",
      "\n",
      " Epoch 5733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4569640159607\n",
      "\n",
      " Epoch 5734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845890045166\n",
      "\n",
      " Epoch 5735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883369445801\n",
      "\n",
      " Epoch 5736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46003723144531\n",
      "\n",
      " Epoch 5737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921802520752\n",
      "\n",
      " Epoch 5738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837545394897\n",
      "\n",
      " Epoch 5739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935010910034\n",
      "\n",
      " Epoch 5740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761442184448\n",
      "\n",
      " Epoch 5741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945596694946\n",
      "\n",
      " Epoch 5742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 5743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592137336731\n",
      "\n",
      " Epoch 5744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847845077515\n",
      "\n",
      " Epoch 5745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563455581665\n",
      "\n",
      " Epoch 5746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851182937622\n",
      "\n",
      " Epoch 5747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879459381104\n",
      "\n",
      " Epoch 5748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577693939209\n",
      "\n",
      " Epoch 5749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581389427185\n",
      "\n",
      " Epoch 5750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786142349243\n",
      "\n",
      " Epoch 5751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565839767456\n",
      "\n",
      " Epoch 5752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856857299805\n",
      "\n",
      " Epoch 5753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46035528182983\n",
      "\n",
      " Epoch 5754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900678634644\n",
      "\n",
      " Epoch 5755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849084854126\n",
      "\n",
      " Epoch 5756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891571044922\n",
      "\n",
      " Epoch 5757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804119110107\n",
      "\n",
      " Epoch 5758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905923843384\n",
      "\n",
      " Epoch 5759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566740989685\n",
      "\n",
      " Epoch 5760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859909057617\n",
      "\n",
      " Epoch 5761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857858657837\n",
      "\n",
      " Epoch 5762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804977416992\n",
      "\n",
      " Epoch 5763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930814743042\n",
      "\n",
      " Epoch 5764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45514154434204\n",
      "\n",
      " Epoch 5765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587869644165\n",
      "\n",
      " Epoch 5766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021175384521\n",
      "\n",
      " Epoch 5767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891427993774\n",
      "\n",
      " Epoch 5768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834302902222\n",
      "\n",
      " Epoch 5769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589147567749\n",
      "\n",
      " Epoch 5770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795774459839\n",
      "\n",
      " Epoch 5771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939302444458\n",
      "\n",
      " Epoch 5772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648527145386\n",
      "\n",
      " Epoch 5773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845937728882\n",
      "\n",
      " Epoch 5774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867919921875\n",
      "\n",
      " Epoch 5775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839500427246\n",
      "\n",
      " Epoch 5776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45503187179565\n",
      "\n",
      " Epoch 5777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780897140503\n",
      "\n",
      " Epoch 5778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934963226318\n",
      "\n",
      " Epoch 5779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601821899414\n",
      "\n",
      " Epoch 5780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931911468506\n",
      "\n",
      " Epoch 5781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583969116211\n",
      "\n",
      " Epoch 5782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877122879028\n",
      "\n",
      " Epoch 5783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800638198853\n",
      "\n",
      " Epoch 5784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923900604248\n",
      "\n",
      " Epoch 5785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45686531066895\n",
      "\n",
      " Epoch 5786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838403701782\n",
      "\n",
      " Epoch 5787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876979827881\n",
      "\n",
      " Epoch 5788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859718322754\n",
      "\n",
      " Epoch 5789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45665121078491\n",
      "\n",
      " Epoch 5790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854997634888\n",
      "\n",
      " Epoch 5791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852279663086\n",
      "\n",
      " Epoch 5792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765018463135\n",
      "\n",
      " Epoch 5793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952939987183\n",
      "\n",
      " Epoch 5794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838832855225\n",
      "\n",
      " Epoch 5795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589204788208\n",
      "\n",
      " Epoch 5796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862817764282\n",
      "\n",
      " Epoch 5797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45659494400024\n",
      "\n",
      " Epoch 5798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584493637085\n",
      "\n",
      " Epoch 5799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586730003357\n",
      "\n",
      " Epoch 5800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918703079224\n",
      "\n",
      " Epoch 5801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921230316162\n",
      "\n",
      " Epoch 5802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909595489502\n",
      "\n",
      " Epoch 5803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846033096313\n",
      "\n",
      " Epoch 5804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830965042114\n",
      "\n",
      " Epoch 5805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827531814575\n",
      "\n",
      " Epoch 5806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892572402954\n",
      "\n",
      " Epoch 5807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45588731765747\n",
      "\n",
      " Epoch 5808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863342285156\n",
      "\n",
      " Epoch 5809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817995071411\n",
      "\n",
      " Epoch 5810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591212272644\n",
      "\n",
      " Epoch 5811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759725570679\n",
      "\n",
      " Epoch 5812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662498474121\n",
      "\n",
      " Epoch 5813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852136611938\n",
      "\n",
      " Epoch 5814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796775817871\n",
      "\n",
      " Epoch 5815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938539505005\n",
      "\n",
      " Epoch 5816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850658416748\n",
      "\n",
      " Epoch 5817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45672750473022\n",
      "\n",
      " Epoch 5818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585280418396\n",
      "\n",
      " Epoch 5819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790576934814\n",
      "\n",
      " Epoch 5820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889186859131\n",
      "\n",
      " Epoch 5821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844984054565\n",
      "\n",
      " Epoch 5822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780992507935\n",
      "\n",
      " Epoch 5823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936441421509\n",
      "\n",
      " Epoch 5824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919418334961\n",
      "\n",
      " Epoch 5825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663547515869\n",
      "\n",
      " Epoch 5826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849990844727\n",
      "\n",
      " Epoch 5827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792245864868\n",
      "\n",
      " Epoch 5828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928239822388\n",
      "\n",
      " Epoch 5829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861053466797\n",
      "\n",
      " Epoch 5830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663452148438\n",
      "\n",
      " Epoch 5831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939016342163\n",
      "\n",
      " Epoch 5832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800161361694\n",
      "\n",
      " Epoch 5833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846033096313\n",
      "\n",
      " Epoch 5834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878410339355\n",
      "\n",
      " Epoch 5835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781469345093\n",
      "\n",
      " Epoch 5836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944166183472\n",
      "\n",
      " Epoch 5837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578046798706\n",
      "\n",
      " Epoch 5838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938301086426\n",
      "\n",
      " Epoch 5839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45672655105591\n",
      "\n",
      " Epoch 5840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584150314331\n",
      "\n",
      " Epoch 5841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876836776733\n",
      "\n",
      " Epoch 5842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842170715332\n",
      "\n",
      " Epoch 5843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921230316162\n",
      "\n",
      " Epoch 5844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586296081543\n",
      "\n",
      " Epoch 5845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45671129226685\n",
      "\n",
      " Epoch 5846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843458175659\n",
      "\n",
      " Epoch 5847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790100097656\n",
      "\n",
      " Epoch 5848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928907394409\n",
      "\n",
      " Epoch 5849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760202407837\n",
      "\n",
      " Epoch 5850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930242538452\n",
      "\n",
      " Epoch 5851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872688293457\n",
      "\n",
      " Epoch 5852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800542831421\n",
      "\n",
      " Epoch 5853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591212272644\n",
      "\n",
      " Epoch 5854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953226089478\n",
      "\n",
      " Epoch 5855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891427993774\n",
      "\n",
      " Epoch 5856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927476882935\n",
      "\n",
      " Epoch 5857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864057540894\n",
      "\n",
      " Epoch 5858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798921585083\n",
      "\n",
      " Epoch 5859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902252197266\n",
      "\n",
      " Epoch 5860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949029922485\n",
      "\n",
      " Epoch 5861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587631225586\n",
      "\n",
      " Epoch 5862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45497846603394\n",
      "\n",
      " Epoch 5863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790719985962\n",
      "\n",
      " Epoch 5864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986890792847\n",
      "\n",
      " Epoch 5865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803308486938\n",
      "\n",
      " Epoch 5866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835876464844\n",
      "\n",
      " Epoch 5867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932483673096\n",
      "\n",
      " Epoch 5868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932531356812\n",
      "\n",
      " Epoch 5869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45605134963989\n",
      "\n",
      " Epoch 5870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865058898926\n",
      "\n",
      " Epoch 5871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812606811523\n",
      "\n",
      " Epoch 5872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888328552246\n",
      "\n",
      " Epoch 5873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873308181763\n",
      "\n",
      " Epoch 5874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45661163330078\n",
      "\n",
      " Epoch 5875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832395553589\n",
      "\n",
      " Epoch 5876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 5877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578218460083\n",
      "\n",
      " Epoch 5878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926284790039\n",
      "\n",
      " Epoch 5879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938158035278\n",
      "\n",
      " Epoch 5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827388763428\n",
      "\n",
      " Epoch 5881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564356803894\n",
      "\n",
      " Epoch 5882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817279815674\n",
      "\n",
      " Epoch 5883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892286300659\n",
      "\n",
      " Epoch 5884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849800109863\n",
      "\n",
      " Epoch 5885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882654190063\n",
      "\n",
      " Epoch 5886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795774459839\n",
      "\n",
      " Epoch 5887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932006835938\n",
      "\n",
      " Epoch 5888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662021636963\n",
      "\n",
      " Epoch 5889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834159851074\n",
      "\n",
      " Epoch 5890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861053466797\n",
      "\n",
      " Epoch 5891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585018157959\n",
      "\n",
      " Epoch 5892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45659017562866\n",
      "\n",
      " Epoch 5893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855522155762\n",
      "\n",
      " Epoch 5894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795965194702\n",
      "\n",
      " Epoch 5895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888614654541\n",
      "\n",
      " Epoch 5896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777463912964\n",
      "\n",
      " Epoch 5897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45665121078491\n",
      "\n",
      " Epoch 5898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925426483154\n",
      "\n",
      " Epoch 5899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891618728638\n",
      "\n",
      " Epoch 5900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844268798828\n",
      "\n",
      " Epoch 5901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896196365356\n",
      "\n",
      " Epoch 5902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45794105529785\n",
      "\n",
      " Epoch 5903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926904678345\n",
      "\n",
      " Epoch 5904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790958404541\n",
      "\n",
      " Epoch 5905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45545959472656\n",
      "\n",
      " Epoch 5906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857286453247\n",
      "\n",
      " Epoch 5907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890378952026\n",
      "\n",
      " Epoch 5908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010160446167\n",
      "\n",
      " Epoch 5909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922946929932\n",
      "\n",
      " Epoch 5910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832014083862\n",
      "\n",
      " Epoch 5911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640516281128\n",
      "\n",
      " Epoch 5912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863103866577\n",
      "\n",
      " Epoch 5913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899391174316\n",
      "\n",
      " Epoch 5914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014356613159\n",
      "\n",
      " Epoch 5915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894193649292\n",
      "\n",
      " Epoch 5916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805644989014\n",
      "\n",
      " Epoch 5917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846271514893\n",
      "\n",
      " Epoch 5918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629978179932\n",
      "\n",
      " Epoch 5919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842552185059\n",
      "\n",
      " Epoch 5920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874166488647\n",
      "\n",
      " Epoch 5921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4549446105957\n",
      "\n",
      " Epoch 5922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853233337402\n",
      "\n",
      " Epoch 5923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019887924194\n",
      "\n",
      " Epoch 5924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869970321655\n",
      "\n",
      " Epoch 5925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857524871826\n",
      "\n",
      " Epoch 5926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878887176514\n",
      "\n",
      " Epoch 5927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785331726074\n",
      "\n",
      " Epoch 5928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900917053223\n",
      "\n",
      " Epoch 5929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567198753357\n",
      "\n",
      " Epoch 5930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850419998169\n",
      "\n",
      " Epoch 5931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458749294281\n",
      "\n",
      " Epoch 5932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797395706177\n",
      "\n",
      " Epoch 5933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45535039901733\n",
      "\n",
      " Epoch 5934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585428237915\n",
      "\n",
      " Epoch 5935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875883102417\n",
      "\n",
      " Epoch 5936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904922485352\n",
      "\n",
      " Epoch 5937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842218399048\n",
      "\n",
      " Epoch 5938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967626571655\n",
      "\n",
      " Epoch 5939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798635482788\n",
      "\n",
      " Epoch 5940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835542678833\n",
      "\n",
      " Epoch 5941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932817459106\n",
      "\n",
      " Epoch 5942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796346664429\n",
      "\n",
      " Epoch 5943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856761932373\n",
      "\n",
      " Epoch 5944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635414123535\n",
      "\n",
      " Epoch 5945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848798751831\n",
      "\n",
      " Epoch 5946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876407623291\n",
      "\n",
      " Epoch 5947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635938644409\n",
      "\n",
      " Epoch 5948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836591720581\n",
      "\n",
      " Epoch 5949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586706161499\n",
      "\n",
      " Epoch 5950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835399627686\n",
      "\n",
      " Epoch 5951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593358039856\n",
      "\n",
      " Epoch 5952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590516090393\n",
      "\n",
      " Epoch 5953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45501756668091\n",
      "\n",
      " Epoch 5954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791244506836\n",
      "\n",
      " Epoch 5955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889043807983\n",
      "\n",
      " Epoch 5956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873308181763\n",
      "\n",
      " Epoch 5957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676755905151\n",
      "\n",
      " Epoch 5958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583387374878\n",
      "\n",
      " Epoch 5959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866966247559\n",
      "\n",
      " Epoch 5960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764636993408\n",
      "\n",
      " Epoch 5961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924854278564\n",
      "\n",
      " Epoch 5962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938920974731\n",
      "\n",
      " Epoch 5963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883131027222\n",
      "\n",
      " Epoch 5964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45505332946777\n",
      "\n",
      " Epoch 5965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867443084717\n",
      "\n",
      " Epoch 5966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46036577224731\n",
      "\n",
      " Epoch 5967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913743972778\n",
      "\n",
      " Epoch 5968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836210250854\n",
      "\n",
      " Epoch 5969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848417282104\n",
      "\n",
      " Epoch 5970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971965789795\n",
      "\n",
      " Epoch 5971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578685760498\n",
      "\n",
      " Epoch 5972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585337638855\n",
      "\n",
      " Epoch 5973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45614767074585\n",
      "\n",
      " Epoch 5974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585132598877\n",
      "\n",
      " Epoch 5975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881986618042\n",
      "\n",
      " Epoch 5976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45633745193481\n",
      "\n",
      " Epoch 5977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842552185059\n",
      "\n",
      " Epoch 5978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866298675537\n",
      "\n",
      " Epoch 5979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789766311646\n",
      "\n",
      " Epoch 5980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590163230896\n",
      "\n",
      " Epoch 5981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023607254028\n",
      "\n",
      " Epoch 5982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873498916626\n",
      "\n",
      " Epoch 5983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851707458496\n",
      "\n",
      " Epoch 5984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877313613892\n",
      "\n",
      " Epoch 5985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457772731781\n",
      "\n",
      " Epoch 5986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937395095825\n",
      "\n",
      " Epoch 5987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45504140853882\n",
      "\n",
      " Epoch 5988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787382125854\n",
      "\n",
      " Epoch 5989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896196365356\n",
      "\n",
      " Epoch 5990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792150497437\n",
      "\n",
      " Epoch 5991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915222167969\n",
      "\n",
      " Epoch 5992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45668983459473\n",
      "\n",
      " Epoch 5993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829439163208\n",
      "\n",
      " Epoch 5994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859909057617\n",
      "\n",
      " Epoch 5995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848608016968\n",
      "\n",
      " Epoch 5996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910549163818\n",
      "\n",
      " Epoch 5997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827293395996\n",
      "\n",
      " Epoch 5998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872068405151\n",
      "\n",
      " Epoch 5999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669269561768\n",
      "\n",
      " Epoch 6000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827865600586\n",
      "\n",
      " Epoch 6001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859575271606\n",
      "\n",
      " Epoch 6002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831203460693\n",
      "\n",
      " Epoch 6003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45489931106567\n",
      "\n",
      " Epoch 6004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786428451538\n",
      "\n",
      " Epoch 6005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942831039429\n",
      "\n",
      " Epoch 6006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858144760132\n",
      "\n",
      " Epoch 6007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918989181519\n",
      "\n",
      " Epoch 6008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864009857178\n",
      "\n",
      " Epoch 6009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45708274841309\n",
      "\n",
      " Epoch 6010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862531661987\n",
      "\n",
      " Epoch 6011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638799667358\n",
      "\n",
      " Epoch 6012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850419998169\n",
      "\n",
      " Epoch 6013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602279663086\n",
      "\n",
      " Epoch 6014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868492126465\n",
      "\n",
      " Epoch 6015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832824707031\n",
      "\n",
      " Epoch 6016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588975906372\n",
      "\n",
      " Epoch 6017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835542678833\n",
      "\n",
      " Epoch 6018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675897598267\n",
      "\n",
      " Epoch 6019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831394195557\n",
      "\n",
      " Epoch 6020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782232284546\n",
      "\n",
      " Epoch 6021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918798446655\n",
      "\n",
      " Epoch 6022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855665206909\n",
      "\n",
      " Epoch 6023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45494222640991\n",
      "\n",
      " Epoch 6024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854425430298\n",
      "\n",
      " Epoch 6025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021318435669\n",
      "\n",
      " Epoch 6026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589672088623\n",
      "\n",
      " Epoch 6027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983123779297\n",
      "\n",
      " Epoch 6028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823192596436\n",
      "\n",
      " Epoch 6029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884227752686\n",
      "\n",
      " Epoch 6030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842170715332\n",
      "\n",
      " Epoch 6031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565601348877\n",
      "\n",
      " Epoch 6032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849895477295\n",
      "\n",
      " Epoch 6033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860433578491\n",
      "\n",
      " Epoch 6034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806360244751\n",
      "\n",
      " Epoch 6035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802116394043\n",
      "\n",
      " Epoch 6036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790195465088\n",
      "\n",
      " Epoch 6037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930528640747\n",
      "\n",
      " Epoch 6038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862627029419\n",
      "\n",
      " Epoch 6039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567322731018\n",
      "\n",
      " Epoch 6040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584641456604\n",
      "\n",
      " Epoch 6041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579291343689\n",
      "\n",
      " Epoch 6042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927238464355\n",
      "\n",
      " Epoch 6043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586238861084\n",
      "\n",
      " Epoch 6044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45502853393555\n",
      "\n",
      " Epoch 6045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585976600647\n",
      "\n",
      " Epoch 6046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45931339263916\n",
      "\n",
      " Epoch 6047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846891403198\n",
      "\n",
      " Epoch 6048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964765548706\n",
      "\n",
      " Epoch 6049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886182785034\n",
      "\n",
      " Epoch 6050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840835571289\n",
      "\n",
      " Epoch 6051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589376449585\n",
      "\n",
      " Epoch 6052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583249092102\n",
      "\n",
      " Epoch 6053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45682621002197\n",
      "\n",
      " Epoch 6054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837116241455\n",
      "\n",
      " Epoch 6055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782613754272\n",
      "\n",
      " Epoch 6056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937585830688\n",
      "\n",
      " Epoch 6057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45499277114868\n",
      "\n",
      " Epoch 6058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866870880127\n",
      "\n",
      " Epoch 6059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46025800704956\n",
      "\n",
      " Epoch 6060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881271362305\n",
      "\n",
      " Epoch 6061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583010673523\n",
      "\n",
      " Epoch 6062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881414413452\n",
      "\n",
      " Epoch 6063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839834213257\n",
      "\n",
      " Epoch 6064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45706605911255\n",
      "\n",
      " Epoch 6065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862340927124\n",
      "\n",
      " Epoch 6066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636701583862\n",
      "\n",
      " Epoch 6067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859861373901\n",
      "\n",
      " Epoch 6068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027755737305\n",
      "\n",
      " Epoch 6069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875597000122\n",
      "\n",
      " Epoch 6070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838499069214\n",
      "\n",
      " Epoch 6071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458909034729\n",
      "\n",
      " Epoch 6072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791006088257\n",
      "\n",
      " Epoch 6073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908689498901\n",
      "\n",
      " Epoch 6074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799016952515\n",
      "\n",
      " Epoch 6075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45528936386108\n",
      "\n",
      " Epoch 6076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852661132812\n",
      "\n",
      " Epoch 6077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882797241211\n",
      "\n",
      " Epoch 6078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022176742554\n",
      "\n",
      " Epoch 6079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924472808838\n",
      "\n",
      " Epoch 6080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836448669434\n",
      "\n",
      " Epoch 6081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638370513916\n",
      "\n",
      " Epoch 6082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868062973022\n",
      "\n",
      " Epoch 6083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893335342407\n",
      "\n",
      " Epoch 6084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919799804688\n",
      "\n",
      " Epoch 6085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827770233154\n",
      "\n",
      " Epoch 6086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589033126831\n",
      "\n",
      " Epoch 6087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833444595337\n",
      "\n",
      " Epoch 6088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4549651145935\n",
      "\n",
      " Epoch 6089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773601531982\n",
      "\n",
      " Epoch 6090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588770866394\n",
      "\n",
      " Epoch 6091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023416519165\n",
      "\n",
      " Epoch 6092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908117294312\n",
      "\n",
      " Epoch 6093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875644683838\n",
      "\n",
      " Epoch 6094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952987670898\n",
      "\n",
      " Epoch 6095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883560180664\n",
      "\n",
      " Epoch 6096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771169662476\n",
      "\n",
      " Epoch 6097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907592773438\n",
      "\n",
      " Epoch 6098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944261550903\n",
      "\n",
      " Epoch 6099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832967758179\n",
      "\n",
      " Epoch 6100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644998550415\n",
      "\n",
      " Epoch 6101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45730781555176\n",
      "\n",
      " Epoch 6102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859050750732\n",
      "\n",
      " Epoch 6103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859336853027\n",
      "\n",
      " Epoch 6104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592432975769\n",
      "\n",
      " Epoch 6105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905542373657\n",
      "\n",
      " Epoch 6106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906019210815\n",
      "\n",
      " Epoch 6107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831680297852\n",
      "\n",
      " Epoch 6108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45623731613159\n",
      "\n",
      " Epoch 6109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848083496094\n",
      "\n",
      " Epoch 6110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806312561035\n",
      "\n",
      " Epoch 6111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586296081543\n",
      "\n",
      " Epoch 6112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876932144165\n",
      "\n",
      " Epoch 6113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45664739608765\n",
      "\n",
      " Epoch 6114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582200050354\n",
      "\n",
      " Epoch 6115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851755142212\n",
      "\n",
      " Epoch 6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740509033203\n",
      "\n",
      " Epoch 6117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933628082275\n",
      "\n",
      " Epoch 6118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839595794678\n",
      "\n",
      " Epoch 6119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589262008667\n",
      "\n",
      " Epoch 6120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45589780807495\n",
      "\n",
      " Epoch 6121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744466781616\n",
      "\n",
      " Epoch 6122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795488357544\n",
      "\n",
      " Epoch 6123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935010910034\n",
      "\n",
      " Epoch 6124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001720428467\n",
      "\n",
      " Epoch 6125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592342376709\n",
      "\n",
      " Epoch 6126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833969116211\n",
      "\n",
      " Epoch 6127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636892318726\n",
      "\n",
      " Epoch 6128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863771438599\n",
      "\n",
      " Epoch 6129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 6130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45613098144531\n",
      "\n",
      " Epoch 6131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 6132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873212814331\n",
      "\n",
      " Epoch 6133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563217163086\n",
      "\n",
      " Epoch 6134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832872390747\n",
      "\n",
      " Epoch 6135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861911773682\n",
      "\n",
      " Epoch 6136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756578445435\n",
      "\n",
      " Epoch 6137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45960998535156\n",
      "\n",
      " Epoch 6138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861911773682\n",
      "\n",
      " Epoch 6139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779800415039\n",
      "\n",
      " Epoch 6140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904350280762\n",
      "\n",
      " Epoch 6141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567928314209\n",
      "\n",
      " Epoch 6142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831441879272\n",
      "\n",
      " Epoch 6143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856046676636\n",
      "\n",
      " Epoch 6144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772695541382\n",
      "\n",
      " Epoch 6145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45531034469604\n",
      "\n",
      " Epoch 6146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853996276855\n",
      "\n",
      " Epoch 6147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874166488647\n",
      "\n",
      " Epoch 6148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629501342773\n",
      "\n",
      " Epoch 6149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846652984619\n",
      "\n",
      " Epoch 6150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586181640625\n",
      "\n",
      " Epoch 6151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783472061157\n",
      "\n",
      " Epoch 6152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901155471802\n",
      "\n",
      " Epoch 6153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019458770752\n",
      "\n",
      " Epoch 6154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890283584595\n",
      "\n",
      " Epoch 6155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45965433120728\n",
      "\n",
      " Epoch 6156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586009979248\n",
      "\n",
      " Epoch 6157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847654342651\n",
      "\n",
      " Epoch 6158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773315429688\n",
      "\n",
      " Epoch 6159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45547008514404\n",
      "\n",
      " Epoch 6160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853757858276\n",
      "\n",
      " Epoch 6161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811128616333\n",
      "\n",
      " Epoch 6162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924663543701\n",
      "\n",
      " Epoch 6163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031999588013\n",
      "\n",
      " Epoch 6164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587459564209\n",
      "\n",
      " Epoch 6165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833969116211\n",
      "\n",
      " Epoch 6166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890378952026\n",
      "\n",
      " Epoch 6167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45583486557007\n",
      "\n",
      " Epoch 6168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45738410949707\n",
      "\n",
      " Epoch 6169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791530609131\n",
      "\n",
      " Epoch 6170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932197570801\n",
      "\n",
      " Epoch 6171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912218093872\n",
      "\n",
      " Epoch 6172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858001708984\n",
      "\n",
      " Epoch 6173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942783355713\n",
      "\n",
      " Epoch 6174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877695083618\n",
      "\n",
      " Epoch 6175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773696899414\n",
      "\n",
      " Epoch 6176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916986465454\n",
      "\n",
      " Epoch 6177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930194854736\n",
      "\n",
      " Epoch 6178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824432373047\n",
      "\n",
      " Epoch 6179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638179779053\n",
      "\n",
      " Epoch 6180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814228057861\n",
      "\n",
      " Epoch 6181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588565826416\n",
      "\n",
      " Epoch 6182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871496200562\n",
      "\n",
      " Epoch 6183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779609680176\n",
      "\n",
      " Epoch 6184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861101150513\n",
      "\n",
      " Epoch 6185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45621824264526\n",
      "\n",
      " Epoch 6186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856761932373\n",
      "\n",
      " Epoch 6187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587893486023\n",
      "\n",
      " Epoch 6188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45646572113037\n",
      "\n",
      " Epoch 6189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832347869873\n",
      "\n",
      " Epoch 6190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856237411499\n",
      "\n",
      " Epoch 6191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827007293701\n",
      "\n",
      " Epoch 6192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45501470565796\n",
      "\n",
      " Epoch 6193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790815353394\n",
      "\n",
      " Epoch 6194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926189422607\n",
      "\n",
      " Epoch 6195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006631851196\n",
      "\n",
      " Epoch 6196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899438858032\n",
      "\n",
      " Epoch 6197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880031585693\n",
      "\n",
      " Epoch 6198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45681476593018\n",
      "\n",
      " Epoch 6199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839309692383\n",
      "\n",
      " Epoch 6200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626783370972\n",
      "\n",
      " Epoch 6201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846033096313\n",
      "\n",
      " Epoch 6202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868921279907\n",
      "\n",
      " Epoch 6203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632457733154\n",
      "\n",
      " Epoch 6204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839977264404\n",
      "\n",
      " Epoch 6205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458580493927\n",
      "\n",
      " Epoch 6206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830297470093\n",
      "\n",
      " Epoch 6207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934247970581\n",
      "\n",
      " Epoch 6208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892715454102\n",
      "\n",
      " Epoch 6209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 6210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808267593384\n",
      "\n",
      " Epoch 6211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780992507935\n",
      "\n",
      " Epoch 6212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593915939331\n",
      "\n",
      " Epoch 6213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45646905899048\n",
      "\n",
      " Epoch 6214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839071273804\n",
      "\n",
      " Epoch 6215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869064331055\n",
      "\n",
      " Epoch 6216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996332168579\n",
      "\n",
      " Epoch 6217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912599563599\n",
      "\n",
      " Epoch 6218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826196670532\n",
      "\n",
      " Epoch 6219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886421203613\n",
      "\n",
      " Epoch 6220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825529098511\n",
      "\n",
      " Epoch 6221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669937133789\n",
      "\n",
      " Epoch 6222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821619033813\n",
      "\n",
      " Epoch 6223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576826095581\n",
      "\n",
      " Epoch 6224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592809677124\n",
      "\n",
      " Epoch 6225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740127563477\n",
      "\n",
      " Epoch 6226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660829544067\n",
      "\n",
      " Epoch 6227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918130874634\n",
      "\n",
      " Epoch 6228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589524269104\n",
      "\n",
      " Epoch 6229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831537246704\n",
      "\n",
      " Epoch 6230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881223678589\n",
      "\n",
      " Epoch 6231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792007446289\n",
      "\n",
      " Epoch 6232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593186378479\n",
      "\n",
      " Epoch 6233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640850067139\n",
      "\n",
      " Epoch 6234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829248428345\n",
      "\n",
      " Epoch 6235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863246917725\n",
      "\n",
      " Epoch 6236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582986831665\n",
      "\n",
      " Epoch 6237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740175247192\n",
      "\n",
      " Epoch 6238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45964574813843\n",
      "\n",
      " Epoch 6239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562873840332\n",
      "\n",
      " Epoch 6240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796871185303\n",
      "\n",
      " Epoch 6241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587140083313\n",
      "\n",
      " Epoch 6242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458016872406\n",
      "\n",
      " Epoch 6243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922374725342\n",
      "\n",
      " Epoch 6244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45708703994751\n",
      "\n",
      " Epoch 6245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45702743530273\n",
      "\n",
      " Epoch 6246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779371261597\n",
      "\n",
      " Epoch 6247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932149887085\n",
      "\n",
      " Epoch 6248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772886276245\n",
      "\n",
      " Epoch 6249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930576324463\n",
      "\n",
      " Epoch 6250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567084312439\n",
      "\n",
      " Epoch 6251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849180221558\n",
      "\n",
      " Epoch 6252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868110656738\n",
      "\n",
      " Epoch 6253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843553543091\n",
      "\n",
      " Epoch 6254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45498657226562\n",
      "\n",
      " Epoch 6255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577431678772\n",
      "\n",
      " Epoch 6256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886611938477\n",
      "\n",
      " Epoch 6257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46020412445068\n",
      "\n",
      " Epoch 6258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590482711792\n",
      "\n",
      " Epoch 6259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874500274658\n",
      "\n",
      " Epoch 6260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943546295166\n",
      "\n",
      " Epoch 6261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879888534546\n",
      "\n",
      " Epoch 6262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771312713623\n",
      "\n",
      " Epoch 6263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851421356201\n",
      "\n",
      " Epoch 6264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45614957809448\n",
      "\n",
      " Epoch 6265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846605300903\n",
      "\n",
      " Epoch 6266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872735977173\n",
      "\n",
      " Epoch 6267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741367340088\n",
      "\n",
      " Epoch 6268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676040649414\n",
      "\n",
      " Epoch 6269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838069915771\n",
      "\n",
      " Epoch 6270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786952972412\n",
      "\n",
      " Epoch 6271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907020568848\n",
      "\n",
      " Epoch 6272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866298675537\n",
      "\n",
      " Epoch 6273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45488834381104\n",
      "\n",
      " Epoch 6274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784664154053\n",
      "\n",
      " Epoch 6275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921802520752\n",
      "\n",
      " Epoch 6276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860433578491\n",
      "\n",
      " Epoch 6277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936679840088\n",
      "\n",
      " Epoch 6278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023321151733\n",
      "\n",
      " Epoch 6279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587140083313\n",
      "\n",
      " Epoch 6280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834016799927\n",
      "\n",
      " Epoch 6281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588885307312\n",
      "\n",
      " Epoch 6282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784378051758\n",
      "\n",
      " Epoch 6283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921325683594\n",
      "\n",
      " Epoch 6284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45505666732788\n",
      "\n",
      " Epoch 6285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458411693573\n",
      "\n",
      " Epoch 6286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015644073486\n",
      "\n",
      " Epoch 6287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906066894531\n",
      "\n",
      " Epoch 6288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833110809326\n",
      "\n",
      " Epoch 6289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879554748535\n",
      "\n",
      " Epoch 6290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803213119507\n",
      "\n",
      " Epoch 6291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905590057373\n",
      "\n",
      " Epoch 6292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651721954346\n",
      "\n",
      " Epoch 6293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842790603638\n",
      "\n",
      " Epoch 6294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842742919922\n",
      "\n",
      " Epoch 6295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785284042358\n",
      "\n",
      " Epoch 6296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639324188232\n",
      "\n",
      " Epoch 6297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581413269043\n",
      "\n",
      " Epoch 6298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897340774536\n",
      "\n",
      " Epoch 6299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583854675293\n",
      "\n",
      " Epoch 6300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885276794434\n",
      "\n",
      " Epoch 6301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795631408691\n",
      "\n",
      " Epoch 6302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921421051025\n",
      "\n",
      " Epoch 6303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656681060791\n",
      "\n",
      " Epoch 6304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841550827026\n",
      "\n",
      " Epoch 6305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861101150513\n",
      "\n",
      " Epoch 6306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834398269653\n",
      "\n",
      " Epoch 6307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45495796203613\n",
      "\n",
      " Epoch 6308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774793624878\n",
      "\n",
      " Epoch 6309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924472808838\n",
      "\n",
      " Epoch 6310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013021469116\n",
      "\n",
      " Epoch 6311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925283432007\n",
      "\n",
      " Epoch 6312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829486846924\n",
      "\n",
      " Epoch 6313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883750915527\n",
      "\n",
      " Epoch 6314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793533325195\n",
      "\n",
      " Epoch 6315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590744972229\n",
      "\n",
      " Epoch 6316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45680046081543\n",
      "\n",
      " Epoch 6317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835638046265\n",
      "\n",
      " Epoch 6318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857620239258\n",
      "\n",
      " Epoch 6319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779514312744\n",
      "\n",
      " Epoch 6320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796012878418\n",
      "\n",
      " Epoch 6321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578652381897\n",
      "\n",
      " Epoch 6322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924615859985\n",
      "\n",
      " Epoch 6323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656728744507\n",
      "\n",
      " Epoch 6324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830154418945\n",
      "\n",
      " Epoch 6325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855379104614\n",
      "\n",
      " Epoch 6326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006917953491\n",
      "\n",
      " Epoch 6327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898008346558\n",
      "\n",
      " Epoch 6328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833969116211\n",
      "\n",
      " Epoch 6329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871782302856\n",
      "\n",
      " Epoch 6330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835971832275\n",
      "\n",
      " Epoch 6331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45483160018921\n",
      "\n",
      " Epoch 6332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776414871216\n",
      "\n",
      " Epoch 6333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593334197998\n",
      "\n",
      " Epoch 6334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846891403198\n",
      "\n",
      " Epoch 6335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933246612549\n",
      "\n",
      " Epoch 6336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4559235572815\n",
      "\n",
      " Epoch 6337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577374458313\n",
      "\n",
      " Epoch 6338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881462097168\n",
      "\n",
      " Epoch 6339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780992507935\n",
      "\n",
      " Epoch 6340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904874801636\n",
      "\n",
      " Epoch 6341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45713472366333\n",
      "\n",
      " Epoch 6342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45717906951904\n",
      "\n",
      " Epoch 6343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789432525635\n",
      "\n",
      " Epoch 6344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922708511353\n",
      "\n",
      " Epoch 6345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008396148682\n",
      "\n",
      " Epoch 6346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922613143921\n",
      "\n",
      " Epoch 6347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589695930481\n",
      "\n",
      " Epoch 6348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575891494751\n",
      "\n",
      " Epoch 6349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944404602051\n",
      "\n",
      " Epoch 6350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628452301025\n",
      "\n",
      " Epoch 6351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793199539185\n",
      "\n",
      " Epoch 6352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878314971924\n",
      "\n",
      " Epoch 6353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837926864624\n",
      "\n",
      " Epoch 6354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45658254623413\n",
      "\n",
      " Epoch 6355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835781097412\n",
      "\n",
      " Epoch 6356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842504501343\n",
      "\n",
      " Epoch 6357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919132232666\n",
      "\n",
      " Epoch 6358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885801315308\n",
      "\n",
      " Epoch 6359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45736312866211\n",
      "\n",
      " Epoch 6360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935249328613\n",
      "\n",
      " Epoch 6361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881843566895\n",
      "\n",
      " Epoch 6362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579496383667\n",
      "\n",
      " Epoch 6363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915460586548\n",
      "\n",
      " Epoch 6364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918321609497\n",
      "\n",
      " Epoch 6365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910739898682\n",
      "\n",
      " Epoch 6366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781421661377\n",
      "\n",
      " Epoch 6367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45545625686646\n",
      "\n",
      " Epoch 6368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851516723633\n",
      "\n",
      " Epoch 6369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809173583984\n",
      "\n",
      " Epoch 6370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876598358154\n",
      "\n",
      " Epoch 6371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804691314697\n",
      "\n",
      " Epoch 6372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640516281128\n",
      "\n",
      " Epoch 6373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865297317505\n",
      "\n",
      " Epoch 6374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46031188964844\n",
      "\n",
      " Epoch 6375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648384094238\n",
      "\n",
      " Epoch 6376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584550857544\n",
      "\n",
      " Epoch 6377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628786087036\n",
      "\n",
      " Epoch 6378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858240127563\n",
      "\n",
      " Epoch 6379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904731750488\n",
      "\n",
      " Epoch 6380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013689041138\n",
      "\n",
      " Epoch 6381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891332626343\n",
      "\n",
      " Epoch 6382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836162567139\n",
      "\n",
      " Epoch 6383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588189125061\n",
      "\n",
      " Epoch 6384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865631103516\n",
      "\n",
      " Epoch 6385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631647109985\n",
      "\n",
      " Epoch 6386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828056335449\n",
      "\n",
      " Epoch 6387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858240127563\n",
      "\n",
      " Epoch 6388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758438110352\n",
      "\n",
      " Epoch 6389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580454826355\n",
      "\n",
      " Epoch 6390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772218704224\n",
      "\n",
      " Epoch 6391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593710899353\n",
      "\n",
      " Epoch 6392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566445350647\n",
      "\n",
      " Epoch 6393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846271514893\n",
      "\n",
      " Epoch 6394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852899551392\n",
      "\n",
      " Epoch 6395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656681060791\n",
      "\n",
      " Epoch 6396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839548110962\n",
      "\n",
      " Epoch 6397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865106582642\n",
      "\n",
      " Epoch 6398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843029022217\n",
      "\n",
      " Epoch 6399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574408531189\n",
      "\n",
      " Epoch 6400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961093902588\n",
      "\n",
      " Epoch 6401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853424072266\n",
      "\n",
      " Epoch 6402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936918258667\n",
      "\n",
      " Epoch 6403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837783813477\n",
      "\n",
      " Epoch 6404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588942527771\n",
      "\n",
      " Epoch 6405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778512954712\n",
      "\n",
      " Epoch 6406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919895172119\n",
      "\n",
      " Epoch 6407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45512533187866\n",
      "\n",
      " Epoch 6408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585599899292\n",
      "\n",
      " Epoch 6409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46022939682007\n",
      "\n",
      " Epoch 6410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870590209961\n",
      "\n",
      " Epoch 6411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836687088013\n",
      "\n",
      " Epoch 6412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889186859131\n",
      "\n",
      " Epoch 6413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787239074707\n",
      "\n",
      " Epoch 6414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906686782837\n",
      "\n",
      " Epoch 6415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45659923553467\n",
      "\n",
      " Epoch 6416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848989486694\n",
      "\n",
      " Epoch 6417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865964889526\n",
      "\n",
      " Epoch 6418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584608078003\n",
      "\n",
      " Epoch 6419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45484447479248\n",
      "\n",
      " Epoch 6420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779228210449\n",
      "\n",
      " Epoch 6421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887994766235\n",
      "\n",
      " Epoch 6422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46021842956543\n",
      "\n",
      " Epoch 6423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905828475952\n",
      "\n",
      " Epoch 6424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874071121216\n",
      "\n",
      " Epoch 6425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781326293945\n",
      "\n",
      " Epoch 6426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935726165771\n",
      "\n",
      " Epoch 6427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643377304077\n",
      "\n",
      " Epoch 6428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835208892822\n",
      "\n",
      " Epoch 6429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860624313354\n",
      "\n",
      " Epoch 6430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987272262573\n",
      "\n",
      " Epoch 6431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906782150269\n",
      "\n",
      " Epoch 6432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825338363647\n",
      "\n",
      " Epoch 6433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882940292358\n",
      "\n",
      " Epoch 6434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45690679550171\n",
      "\n",
      " Epoch 6435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590859413147\n",
      "\n",
      " Epoch 6436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927715301514\n",
      "\n",
      " Epoch 6437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869636535645\n",
      "\n",
      " Epoch 6438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45495748519897\n",
      "\n",
      " Epoch 6439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786333084106\n",
      "\n",
      " Epoch 6440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45971441268921\n",
      "\n",
      " Epoch 6441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895385742188\n",
      "\n",
      " Epoch 6442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583215713501\n",
      "\n",
      " Epoch 6443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588713645935\n",
      "\n",
      " Epoch 6444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577202796936\n",
      "\n",
      " Epoch 6445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644092559814\n",
      "\n",
      " Epoch 6446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851230621338\n",
      "\n",
      " Epoch 6447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46028089523315\n",
      "\n",
      " Epoch 6448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872974395752\n",
      "\n",
      " Epoch 6449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss :  82.458251953125\n",
      "\n",
      " Epoch 6450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886898040771\n",
      "\n",
      " Epoch 6451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776653289795\n",
      "\n",
      " Epoch 6452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914936065674\n",
      "\n",
      " Epoch 6453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45508050918579\n",
      "\n",
      " Epoch 6454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846891403198\n",
      "\n",
      " Epoch 6455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924854278564\n",
      "\n",
      " Epoch 6456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877408981323\n",
      "\n",
      " Epoch 6457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578709602356\n",
      "\n",
      " Epoch 6458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626449584961\n",
      "\n",
      " Epoch 6459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854043960571\n",
      "\n",
      " Epoch 6460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810651779175\n",
      "\n",
      " Epoch 6461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863056182861\n",
      "\n",
      " Epoch 6462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566798210144\n",
      "\n",
      " Epoch 6463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584321975708\n",
      "\n",
      " Epoch 6464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586911201477\n",
      "\n",
      " Epoch 6465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847845077515\n",
      "\n",
      " Epoch 6466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45485353469849\n",
      "\n",
      " Epoch 6467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773506164551\n",
      "\n",
      " Epoch 6468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930767059326\n",
      "\n",
      " Epoch 6469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844507217407\n",
      "\n",
      " Epoch 6470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928955078125\n",
      "\n",
      " Epoch 6471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46019411087036\n",
      "\n",
      " Epoch 6472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586591720581\n",
      "\n",
      " Epoch 6473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846319198608\n",
      "\n",
      " Epoch 6474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871257781982\n",
      "\n",
      " Epoch 6475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776414871216\n",
      "\n",
      " Epoch 6476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913791656494\n",
      "\n",
      " Epoch 6477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45500707626343\n",
      "\n",
      " Epoch 6478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578685760498\n",
      "\n",
      " Epoch 6479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968294143677\n",
      "\n",
      " Epoch 6480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579644203186\n",
      "\n",
      " Epoch 6481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828294754028\n",
      "\n",
      " Epoch 6482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588828086853\n",
      "\n",
      " Epoch 6483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925569534302\n",
      "\n",
      " Epoch 6484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860767364502\n",
      "\n",
      " Epoch 6485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458580493927\n",
      "\n",
      " Epoch 6486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638370513916\n",
      "\n",
      " Epoch 6487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835018157959\n",
      "\n",
      " Epoch 6488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862102508545\n",
      "\n",
      " Epoch 6489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564995765686\n",
      "\n",
      " Epoch 6490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844411849976\n",
      "\n",
      " Epoch 6491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839166641235\n",
      "\n",
      " Epoch 6492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806741714478\n",
      "\n",
      " Epoch 6493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903205871582\n",
      "\n",
      " Epoch 6494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45500469207764\n",
      "\n",
      " Epoch 6495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 6496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005773544312\n",
      "\n",
      " Epoch 6497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879316329956\n",
      "\n",
      " Epoch 6498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841217041016\n",
      "\n",
      " Epoch 6499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865821838379\n",
      "\n",
      " Epoch 6500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927858352661\n",
      "\n",
      " Epoch 6501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877408981323\n",
      "\n",
      " Epoch 6502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578709602356\n",
      "\n",
      " Epoch 6503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921182632446\n",
      "\n",
      " Epoch 6504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45492506027222\n",
      "\n",
      " Epoch 6505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774030685425\n",
      "\n",
      " Epoch 6506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875453948975\n",
      "\n",
      " Epoch 6507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45581007003784\n",
      "\n",
      " Epoch 6508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854425430298\n",
      "\n",
      " Epoch 6509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46016597747803\n",
      "\n",
      " Epoch 6510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586501121521\n",
      "\n",
      " Epoch 6511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829010009766\n",
      "\n",
      " Epoch 6512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883131027222\n",
      "\n",
      " Epoch 6513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577407836914\n",
      "\n",
      " Epoch 6514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914459228516\n",
      "\n",
      " Epoch 6515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45505857467651\n",
      "\n",
      " Epoch 6516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773029327393\n",
      "\n",
      " Epoch 6517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921754837036\n",
      "\n",
      " Epoch 6518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585919380188\n",
      "\n",
      " Epoch 6519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46003007888794\n",
      "\n",
      " Epoch 6520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910692214966\n",
      "\n",
      " Epoch 6521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823192596436\n",
      "\n",
      " Epoch 6522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634078979492\n",
      "\n",
      " Epoch 6523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45737743377686\n",
      "\n",
      " Epoch 6524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834302902222\n",
      "\n",
      " Epoch 6525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917797088623\n",
      "\n",
      " Epoch 6526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835208892822\n",
      "\n",
      " Epoch 6527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619297027588\n",
      "\n",
      " Epoch 6528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833730697632\n",
      "\n",
      " Epoch 6529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586443901062\n",
      "\n",
      " Epoch 6530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976209640503\n",
      "\n",
      " Epoch 6531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886659622192\n",
      "\n",
      " Epoch 6532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958518981934\n",
      "\n",
      " Epoch 6533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823049545288\n",
      "\n",
      " Epoch 6534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952033996582\n",
      "\n",
      " Epoch 6535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768642425537\n",
      "\n",
      " Epoch 6536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581151008606\n",
      "\n",
      " Epoch 6537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585828781128\n",
      "\n",
      " Epoch 6538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45602560043335\n",
      "\n",
      " Epoch 6539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778131484985\n",
      "\n",
      " Epoch 6540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890378952026\n",
      "\n",
      " Epoch 6541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786380767822\n",
      "\n",
      " Epoch 6542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905208587646\n",
      "\n",
      " Epoch 6543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45520544052124\n",
      "\n",
      " Epoch 6544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833921432495\n",
      "\n",
      " Epoch 6545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010732650757\n",
      "\n",
      " Epoch 6546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883274078369\n",
      "\n",
      " Epoch 6547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825862884521\n",
      "\n",
      " Epoch 6548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588270187378\n",
      "\n",
      " Epoch 6549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774126052856\n",
      "\n",
      " Epoch 6550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918035507202\n",
      "\n",
      " Epoch 6551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45653104782104\n",
      "\n",
      " Epoch 6552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829820632935\n",
      "\n",
      " Epoch 6553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862674713135\n",
      "\n",
      " Epoch 6554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757579803467\n",
      "\n",
      " Epoch 6555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802354812622\n",
      "\n",
      " Epoch 6556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775699615479\n",
      "\n",
      " Epoch 6557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45932054519653\n",
      "\n",
      " Epoch 6558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45710372924805\n",
      "\n",
      " Epoch 6559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45702171325684\n",
      "\n",
      " Epoch 6560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778322219849\n",
      "\n",
      " Epoch 6561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915842056274\n",
      "\n",
      " Epoch 6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784521102905\n",
      "\n",
      " Epoch 6563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920610427856\n",
      "\n",
      " Epoch 6564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45666027069092\n",
      "\n",
      " Epoch 6565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838642120361\n",
      "\n",
      " Epoch 6566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863676071167\n",
      "\n",
      " Epoch 6567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836687088013\n",
      "\n",
      " Epoch 6568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762348175049\n",
      "\n",
      " Epoch 6569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45952796936035\n",
      "\n",
      " Epoch 6570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619249343872\n",
      "\n",
      " Epoch 6571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786333084106\n",
      "\n",
      " Epoch 6572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877408981323\n",
      "\n",
      " Epoch 6573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842981338501\n",
      "\n",
      " Epoch 6574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45658493041992\n",
      "\n",
      " Epoch 6575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593243598938\n",
      "\n",
      " Epoch 6576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791912078857\n",
      "\n",
      " Epoch 6577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824766159058\n",
      "\n",
      " Epoch 6578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881605148315\n",
      "\n",
      " Epoch 6579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780801773071\n",
      "\n",
      " Epoch 6580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903158187866\n",
      "\n",
      " Epoch 6581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651912689209\n",
      "\n",
      " Epoch 6582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837068557739\n",
      "\n",
      " Epoch 6583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866107940674\n",
      "\n",
      " Epoch 6584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839357376099\n",
      "\n",
      " Epoch 6585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899105072021\n",
      "\n",
      " Epoch 6586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845365524292\n",
      "\n",
      " Epoch 6587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827770233154\n",
      "\n",
      " Epoch 6588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813512802124\n",
      "\n",
      " Epoch 6589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884084701538\n",
      "\n",
      " Epoch 6590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864915847778\n",
      "\n",
      " Epoch 6591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566297531128\n",
      "\n",
      " Epoch 6592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849514007568\n",
      "\n",
      " Epoch 6593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844316482544\n",
      "\n",
      " Epoch 6594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793581008911\n",
      "\n",
      " Epoch 6595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45623540878296\n",
      "\n",
      " Epoch 6596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584846496582\n",
      "\n",
      " Epoch 6597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014785766602\n",
      "\n",
      " Epoch 6598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871543884277\n",
      "\n",
      " Epoch 6599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815467834473\n",
      "\n",
      " Epoch 6600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873355865479\n",
      "\n",
      " Epoch 6601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838785171509\n",
      "\n",
      " Epoch 6602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45486831665039\n",
      "\n",
      " Epoch 6603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782995223999\n",
      "\n",
      " Epoch 6604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919561386108\n",
      "\n",
      " Epoch 6605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858812332153\n",
      "\n",
      " Epoch 6606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592776298523\n",
      "\n",
      " Epoch 6607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803308486938\n",
      "\n",
      " Epoch 6608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878219604492\n",
      "\n",
      " Epoch 6609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564995765686\n",
      "\n",
      " Epoch 6610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582724571228\n",
      "\n",
      " Epoch 6611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865058898926\n",
      "\n",
      " Epoch 6612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837688446045\n",
      "\n",
      " Epoch 6613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45480489730835\n",
      "\n",
      " Epoch 6614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457688331604\n",
      "\n",
      " Epoch 6615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929098129272\n",
      "\n",
      " Epoch 6616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998334884644\n",
      "\n",
      " Epoch 6617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910406112671\n",
      "\n",
      " Epoch 6618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821952819824\n",
      "\n",
      " Epoch 6619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883893966675\n",
      "\n",
      " Epoch 6620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581208229065\n",
      "\n",
      " Epoch 6621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45661067962646\n",
      "\n",
      " Epoch 6622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824766159058\n",
      "\n",
      " Epoch 6623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826244354248\n",
      "\n",
      " Epoch 6624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45730590820312\n",
      "\n",
      " Epoch 6625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45950365066528\n",
      "\n",
      " Epoch 6626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955419540405\n",
      "\n",
      " Epoch 6627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853042602539\n",
      "\n",
      " Epoch 6628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782470703125\n",
      "\n",
      " Epoch 6629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888662338257\n",
      "\n",
      " Epoch 6630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45479583740234\n",
      "\n",
      " Epoch 6631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766544342041\n",
      "\n",
      " Epoch 6632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878648757935\n",
      "\n",
      " Epoch 6633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799112319946\n",
      "\n",
      " Epoch 6634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886993408203\n",
      "\n",
      " Epoch 6635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45727443695068\n",
      "\n",
      " Epoch 6636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771598815918\n",
      "\n",
      " Epoch 6637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875883102417\n",
      "\n",
      " Epoch 6638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779228210449\n",
      "\n",
      " Epoch 6639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915794372559\n",
      "\n",
      " Epoch 6640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751285552979\n",
      "\n",
      " Epoch 6641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45693492889404\n",
      "\n",
      " Epoch 6642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575424194336\n",
      "\n",
      " Epoch 6643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862817764282\n",
      "\n",
      " Epoch 6644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913028717041\n",
      "\n",
      " Epoch 6645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863962173462\n",
      "\n",
      " Epoch 6646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857906341553\n",
      "\n",
      " Epoch 6647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632457733154\n",
      "\n",
      " Epoch 6648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832824707031\n",
      "\n",
      " Epoch 6649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859622955322\n",
      "\n",
      " Epoch 6650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986890792847\n",
      "\n",
      " Epoch 6651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904636383057\n",
      "\n",
      " Epoch 6652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582085609436\n",
      "\n",
      " Epoch 6653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587950706482\n",
      "\n",
      " Epoch 6654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45690107345581\n",
      "\n",
      " Epoch 6655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894193649292\n",
      "\n",
      " Epoch 6656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663356781006\n",
      "\n",
      " Epoch 6657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826005935669\n",
      "\n",
      " Epoch 6658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774555206299\n",
      "\n",
      " Epoch 6659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865154266357\n",
      "\n",
      " Epoch 6660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 6661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648384094238\n",
      "\n",
      " Epoch 6662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918560028076\n",
      "\n",
      " Epoch 6663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782613754272\n",
      "\n",
      " Epoch 6664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816898345947\n",
      "\n",
      " Epoch 6665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591875076294\n",
      "\n",
      " Epoch 6666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760822296143\n",
      "\n",
      " Epoch 6667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876598358154\n",
      "\n",
      " Epoch 6668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851850509644\n",
      "\n",
      " Epoch 6669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45670413970947\n",
      "\n",
      " Epoch 6670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828247070312\n",
      "\n",
      " Epoch 6671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779132843018\n",
      "\n",
      " Epoch 6672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913553237915\n",
      "\n",
      " Epoch 6673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749092102051\n",
      "\n",
      " Epoch 6674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45578289031982\n",
      "\n",
      " Epoch 6675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784568786621\n",
      "\n",
      " Epoch 6676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588770866394\n",
      "\n",
      " Epoch 6677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776462554932\n",
      "\n",
      " Epoch 6678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923137664795\n",
      "\n",
      " Epoch 6679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876264572144\n",
      "\n",
      " Epoch 6680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590573310852\n",
      "\n",
      " Epoch 6681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837116241455\n",
      "\n",
      " Epoch 6682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622062683105\n",
      "\n",
      " Epoch 6683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848846435547\n",
      "\n",
      " Epoch 6684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872402191162\n",
      "\n",
      " Epoch 6685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634889602661\n",
      "\n",
      " Epoch 6686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838117599487\n",
      "\n",
      " Epoch 6687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858097076416\n",
      "\n",
      " Epoch 6688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987510681152\n",
      "\n",
      " Epoch 6689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888757705688\n",
      "\n",
      " Epoch 6690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45794105529785\n",
      "\n",
      " Epoch 6691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586877822876\n",
      "\n",
      " Epoch 6692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766878128052\n",
      "\n",
      " Epoch 6693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799446105957\n",
      "\n",
      " Epoch 6694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769262313843\n",
      "\n",
      " Epoch 6695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934295654297\n",
      "\n",
      " Epoch 6696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563980102539\n",
      "\n",
      " Epoch 6697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458327293396\n",
      "\n",
      " Epoch 6698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585919380188\n",
      "\n",
      " Epoch 6699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986700057983\n",
      "\n",
      " Epoch 6700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905923843384\n",
      "\n",
      " Epoch 6701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816707611084\n",
      "\n",
      " Epoch 6702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880460739136\n",
      "\n",
      " Epoch 6703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811986923218\n",
      "\n",
      " Epoch 6704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45495748519897\n",
      "\n",
      " Epoch 6705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765399932861\n",
      "\n",
      " Epoch 6706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918607711792\n",
      "\n",
      " Epoch 6707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002197265625\n",
      "\n",
      " Epoch 6708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918560028076\n",
      "\n",
      " Epoch 6709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817518234253\n",
      "\n",
      " Epoch 6710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874118804932\n",
      "\n",
      " Epoch 6711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783758163452\n",
      "\n",
      " Epoch 6712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4554328918457\n",
      "\n",
      " Epoch 6713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583740234375\n",
      "\n",
      " Epoch 6714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 6715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895671844482\n",
      "\n",
      " Epoch 6716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825958251953\n",
      "\n",
      " Epoch 6717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883274078369\n",
      "\n",
      " Epoch 6718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576735496521\n",
      "\n",
      " Epoch 6719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660543441772\n",
      "\n",
      " Epoch 6720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583044052124\n",
      "\n",
      " Epoch 6721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771217346191\n",
      "\n",
      " Epoch 6722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883226394653\n",
      "\n",
      " Epoch 6723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836639404297\n",
      "\n",
      " Epoch 6724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645141601562\n",
      "\n",
      " Epoch 6725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830583572388\n",
      "\n",
      " Epoch 6726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848655700684\n",
      "\n",
      " Epoch 6727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644092559814\n",
      "\n",
      " Epoch 6728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827770233154\n",
      "\n",
      " Epoch 6729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857095718384\n",
      "\n",
      " Epoch 6730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763301849365\n",
      "\n",
      " Epoch 6731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785903930664\n",
      "\n",
      " Epoch 6732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793104171753\n",
      "\n",
      " Epoch 6733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884609222412\n",
      "\n",
      " Epoch 6734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651149749756\n",
      "\n",
      " Epoch 6735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582314491272\n",
      "\n",
      " Epoch 6736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585690498352\n",
      "\n",
      " Epoch 6737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824766159058\n",
      "\n",
      " Epoch 6738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909118652344\n",
      "\n",
      " Epoch 6739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805883407593\n",
      "\n",
      " Epoch 6740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870208740234\n",
      "\n",
      " Epoch 6741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642280578613\n",
      "\n",
      " Epoch 6742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822048187256\n",
      "\n",
      " Epoch 6743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587950706482\n",
      "\n",
      " Epoch 6744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574761390686\n",
      "\n",
      " Epoch 6745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929479598999\n",
      "\n",
      " Epoch 6746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887470245361\n",
      "\n",
      " Epoch 6747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916652679443\n",
      "\n",
      " Epoch 6748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826625823975\n",
      "\n",
      " Epoch 6749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866441726685\n",
      "\n",
      " Epoch 6750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814943313599\n",
      "\n",
      " Epoch 6751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45498847961426\n",
      "\n",
      " Epoch 6752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786762237549\n",
      "\n",
      " Epoch 6753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907545089722\n",
      "\n",
      " Epoch 6754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848941802979\n",
      "\n",
      " Epoch 6755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45735311508179\n",
      "\n",
      " Epoch 6756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953750610352\n",
      "\n",
      " Epoch 6757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858192443848\n",
      "\n",
      " Epoch 6758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.456533908844\n",
      "\n",
      " Epoch 6759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835208892822\n",
      "\n",
      " Epoch 6760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776224136353\n",
      "\n",
      " Epoch 6761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921993255615\n",
      "\n",
      " Epoch 6762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836114883423\n",
      "\n",
      " Epoch 6763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45488262176514\n",
      "\n",
      " Epoch 6764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578332901001\n",
      "\n",
      " Epoch 6765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936584472656\n",
      "\n",
      " Epoch 6766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997047424316\n",
      "\n",
      " Epoch 6767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889806747437\n",
      "\n",
      " Epoch 6768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583101272583\n",
      "\n",
      " Epoch 6769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874309539795\n",
      "\n",
      " Epoch 6770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564299583435\n",
      "\n",
      " Epoch 6771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832538604736\n",
      "\n",
      " Epoch 6772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860433578491\n",
      "\n",
      " Epoch 6773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 6774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45477485656738\n",
      "\n",
      " Epoch 6775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769119262695\n",
      "\n",
      " Epoch 6776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925855636597\n",
      "\n",
      " Epoch 6777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838356018066\n",
      "\n",
      " Epoch 6778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459237575531\n",
      "\n",
      " Epoch 6779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012496948242\n",
      "\n",
      " Epoch 6780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858812332153\n",
      "\n",
      " Epoch 6781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836400985718\n",
      "\n",
      " Epoch 6782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861625671387\n",
      "\n",
      " Epoch 6783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581618309021\n",
      "\n",
      " Epoch 6784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45487451553345\n",
      "\n",
      " Epoch 6785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765829086304\n",
      "\n",
      " Epoch 6786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587950706482\n",
      "\n",
      " Epoch 6787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938062667847\n",
      "\n",
      " Epoch 6788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586501121521\n",
      "\n",
      " Epoch 6789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645093917847\n",
      "\n",
      " Epoch 6790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909214019775\n",
      "\n",
      " Epoch 6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775699615479\n",
      "\n",
      " Epoch 6792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826387405396\n",
      "\n",
      " Epoch 6793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861196517944\n",
      "\n",
      " Epoch 6794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816421508789\n",
      "\n",
      " Epoch 6795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947217941284\n",
      "\n",
      " Epoch 6796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857954025269\n",
      "\n",
      " Epoch 6797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750999450684\n",
      "\n",
      " Epoch 6798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846462249756\n",
      "\n",
      " Epoch 6799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900821685791\n",
      "\n",
      " Epoch 6800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45498847961426\n",
      "\n",
      " Epoch 6801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758962631226\n",
      "\n",
      " Epoch 6802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45961999893188\n",
      "\n",
      " Epoch 6803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899820327759\n",
      "\n",
      " Epoch 6804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947742462158\n",
      "\n",
      " Epoch 6805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847511291504\n",
      "\n",
      " Epoch 6806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576187133789\n",
      "\n",
      " Epoch 6807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921611785889\n",
      "\n",
      " Epoch 6808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45486736297607\n",
      "\n",
      " Epoch 6809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774602890015\n",
      "\n",
      " Epoch 6810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887660980225\n",
      "\n",
      " Epoch 6811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834732055664\n",
      "\n",
      " Epoch 6812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669651031494\n",
      "\n",
      " Epoch 6813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826148986816\n",
      "\n",
      " Epoch 6814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774555206299\n",
      "\n",
      " Epoch 6815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911979675293\n",
      "\n",
      " Epoch 6816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745372772217\n",
      "\n",
      " Epoch 6817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918035507202\n",
      "\n",
      " Epoch 6818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860242843628\n",
      "\n",
      " Epoch 6819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792245864868\n",
      "\n",
      " Epoch 6820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897006988525\n",
      "\n",
      " Epoch 6821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594373703003\n",
      "\n",
      " Epoch 6822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864009857178\n",
      "\n",
      " Epoch 6823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564561843872\n",
      "\n",
      " Epoch 6824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840835571289\n",
      "\n",
      " Epoch 6825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780420303345\n",
      "\n",
      " Epoch 6826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587550163269\n",
      "\n",
      " Epoch 6827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817995071411\n",
      "\n",
      " Epoch 6828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45496129989624\n",
      "\n",
      " Epoch 6829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834684371948\n",
      "\n",
      " Epoch 6830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909833908081\n",
      "\n",
      " Epoch 6831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828008651733\n",
      "\n",
      " Epoch 6832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595422744751\n",
      "\n",
      " Epoch 6833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783233642578\n",
      "\n",
      " Epoch 6834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815849304199\n",
      "\n",
      " Epoch 6835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879745483398\n",
      "\n",
      " Epoch 6836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916652679443\n",
      "\n",
      " Epoch 6837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852470397949\n",
      "\n",
      " Epoch 6838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777893066406\n",
      "\n",
      " Epoch 6839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835161209106\n",
      "\n",
      " Epoch 6840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625972747803\n",
      "\n",
      " Epoch 6841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835828781128\n",
      "\n",
      " Epoch 6842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010446548462\n",
      "\n",
      " Epoch 6843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 6844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812845230103\n",
      "\n",
      " Epoch 6845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877361297607\n",
      "\n",
      " Epoch 6846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581823348999\n",
      "\n",
      " Epoch 6847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45491695404053\n",
      "\n",
      " Epoch 6848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763826370239\n",
      "\n",
      " Epoch 6849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591908454895\n",
      "\n",
      " Epoch 6850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780611038208\n",
      "\n",
      " Epoch 6851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45522499084473\n",
      "\n",
      " Epoch 6852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845174789429\n",
      "\n",
      " Epoch 6853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4602780342102\n",
      "\n",
      " Epoch 6854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864963531494\n",
      "\n",
      " Epoch 6855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 6856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882415771484\n",
      "\n",
      " Epoch 6857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775079727173\n",
      "\n",
      " Epoch 6858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625162124634\n",
      "\n",
      " Epoch 6859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836925506592\n",
      "\n",
      " Epoch 6860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46015501022339\n",
      "\n",
      " Epoch 6861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563660621643\n",
      "\n",
      " Epoch 6862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837688446045\n",
      "\n",
      " Epoch 6863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899963378906\n",
      "\n",
      " Epoch 6864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840263366699\n",
      "\n",
      " Epoch 6865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592776298523\n",
      "\n",
      " Epoch 6866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45593547821045\n",
      "\n",
      " Epoch 6867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848941802979\n",
      "\n",
      " Epoch 6868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592514038086\n",
      "\n",
      " Epoch 6869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864582061768\n",
      "\n",
      " Epoch 6870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45733976364136\n",
      "\n",
      " Epoch 6871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649242401123\n",
      "\n",
      " Epoch 6872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827960968018\n",
      "\n",
      " Epoch 6873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577579498291\n",
      "\n",
      " Epoch 6874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901823043823\n",
      "\n",
      " Epoch 6875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770263671875\n",
      "\n",
      " Epoch 6876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45519685745239\n",
      "\n",
      " Epoch 6877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584584236145\n",
      "\n",
      " Epoch 6878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867252349854\n",
      "\n",
      " Epoch 6879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626974105835\n",
      "\n",
      " Epoch 6880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828247070312\n",
      "\n",
      " Epoch 6881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856618881226\n",
      "\n",
      " Epoch 6882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825004577637\n",
      "\n",
      " Epoch 6883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923471450806\n",
      "\n",
      " Epoch 6884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589295387268\n",
      "\n",
      " Epoch 6885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740604400635\n",
      "\n",
      " Epoch 6886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656299591064\n",
      "\n",
      " Epoch 6887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840883255005\n",
      "\n",
      " Epoch 6888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785474777222\n",
      "\n",
      " Epoch 6889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590950012207\n",
      "\n",
      " Epoch 6890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584527015686\n",
      "\n",
      " Epoch 6891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655250549316\n",
      "\n",
      " Epoch 6892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841073989868\n",
      "\n",
      " Epoch 6893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830821990967\n",
      "\n",
      " Epoch 6894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903587341309\n",
      "\n",
      " Epoch 6895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799350738525\n",
      "\n",
      " Epoch 6896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787811279297\n",
      "\n",
      " Epoch 6897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457763671875\n",
      "\n",
      " Epoch 6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915746688843\n",
      "\n",
      " Epoch 6899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643091201782\n",
      "\n",
      " Epoch 6900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819425582886\n",
      "\n",
      " Epoch 6901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846796035767\n",
      "\n",
      " Epoch 6902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836591720581\n",
      "\n",
      " Epoch 6903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897102355957\n",
      "\n",
      " Epoch 6904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 6905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642566680908\n",
      "\n",
      " Epoch 6906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832777023315\n",
      "\n",
      " Epoch 6907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824766159058\n",
      "\n",
      " Epoch 6908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577865600586\n",
      "\n",
      " Epoch 6909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911026000977\n",
      "\n",
      " Epoch 6910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746612548828\n",
      "\n",
      " Epoch 6911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920610427856\n",
      "\n",
      " Epoch 6912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840358734131\n",
      "\n",
      " Epoch 6913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561882019043\n",
      "\n",
      " Epoch 6914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795154571533\n",
      "\n",
      " Epoch 6915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872449874878\n",
      "\n",
      " Epoch 6916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583010673523\n",
      "\n",
      " Epoch 6917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882749557495\n",
      "\n",
      " Epoch 6918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638036727905\n",
      "\n",
      " Epoch 6919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927715301514\n",
      "\n",
      " Epoch 6920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897054672241\n",
      "\n",
      " Epoch 6921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783376693726\n",
      "\n",
      " Epoch 6922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900917053223\n",
      "\n",
      " Epoch 6923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770502090454\n",
      "\n",
      " Epoch 6924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775413513184\n",
      "\n",
      " Epoch 6925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457772731781\n",
      "\n",
      " Epoch 6926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910835266113\n",
      "\n",
      " Epoch 6927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45703458786011\n",
      "\n",
      " Epoch 6928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45697593688965\n",
      "\n",
      " Epoch 6929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765924453735\n",
      "\n",
      " Epoch 6930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592604637146\n",
      "\n",
      " Epoch 6931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999002456665\n",
      "\n",
      " Epoch 6932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911931991577\n",
      "\n",
      " Epoch 6933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823574066162\n",
      "\n",
      " Epoch 6934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884132385254\n",
      "\n",
      " Epoch 6935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818710327148\n",
      "\n",
      " Epoch 6936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45659732818604\n",
      "\n",
      " Epoch 6937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818853378296\n",
      "\n",
      " Epoch 6938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768308639526\n",
      "\n",
      " Epoch 6939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921516418457\n",
      "\n",
      " Epoch 6940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734453201294\n",
      "\n",
      " Epoch 6941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45653629302979\n",
      "\n",
      " Epoch 6942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827341079712\n",
      "\n",
      " Epoch 6943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775365829468\n",
      "\n",
      " Epoch 6944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910692214966\n",
      "\n",
      " Epoch 6945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846700668335\n",
      "\n",
      " Epoch 6946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4547438621521\n",
      "\n",
      " Epoch 6947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765924453735\n",
      "\n",
      " Epoch 6948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879125595093\n",
      "\n",
      " Epoch 6949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4601526260376\n",
      "\n",
      " Epoch 6950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898580551147\n",
      "\n",
      " Epoch 6951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867538452148\n",
      "\n",
      " Epoch 6952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631837844849\n",
      "\n",
      " Epoch 6953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829916000366\n",
      "\n",
      " Epoch 6954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776653289795\n",
      "\n",
      " Epoch 6955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916604995728\n",
      "\n",
      " Epoch 6956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726776123047\n",
      "\n",
      " Epoch 6957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644474029541\n",
      "\n",
      " Epoch 6958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907306671143\n",
      "\n",
      " Epoch 6959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878076553345\n",
      "\n",
      " Epoch 6960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582929611206\n",
      "\n",
      " Epoch 6961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882368087769\n",
      "\n",
      " Epoch 6962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771741867065\n",
      "\n",
      " Epoch 6963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590973854065\n",
      "\n",
      " Epoch 6964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745468139648\n",
      "\n",
      " Epoch 6965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918416976929\n",
      "\n",
      " Epoch 6966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585952758789\n",
      "\n",
      " Epoch 6967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901775360107\n",
      "\n",
      " Epoch 6968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813655853271\n",
      "\n",
      " Epoch 6969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628595352173\n",
      "\n",
      " Epoch 6970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832872390747\n",
      "\n",
      " Epoch 6971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792245864868\n",
      "\n",
      " Epoch 6972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868682861328\n",
      "\n",
      " Epoch 6973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45485162734985\n",
      "\n",
      " Epoch 6974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584469795227\n",
      "\n",
      " Epoch 6975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46009969711304\n",
      "\n",
      " Epoch 6976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859146118164\n",
      "\n",
      " Epoch 6977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821237564087\n",
      "\n",
      " Epoch 6978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878267288208\n",
      "\n",
      " Epoch 6979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771360397339\n",
      "\n",
      " Epoch 6980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908403396606\n",
      "\n",
      " Epoch 6981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4549789428711\n",
      "\n",
      " Epoch 6982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784044265747\n",
      "\n",
      " Epoch 6983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45965385437012\n",
      "\n",
      " Epoch 6984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895624160767\n",
      "\n",
      " Epoch 6985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956420898438\n",
      "\n",
      " Epoch 6986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845746994019\n",
      "\n",
      " Epoch 6987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773649215698\n",
      "\n",
      " Epoch 6988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591269493103\n",
      "\n",
      " Epoch 6989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896053314209\n",
      "\n",
      " Epoch 6990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806360244751\n",
      "\n",
      " Epoch 6991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616388320923\n",
      "\n",
      " Epoch 6992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458167552948\n",
      "\n",
      " Epoch 6993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872735977173\n",
      "\n",
      " Epoch 6994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582257270813\n",
      "\n",
      " Epoch 6995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881986618042\n",
      "\n",
      " Epoch 6996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577841758728\n",
      "\n",
      " Epoch 6997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914602279663\n",
      "\n",
      " Epoch 6998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45489549636841\n",
      "\n",
      " Epoch 6999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837640762329\n",
      "\n",
      " Epoch 7000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010065078735\n",
      "\n",
      " Epoch 7001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863342285156\n",
      "\n",
      " Epoch 7002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824098587036\n",
      "\n",
      " Epoch 7003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879173278809\n",
      "\n",
      " Epoch 7004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629787445068\n",
      "\n",
      " Epoch 7005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832538604736\n",
      "\n",
      " Epoch 7006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831966400146\n",
      "\n",
      " Epoch 7007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777320861816\n",
      "\n",
      " Epoch 7008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912027359009\n",
      "\n",
      " Epoch 7009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742893218994\n",
      "\n",
      " Epoch 7010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45618677139282\n",
      "\n",
      " Epoch 7011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817565917969\n",
      "\n",
      " Epoch 7012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848655700684\n",
      "\n",
      " Epoch 7013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893001556396\n",
      "\n",
      " Epoch 7014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580397605896\n",
      "\n",
      " Epoch 7015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856237411499\n",
      "\n",
      " Epoch 7016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644474029541\n",
      "\n",
      " Epoch 7017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810556411743\n",
      "\n",
      " Epoch 7018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854234695435\n",
      "\n",
      " Epoch 7019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820665359497\n",
      "\n",
      " Epoch 7020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641422271729\n",
      "\n",
      " Epoch 7021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829010009766\n",
      "\n",
      " Epoch 7022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826530456543\n",
      "\n",
      " Epoch 7023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45718288421631\n",
      "\n",
      " Epoch 7024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45937395095825\n",
      "\n",
      " Epoch 7025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942306518555\n",
      "\n",
      " Epoch 7026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807838439941\n",
      "\n",
      " Epoch 7027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877838134766\n",
      "\n",
      " Epoch 7028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820903778076\n",
      "\n",
      " Epoch 7029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45464897155762\n",
      "\n",
      " Epoch 7030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758485794067\n",
      "\n",
      " Epoch 7031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876407623291\n",
      "\n",
      " Epoch 7032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45794439315796\n",
      "\n",
      " Epoch 7033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796632766724\n",
      "\n",
      " Epoch 7034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783710479736\n",
      "\n",
      " Epoch 7035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921611785889\n",
      "\n",
      " Epoch 7036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648384094238\n",
      "\n",
      " Epoch 7037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822954177856\n",
      "\n",
      " Epoch 7038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847606658936\n",
      "\n",
      " Epoch 7039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997524261475\n",
      "\n",
      " Epoch 7040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890045166016\n",
      "\n",
      " Epoch 7041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779275894165\n",
      "\n",
      " Epoch 7042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905065536499\n",
      "\n",
      " Epoch 7043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834732055664\n",
      "\n",
      " Epoch 7044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643472671509\n",
      "\n",
      " Epoch 7045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834589004517\n",
      "\n",
      " Epoch 7046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773506164551\n",
      "\n",
      " Epoch 7047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45933866500854\n",
      "\n",
      " Epoch 7048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754432678223\n",
      "\n",
      " Epoch 7049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906782150269\n",
      "\n",
      " Epoch 7050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586009979248\n",
      "\n",
      " Epoch 7051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785140991211\n",
      "\n",
      " Epoch 7052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872259140015\n",
      "\n",
      " Epoch 7053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45513725280762\n",
      "\n",
      " Epoch 7054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772504806519\n",
      "\n",
      " Epoch 7055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903444290161\n",
      "\n",
      " Epoch 7056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46003293991089\n",
      "\n",
      " Epoch 7057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889854431152\n",
      "\n",
      " Epoch 7058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775175094604\n",
      "\n",
      " Epoch 7059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591612815857\n",
      "\n",
      " Epoch 7060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834684371948\n",
      "\n",
      " Epoch 7061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45472240447998\n",
      "\n",
      " Epoch 7062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766878128052\n",
      "\n",
      " Epoch 7063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879411697388\n",
      "\n",
      " Epoch 7064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012306213379\n",
      "\n",
      " Epoch 7065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897960662842\n",
      "\n",
      " Epoch 7066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866441726685\n",
      "\n",
      " Epoch 7067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634365081787\n",
      "\n",
      " Epoch 7068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829486846924\n",
      "\n",
      " Epoch 7069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457772731781\n",
      "\n",
      " Epoch 7070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459153175354\n",
      "\n",
      " Epoch 7071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726919174194\n",
      "\n",
      " Epoch 7072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645809173584\n",
      "\n",
      " Epoch 7073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820713043213\n",
      "\n",
      " Epoch 7074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764064788818\n",
      "\n",
      " Epoch 7075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923852920532\n",
      "\n",
      " Epoch 7076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835208892822\n",
      "\n",
      " Epoch 7077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45486259460449\n",
      "\n",
      " Epoch 7078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758962631226\n",
      "\n",
      " Epoch 7079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874977111816\n",
      "\n",
      " Epoch 7080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46010208129883\n",
      "\n",
      " Epoch 7081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589352607727\n",
      "\n",
      " Epoch 7082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864248275757\n",
      "\n",
      " Epoch 7083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628213882446\n",
      "\n",
      " Epoch 7084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824670791626\n",
      "\n",
      " Epoch 7085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773410797119\n",
      "\n",
      " Epoch 7086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914888381958\n",
      "\n",
      " Epoch 7087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723485946655\n",
      "\n",
      " Epoch 7088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644426345825\n",
      "\n",
      " Epoch 7089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818614959717\n",
      "\n",
      " Epoch 7090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812702178955\n",
      "\n",
      " Epoch 7091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782327651978\n",
      "\n",
      " Epoch 7092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916700363159\n",
      "\n",
      " Epoch 7093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642518997192\n",
      "\n",
      " Epoch 7094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811891555786\n",
      "\n",
      " Epoch 7095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844745635986\n",
      "\n",
      " Epoch 7096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576005935669\n",
      "\n",
      " Epoch 7097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786428451538\n",
      "\n",
      " Epoch 7098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642471313477\n",
      "\n",
      " Epoch 7099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907354354858\n",
      "\n",
      " Epoch 7100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882320404053\n",
      "\n",
      " Epoch 7101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817375183105\n",
      "\n",
      " Epoch 7102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867681503296\n",
      "\n",
      " Epoch 7103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577989578247\n",
      "\n",
      " Epoch 7104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917129516602\n",
      "\n",
      " Epoch 7105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45500993728638\n",
      "\n",
      " Epoch 7106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763111114502\n",
      "\n",
      " Epoch 7107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949459075928\n",
      "\n",
      " Epoch 7108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876836776733\n",
      "\n",
      " Epoch 7109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46027326583862\n",
      "\n",
      " Epoch 7110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897245407104\n",
      "\n",
      " Epoch 7111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45945978164673\n",
      "\n",
      " Epoch 7112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843601226807\n",
      "\n",
      " Epoch 7113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574875831604\n",
      "\n",
      " Epoch 7114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827722549438\n",
      "\n",
      " Epoch 7115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45606756210327\n",
      "\n",
      " Epoch 7116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582839012146\n",
      "\n",
      " Epoch 7117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792388916016\n",
      "\n",
      " Epoch 7118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785903930664\n",
      "\n",
      " Epoch 7119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824432373047\n",
      "\n",
      " Epoch 7120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636653900146\n",
      "\n",
      " Epoch 7121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829248428345\n",
      "\n",
      " Epoch 7122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837640762329\n",
      "\n",
      " Epoch 7123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895624160767\n",
      "\n",
      " Epoch 7124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879554748535\n",
      "\n",
      " Epoch 7125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45717239379883\n",
      "\n",
      " Epoch 7126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934343338013\n",
      "\n",
      " Epoch 7127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880222320557\n",
      "\n",
      " Epoch 7128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563193321228\n",
      "\n",
      " Epoch 7129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832967758179\n",
      "\n",
      " Epoch 7130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775604248047\n",
      "\n",
      " Epoch 7131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589958190918\n",
      "\n",
      " Epoch 7132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45738172531128\n",
      "\n",
      " Epoch 7133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642328262329\n",
      "\n",
      " Epoch 7134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816802978516\n",
      "\n",
      " Epoch 7135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814800262451\n",
      "\n",
      " Epoch 7136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773696899414\n",
      "\n",
      " Epoch 7137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914554595947\n",
      "\n",
      " Epoch 7138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740175247192\n",
      "\n",
      " Epoch 7139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591293334961\n",
      "\n",
      " Epoch 7140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583854675293\n",
      "\n",
      " Epoch 7141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868444442749\n",
      "\n",
      " Epoch 7142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630502700806\n",
      "\n",
      " Epoch 7143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592022895813\n",
      "\n",
      " Epoch 7144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888662338257\n",
      "\n",
      " Epoch 7145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775842666626\n",
      "\n",
      " Epoch 7146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911312103271\n",
      "\n",
      " Epoch 7147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754909515381\n",
      "\n",
      " Epoch 7148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788908004761\n",
      "\n",
      " Epoch 7149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760154724121\n",
      "\n",
      " Epoch 7150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631170272827\n",
      "\n",
      " Epoch 7151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836353302002\n",
      "\n",
      " Epoch 7152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008729934692\n",
      "\n",
      " Epoch 7153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852851867676\n",
      "\n",
      " Epoch 7154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581971168518\n",
      "\n",
      " Epoch 7155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857906341553\n",
      "\n",
      " Epoch 7156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753383636475\n",
      "\n",
      " Epoch 7157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918703079224\n",
      "\n",
      " Epoch 7158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45488739013672\n",
      "\n",
      " Epoch 7159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845222473145\n",
      "\n",
      " Epoch 7160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012735366821\n",
      "\n",
      " Epoch 7161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861434936523\n",
      "\n",
      " Epoch 7162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823621749878\n",
      "\n",
      " Epoch 7163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587950706482\n",
      "\n",
      " Epoch 7164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581995010376\n",
      "\n",
      " Epoch 7165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662927627563\n",
      "\n",
      " Epoch 7166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816469192505\n",
      "\n",
      " Epoch 7167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770120620728\n",
      "\n",
      " Epoch 7168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904588699341\n",
      "\n",
      " Epoch 7169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740127563477\n",
      "\n",
      " Epoch 7170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45637655258179\n",
      "\n",
      " Epoch 7171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827913284302\n",
      "\n",
      " Epoch 7172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773363113403\n",
      "\n",
      " Epoch 7173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913076400757\n",
      "\n",
      " Epoch 7174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772314071655\n",
      "\n",
      " Epoch 7175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782327651978\n",
      "\n",
      " Epoch 7176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764589309692\n",
      "\n",
      " Epoch 7177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591417312622\n",
      "\n",
      " Epoch 7178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644760131836\n",
      "\n",
      " Epoch 7179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582839012146\n",
      "\n",
      " Epoch 7180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858097076416\n",
      "\n",
      " Epoch 7181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 7182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909976959229\n",
      "\n",
      " Epoch 7183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46013736724854\n",
      "\n",
      " Epoch 7184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753860473633\n",
      "\n",
      " Epoch 7185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831251144409\n",
      "\n",
      " Epoch 7186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45593357086182\n",
      "\n",
      " Epoch 7187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838165283203\n",
      "\n",
      " Epoch 7188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861101150513\n",
      "\n",
      " Epoch 7189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881509780884\n",
      "\n",
      " Epoch 7190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815992355347\n",
      "\n",
      " Epoch 7191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45596075057983\n",
      "\n",
      " Epoch 7192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840167999268\n",
      "\n",
      " Epoch 7193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 7194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45736503601074\n",
      "\n",
      " Epoch 7195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925331115723\n",
      "\n",
      " Epoch 7196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821714401245\n",
      "\n",
      " Epoch 7197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884132385254\n",
      "\n",
      " Epoch 7198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769023895264\n",
      "\n",
      " Epoch 7199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906591415405\n",
      "\n",
      " Epoch 7200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45497703552246\n",
      "\n",
      " Epoch 7201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850944519043\n",
      "\n",
      " Epoch 7202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46018266677856\n",
      "\n",
      " Epoch 7203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864772796631\n",
      "\n",
      " Epoch 7204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825433731079\n",
      "\n",
      " Epoch 7205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880126953125\n",
      "\n",
      " Epoch 7206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774173736572\n",
      "\n",
      " Epoch 7207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589409828186\n",
      "\n",
      " Epoch 7208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634508132935\n",
      "\n",
      " Epoch 7209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819330215454\n",
      "\n",
      " Epoch 7210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851802825928\n",
      "\n",
      " Epoch 7211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728635787964\n",
      "\n",
      " Epoch 7212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45658731460571\n",
      "\n",
      " Epoch 7213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827531814575\n",
      "\n",
      " Epoch 7214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577465057373\n",
      "\n",
      " Epoch 7215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900106430054\n",
      "\n",
      " Epoch 7216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841264724731\n",
      "\n",
      " Epoch 7217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4548225402832\n",
      "\n",
      " Epoch 7218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577374458313\n",
      "\n",
      " Epoch 7219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955610275269\n",
      "\n",
      " Epoch 7220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890998840332\n",
      "\n",
      " Epoch 7221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939064025879\n",
      "\n",
      " Epoch 7222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837211608887\n",
      "\n",
      " Epoch 7223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891237258911\n",
      "\n",
      " Epoch 7224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912456512451\n",
      "\n",
      " Epoch 7225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875835418701\n",
      "\n",
      " Epoch 7226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920467376709\n",
      "\n",
      " Epoch 7227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792245864868\n",
      "\n",
      " Epoch 7228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873069763184\n",
      "\n",
      " Epoch 7229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45456218719482\n",
      "\n",
      " Epoch 7230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814514160156\n",
      "\n",
      " Epoch 7231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776700973511\n",
      "\n",
      " Epoch 7232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911502838135\n",
      "\n",
      " Epoch 7233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574122428894\n",
      "\n",
      " Epoch 7234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563536643982\n",
      "\n",
      " Epoch 7235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842456817627\n",
      "\n",
      " Epoch 7236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584813117981\n",
      "\n",
      " Epoch 7237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908880233765\n",
      "\n",
      " Epoch 7238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870304107666\n",
      "\n",
      " Epoch 7239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778179168701\n",
      "\n",
      " Epoch 7240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903587341309\n",
      "\n",
      " Epoch 7241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890522003174\n",
      "\n",
      " Epoch 7242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887279510498\n",
      "\n",
      " Epoch 7243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915460586548\n",
      "\n",
      " Epoch 7244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826435089111\n",
      "\n",
      " Epoch 7245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789766311646\n",
      "\n",
      " Epoch 7246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45516109466553\n",
      "\n",
      " Epoch 7247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834159851074\n",
      "\n",
      " Epoch 7248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789194107056\n",
      "\n",
      " Epoch 7249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45595359802246\n",
      "\n",
      " Epoch 7250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821380615234\n",
      "\n",
      " Epoch 7251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891857147217\n",
      "\n",
      " Epoch 7252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869874954224\n",
      "\n",
      " Epoch 7253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935297012329\n",
      "\n",
      " Epoch 7254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854425430298\n",
      "\n",
      " Epoch 7255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758295059204\n",
      "\n",
      " Epoch 7256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831108093262\n",
      "\n",
      " Epoch 7257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45615196228027\n",
      "\n",
      " Epoch 7258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828199386597\n",
      "\n",
      " Epoch 7259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002721786499\n",
      "\n",
      " Epoch 7260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745611190796\n",
      "\n",
      " Epoch 7261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458176612854\n",
      "\n",
      " Epoch 7262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594554901123\n",
      "\n",
      " Epoch 7263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458731174469\n",
      "\n",
      " Epoch 7264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831394195557\n",
      "\n",
      " Epoch 7265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881366729736\n",
      "\n",
      " Epoch 7266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641803741455\n",
      "\n",
      " Epoch 7267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810079574585\n",
      "\n",
      " Epoch 7268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813179016113\n",
      "\n",
      " Epoch 7269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578104019165\n",
      "\n",
      " Epoch 7270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911359786987\n",
      "\n",
      " Epoch 7271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742654800415\n",
      "\n",
      " Epoch 7272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936155319214\n",
      "\n",
      " Epoch 7273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871210098267\n",
      "\n",
      " Epoch 7274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876455307007\n",
      "\n",
      " Epoch 7275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810651779175\n",
      "\n",
      " Epoch 7276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625638961792\n",
      "\n",
      " Epoch 7277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831155776978\n",
      "\n",
      " Epoch 7278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788860321045\n",
      "\n",
      " Epoch 7279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767879486084\n",
      "\n",
      " Epoch 7280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834589004517\n",
      "\n",
      " Epoch 7281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566068649292\n",
      "\n",
      " Epoch 7282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828151702881\n",
      "\n",
      " Epoch 7283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776700973511\n",
      "\n",
      " Epoch 7284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893239974976\n",
      "\n",
      " Epoch 7285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784711837769\n",
      "\n",
      " Epoch 7286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851373672485\n",
      "\n",
      " Epoch 7287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873355865479\n",
      "\n",
      " Epoch 7288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594235420227\n",
      "\n",
      " Epoch 7289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856142044067\n",
      "\n",
      " Epoch 7290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632553100586\n",
      "\n",
      " Epoch 7291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831251144409\n",
      "\n",
      " Epoch 7292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777559280396\n",
      "\n",
      " Epoch 7293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45942687988281\n",
      "\n",
      " Epoch 7294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760011672974\n",
      "\n",
      " Epoch 7295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831298828125\n",
      "\n",
      " Epoch 7296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616388320923\n",
      "\n",
      " Epoch 7297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832443237305\n",
      "\n",
      " Epoch 7298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787858963013\n",
      "\n",
      " Epoch 7299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888757705688\n",
      "\n",
      " Epoch 7300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573745727539\n",
      "\n",
      " Epoch 7301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636224746704\n",
      "\n",
      " Epoch 7302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828866958618\n",
      "\n",
      " Epoch 7303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776271820068\n",
      "\n",
      " Epoch 7304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911502838135\n",
      "\n",
      " Epoch 7305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846176147461\n",
      "\n",
      " Epoch 7306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898485183716\n",
      "\n",
      " Epoch 7307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833587646484\n",
      "\n",
      " Epoch 7308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758867263794\n",
      "\n",
      " Epoch 7309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828104019165\n",
      "\n",
      " Epoch 7310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591178894043\n",
      "\n",
      " Epoch 7311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45495128631592\n",
      "\n",
      " Epoch 7312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847129821777\n",
      "\n",
      " Epoch 7313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46023845672607\n",
      "\n",
      " Epoch 7314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864391326904\n",
      "\n",
      " Epoch 7315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816993713379\n",
      "\n",
      " Epoch 7316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881128311157\n",
      "\n",
      " Epoch 7317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642948150635\n",
      "\n",
      " Epoch 7318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817136764526\n",
      "\n",
      " Epoch 7319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760297775269\n",
      "\n",
      " Epoch 7320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45603084564209\n",
      "\n",
      " Epoch 7321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803499221802\n",
      "\n",
      " Epoch 7322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767593383789\n",
      "\n",
      " Epoch 7323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903539657593\n",
      "\n",
      " Epoch 7324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740270614624\n",
      "\n",
      " Epoch 7325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809555053711\n",
      "\n",
      " Epoch 7326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45565366744995\n",
      "\n",
      " Epoch 7327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827960968018\n",
      "\n",
      " Epoch 7328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867252349854\n",
      "\n",
      " Epoch 7329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756530761719\n",
      "\n",
      " Epoch 7330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903253555298\n",
      "\n",
      " Epoch 7331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459219455719\n",
      "\n",
      " Epoch 7332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582142829895\n",
      "\n",
      " Epoch 7333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881748199463\n",
      "\n",
      " Epoch 7334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829010009766\n",
      "\n",
      " Epoch 7335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641279220581\n",
      "\n",
      " Epoch 7336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830059051514\n",
      "\n",
      " Epoch 7337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778751373291\n",
      "\n",
      " Epoch 7338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910930633545\n",
      "\n",
      " Epoch 7339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745468139648\n",
      "\n",
      " Epoch 7340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636367797852\n",
      "\n",
      " Epoch 7341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917177200317\n",
      "\n",
      " Epoch 7342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886707305908\n",
      "\n",
      " Epoch 7343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818138122559\n",
      "\n",
      " Epoch 7344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876789093018\n",
      "\n",
      " Epoch 7345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817995071411\n",
      "\n",
      " Epoch 7346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45487880706787\n",
      "\n",
      " Epoch 7347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762395858765\n",
      "\n",
      " Epoch 7348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915031433105\n",
      "\n",
      " Epoch 7349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600396156311\n",
      "\n",
      " Epoch 7350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912075042725\n",
      "\n",
      " Epoch 7351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815324783325\n",
      "\n",
      " Epoch 7352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871591567993\n",
      "\n",
      " Epoch 7353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639038085938\n",
      "\n",
      " Epoch 7354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824909210205\n",
      "\n",
      " Epoch 7355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586009979248\n",
      "\n",
      " Epoch 7356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760679244995\n",
      "\n",
      " Epoch 7357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782566070557\n",
      "\n",
      " Epoch 7358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775270462036\n",
      "\n",
      " Epoch 7359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914077758789\n",
      "\n",
      " Epoch 7360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45664119720459\n",
      "\n",
      " Epoch 7361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824003219604\n",
      "\n",
      " Epoch 7362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582142829895\n",
      "\n",
      " Epoch 7363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993709564209\n",
      "\n",
      " Epoch 7364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588303565979\n",
      "\n",
      " Epoch 7365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818424224854\n",
      "\n",
      " Epoch 7366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875406265259\n",
      "\n",
      " Epoch 7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45633029937744\n",
      "\n",
      " Epoch 7368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581389427185\n",
      "\n",
      " Epoch 7369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807218551636\n",
      "\n",
      " Epoch 7370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723152160645\n",
      "\n",
      " Epoch 7371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45925569534302\n",
      "\n",
      " Epoch 7372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868825912476\n",
      "\n",
      " Epoch 7373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45694017410278\n",
      "\n",
      " Epoch 7374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829391479492\n",
      "\n",
      " Epoch 7375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561562538147\n",
      "\n",
      " Epoch 7376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829963684082\n",
      "\n",
      " Epoch 7377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858335494995\n",
      "\n",
      " Epoch 7378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45621824264526\n",
      "\n",
      " Epoch 7379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817613601685\n",
      "\n",
      " Epoch 7380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850706100464\n",
      "\n",
      " Epoch 7381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818614959717\n",
      "\n",
      " Epoch 7382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567437171936\n",
      "\n",
      " Epoch 7383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890283584595\n",
      "\n",
      " Epoch 7384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660543441772\n",
      "\n",
      " Epoch 7385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811223983765\n",
      "\n",
      " Epoch 7386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458411693573\n",
      "\n",
      " Epoch 7387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762825012207\n",
      "\n",
      " Epoch 7388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904493331909\n",
      "\n",
      " Epoch 7389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920658111572\n",
      "\n",
      " Epoch 7390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877361297607\n",
      "\n",
      " Epoch 7391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728826522827\n",
      "\n",
      " Epoch 7392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881462097168\n",
      "\n",
      " Epoch 7393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45713901519775\n",
      "\n",
      " Epoch 7394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45699262619019\n",
      "\n",
      " Epoch 7395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782661437988\n",
      "\n",
      " Epoch 7396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898008346558\n",
      "\n",
      " Epoch 7397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45986652374268\n",
      "\n",
      " Epoch 7398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881223678589\n",
      "\n",
      " Epoch 7399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45953464508057\n",
      "\n",
      " Epoch 7400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850563049316\n",
      "\n",
      " Epoch 7401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759534835815\n",
      "\n",
      " Epoch 7402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838499069214\n",
      "\n",
      " Epoch 7403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45606136322021\n",
      "\n",
      " Epoch 7404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822525024414\n",
      "\n",
      " Epoch 7405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780754089355\n",
      "\n",
      " Epoch 7406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875835418701\n",
      "\n",
      " Epoch 7407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582462310791\n",
      "\n",
      " Epoch 7408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45493364334106\n",
      "\n",
      " Epoch 7409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756196975708\n",
      "\n",
      " Epoch 7410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897579193115\n",
      "\n",
      " Epoch 7411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600076675415\n",
      "\n",
      " Epoch 7412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879125595093\n",
      "\n",
      " Epoch 7413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826625823975\n",
      "\n",
      " Epoch 7414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585371017456\n",
      "\n",
      " Epoch 7415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649337768555\n",
      "\n",
      " Epoch 7416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823526382446\n",
      "\n",
      " Epoch 7417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864677429199\n",
      "\n",
      " Epoch 7418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834350585938\n",
      "\n",
      " Epoch 7419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45479679107666\n",
      "\n",
      " Epoch 7420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772314071655\n",
      "\n",
      " Epoch 7421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908212661743\n",
      "\n",
      " Epoch 7422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845699310303\n",
      "\n",
      " Epoch 7423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45736742019653\n",
      "\n",
      " Epoch 7424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459388256073\n",
      "\n",
      " Epoch 7425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880031585693\n",
      "\n",
      " Epoch 7426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4566330909729\n",
      "\n",
      " Epoch 7427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826196670532\n",
      "\n",
      " Epoch 7428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772933959961\n",
      "\n",
      " Epoch 7429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895004272461\n",
      "\n",
      " Epoch 7430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783519744873\n",
      "\n",
      " Epoch 7431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4551796913147\n",
      "\n",
      " Epoch 7432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839405059814\n",
      "\n",
      " Epoch 7433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46006774902344\n",
      "\n",
      " Epoch 7434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853662490845\n",
      "\n",
      " Epoch 7435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814180374146\n",
      "\n",
      " Epoch 7436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872926712036\n",
      "\n",
      " Epoch 7437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813417434692\n",
      "\n",
      " Epoch 7438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655155181885\n",
      "\n",
      " Epoch 7439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817518234253\n",
      "\n",
      " Epoch 7440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768690109253\n",
      "\n",
      " Epoch 7441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590368270874\n",
      "\n",
      " Epoch 7442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45737934112549\n",
      "\n",
      " Epoch 7443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631980895996\n",
      "\n",
      " Epoch 7444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906639099121\n",
      "\n",
      " Epoch 7445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880174636841\n",
      "\n",
      " Epoch 7446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817279815674\n",
      "\n",
      " Epoch 7447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870065689087\n",
      "\n",
      " Epoch 7448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831727981567\n",
      "\n",
      " Epoch 7449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641708374023\n",
      "\n",
      " Epoch 7450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582872390747\n",
      "\n",
      " Epoch 7451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774745941162\n",
      "\n",
      " Epoch 7452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914697647095\n",
      "\n",
      " Epoch 7453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726156234741\n",
      "\n",
      " Epoch 7454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642185211182\n",
      "\n",
      " Epoch 7455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816946029663\n",
      "\n",
      " Epoch 7456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765447616577\n",
      "\n",
      " Epoch 7457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905208587646\n",
      "\n",
      " Epoch 7458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583911895752\n",
      "\n",
      " Epoch 7459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45466756820679\n",
      "\n",
      " Epoch 7460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757722854614\n",
      "\n",
      " Epoch 7461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918846130371\n",
      "\n",
      " Epoch 7462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976066589355\n",
      "\n",
      " Epoch 7463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884227752686\n",
      "\n",
      " Epoch 7464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833206176758\n",
      "\n",
      " Epoch 7465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857238769531\n",
      "\n",
      " Epoch 7466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45652723312378\n",
      "\n",
      " Epoch 7467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805549621582\n",
      "\n",
      " Epoch 7468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845603942871\n",
      "\n",
      " Epoch 7469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816278457642\n",
      "\n",
      " Epoch 7470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565258026123\n",
      "\n",
      " Epoch 7471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589319229126\n",
      "\n",
      " Epoch 7472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591269493103\n",
      "\n",
      " Epoch 7473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807790756226\n",
      "\n",
      " Epoch 7474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591383934021\n",
      "\n",
      " Epoch 7475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4549913406372\n",
      "\n",
      " Epoch 7476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833778381348\n",
      "\n",
      " Epoch 7477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45999050140381\n",
      "\n",
      " Epoch 7478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869779586792\n",
      "\n",
      " Epoch 7479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811414718628\n",
      "\n",
      " Epoch 7480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871114730835\n",
      "\n",
      " Epoch 7481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828580856323\n",
      "\n",
      " Epoch 7482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45646524429321\n",
      "\n",
      " Epoch 7483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828819274902\n",
      "\n",
      " Epoch 7484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771026611328\n",
      "\n",
      " Epoch 7485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914697647095\n",
      "\n",
      " Epoch 7486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726299285889\n",
      "\n",
      " Epoch 7487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644664764404\n",
      "\n",
      " Epoch 7488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820093154907\n",
      "\n",
      " Epoch 7489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819139480591\n",
      "\n",
      " Epoch 7490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45985078811646\n",
      "\n",
      " Epoch 7491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875024795532\n",
      "\n",
      " Epoch 7492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45956468582153\n",
      "\n",
      " Epoch 7493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812654495239\n",
      "\n",
      " Epoch 7494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855379104614\n",
      "\n",
      " Epoch 7495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802116394043\n",
      "\n",
      " Epoch 7496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888614654541\n",
      "\n",
      " Epoch 7497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45492792129517\n",
      "\n",
      " Epoch 7498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758295059204\n",
      "\n",
      " Epoch 7499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859861373901\n",
      "\n",
      " Epoch 7500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858526229858\n",
      "\n",
      " Epoch 7501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4548749923706\n",
      "\n",
      " Epoch 7502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841836929321\n",
      "\n",
      " Epoch 7503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915412902832\n",
      "\n",
      " Epoch 7504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881605148315\n",
      "\n",
      " Epoch 7505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995569229126\n",
      "\n",
      " Epoch 7506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882320404053\n",
      "\n",
      " Epoch 7507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820903778076\n",
      "\n",
      " Epoch 7508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879650115967\n",
      "\n",
      " Epoch 7509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580774307251\n",
      "\n",
      " Epoch 7510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892190933228\n",
      "\n",
      " Epoch 7511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811748504639\n",
      "\n",
      " Epoch 7512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586067199707\n",
      "\n",
      " Epoch 7513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635509490967\n",
      "\n",
      " Epoch 7514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813751220703\n",
      "\n",
      " Epoch 7515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852851867676\n",
      "\n",
      " Epoch 7516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45483589172363\n",
      "\n",
      " Epoch 7517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767164230347\n",
      "\n",
      " Epoch 7518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908641815186\n",
      "\n",
      " Epoch 7519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573655128479\n",
      "\n",
      " Epoch 7520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814275741577\n",
      "\n",
      " Epoch 7521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660352706909\n",
      "\n",
      " Epoch 7522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814323425293\n",
      "\n",
      " Epoch 7523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457839012146\n",
      "\n",
      " Epoch 7524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872640609741\n",
      "\n",
      " Epoch 7525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790004730225\n",
      "\n",
      " Epoch 7526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911502838135\n",
      "\n",
      " Epoch 7527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45657253265381\n",
      "\n",
      " Epoch 7528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823287963867\n",
      "\n",
      " Epoch 7529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851421356201\n",
      "\n",
      " Epoch 7530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722103118896\n",
      "\n",
      " Epoch 7531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918607711792\n",
      "\n",
      " Epoch 7532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816898345947\n",
      "\n",
      " Epoch 7533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857906341553\n",
      "\n",
      " Epoch 7534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641946792603\n",
      "\n",
      " Epoch 7535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906734466553\n",
      "\n",
      " Epoch 7536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768928527832\n",
      "\n",
      " Epoch 7537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811653137207\n",
      "\n",
      " Epoch 7538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856094360352\n",
      "\n",
      " Epoch 7539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811414718628\n",
      "\n",
      " Epoch 7540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45647525787354\n",
      "\n",
      " Epoch 7541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808362960815\n",
      "\n",
      " Epoch 7542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750331878662\n",
      "\n",
      " Epoch 7543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913791656494\n",
      "\n",
      " Epoch 7544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827150344849\n",
      "\n",
      " Epoch 7545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732593536377\n",
      "\n",
      " Epoch 7546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592227935791\n",
      "\n",
      " Epoch 7547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824003219604\n",
      "\n",
      " Epoch 7548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879936218262\n",
      "\n",
      " Epoch 7549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631074905396\n",
      "\n",
      " Epoch 7550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919799804688\n",
      "\n",
      " Epoch 7551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777654647827\n",
      "\n",
      " Epoch 7552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809745788574\n",
      "\n",
      " Epoch 7553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873260498047\n",
      "\n",
      " Epoch 7554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819520950317\n",
      "\n",
      " Epoch 7555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45652103424072\n",
      "\n",
      " Epoch 7556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581880569458\n",
      "\n",
      " Epoch 7557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576997756958\n",
      "\n",
      " Epoch 7558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903062820435\n",
      "\n",
      " Epoch 7559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841455459595\n",
      "\n",
      " Epoch 7560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45479011535645\n",
      "\n",
      " Epoch 7561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768785476685\n",
      "\n",
      " Epoch 7562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877838134766\n",
      "\n",
      " Epoch 7563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46011972427368\n",
      "\n",
      " Epoch 7564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894527435303\n",
      "\n",
      " Epoch 7565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861434936523\n",
      "\n",
      " Epoch 7566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926856994629\n",
      "\n",
      " Epoch 7567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864629745483\n",
      "\n",
      " Epoch 7568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756769180298\n",
      "\n",
      " Epoch 7569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582085609436\n",
      "\n",
      " Epoch 7570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45604228973389\n",
      "\n",
      " Epoch 7571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801591873169\n",
      "\n",
      " Epoch 7572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884275436401\n",
      "\n",
      " Epoch 7573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820140838623\n",
      "\n",
      " Epoch 7574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872402191162\n",
      "\n",
      " Epoch 7575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45646715164185\n",
      "\n",
      " Epoch 7576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828342437744\n",
      "\n",
      " Epoch 7577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771312713623\n",
      "\n",
      " Epoch 7578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941019058228\n",
      "\n",
      " Epoch 7579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758628845215\n",
      "\n",
      " Epoch 7580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811557769775\n",
      "\n",
      " Epoch 7581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625734329224\n",
      "\n",
      " Epoch 7582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827198028564\n",
      "\n",
      " Epoch 7583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45786666870117\n",
      "\n",
      " Epoch 7584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871305465698\n",
      "\n",
      " Epoch 7585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740938186646\n",
      "\n",
      " Epoch 7586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648193359375\n",
      "\n",
      " Epoch 7587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824527740479\n",
      "\n",
      " Epoch 7588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773410797119\n",
      "\n",
      " Epoch 7589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908498764038\n",
      "\n",
      " Epoch 7590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577374458313\n",
      "\n",
      " Epoch 7591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885992050171\n",
      "\n",
      " Epoch 7592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567494392395\n",
      "\n",
      " Epoch 7593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905637741089\n",
      "\n",
      " Epoch 7594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780658721924\n",
      "\n",
      " Epoch 7595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812702178955\n",
      "\n",
      " Epoch 7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877456665039\n",
      "\n",
      " Epoch 7597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769834518433\n",
      "\n",
      " Epoch 7598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588942527771\n",
      "\n",
      " Epoch 7599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625495910645\n",
      "\n",
      " Epoch 7600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816135406494\n",
      "\n",
      " Epoch 7601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847034454346\n",
      "\n",
      " Epoch 7602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819759368896\n",
      "\n",
      " Epoch 7603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45672178268433\n",
      "\n",
      " Epoch 7604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889282226562\n",
      "\n",
      " Epoch 7605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565782546997\n",
      "\n",
      " Epoch 7606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810317993164\n",
      "\n",
      " Epoch 7607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842266082764\n",
      "\n",
      " Epoch 7608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574408531189\n",
      "\n",
      " Epoch 7609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902585983276\n",
      "\n",
      " Epoch 7610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46014881134033\n",
      "\n",
      " Epoch 7611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753002166748\n",
      "\n",
      " Epoch 7612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807552337646\n",
      "\n",
      " Epoch 7613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622873306274\n",
      "\n",
      " Epoch 7614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828819274902\n",
      "\n",
      " Epoch 7615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785093307495\n",
      "\n",
      " Epoch 7616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870304107666\n",
      "\n",
      " Epoch 7617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574499130249\n",
      "\n",
      " Epoch 7618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564938545227\n",
      "\n",
      " Epoch 7619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827436447144\n",
      "\n",
      " Epoch 7620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773363113403\n",
      "\n",
      " Epoch 7621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591612815857\n",
      "\n",
      " Epoch 7622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845794677734\n",
      "\n",
      " Epoch 7623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642232894897\n",
      "\n",
      " Epoch 7624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824813842773\n",
      "\n",
      " Epoch 7625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825862884521\n",
      "\n",
      " Epoch 7626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976161956787\n",
      "\n",
      " Epoch 7627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891237258911\n",
      "\n",
      " Epoch 7628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580569267273\n",
      "\n",
      " Epoch 7629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870113372803\n",
      "\n",
      " Epoch 7630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45678043365479\n",
      "\n",
      " Epoch 7631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895767211914\n",
      "\n",
      " Epoch 7632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917701721191\n",
      "\n",
      " Epoch 7633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834445953369\n",
      "\n",
      " Epoch 7634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584288597107\n",
      "\n",
      " Epoch 7635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588212966919\n",
      "\n",
      " Epoch 7636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819997787476\n",
      "\n",
      " Epoch 7637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628833770752\n",
      "\n",
      " Epoch 7638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796966552734\n",
      "\n",
      " Epoch 7639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881843566895\n",
      "\n",
      " Epoch 7640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822381973267\n",
      "\n",
      " Epoch 7641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45602178573608\n",
      "\n",
      " Epoch 7642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843601226807\n",
      "\n",
      " Epoch 7643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579348564148\n",
      "\n",
      " Epoch 7644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854711532593\n",
      "\n",
      " Epoch 7645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626020431519\n",
      "\n",
      " Epoch 7646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911407470703\n",
      "\n",
      " Epoch 7647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577841758728\n",
      "\n",
      " Epoch 7648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806741714478\n",
      "\n",
      " Epoch 7649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873069763184\n",
      "\n",
      " Epoch 7650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787477493286\n",
      "\n",
      " Epoch 7651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586009979248\n",
      "\n",
      " Epoch 7652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588451385498\n",
      "\n",
      " Epoch 7653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792627334595\n",
      "\n",
      " Epoch 7654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458984375\n",
      "\n",
      " Epoch 7655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909357070923\n",
      "\n",
      " Epoch 7656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892143249512\n",
      "\n",
      " Epoch 7657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908880233765\n",
      "\n",
      " Epoch 7658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818042755127\n",
      "\n",
      " Epoch 7659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749092102051\n",
      "\n",
      " Epoch 7660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45527362823486\n",
      "\n",
      " Epoch 7661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833587646484\n",
      "\n",
      " Epoch 7662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789194107056\n",
      "\n",
      " Epoch 7663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880270004272\n",
      "\n",
      " Epoch 7664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994424819946\n",
      "\n",
      " Epoch 7665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903968811035\n",
      "\n",
      " Epoch 7666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770788192749\n",
      "\n",
      " Epoch 7667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908403396606\n",
      "\n",
      " Epoch 7668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751667022705\n",
      "\n",
      " Epoch 7669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45523262023926\n",
      "\n",
      " Epoch 7670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826816558838\n",
      "\n",
      " Epoch 7671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584846496582\n",
      "\n",
      " Epoch 7672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907831192017\n",
      "\n",
      " Epoch 7673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861911773682\n",
      "\n",
      " Epoch 7674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45647287368774\n",
      "\n",
      " Epoch 7675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814800262451\n",
      "\n",
      " Epoch 7676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764064788818\n",
      "\n",
      " Epoch 7677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884990692139\n",
      "\n",
      " Epoch 7678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747947692871\n",
      "\n",
      " Epoch 7679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581151008606\n",
      "\n",
      " Epoch 7680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565019607544\n",
      "\n",
      " Epoch 7681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831441879272\n",
      "\n",
      " Epoch 7682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828056335449\n",
      "\n",
      " Epoch 7683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590253829956\n",
      "\n",
      " Epoch 7684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45785665512085\n",
      "\n",
      " Epoch 7685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880365371704\n",
      "\n",
      " Epoch 7686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45733499526978\n",
      "\n",
      " Epoch 7687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895099639893\n",
      "\n",
      " Epoch 7688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589524269104\n",
      "\n",
      " Epoch 7689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641565322876\n",
      "\n",
      " Epoch 7690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820617675781\n",
      "\n",
      " Epoch 7691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766592025757\n",
      "\n",
      " Epoch 7692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590163230896\n",
      "\n",
      " Epoch 7693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457679271698\n",
      "\n",
      " Epoch 7694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45590925216675\n",
      "\n",
      " Epoch 7695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836114883423\n",
      "\n",
      " Epoch 7696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583511352539\n",
      "\n",
      " Epoch 7697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722723007202\n",
      "\n",
      " Epoch 7698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660543441772\n",
      "\n",
      " Epoch 7699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821857452393\n",
      "\n",
      " Epoch 7700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577226638794\n",
      "\n",
      " Epoch 7701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892286300659\n",
      "\n",
      " Epoch 7702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835733413696\n",
      "\n",
      " Epoch 7703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4548773765564\n",
      "\n",
      " Epoch 7704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 7705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590859413147\n",
      "\n",
      " Epoch 7706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976066589355\n",
      "\n",
      " Epoch 7707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587893486023\n",
      "\n",
      " Epoch 7708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584732055664\n",
      "\n",
      " Epoch 7709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45920181274414\n",
      "\n",
      " Epoch 7710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577465057373\n",
      "\n",
      " Epoch 7711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908784866333\n",
      "\n",
      " Epoch 7712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820569992065\n",
      "\n",
      " Epoch 7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45483732223511\n",
      "\n",
      " Epoch 7714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760679244995\n",
      "\n",
      " Epoch 7715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895862579346\n",
      "\n",
      " Epoch 7716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998048782349\n",
      "\n",
      " Epoch 7717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882511138916\n",
      "\n",
      " Epoch 7718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826196670532\n",
      "\n",
      " Epoch 7719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586935043335\n",
      "\n",
      " Epoch 7720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640325546265\n",
      "\n",
      " Epoch 7721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824766159058\n",
      "\n",
      " Epoch 7722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859146118164\n",
      "\n",
      " Epoch 7723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575982093811\n",
      "\n",
      " Epoch 7724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882034301758\n",
      "\n",
      " Epoch 7725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45727157592773\n",
      "\n",
      " Epoch 7726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629024505615\n",
      "\n",
      " Epoch 7727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845603942871\n",
      "\n",
      " Epoch 7728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600977897644\n",
      "\n",
      " Epoch 7729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851135253906\n",
      "\n",
      " Epoch 7730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808553695679\n",
      "\n",
      " Epoch 7731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873069763184\n",
      "\n",
      " Epoch 7732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815229415894\n",
      "\n",
      " Epoch 7733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45478773117065\n",
      "\n",
      " Epoch 7734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755767822266\n",
      "\n",
      " Epoch 7735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911312103271\n",
      "\n",
      " Epoch 7736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988035202026\n",
      "\n",
      " Epoch 7737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880126953125\n",
      "\n",
      " Epoch 7738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825338363647\n",
      "\n",
      " Epoch 7739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867347717285\n",
      "\n",
      " Epoch 7740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642805099487\n",
      "\n",
      " Epoch 7741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580454826355\n",
      "\n",
      " Epoch 7742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840501785278\n",
      "\n",
      " Epoch 7743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759105682373\n",
      "\n",
      " Epoch 7744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780181884766\n",
      "\n",
      " Epoch 7745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577522277832\n",
      "\n",
      " Epoch 7746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910692214966\n",
      "\n",
      " Epoch 7747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634078979492\n",
      "\n",
      " Epoch 7748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816278457642\n",
      "\n",
      " Epoch 7749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837306976318\n",
      "\n",
      " Epoch 7750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763778686523\n",
      "\n",
      " Epoch 7751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778560638428\n",
      "\n",
      " Epoch 7752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632028579712\n",
      "\n",
      " Epoch 7753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924615859985\n",
      "\n",
      " Epoch 7754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890617370605\n",
      "\n",
      " Epoch 7755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824909210205\n",
      "\n",
      " Epoch 7756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878505706787\n",
      "\n",
      " Epoch 7757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819759368896\n",
      "\n",
      " Epoch 7758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45650291442871\n",
      "\n",
      " Epoch 7759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817184448242\n",
      "\n",
      " Epoch 7760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767402648926\n",
      "\n",
      " Epoch 7761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588394165039\n",
      "\n",
      " Epoch 7762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746278762817\n",
      "\n",
      " Epoch 7763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827627182007\n",
      "\n",
      " Epoch 7764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941305160522\n",
      "\n",
      " Epoch 7765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619058609009\n",
      "\n",
      " Epoch 7766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773077011108\n",
      "\n",
      " Epoch 7767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870780944824\n",
      "\n",
      " Epoch 7768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813751220703\n",
      "\n",
      " Epoch 7769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564905166626\n",
      "\n",
      " Epoch 7770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581823348999\n",
      "\n",
      " Epoch 7771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581789970398\n",
      "\n",
      " Epoch 7772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45724439620972\n",
      "\n",
      " Epoch 7773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45939064025879\n",
      "\n",
      " Epoch 7774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829916000366\n",
      "\n",
      " Epoch 7775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868587493896\n",
      "\n",
      " Epoch 7776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564037322998\n",
      "\n",
      " Epoch 7777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829772949219\n",
      "\n",
      " Epoch 7778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 7779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583330154419\n",
      "\n",
      " Epoch 7780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45473003387451\n",
      "\n",
      " Epoch 7781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764207839966\n",
      "\n",
      " Epoch 7782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459228515625\n",
      "\n",
      " Epoch 7783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834732055664\n",
      "\n",
      " Epoch 7784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573302268982\n",
      "\n",
      " Epoch 7785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593710899353\n",
      "\n",
      " Epoch 7786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878744125366\n",
      "\n",
      " Epoch 7787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662355422974\n",
      "\n",
      " Epoch 7788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824003219604\n",
      "\n",
      " Epoch 7789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770168304443\n",
      "\n",
      " Epoch 7790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892190933228\n",
      "\n",
      " Epoch 7791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995473861694\n",
      "\n",
      " Epoch 7792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743465423584\n",
      "\n",
      " Epoch 7793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807886123657\n",
      "\n",
      " Epoch 7794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.459153175354\n",
      "\n",
      " Epoch 7795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45978260040283\n",
      "\n",
      " Epoch 7796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896100997925\n",
      "\n",
      " Epoch 7797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809602737427\n",
      "\n",
      " Epoch 7798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45617961883545\n",
      "\n",
      " Epoch 7799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823383331299\n",
      "\n",
      " Epoch 7800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768642425537\n",
      "\n",
      " Epoch 7801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 7802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45570278167725\n",
      "\n",
      " Epoch 7803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45714950561523\n",
      "\n",
      " Epoch 7804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764636993408\n",
      "\n",
      " Epoch 7805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908403396606\n",
      "\n",
      " Epoch 7806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45633316040039\n",
      "\n",
      " Epoch 7807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813703536987\n",
      "\n",
      " Epoch 7808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846176147461\n",
      "\n",
      " Epoch 7809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4597225189209\n",
      "\n",
      " Epoch 7810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891046524048\n",
      "\n",
      " Epoch 7811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804691314697\n",
      "\n",
      " Epoch 7812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586386680603\n",
      "\n",
      " Epoch 7813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742321014404\n",
      "\n",
      " Epoch 7814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45531606674194\n",
      "\n",
      " Epoch 7815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835304260254\n",
      "\n",
      " Epoch 7816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457932472229\n",
      "\n",
      " Epoch 7817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874071121216\n",
      "\n",
      " Epoch 7818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574875831604\n",
      "\n",
      " Epoch 7819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564061164856\n",
      "\n",
      " Epoch 7820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919513702393\n",
      "\n",
      " Epoch 7821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889520645142\n",
      "\n",
      " Epoch 7822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825099945068\n",
      "\n",
      " Epoch 7823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877504348755\n",
      "\n",
      " Epoch 7824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625352859497\n",
      "\n",
      " Epoch 7825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825338363647\n",
      "\n",
      " Epoch 7826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823860168457\n",
      "\n",
      " Epoch 7827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775938034058\n",
      "\n",
      " Epoch 7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902824401855\n",
      "\n",
      " Epoch 7829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45736837387085\n",
      "\n",
      " Epoch 7830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930290222168\n",
      "\n",
      " Epoch 7831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586124420166\n",
      "\n",
      " Epoch 7832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754146575928\n",
      "\n",
      " Epoch 7833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887279510498\n",
      "\n",
      " Epoch 7834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930290222168\n",
      "\n",
      " Epoch 7835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813226699829\n",
      "\n",
      " Epoch 7836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45610570907593\n",
      "\n",
      " Epoch 7837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806407928467\n",
      "\n",
      " Epoch 7838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861053466797\n",
      "\n",
      " Epoch 7839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819234848022\n",
      "\n",
      " Epoch 7840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587836265564\n",
      "\n",
      " Epoch 7841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818328857422\n",
      "\n",
      " Epoch 7842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565691947937\n",
      "\n",
      " Epoch 7843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581708908081\n",
      "\n",
      " Epoch 7844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762825012207\n",
      "\n",
      " Epoch 7845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916795730591\n",
      "\n",
      " Epoch 7846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573106765747\n",
      "\n",
      " Epoch 7847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564700126648\n",
      "\n",
      " Epoch 7848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581389427185\n",
      "\n",
      " Epoch 7849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761775970459\n",
      "\n",
      " Epoch 7850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901155471802\n",
      "\n",
      " Epoch 7851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583969116211\n",
      "\n",
      " Epoch 7852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45473957061768\n",
      "\n",
      " Epoch 7853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764493942261\n",
      "\n",
      " Epoch 7854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877313613892\n",
      "\n",
      " Epoch 7855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46012926101685\n",
      "\n",
      " Epoch 7856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589295387268\n",
      "\n",
      " Epoch 7857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862817764282\n",
      "\n",
      " Epoch 7858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631551742554\n",
      "\n",
      " Epoch 7859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823049545288\n",
      "\n",
      " Epoch 7860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814609527588\n",
      "\n",
      " Epoch 7861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 7862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902824401855\n",
      "\n",
      " Epoch 7863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45490312576294\n",
      "\n",
      " Epoch 7864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780038833618\n",
      "\n",
      " Epoch 7865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893239974976\n",
      "\n",
      " Epoch 7866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998334884644\n",
      "\n",
      " Epoch 7867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744466781616\n",
      "\n",
      " Epoch 7868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804214477539\n",
      "\n",
      " Epoch 7869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913362503052\n",
      "\n",
      " Epoch 7870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45978927612305\n",
      "\n",
      " Epoch 7871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894193649292\n",
      "\n",
      " Epoch 7872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580602645874\n",
      "\n",
      " Epoch 7873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869302749634\n",
      "\n",
      " Epoch 7874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753002166748\n",
      "\n",
      " Epoch 7875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590163230896\n",
      "\n",
      " Epoch 7876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916175842285\n",
      "\n",
      " Epoch 7877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853805541992\n",
      "\n",
      " Epoch 7878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45472288131714\n",
      "\n",
      " Epoch 7879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761632919312\n",
      "\n",
      " Epoch 7880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871639251709\n",
      "\n",
      " Epoch 7881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768451690674\n",
      "\n",
      " Epoch 7882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589147567749\n",
      "\n",
      " Epoch 7883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645475387573\n",
      "\n",
      " Epoch 7884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810651779175\n",
      "\n",
      " Epoch 7885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838499069214\n",
      "\n",
      " Epoch 7886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831203460693\n",
      "\n",
      " Epoch 7887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45472574234009\n",
      "\n",
      " Epoch 7888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576907157898\n",
      "\n",
      " Epoch 7889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590334892273\n",
      "\n",
      " Epoch 7890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835018157959\n",
      "\n",
      " Epoch 7891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911693572998\n",
      "\n",
      " Epoch 7892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829391479492\n",
      "\n",
      " Epoch 7893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564881324768\n",
      "\n",
      " Epoch 7894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809841156006\n",
      "\n",
      " Epoch 7895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803213119507\n",
      "\n",
      " Epoch 7896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890855789185\n",
      "\n",
      " Epoch 7897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791101455688\n",
      "\n",
      " Epoch 7898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858955383301\n",
      "\n",
      " Epoch 7899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45627498626709\n",
      "\n",
      " Epoch 7900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810842514038\n",
      "\n",
      " Epoch 7901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849227905273\n",
      "\n",
      " Epoch 7902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726871490479\n",
      "\n",
      " Epoch 7903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916366577148\n",
      "\n",
      " Epoch 7904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807647705078\n",
      "\n",
      " Epoch 7905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871257781982\n",
      "\n",
      " Epoch 7906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750331878662\n",
      "\n",
      " Epoch 7907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902681350708\n",
      "\n",
      " Epoch 7908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45476245880127\n",
      "\n",
      " Epoch 7909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458092212677\n",
      "\n",
      " Epoch 7910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45982027053833\n",
      "\n",
      " Epoch 7911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872402191162\n",
      "\n",
      " Epoch 7912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813798904419\n",
      "\n",
      " Epoch 7913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871448516846\n",
      "\n",
      " Epoch 7914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581208229065\n",
      "\n",
      " Epoch 7915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.456552028656\n",
      "\n",
      " Epoch 7916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815420150757\n",
      "\n",
      " Epoch 7917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767211914062\n",
      "\n",
      " Epoch 7918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902013778687\n",
      "\n",
      " Epoch 7919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573712348938\n",
      "\n",
      " Epoch 7920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45605707168579\n",
      "\n",
      " Epoch 7921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808458328247\n",
      "\n",
      " Epoch 7922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837068557739\n",
      "\n",
      " Epoch 7923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573917388916\n",
      "\n",
      " Epoch 7924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583683013916\n",
      "\n",
      " Epoch 7925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891666412354\n",
      "\n",
      " Epoch 7926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45496892929077\n",
      "\n",
      " Epoch 7927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829343795776\n",
      "\n",
      " Epoch 7928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004343032837\n",
      "\n",
      " Epoch 7929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881795883179\n",
      "\n",
      " Epoch 7930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822429656982\n",
      "\n",
      " Epoch 7931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859861373901\n",
      "\n",
      " Epoch 7932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973920822144\n",
      "\n",
      " Epoch 7933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876455307007\n",
      "\n",
      " Epoch 7934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788812637329\n",
      "\n",
      " Epoch 7935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787620544434\n",
      "\n",
      " Epoch 7936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761728286743\n",
      "\n",
      " Epoch 7937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915269851685\n",
      "\n",
      " Epoch 7938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45613145828247\n",
      "\n",
      " Epoch 7939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816230773926\n",
      "\n",
      " Epoch 7940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 7941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45968723297119\n",
      "\n",
      " Epoch 7942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886087417603\n",
      "\n",
      " Epoch 7943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784902572632\n",
      "\n",
      " Epoch 7944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853281021118\n",
      "\n",
      " Epoch 7945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577407836914\n",
      "\n",
      " Epoch 7946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45530986785889\n",
      "\n",
      " Epoch 7947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838069915771\n",
      "\n",
      " Epoch 7948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579086303711\n",
      "\n",
      " Epoch 7949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874404907227\n",
      "\n",
      " Epoch 7950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748567581177\n",
      "\n",
      " Epoch 7951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632553100586\n",
      "\n",
      " Epoch 7952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825576782227\n",
      "\n",
      " Epoch 7953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772314071655\n",
      "\n",
      " Epoch 7954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940780639648\n",
      "\n",
      " Epoch 7955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869588851929\n",
      "\n",
      " Epoch 7956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823526382446\n",
      "\n",
      " Epoch 7957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876169204712\n",
      "\n",
      " Epoch 7958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45683860778809\n",
      "\n",
      " Epoch 7959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839548110962\n",
      "\n",
      " Epoch 7960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45602941513062\n",
      "\n",
      " Epoch 7961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832347869873\n",
      "\n",
      " Epoch 7962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005630493164\n",
      "\n",
      " Epoch 7963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846223831177\n",
      "\n",
      " Epoch 7964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803928375244\n",
      "\n",
      " Epoch 7965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870876312256\n",
      "\n",
      " Epoch 7966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810604095459\n",
      "\n",
      " Epoch 7967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45476245880127\n",
      "\n",
      " Epoch 7968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754861831665\n",
      "\n",
      " Epoch 7969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871925354004\n",
      "\n",
      " Epoch 7970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46005582809448\n",
      "\n",
      " Epoch 7971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889282226562\n",
      "\n",
      " Epoch 7972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 7973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45623874664307\n",
      "\n",
      " Epoch 7974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821189880371\n",
      "\n",
      " Epoch 7975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767450332642\n",
      "\n",
      " Epoch 7976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908260345459\n",
      "\n",
      " Epoch 7977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45719385147095\n",
      "\n",
      " Epoch 7978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563717842102\n",
      "\n",
      " Epoch 7979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806789398193\n",
      "\n",
      " Epoch 7980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579906463623\n",
      "\n",
      " Epoch 7981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766019821167\n",
      "\n",
      " Epoch 7982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906352996826\n",
      "\n",
      " Epoch 7983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632648468018\n",
      "\n",
      " Epoch 7984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803260803223\n",
      "\n",
      " Epoch 7985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 7986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825242996216\n",
      "\n",
      " Epoch 7987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883178710938\n",
      "\n",
      " Epoch 7988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839405059814\n",
      "\n",
      " Epoch 7989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759439468384\n",
      "\n",
      " Epoch 7990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830249786377\n",
      "\n",
      " Epoch 7991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565634727478\n",
      "\n",
      " Epoch 7992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458167552948\n",
      "\n",
      " Epoch 7993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765018463135\n",
      "\n",
      " Epoch 7994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884323120117\n",
      "\n",
      " Epoch 7995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745801925659\n",
      "\n",
      " Epoch 7996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629453659058\n",
      "\n",
      " Epoch 7997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45915460586548\n",
      "\n",
      " Epoch 7998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885753631592\n",
      "\n",
      " Epoch 7999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819234848022\n",
      "\n",
      " Epoch 8000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874643325806\n",
      "\n",
      " Epoch 8001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813608169556\n",
      "\n",
      " Epoch 8002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648002624512\n",
      "\n",
      " Epoch 8003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811891555786\n",
      "\n",
      " Epoch 8004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756769180298\n",
      "\n",
      " Epoch 8005\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591474533081\n",
      "\n",
      " Epoch 8006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726585388184\n",
      "\n",
      " Epoch 8007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564151763916\n",
      "\n",
      " Epoch 8008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818281173706\n",
      "\n",
      " Epoch 8009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764207839966\n",
      "\n",
      " Epoch 8010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904064178467\n",
      "\n",
      " Epoch 8011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837545394897\n",
      "\n",
      " Epoch 8012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45464515686035\n",
      "\n",
      " Epoch 8013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757150650024\n",
      "\n",
      " Epoch 8014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918655395508\n",
      "\n",
      " Epoch 8015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974254608154\n",
      "\n",
      " Epoch 8016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876884460449\n",
      "\n",
      " Epoch 8017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828247070312\n",
      "\n",
      " Epoch 8018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850610733032\n",
      "\n",
      " Epoch 8019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639896392822\n",
      "\n",
      " Epoch 8020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802736282349\n",
      "\n",
      " Epoch 8021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584231376648\n",
      "\n",
      " Epoch 8022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812845230103\n",
      "\n",
      " Epoch 8023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649099349976\n",
      "\n",
      " Epoch 8024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458909034729\n",
      "\n",
      " Epoch 8025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910596847534\n",
      "\n",
      " Epoch 8026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580225944519\n",
      "\n",
      " Epoch 8027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616245269775\n",
      "\n",
      " Epoch 8028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822334289551\n",
      "\n",
      " Epoch 8029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762777328491\n",
      "\n",
      " Epoch 8030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45604467391968\n",
      "\n",
      " Epoch 8031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579963684082\n",
      "\n",
      " Epoch 8032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868301391602\n",
      "\n",
      " Epoch 8033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 8034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860576629639\n",
      "\n",
      " Epoch 8035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635414123535\n",
      "\n",
      " Epoch 8036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590311050415\n",
      "\n",
      " Epoch 8037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760774612427\n",
      "\n",
      " Epoch 8038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815420150757\n",
      "\n",
      " Epoch 8039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898103713989\n",
      "\n",
      " Epoch 8040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583387374878\n",
      "\n",
      " Epoch 8041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588713645935\n",
      "\n",
      " Epoch 8042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840072631836\n",
      "\n",
      " Epoch 8043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573745727539\n",
      "\n",
      " Epoch 8044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891904830933\n",
      "\n",
      " Epoch 8045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928907394409\n",
      "\n",
      " Epoch 8046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808935165405\n",
      "\n",
      " Epoch 8047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4560718536377\n",
      "\n",
      " Epoch 8048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783472061157\n",
      "\n",
      " Epoch 8049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861864089966\n",
      "\n",
      " Epoch 8050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818710327148\n",
      "\n",
      " Epoch 8051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874881744385\n",
      "\n",
      " Epoch 8052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582028388977\n",
      "\n",
      " Epoch 8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45660400390625\n",
      "\n",
      " Epoch 8054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814895629883\n",
      "\n",
      " Epoch 8055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764207839966\n",
      "\n",
      " Epoch 8056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589900970459\n",
      "\n",
      " Epoch 8057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734548568726\n",
      "\n",
      " Epoch 8058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630407333374\n",
      "\n",
      " Epoch 8059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823192596436\n",
      "\n",
      " Epoch 8060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765972137451\n",
      "\n",
      " Epoch 8061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906782150269\n",
      "\n",
      " Epoch 8062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839834213257\n",
      "\n",
      " Epoch 8063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45465803146362\n",
      "\n",
      " Epoch 8064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759057998657\n",
      "\n",
      " Epoch 8065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918369293213\n",
      "\n",
      " Epoch 8066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975351333618\n",
      "\n",
      " Epoch 8067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882654190063\n",
      "\n",
      " Epoch 8068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857048034668\n",
      "\n",
      " Epoch 8069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675849914551\n",
      "\n",
      " Epoch 8070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583683013916\n",
      "\n",
      " Epoch 8071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45612859725952\n",
      "\n",
      " Epoch 8072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819616317749\n",
      "\n",
      " Epoch 8073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781564712524\n",
      "\n",
      " Epoch 8074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590106010437\n",
      "\n",
      " Epoch 8075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573426246643\n",
      "\n",
      " Epoch 8076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562578201294\n",
      "\n",
      " Epoch 8077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823669433594\n",
      "\n",
      " Epoch 8078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854139328003\n",
      "\n",
      " Epoch 8079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983028411865\n",
      "\n",
      " Epoch 8080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897388458252\n",
      "\n",
      " Epoch 8081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810842514038\n",
      "\n",
      " Epoch 8082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872592926025\n",
      "\n",
      " Epoch 8083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457510471344\n",
      "\n",
      " Epoch 8084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45614528656006\n",
      "\n",
      " Epoch 8085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814228057861\n",
      "\n",
      " Epoch 8086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841264724731\n",
      "\n",
      " Epoch 8087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743322372437\n",
      "\n",
      " Epoch 8088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837688446045\n",
      "\n",
      " Epoch 8089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45595598220825\n",
      "\n",
      " Epoch 8090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829677581787\n",
      "\n",
      " Epoch 8091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002197265625\n",
      "\n",
      " Epoch 8092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851373672485\n",
      "\n",
      " Epoch 8093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581241607666\n",
      "\n",
      " Epoch 8094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585223197937\n",
      "\n",
      " Epoch 8095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765590667725\n",
      "\n",
      " Epoch 8096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590654373169\n",
      "\n",
      " Epoch 8097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45493936538696\n",
      "\n",
      " Epoch 8098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458251953125\n",
      "\n",
      " Epoch 8099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994234085083\n",
      "\n",
      " Epoch 8100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862102508545\n",
      "\n",
      " Epoch 8101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580454826355\n",
      "\n",
      " Epoch 8102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864582061768\n",
      "\n",
      " Epoch 8103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822143554688\n",
      "\n",
      " Epoch 8104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45552396774292\n",
      "\n",
      " Epoch 8105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815467834473\n",
      "\n",
      " Epoch 8106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849704742432\n",
      "\n",
      " Epoch 8107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596815109253\n",
      "\n",
      " Epoch 8108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588770866394\n",
      "\n",
      " Epoch 8109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918130874634\n",
      "\n",
      " Epoch 8110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803737640381\n",
      "\n",
      " Epoch 8111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867729187012\n",
      "\n",
      " Epoch 8112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580078125\n",
      "\n",
      " Epoch 8113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771312713623\n",
      "\n",
      " Epoch 8114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830774307251\n",
      "\n",
      " Epoch 8115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45603942871094\n",
      "\n",
      " Epoch 8116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583330154419\n",
      "\n",
      " Epoch 8117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728397369385\n",
      "\n",
      " Epoch 8118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802021026611\n",
      "\n",
      " Epoch 8119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816707611084\n",
      "\n",
      " Epoch 8120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812606811523\n",
      "\n",
      " Epoch 8121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875358581543\n",
      "\n",
      " Epoch 8122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775651931763\n",
      "\n",
      " Epoch 8123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890522003174\n",
      "\n",
      " Epoch 8124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639753341675\n",
      "\n",
      " Epoch 8125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822429656982\n",
      "\n",
      " Epoch 8126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854330062866\n",
      "\n",
      " Epoch 8127\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582142829895\n",
      "\n",
      " Epoch 8128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903396606445\n",
      "\n",
      " Epoch 8129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916271209717\n",
      "\n",
      " Epoch 8130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853042602539\n",
      "\n",
      " Epoch 8131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775890350342\n",
      "\n",
      " Epoch 8132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 8133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.454843044281\n",
      "\n",
      " Epoch 8134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576940536499\n",
      "\n",
      " Epoch 8135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949935913086\n",
      "\n",
      " Epoch 8136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873832702637\n",
      "\n",
      " Epoch 8137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826005935669\n",
      "\n",
      " Epoch 8138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587721824646\n",
      "\n",
      " Epoch 8139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45570850372314\n",
      "\n",
      " Epoch 8140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722484588623\n",
      "\n",
      " Epoch 8141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773983001709\n",
      "\n",
      " Epoch 8142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911836624146\n",
      "\n",
      " Epoch 8143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914125442505\n",
      "\n",
      " Epoch 8144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45584487915039\n",
      "\n",
      " Epoch 8145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583067893982\n",
      "\n",
      " Epoch 8146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46000385284424\n",
      "\n",
      " Epoch 8147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854616165161\n",
      "\n",
      " Epoch 8148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813751220703\n",
      "\n",
      " Epoch 8149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870637893677\n",
      "\n",
      " Epoch 8150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768737792969\n",
      "\n",
      " Epoch 8151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884466171265\n",
      "\n",
      " Epoch 8152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45496892929077\n",
      "\n",
      " Epoch 8153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777988433838\n",
      "\n",
      " Epoch 8154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589467048645\n",
      "\n",
      " Epoch 8155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834112167358\n",
      "\n",
      " Epoch 8156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663642883301\n",
      "\n",
      " Epoch 8157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898294448853\n",
      "\n",
      " Epoch 8158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45921611785889\n",
      "\n",
      " Epoch 8159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883703231812\n",
      "\n",
      " Epoch 8160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917272567749\n",
      "\n",
      " Epoch 8161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850896835327\n",
      "\n",
      " Epoch 8162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903587341309\n",
      "\n",
      " Epoch 8163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836639404297\n",
      "\n",
      " Epoch 8164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630264282227\n",
      "\n",
      " Epoch 8165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822620391846\n",
      "\n",
      " Epoch 8166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820713043213\n",
      "\n",
      " Epoch 8167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571442604065\n",
      "\n",
      " Epoch 8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930480957031\n",
      "\n",
      " Epoch 8169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851707458496\n",
      "\n",
      " Epoch 8170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644330978394\n",
      "\n",
      " Epoch 8171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811700820923\n",
      "\n",
      " Epoch 8172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760107040405\n",
      "\n",
      " Epoch 8173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589729309082\n",
      "\n",
      " Epoch 8174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762729644775\n",
      "\n",
      " Epoch 8175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45506858825684\n",
      "\n",
      " Epoch 8176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828676223755\n",
      "\n",
      " Epoch 8177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852899551392\n",
      "\n",
      " Epoch 8178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883178710938\n",
      "\n",
      " Epoch 8179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880603790283\n",
      "\n",
      " Epoch 8180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995616912842\n",
      "\n",
      " Epoch 8181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839643478394\n",
      "\n",
      " Epoch 8182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803213119507\n",
      "\n",
      " Epoch 8183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865535736084\n",
      "\n",
      " Epoch 8184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806980133057\n",
      "\n",
      " Epoch 8185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45481252670288\n",
      "\n",
      " Epoch 8186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758104324341\n",
      "\n",
      " Epoch 8187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869779586792\n",
      "\n",
      " Epoch 8188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927953720093\n",
      "\n",
      " Epoch 8189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45604276657104\n",
      "\n",
      " Epoch 8190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835304260254\n",
      "\n",
      " Epoch 8191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793437957764\n",
      "\n",
      " Epoch 8192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858192443848\n",
      "\n",
      " Epoch 8193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575605392456\n",
      "\n",
      " Epoch 8194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45989561080933\n",
      "\n",
      " Epoch 8195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878219604492\n",
      "\n",
      " Epoch 8196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816946029663\n",
      "\n",
      " Epoch 8197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875263214111\n",
      "\n",
      " Epoch 8198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45564413070679\n",
      "\n",
      " Epoch 8199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766639709473\n",
      "\n",
      " Epoch 8200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854425430298\n",
      "\n",
      " Epoch 8201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629787445068\n",
      "\n",
      " Epoch 8202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580774307251\n",
      "\n",
      " Epoch 8203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809745788574\n",
      "\n",
      " Epoch 8204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45714855194092\n",
      "\n",
      " Epoch 8205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910930633545\n",
      "\n",
      " Epoch 8206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812559127808\n",
      "\n",
      " Epoch 8207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869970321655\n",
      "\n",
      " Epoch 8208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754480361938\n",
      "\n",
      " Epoch 8209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899629592896\n",
      "\n",
      " Epoch 8210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45494651794434\n",
      "\n",
      " Epoch 8211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771312713623\n",
      "\n",
      " Epoch 8212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45955085754395\n",
      "\n",
      " Epoch 8213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878553390503\n",
      "\n",
      " Epoch 8214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46030139923096\n",
      "\n",
      " Epoch 8215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895385742188\n",
      "\n",
      " Epoch 8216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807886123657\n",
      "\n",
      " Epoch 8217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872688293457\n",
      "\n",
      " Epoch 8218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45731735229492\n",
      "\n",
      " Epoch 8219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45530986785889\n",
      "\n",
      " Epoch 8220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822477340698\n",
      "\n",
      " Epoch 8221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771265029907\n",
      "\n",
      " Epoch 8222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866870880127\n",
      "\n",
      " Epoch 8223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642709732056\n",
      "\n",
      " Epoch 8224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826196670532\n",
      "\n",
      " Epoch 8225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863580703735\n",
      "\n",
      " Epoch 8226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583158493042\n",
      "\n",
      " Epoch 8227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45637273788452\n",
      "\n",
      " Epoch 8228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827865600586\n",
      "\n",
      " Epoch 8229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582371711731\n",
      "\n",
      " Epoch 8230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45460367202759\n",
      "\n",
      " Epoch 8231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830869674683\n",
      "\n",
      " Epoch 8232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46001625061035\n",
      "\n",
      " Epoch 8233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879983901978\n",
      "\n",
      " Epoch 8234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45928525924683\n",
      "\n",
      " Epoch 8235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814657211304\n",
      "\n",
      " Epoch 8236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851039886475\n",
      "\n",
      " Epoch 8237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758199691772\n",
      "\n",
      " Epoch 8238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750379562378\n",
      "\n",
      " Epoch 8239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823907852173\n",
      "\n",
      " Epoch 8240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45607328414917\n",
      "\n",
      " Epoch 8241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840692520142\n",
      "\n",
      " Epoch 8242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993852615356\n",
      "\n",
      " Epoch 8243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859003067017\n",
      "\n",
      " Epoch 8244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798778533936\n",
      "\n",
      " Epoch 8245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864772796631\n",
      "\n",
      " Epoch 8246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803499221802\n",
      "\n",
      " Epoch 8247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4547381401062\n",
      "\n",
      " Epoch 8248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749235153198\n",
      "\n",
      " Epoch 8249\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907688140869\n",
      "\n",
      " Epoch 8250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840835571289\n",
      "\n",
      " Epoch 8251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45649719238281\n",
      "\n",
      " Epoch 8252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828580856323\n",
      "\n",
      " Epoch 8253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770025253296\n",
      "\n",
      " Epoch 8254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905828475952\n",
      "\n",
      " Epoch 8255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45738124847412\n",
      "\n",
      " Epoch 8256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580945968628\n",
      "\n",
      " Epoch 8257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917272567749\n",
      "\n",
      " Epoch 8258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820140838623\n",
      "\n",
      " Epoch 8259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891380310059\n",
      "\n",
      " Epoch 8260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934581756592\n",
      "\n",
      " Epoch 8261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856285095215\n",
      "\n",
      " Epoch 8262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45474004745483\n",
      "\n",
      " Epoch 8263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761823654175\n",
      "\n",
      " Epoch 8264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45958662033081\n",
      "\n",
      " Epoch 8265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588451385498\n",
      "\n",
      " Epoch 8266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593391418457\n",
      "\n",
      " Epoch 8267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819234848022\n",
      "\n",
      " Epoch 8268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 8269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901727676392\n",
      "\n",
      " Epoch 8270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662498474121\n",
      "\n",
      " Epoch 8271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896816253662\n",
      "\n",
      " Epoch 8272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45666456222534\n",
      "\n",
      " Epoch 8273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812606811523\n",
      "\n",
      " Epoch 8274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584641456604\n",
      "\n",
      " Epoch 8275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832920074463\n",
      "\n",
      " Epoch 8276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641326904297\n",
      "\n",
      " Epoch 8277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822763442993\n",
      "\n",
      " Epoch 8278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821189880371\n",
      "\n",
      " Epoch 8279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45970249176025\n",
      "\n",
      " Epoch 8280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887422561646\n",
      "\n",
      " Epoch 8281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805549621582\n",
      "\n",
      " Epoch 8282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865535736084\n",
      "\n",
      " Epoch 8283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45673513412476\n",
      "\n",
      " Epoch 8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879220962524\n",
      "\n",
      " Epoch 8285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648765563965\n",
      "\n",
      " Epoch 8286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812177658081\n",
      "\n",
      " Epoch 8287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810031890869\n",
      "\n",
      " Epoch 8288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45776891708374\n",
      "\n",
      " Epoch 8289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590311050415\n",
      "\n",
      " Epoch 8290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45735549926758\n",
      "\n",
      " Epoch 8291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45637464523315\n",
      "\n",
      " Epoch 8292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820426940918\n",
      "\n",
      " Epoch 8293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763969421387\n",
      "\n",
      " Epoch 8294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908832550049\n",
      "\n",
      " Epoch 8295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823287963867\n",
      "\n",
      " Epoch 8296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45476341247559\n",
      "\n",
      " Epoch 8297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576768875122\n",
      "\n",
      " Epoch 8298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879220962524\n",
      "\n",
      " Epoch 8299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639228820801\n",
      "\n",
      " Epoch 8300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905828475952\n",
      "\n",
      " Epoch 8301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872592926025\n",
      "\n",
      " Epoch 8302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822238922119\n",
      "\n",
      " Epoch 8303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876789093018\n",
      "\n",
      " Epoch 8304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826959609985\n",
      "\n",
      " Epoch 8305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45466804504395\n",
      "\n",
      " Epoch 8306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576005935669\n",
      "\n",
      " Epoch 8307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901203155518\n",
      "\n",
      " Epoch 8308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983409881592\n",
      "\n",
      " Epoch 8309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878076553345\n",
      "\n",
      " Epoch 8310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949268341064\n",
      "\n",
      " Epoch 8311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796585083008\n",
      "\n",
      " Epoch 8312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45951843261719\n",
      "\n",
      " Epoch 8313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45774555206299\n",
      "\n",
      " Epoch 8314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805215835571\n",
      "\n",
      " Epoch 8315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586853981018\n",
      "\n",
      " Epoch 8316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4556884765625\n",
      "\n",
      " Epoch 8317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 8318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862483978271\n",
      "\n",
      " Epoch 8319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763063430786\n",
      "\n",
      " Epoch 8320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903062820435\n",
      "\n",
      " Epoch 8321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45480251312256\n",
      "\n",
      " Epoch 8322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576964378357\n",
      "\n",
      " Epoch 8323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45592832565308\n",
      "\n",
      " Epoch 8324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908641815186\n",
      "\n",
      " Epoch 8325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769214630127\n",
      "\n",
      " Epoch 8326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809936523438\n",
      "\n",
      " Epoch 8327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875883102417\n",
      "\n",
      " Epoch 8328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45617151260376\n",
      "\n",
      " Epoch 8329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919370651245\n",
      "\n",
      " Epoch 8330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885992050171\n",
      "\n",
      " Epoch 8331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812797546387\n",
      "\n",
      " Epoch 8332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872688293457\n",
      "\n",
      " Epoch 8333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807456970215\n",
      "\n",
      " Epoch 8334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642137527466\n",
      "\n",
      " Epoch 8335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806217193604\n",
      "\n",
      " Epoch 8336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811080932617\n",
      "\n",
      " Epoch 8337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962285995483\n",
      "\n",
      " Epoch 8338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880603790283\n",
      "\n",
      " Epoch 8339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797872543335\n",
      "\n",
      " Epoch 8340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899391174316\n",
      "\n",
      " Epoch 8341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728778839111\n",
      "\n",
      " Epoch 8342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588565826416\n",
      "\n",
      " Epoch 8343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813751220703\n",
      "\n",
      " Epoch 8344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870113372803\n",
      "\n",
      " Epoch 8345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972919464111\n",
      "\n",
      " Epoch 8346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892572402954\n",
      "\n",
      " Epoch 8347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784854888916\n",
      "\n",
      " Epoch 8348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853185653687\n",
      "\n",
      " Epoch 8349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777130126953\n",
      "\n",
      " Epoch 8350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45516777038574\n",
      "\n",
      " Epoch 8351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830726623535\n",
      "\n",
      " Epoch 8352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578309059143\n",
      "\n",
      " Epoch 8353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880794525146\n",
      "\n",
      " Epoch 8354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726490020752\n",
      "\n",
      " Epoch 8355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640993118286\n",
      "\n",
      " Epoch 8356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583067893982\n",
      "\n",
      " Epoch 8357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778465270996\n",
      "\n",
      " Epoch 8358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856380462646\n",
      "\n",
      " Epoch 8359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45566892623901\n",
      "\n",
      " Epoch 8360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830488204956\n",
      "\n",
      " Epoch 8361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998334884644\n",
      "\n",
      " Epoch 8362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851182937622\n",
      "\n",
      " Epoch 8363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812702178955\n",
      "\n",
      " Epoch 8364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867872238159\n",
      "\n",
      " Epoch 8365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805406570435\n",
      "\n",
      " Epoch 8366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640659332275\n",
      "\n",
      " Epoch 8367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808935165405\n",
      "\n",
      " Epoch 8368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763111114502\n",
      "\n",
      " Epoch 8369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898151397705\n",
      "\n",
      " Epoch 8370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734548568726\n",
      "\n",
      " Epoch 8371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804786682129\n",
      "\n",
      " Epoch 8372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916843414307\n",
      "\n",
      " Epoch 8373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841407775879\n",
      "\n",
      " Epoch 8374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616960525513\n",
      "\n",
      " Epoch 8375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582576751709\n",
      "\n",
      " Epoch 8376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993995666504\n",
      "\n",
      " Epoch 8377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732927322388\n",
      "\n",
      " Epoch 8378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812749862671\n",
      "\n",
      " Epoch 8379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848846435547\n",
      "\n",
      " Epoch 8380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589409828186\n",
      "\n",
      " Epoch 8381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853090286255\n",
      "\n",
      " Epoch 8382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772361755371\n",
      "\n",
      " Epoch 8383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883798599243\n",
      "\n",
      " Epoch 8384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909929275513\n",
      "\n",
      " Epoch 8385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859479904175\n",
      "\n",
      " Epoch 8386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45481443405151\n",
      "\n",
      " Epoch 8387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744705200195\n",
      "\n",
      " Epoch 8388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864391326904\n",
      "\n",
      " Epoch 8389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775365829468\n",
      "\n",
      " Epoch 8390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900440216064\n",
      "\n",
      " Epoch 8391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832252502441\n",
      "\n",
      " Epoch 8392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625448226929\n",
      "\n",
      " Epoch 8393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823001861572\n",
      "\n",
      " Epoch 8394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585108757019\n",
      "\n",
      " Epoch 8395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574728012085\n",
      "\n",
      " Epoch 8396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789670944214\n",
      "\n",
      " Epoch 8397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630931854248\n",
      "\n",
      " Epoch 8398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916748046875\n",
      "\n",
      " Epoch 8399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883893966675\n",
      "\n",
      " Epoch 8400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818185806274\n",
      "\n",
      " Epoch 8401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587287902832\n",
      "\n",
      " Epoch 8402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761394500732\n",
      "\n",
      " Epoch 8403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45611715316772\n",
      "\n",
      " Epoch 8404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582166671753\n",
      "\n",
      " Epoch 8405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45995616912842\n",
      "\n",
      " Epoch 8406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734167098999\n",
      "\n",
      " Epoch 8407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795059204102\n",
      "\n",
      " Epoch 8408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862245559692\n",
      "\n",
      " Epoch 8409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780181884766\n",
      "\n",
      " Epoch 8410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866441726685\n",
      "\n",
      " Epoch 8411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639371871948\n",
      "\n",
      " Epoch 8412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815753936768\n",
      "\n",
      " Epoch 8413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842838287354\n",
      "\n",
      " Epoch 8414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581618309021\n",
      "\n",
      " Epoch 8415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45479536056519\n",
      "\n",
      " Epoch 8416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752334594727\n",
      "\n",
      " Epoch 8417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911598205566\n",
      "\n",
      " Epoch 8418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823669433594\n",
      "\n",
      " Epoch 8419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648288726807\n",
      "\n",
      " Epoch 8420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832824707031\n",
      "\n",
      " Epoch 8421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769357681274\n",
      "\n",
      " Epoch 8422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911073684692\n",
      "\n",
      " Epoch 8423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722913742065\n",
      "\n",
      " Epoch 8424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561276435852\n",
      "\n",
      " Epoch 8425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807361602783\n",
      "\n",
      " Epoch 8426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583158493042\n",
      "\n",
      " Epoch 8427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827341079712\n",
      "\n",
      " Epoch 8428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824003219604\n",
      "\n",
      " Epoch 8429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807456970215\n",
      "\n",
      " Epoch 8430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869588851929\n",
      "\n",
      " Epoch 8431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997524261475\n",
      "\n",
      " Epoch 8432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588360786438\n",
      "\n",
      " Epoch 8433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845365524292\n",
      "\n",
      " Epoch 8434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896482467651\n",
      "\n",
      " Epoch 8435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779466629028\n",
      "\n",
      " Epoch 8436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889377593994\n",
      "\n",
      " Epoch 8437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576416015625\n",
      "\n",
      " Epoch 8438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622634887695\n",
      "\n",
      " Epoch 8439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45703601837158\n",
      "\n",
      " Epoch 8440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759057998657\n",
      "\n",
      " Epoch 8441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590220451355\n",
      "\n",
      " Epoch 8442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830821990967\n",
      "\n",
      " Epoch 8443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641994476318\n",
      "\n",
      " Epoch 8444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45830631256104\n",
      "\n",
      " Epoch 8445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766115188599\n",
      "\n",
      " Epoch 8446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904397964478\n",
      "\n",
      " Epoch 8447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573564529419\n",
      "\n",
      " Epoch 8448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812273025513\n",
      "\n",
      " Epoch 8449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45659065246582\n",
      "\n",
      " Epoch 8450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811891555786\n",
      "\n",
      " Epoch 8451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753192901611\n",
      "\n",
      " Epoch 8452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913982391357\n",
      "\n",
      " Epoch 8453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45617389678955\n",
      "\n",
      " Epoch 8454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816993713379\n",
      "\n",
      " Epoch 8455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847225189209\n",
      "\n",
      " Epoch 8456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816135406494\n",
      "\n",
      " Epoch 8457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572491645813\n",
      "\n",
      " Epoch 8458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45944023132324\n",
      "\n",
      " Epoch 8459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855760574341\n",
      "\n",
      " Epoch 8460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45646142959595\n",
      "\n",
      " Epoch 8461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815753936768\n",
      "\n",
      " Epoch 8462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764493942261\n",
      "\n",
      " Epoch 8463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901346206665\n",
      "\n",
      " Epoch 8464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573106765747\n",
      "\n",
      " Epoch 8465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904922485352\n",
      "\n",
      " Epoch 8466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819807052612\n",
      "\n",
      " Epoch 8467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860481262207\n",
      "\n",
      " Epoch 8468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561357498169\n",
      "\n",
      " Epoch 8469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912075042725\n",
      "\n",
      " Epoch 8470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775842666626\n",
      "\n",
      " Epoch 8471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795726776123\n",
      "\n",
      " Epoch 8472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863819122314\n",
      "\n",
      " Epoch 8473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803737640381\n",
      "\n",
      " Epoch 8474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632648468018\n",
      "\n",
      " Epoch 8475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812940597534\n",
      "\n",
      " Epoch 8476\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45763969421387\n",
      "\n",
      " Epoch 8477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897579193115\n",
      "\n",
      " Epoch 8478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825672149658\n",
      "\n",
      " Epoch 8479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875835418701\n",
      "\n",
      " Epoch 8480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792818069458\n",
      "\n",
      " Epoch 8481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585690498352\n",
      "\n",
      " Epoch 8482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632886886597\n",
      "\n",
      " Epoch 8483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891094207764\n",
      "\n",
      " Epoch 8484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765256881714\n",
      "\n",
      " Epoch 8485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798921585083\n",
      "\n",
      " Epoch 8486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862770080566\n",
      "\n",
      " Epoch 8487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810222625732\n",
      "\n",
      " Epoch 8488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645523071289\n",
      "\n",
      " Epoch 8489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808696746826\n",
      "\n",
      " Epoch 8490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755863189697\n",
      "\n",
      " Epoch 8491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894813537598\n",
      "\n",
      " Epoch 8492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45729160308838\n",
      "\n",
      " Epoch 8493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561972618103\n",
      "\n",
      " Epoch 8494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910310745239\n",
      "\n",
      " Epoch 8495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878314971924\n",
      "\n",
      " Epoch 8496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812654495239\n",
      "\n",
      " Epoch 8497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867872238159\n",
      "\n",
      " Epoch 8498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803546905518\n",
      "\n",
      " Epoch 8499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642566680908\n",
      "\n",
      " Epoch 8500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809030532837\n",
      "\n",
      " Epoch 8501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752716064453\n",
      "\n",
      " Epoch 8502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911598205566\n",
      "\n",
      " Epoch 8503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722961425781\n",
      "\n",
      " Epoch 8504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815229415894\n",
      "\n",
      " Epoch 8505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810604095459\n",
      "\n",
      " Epoch 8506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809173583984\n",
      "\n",
      " Epoch 8507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586935043335\n",
      "\n",
      " Epoch 8508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761919021606\n",
      "\n",
      " Epoch 8509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904207229614\n",
      "\n",
      " Epoch 8510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635795593262\n",
      "\n",
      " Epoch 8511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816898345947\n",
      "\n",
      " Epoch 8512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849418640137\n",
      "\n",
      " Epoch 8513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815515518188\n",
      "\n",
      " Epoch 8514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899438858032\n",
      "\n",
      " Epoch 8515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580979347229\n",
      "\n",
      " Epoch 8516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45525646209717\n",
      "\n",
      " Epoch 8517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834875106812\n",
      "\n",
      " Epoch 8518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866060256958\n",
      "\n",
      " Epoch 8519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561357498169\n",
      "\n",
      " Epoch 8520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582257270813\n",
      "\n",
      " Epoch 8521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845699310303\n",
      "\n",
      " Epoch 8522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751094818115\n",
      "\n",
      " Epoch 8523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768594741821\n",
      "\n",
      " Epoch 8524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827674865723\n",
      "\n",
      " Epoch 8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663642883301\n",
      "\n",
      " Epoch 8526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806741714478\n",
      "\n",
      " Epoch 8527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840120315552\n",
      "\n",
      " Epoch 8528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810031890869\n",
      "\n",
      " Epoch 8529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911836624146\n",
      "\n",
      " Epoch 8530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581127166748\n",
      "\n",
      " Epoch 8531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778894424438\n",
      "\n",
      " Epoch 8532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766258239746\n",
      "\n",
      " Epoch 8533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904874801636\n",
      "\n",
      " Epoch 8534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634698867798\n",
      "\n",
      " Epoch 8535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581446647644\n",
      "\n",
      " Epoch 8536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841217041016\n",
      "\n",
      " Epoch 8537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583010673523\n",
      "\n",
      " Epoch 8538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638084411621\n",
      "\n",
      " Epoch 8539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827388763428\n",
      "\n",
      " Epoch 8540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825672149658\n",
      "\n",
      " Epoch 8541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974254608154\n",
      "\n",
      " Epoch 8542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889186859131\n",
      "\n",
      " Epoch 8543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803308486938\n",
      "\n",
      " Epoch 8544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866632461548\n",
      "\n",
      " Epoch 8545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567322731018\n",
      "\n",
      " Epoch 8546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878410339355\n",
      "\n",
      " Epoch 8547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648241043091\n",
      "\n",
      " Epoch 8548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810270309448\n",
      "\n",
      " Epoch 8549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458083152771\n",
      "\n",
      " Epoch 8550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773983001709\n",
      "\n",
      " Epoch 8551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902395248413\n",
      "\n",
      " Epoch 8552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573450088501\n",
      "\n",
      " Epoch 8553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563341140747\n",
      "\n",
      " Epoch 8554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905303955078\n",
      "\n",
      " Epoch 8555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877313613892\n",
      "\n",
      " Epoch 8556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813608169556\n",
      "\n",
      " Epoch 8557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587049484253\n",
      "\n",
      " Epoch 8558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45618963241577\n",
      "\n",
      " Epoch 8559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817756652832\n",
      "\n",
      " Epoch 8560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816802978516\n",
      "\n",
      " Epoch 8561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760774612427\n",
      "\n",
      " Epoch 8562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591417312622\n",
      "\n",
      " Epoch 8563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45479822158813\n",
      "\n",
      " Epoch 8564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765972137451\n",
      "\n",
      " Epoch 8565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886945724487\n",
      "\n",
      " Epoch 8566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743083953857\n",
      "\n",
      " Epoch 8567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811986923218\n",
      "\n",
      " Epoch 8568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655918121338\n",
      "\n",
      " Epoch 8569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816850662231\n",
      "\n",
      " Epoch 8570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759153366089\n",
      "\n",
      " Epoch 8571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916080474854\n",
      "\n",
      " Epoch 8572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45615196228027\n",
      "\n",
      " Epoch 8573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810842514038\n",
      "\n",
      " Epoch 8574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458411693573\n",
      "\n",
      " Epoch 8575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811223983765\n",
      "\n",
      " Epoch 8576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893716812134\n",
      "\n",
      " Epoch 8577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787239074707\n",
      "\n",
      " Epoch 8578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854806900024\n",
      "\n",
      " Epoch 8579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45624446868896\n",
      "\n",
      " Epoch 8580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802783966064\n",
      "\n",
      " Epoch 8581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586238861084\n",
      "\n",
      " Epoch 8582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45731210708618\n",
      "\n",
      " Epoch 8583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45930099487305\n",
      "\n",
      " Epoch 8584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798587799072\n",
      "\n",
      " Epoch 8585\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869493484497\n",
      "\n",
      " Epoch 8586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803880691528\n",
      "\n",
      " Epoch 8587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640277862549\n",
      "\n",
      " Epoch 8588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810031890869\n",
      "\n",
      " Epoch 8589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458083152771\n",
      "\n",
      " Epoch 8590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715999603271\n",
      "\n",
      " Epoch 8591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45934820175171\n",
      "\n",
      " Epoch 8592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582371711731\n",
      "\n",
      " Epoch 8593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862579345703\n",
      "\n",
      " Epoch 8594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638036727905\n",
      "\n",
      " Epoch 8595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807409286499\n",
      "\n",
      " Epoch 8596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833253860474\n",
      "\n",
      " Epoch 8597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827913284302\n",
      "\n",
      " Epoch 8598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45464611053467\n",
      "\n",
      " Epoch 8599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757389068604\n",
      "\n",
      " Epoch 8600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591646194458\n",
      "\n",
      " Epoch 8601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582724571228\n",
      "\n",
      " Epoch 8602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45727586746216\n",
      "\n",
      " Epoch 8603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594497680664\n",
      "\n",
      " Epoch 8604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857906341553\n",
      "\n",
      " Epoch 8605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656681060791\n",
      "\n",
      " Epoch 8606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813465118408\n",
      "\n",
      " Epoch 8607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762491226196\n",
      "\n",
      " Epoch 8608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900297164917\n",
      "\n",
      " Epoch 8609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835542678833\n",
      "\n",
      " Epoch 8610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45473623275757\n",
      "\n",
      " Epoch 8611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762729644775\n",
      "\n",
      " Epoch 8612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918226242065\n",
      "\n",
      " Epoch 8613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45974254608154\n",
      "\n",
      " Epoch 8614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876979827881\n",
      "\n",
      " Epoch 8615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826768875122\n",
      "\n",
      " Epoch 8616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849847793579\n",
      "\n",
      " Epoch 8617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641422271729\n",
      "\n",
      " Epoch 8618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801973342896\n",
      "\n",
      " Epoch 8619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842838287354\n",
      "\n",
      " Epoch 8620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573884010315\n",
      "\n",
      " Epoch 8621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784950256348\n",
      "\n",
      " Epoch 8622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561676979065\n",
      "\n",
      " Epoch 8623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899868011475\n",
      "\n",
      " Epoch 8624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871162414551\n",
      "\n",
      " Epoch 8625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804405212402\n",
      "\n",
      " Epoch 8626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860385894775\n",
      "\n",
      " Epoch 8627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822763442993\n",
      "\n",
      " Epoch 8628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630264282227\n",
      "\n",
      " Epoch 8629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827531814575\n",
      "\n",
      " Epoch 8630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771312713623\n",
      "\n",
      " Epoch 8631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909547805786\n",
      "\n",
      " Epoch 8632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45720958709717\n",
      "\n",
      " Epoch 8633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634841918945\n",
      "\n",
      " Epoch 8634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805025100708\n",
      "\n",
      " Epoch 8635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839214324951\n",
      "\n",
      " Epoch 8636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572525024414\n",
      "\n",
      " Epoch 8637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889091491699\n",
      "\n",
      " Epoch 8638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888471603394\n",
      "\n",
      " Epoch 8639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588508605957\n",
      "\n",
      " Epoch 8640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836973190308\n",
      "\n",
      " Epoch 8641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893049240112\n",
      "\n",
      " Epoch 8642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580488204956\n",
      "\n",
      " Epoch 8643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867347717285\n",
      "\n",
      " Epoch 8644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796155929565\n",
      "\n",
      " Epoch 8645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638847351074\n",
      "\n",
      " Epoch 8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803642272949\n",
      "\n",
      " Epoch 8647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802307128906\n",
      "\n",
      " Epoch 8648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45711183547974\n",
      "\n",
      " Epoch 8649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4592981338501\n",
      "\n",
      " Epoch 8650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585337638855\n",
      "\n",
      " Epoch 8651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644044876099\n",
      "\n",
      " Epoch 8652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811176300049\n",
      "\n",
      " Epoch 8653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575743675232\n",
      "\n",
      " Epoch 8654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901489257812\n",
      "\n",
      " Epoch 8655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45712995529175\n",
      "\n",
      " Epoch 8656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904588699341\n",
      "\n",
      " Epoch 8657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825672149658\n",
      "\n",
      " Epoch 8658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858478546143\n",
      "\n",
      " Epoch 8659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751571655273\n",
      "\n",
      " Epoch 8660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622730255127\n",
      "\n",
      " Epoch 8661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582200050354\n",
      "\n",
      " Epoch 8662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996475219727\n",
      "\n",
      " Epoch 8663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838260650635\n",
      "\n",
      " Epoch 8664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580135345459\n",
      "\n",
      " Epoch 8665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865297317505\n",
      "\n",
      " Epoch 8666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808029174805\n",
      "\n",
      " Epoch 8667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45476579666138\n",
      "\n",
      " Epoch 8668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747661590576\n",
      "\n",
      " Epoch 8669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893144607544\n",
      "\n",
      " Epoch 8670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760107040405\n",
      "\n",
      " Epoch 8671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4551191329956\n",
      "\n",
      " Epoch 8672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583330154419\n",
      "\n",
      " Epoch 8673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855951309204\n",
      "\n",
      " Epoch 8674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45615148544312\n",
      "\n",
      " Epoch 8675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815753936768\n",
      "\n",
      " Epoch 8676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584321975708\n",
      "\n",
      " Epoch 8677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812797546387\n",
      "\n",
      " Epoch 8678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910024642944\n",
      "\n",
      " Epoch 8679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810651779175\n",
      "\n",
      " Epoch 8680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854377746582\n",
      "\n",
      " Epoch 8681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45627737045288\n",
      "\n",
      " Epoch 8682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815229415894\n",
      "\n",
      " Epoch 8683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845365524292\n",
      "\n",
      " Epoch 8684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819807052612\n",
      "\n",
      " Epoch 8685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45462656021118\n",
      "\n",
      " Epoch 8686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751953125\n",
      "\n",
      " Epoch 8687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911836624146\n",
      "\n",
      " Epoch 8688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45967435836792\n",
      "\n",
      " Epoch 8689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587550163269\n",
      "\n",
      " Epoch 8690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824241638184\n",
      "\n",
      " Epoch 8691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772933959961\n",
      "\n",
      " Epoch 8692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764303207397\n",
      "\n",
      " Epoch 8693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589672088623\n",
      "\n",
      " Epoch 8694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620727539062\n",
      "\n",
      " Epoch 8695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822811126709\n",
      "\n",
      " Epoch 8696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851135253906\n",
      "\n",
      " Epoch 8697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823192596436\n",
      "\n",
      " Epoch 8698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883178710938\n",
      "\n",
      " Epoch 8699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842790603638\n",
      "\n",
      " Epoch 8700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797348022461\n",
      "\n",
      " Epoch 8701\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859813690186\n",
      "\n",
      " Epoch 8702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911455154419\n",
      "\n",
      " Epoch 8703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800876617432\n",
      "\n",
      " Epoch 8704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867109298706\n",
      "\n",
      " Epoch 8705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807695388794\n",
      "\n",
      " Epoch 8706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45648097991943\n",
      "\n",
      " Epoch 8707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808219909668\n",
      "\n",
      " Epoch 8708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749044418335\n",
      "\n",
      " Epoch 8709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892095565796\n",
      "\n",
      " Epoch 8710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734071731567\n",
      "\n",
      " Epoch 8711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636701583862\n",
      "\n",
      " Epoch 8712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808696746826\n",
      "\n",
      " Epoch 8713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755386352539\n",
      "\n",
      " Epoch 8714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877361297607\n",
      "\n",
      " Epoch 8715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844078063965\n",
      "\n",
      " Epoch 8716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45467519760132\n",
      "\n",
      " Epoch 8717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758771896362\n",
      "\n",
      " Epoch 8718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4594407081604\n",
      "\n",
      " Epoch 8719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870923995972\n",
      "\n",
      " Epoch 8720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45936727523804\n",
      "\n",
      " Epoch 8721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847225189209\n",
      "\n",
      " Epoch 8722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669841766357\n",
      "\n",
      " Epoch 8723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587779045105\n",
      "\n",
      " Epoch 8724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45994663238525\n",
      "\n",
      " Epoch 8725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881366729736\n",
      "\n",
      " Epoch 8726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816469192505\n",
      "\n",
      " Epoch 8727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873355865479\n",
      "\n",
      " Epoch 8728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45562744140625\n",
      "\n",
      " Epoch 8729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767164230347\n",
      "\n",
      " Epoch 8730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855712890625\n",
      "\n",
      " Epoch 8731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625925064087\n",
      "\n",
      " Epoch 8732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893812179565\n",
      "\n",
      " Epoch 8733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754671096802\n",
      "\n",
      " Epoch 8734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807456970215\n",
      "\n",
      " Epoch 8735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458505153656\n",
      "\n",
      " Epoch 8736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819282531738\n",
      "\n",
      " Epoch 8737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45675754547119\n",
      "\n",
      " Epoch 8738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894622802734\n",
      "\n",
      " Epoch 8739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911931991577\n",
      "\n",
      " Epoch 8740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581847190857\n",
      "\n",
      " Epoch 8741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45606660842896\n",
      "\n",
      " Epoch 8742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819997787476\n",
      "\n",
      " Epoch 8743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850372314453\n",
      "\n",
      " Epoch 8744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596209526062\n",
      "\n",
      " Epoch 8745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45739459991455\n",
      "\n",
      " Epoch 8746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823287963867\n",
      "\n",
      " Epoch 8747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45585870742798\n",
      "\n",
      " Epoch 8748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825290679932\n",
      "\n",
      " Epoch 8749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775985717773\n",
      "\n",
      " Epoch 8750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878648757935\n",
      "\n",
      " Epoch 8751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457266330719\n",
      "\n",
      " Epoch 8752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562349319458\n",
      "\n",
      " Epoch 8753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822381973267\n",
      "\n",
      " Epoch 8754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767974853516\n",
      "\n",
      " Epoch 8755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864534378052\n",
      "\n",
      " Epoch 8756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45784521102905\n",
      "\n",
      " Epoch 8757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 8758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651483535767\n",
      "\n",
      " Epoch 8759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816802978516\n",
      "\n",
      " Epoch 8760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845603942871\n",
      "\n",
      " Epoch 8761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817756652832\n",
      "\n",
      " Epoch 8762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988893508911\n",
      "\n",
      " Epoch 8763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875310897827\n",
      "\n",
      " Epoch 8764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809268951416\n",
      "\n",
      " Epoch 8765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868921279907\n",
      "\n",
      " Epoch 8766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45676803588867\n",
      "\n",
      " Epoch 8767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827054977417\n",
      "\n",
      " Epoch 8768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45599222183228\n",
      "\n",
      " Epoch 8769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901346206665\n",
      "\n",
      " Epoch 8770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578185081482\n",
      "\n",
      " Epoch 8771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800638198853\n",
      "\n",
      " Epoch 8772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586501121521\n",
      "\n",
      " Epoch 8773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825958251953\n",
      "\n",
      " Epoch 8774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45544290542603\n",
      "\n",
      " Epoch 8775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809745788574\n",
      "\n",
      " Epoch 8776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584584236145\n",
      "\n",
      " Epoch 8777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598708152771\n",
      "\n",
      " Epoch 8778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895004272461\n",
      "\n",
      " Epoch 8779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812892913818\n",
      "\n",
      " Epoch 8780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868158340454\n",
      "\n",
      " Epoch 8781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45727252960205\n",
      "\n",
      " Epoch 8782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817756652832\n",
      "\n",
      " Epoch 8783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45608329772949\n",
      "\n",
      " Epoch 8784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458083152771\n",
      "\n",
      " Epoch 8785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772933959961\n",
      "\n",
      " Epoch 8786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887327194214\n",
      "\n",
      " Epoch 8787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732402801514\n",
      "\n",
      " Epoch 8788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622062683105\n",
      "\n",
      " Epoch 8789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818042755127\n",
      "\n",
      " Epoch 8790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846748352051\n",
      "\n",
      " Epoch 8791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975494384766\n",
      "\n",
      " Epoch 8792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891857147217\n",
      "\n",
      " Epoch 8793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806550979614\n",
      "\n",
      " Epoch 8794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865869522095\n",
      "\n",
      " Epoch 8795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798635482788\n",
      "\n",
      " Epoch 8796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642805099487\n",
      "\n",
      " Epoch 8797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803833007812\n",
      "\n",
      " Epoch 8798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580307006836\n",
      "\n",
      " Epoch 8799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892906188965\n",
      "\n",
      " Epoch 8800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45779132843018\n",
      "\n",
      " Epoch 8801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577841758728\n",
      "\n",
      " Epoch 8802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767641067505\n",
      "\n",
      " Epoch 8803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901489257812\n",
      "\n",
      " Epoch 8804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625972747803\n",
      "\n",
      " Epoch 8805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802545547485\n",
      "\n",
      " Epoch 8806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831537246704\n",
      "\n",
      " Epoch 8807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821523666382\n",
      "\n",
      " Epoch 8808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629644393921\n",
      "\n",
      " Epoch 8809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582200050354\n",
      "\n",
      " Epoch 8810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581995010376\n",
      "\n",
      " Epoch 8811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4570951461792\n",
      "\n",
      " Epoch 8812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45926284790039\n",
      "\n",
      " Epoch 8813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844984054565\n",
      "\n",
      " Epoch 8814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639657974243\n",
      "\n",
      " Epoch 8815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805406570435\n",
      "\n",
      " Epoch 8816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575366973877\n",
      "\n",
      " Epoch 8817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893478393555\n",
      "\n",
      " Epoch 8818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757341384888\n",
      "\n",
      " Epoch 8819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771837234497\n",
      "\n",
      " Epoch 8820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756244659424\n",
      "\n",
      " Epoch 8821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919990539551\n",
      "\n",
      " Epoch 8822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626544952393\n",
      "\n",
      " Epoch 8823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815467834473\n",
      "\n",
      " Epoch 8824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845317840576\n",
      "\n",
      " Epoch 8825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814561843872\n",
      "\n",
      " Epoch 8826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898389816284\n",
      "\n",
      " Epoch 8827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790576934814\n",
      "\n",
      " Epoch 8828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45604753494263\n",
      "\n",
      " Epoch 8829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847702026367\n",
      "\n",
      " Epoch 8830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45719051361084\n",
      "\n",
      " Epoch 8831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817422866821\n",
      "\n",
      " Epoch 8832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45551252365112\n",
      "\n",
      " Epoch 8833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808601379395\n",
      "\n",
      " Epoch 8834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578366279602\n",
      "\n",
      " Epoch 8835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878648757935\n",
      "\n",
      " Epoch 8836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004009246826\n",
      "\n",
      " Epoch 8837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846128463745\n",
      "\n",
      " Epoch 8838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803022384644\n",
      "\n",
      " Epoch 8839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864486694336\n",
      "\n",
      " Epoch 8840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803594589233\n",
      "\n",
      " Epoch 8841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45636177062988\n",
      "\n",
      " Epoch 8842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804405212402\n",
      "\n",
      " Epoch 8843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751953125\n",
      "\n",
      " Epoch 8844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909023284912\n",
      "\n",
      " Epoch 8845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45726108551025\n",
      "\n",
      " Epoch 8846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620489120483\n",
      "\n",
      " Epoch 8847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590425491333\n",
      "\n",
      " Epoch 8848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875978469849\n",
      "\n",
      " Epoch 8849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808172225952\n",
      "\n",
      " Epoch 8850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862054824829\n",
      "\n",
      " Epoch 8851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817232131958\n",
      "\n",
      " Epoch 8852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45678758621216\n",
      "\n",
      " Epoch 8853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834302902222\n",
      "\n",
      " Epoch 8854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609092712402\n",
      "\n",
      " Epoch 8855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583387374878\n",
      "\n",
      " Epoch 8856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46008968353271\n",
      "\n",
      " Epoch 8857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852947235107\n",
      "\n",
      " Epoch 8858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580283164978\n",
      "\n",
      " Epoch 8859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868730545044\n",
      "\n",
      " Epoch 8860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45769596099854\n",
      "\n",
      " Epoch 8861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886468887329\n",
      "\n",
      " Epoch 8862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45480394363403\n",
      "\n",
      " Epoch 8863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827960968018\n",
      "\n",
      " Epoch 8864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4600076675415\n",
      "\n",
      " Epoch 8865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860242843628\n",
      "\n",
      " Epoch 8866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817184448242\n",
      "\n",
      " Epoch 8867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45592069625854\n",
      "\n",
      " Epoch 8868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582896232605\n",
      "\n",
      " Epoch 8869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781087875366\n",
      "\n",
      " Epoch 8870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835542678833\n",
      "\n",
      " Epoch 8871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748233795166\n",
      "\n",
      " Epoch 8872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561505317688\n",
      "\n",
      " Epoch 8873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821809768677\n",
      "\n",
      " Epoch 8874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846891403198\n",
      "\n",
      " Epoch 8875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45979595184326\n",
      "\n",
      " Epoch 8876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587197303772\n",
      "\n",
      " Epoch 8877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808696746826\n",
      "\n",
      " Epoch 8878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867443084717\n",
      "\n",
      " Epoch 8879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567346572876\n",
      "\n",
      " Epoch 8880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894813537598\n",
      "\n",
      " Epoch 8881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642042160034\n",
      "\n",
      " Epoch 8882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814275741577\n",
      "\n",
      " Epoch 8883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840787887573\n",
      "\n",
      " Epoch 8884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741987228394\n",
      "\n",
      " Epoch 8885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780181884766\n",
      "\n",
      " Epoch 8886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750713348389\n",
      "\n",
      " Epoch 8887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622110366821\n",
      "\n",
      " Epoch 8888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582314491272\n",
      "\n",
      " Epoch 8889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46004009246826\n",
      "\n",
      " Epoch 8890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844078063965\n",
      "\n",
      " Epoch 8891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793914794922\n",
      "\n",
      " Epoch 8892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865535736084\n",
      "\n",
      " Epoch 8893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574990272522\n",
      "\n",
      " Epoch 8894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896673202515\n",
      "\n",
      " Epoch 8895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45484972000122\n",
      "\n",
      " Epoch 8896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816087722778\n",
      "\n",
      " Epoch 8897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991516113281\n",
      "\n",
      " Epoch 8898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878839492798\n",
      "\n",
      " Epoch 8899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815801620483\n",
      "\n",
      " Epoch 8900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870018005371\n",
      "\n",
      " Epoch 8901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45625400543213\n",
      "\n",
      " Epoch 8902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805644989014\n",
      "\n",
      " Epoch 8903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580488204956\n",
      "\n",
      " Epoch 8904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765399932861\n",
      "\n",
      " Epoch 8905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903635025024\n",
      "\n",
      " Epoch 8906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45733213424683\n",
      "\n",
      " Epoch 8907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901107788086\n",
      "\n",
      " Epoch 8908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851993560791\n",
      "\n",
      " Epoch 8909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639944076538\n",
      "\n",
      " Epoch 8910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580750465393\n",
      "\n",
      " Epoch 8911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839595794678\n",
      "\n",
      " Epoch 8912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741271972656\n",
      "\n",
      " Epoch 8913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782995223999\n",
      "\n",
      " Epoch 8914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752620697021\n",
      "\n",
      " Epoch 8915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911264419556\n",
      "\n",
      " Epoch 8916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619058609009\n",
      "\n",
      " Epoch 8917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817232131958\n",
      "\n",
      " Epoch 8918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847177505493\n",
      "\n",
      " Epoch 8919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973825454712\n",
      "\n",
      " Epoch 8920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890855789185\n",
      "\n",
      " Epoch 8921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801830291748\n",
      "\n",
      " Epoch 8922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45610809326172\n",
      "\n",
      " Epoch 8923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45718193054199\n",
      "\n",
      " Epoch 8924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581389427185\n",
      "\n",
      " Epoch 8925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897960662842\n",
      "\n",
      " Epoch 8926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579849243164\n",
      "\n",
      " Epoch 8927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862197875977\n",
      "\n",
      " Epoch 8928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988321304321\n",
      "\n",
      " Epoch 8929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741510391235\n",
      "\n",
      " Epoch 8930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820808410645\n",
      "\n",
      " Epoch 8931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45583295822144\n",
      "\n",
      " Epoch 8932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822763442993\n",
      "\n",
      " Epoch 8933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457754611969\n",
      "\n",
      " Epoch 8934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876741409302\n",
      "\n",
      " Epoch 8935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45725536346436\n",
      "\n",
      " Epoch 8936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619821548462\n",
      "\n",
      " Epoch 8937\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907354354858\n",
      "\n",
      " Epoch 8938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878076553345\n",
      "\n",
      " Epoch 8939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813846588135\n",
      "\n",
      " Epoch 8940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866584777832\n",
      "\n",
      " Epoch 8941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45730018615723\n",
      "\n",
      " Epoch 8942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827054977417\n",
      "\n",
      " Epoch 8943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45590877532959\n",
      "\n",
      " Epoch 8944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823955535889\n",
      "\n",
      " Epoch 8945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852613449097\n",
      "\n",
      " Epoch 8946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45721387863159\n",
      "\n",
      " Epoch 8947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631074905396\n",
      "\n",
      " Epoch 8948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811939239502\n",
      "\n",
      " Epoch 8949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761394500732\n",
      "\n",
      " Epoch 8950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898103713989\n",
      "\n",
      " Epoch 8951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582667350769\n",
      "\n",
      " Epoch 8952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632314682007\n",
      "\n",
      " Epoch 8953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825672149658\n",
      "\n",
      " Epoch 8954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759010314941\n",
      "\n",
      " Epoch 8955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922040939331\n",
      "\n",
      " Epoch 8956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574966430664\n",
      "\n",
      " Epoch 8957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45673131942749\n",
      "\n",
      " Epoch 8958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732355117798\n",
      "\n",
      " Epoch 8959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847129821777\n",
      "\n",
      " Epoch 8960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45988607406616\n",
      "\n",
      " Epoch 8961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45739412307739\n",
      "\n",
      " Epoch 8962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581823348999\n",
      "\n",
      " Epoch 8963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831775665283\n",
      "\n",
      " Epoch 8964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775985717773\n",
      "\n",
      " Epoch 8965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886135101318\n",
      "\n",
      " Epoch 8966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622873306274\n",
      "\n",
      " Epoch 8967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579758644104\n",
      "\n",
      " Epoch 8968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582633972168\n",
      "\n",
      " Epoch 8969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458176612854\n",
      "\n",
      " Epoch 8970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891094207764\n",
      "\n",
      " Epoch 8971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815753936768\n",
      "\n",
      " Epoch 8972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768356323242\n",
      "\n",
      " Epoch 8973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809745788574\n",
      "\n",
      " Epoch 8974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45645046234131\n",
      "\n",
      " Epoch 8975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809125900269\n",
      "\n",
      " Epoch 8976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758867263794\n",
      "\n",
      " Epoch 8977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589319229126\n",
      "\n",
      " Epoch 8978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831203460693\n",
      "\n",
      " Epoch 8979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45468521118164\n",
      "\n",
      " Epoch 8980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757102966309\n",
      "\n",
      " Epoch 8981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869970321655\n",
      "\n",
      " Epoch 8982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46002578735352\n",
      "\n",
      " Epoch 8983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884943008423\n",
      "\n",
      " Epoch 8984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854043960571\n",
      "\n",
      " Epoch 8985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45618534088135\n",
      "\n",
      " Epoch 8986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816612243652\n",
      "\n",
      " Epoch 8987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762014389038\n",
      "\n",
      " Epoch 8988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902395248413\n",
      "\n",
      " Epoch 8989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45714092254639\n",
      "\n",
      " Epoch 8990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629692077637\n",
      "\n",
      " Epoch 8991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888662338257\n",
      "\n",
      " Epoch 8992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585485458374\n",
      "\n",
      " Epoch 8993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810794830322\n",
      "\n",
      " Epoch 8994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45867538452148\n",
      "\n",
      " Epoch 8995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762777328491\n",
      "\n",
      " Epoch 8996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898914337158\n",
      "\n",
      " Epoch 8997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45731973648071\n",
      "\n",
      " Epoch 8998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900869369507\n",
      "\n",
      " Epoch 8999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819854736328\n",
      "\n",
      " Epoch 9000\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45855808258057\n",
      "\n",
      " Epoch 9001\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45613479614258\n",
      "\n",
      " Epoch 9002\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902299880981\n",
      "\n",
      " Epoch 9003\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766639709473\n",
      "\n",
      " Epoch 9004\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792818069458\n",
      "\n",
      " Epoch 9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586410522461\n",
      "\n",
      " Epoch 9006\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804738998413\n",
      "\n",
      " Epoch 9007\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638418197632\n",
      "\n",
      " Epoch 9008\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807123184204\n",
      "\n",
      " Epoch 9009\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750522613525\n",
      "\n",
      " Epoch 9010\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908498764038\n",
      "\n",
      " Epoch 9011\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823335647583\n",
      "\n",
      " Epoch 9012\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45481824874878\n",
      "\n",
      " Epoch 9013\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753240585327\n",
      "\n",
      " Epoch 9014\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906925201416\n",
      "\n",
      " Epoch 9015\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841217041016\n",
      "\n",
      " Epoch 9016\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897769927979\n",
      "\n",
      " Epoch 9017\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824003219604\n",
      "\n",
      " Epoch 9018\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804023742676\n",
      "\n",
      " Epoch 9019\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799827575684\n",
      "\n",
      " Epoch 9020\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866012573242\n",
      "\n",
      " Epoch 9021\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809602737427\n",
      "\n",
      " Epoch 9022\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45651721954346\n",
      "\n",
      " Epoch 9023\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814800262451\n",
      "\n",
      " Epoch 9024\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755910873413\n",
      "\n",
      " Epoch 9025\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913314819336\n",
      "\n",
      " Epoch 9026\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826435089111\n",
      "\n",
      " Epoch 9027\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45476341247559\n",
      "\n",
      " Epoch 9028\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457510471344\n",
      "\n",
      " Epoch 9029\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588975906372\n",
      "\n",
      " Epoch 9030\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993757247925\n",
      "\n",
      " Epoch 9031\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868873596191\n",
      "\n",
      " Epoch 9032\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816373825073\n",
      "\n",
      " Epoch 9033\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858669281006\n",
      "\n",
      " Epoch 9034\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45633506774902\n",
      "\n",
      " Epoch 9035\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579668045044\n",
      "\n",
      " Epoch 9036\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836305618286\n",
      "\n",
      " Epoch 9037\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751523971558\n",
      "\n",
      " Epoch 9038\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773315429688\n",
      "\n",
      " Epoch 9039\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768356323242\n",
      "\n",
      " Epoch 9040\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904111862183\n",
      "\n",
      " Epoch 9041\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631504058838\n",
      "\n",
      " Epoch 9042\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808744430542\n",
      "\n",
      " Epoch 9043\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832300186157\n",
      "\n",
      " Epoch 9044\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983028411865\n",
      "\n",
      " Epoch 9045\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874643325806\n",
      "\n",
      " Epoch 9046\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809125900269\n",
      "\n",
      " Epoch 9047\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850896835327\n",
      "\n",
      " Epoch 9048\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805978775024\n",
      "\n",
      " Epoch 9049\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45464134216309\n",
      "\n",
      " Epoch 9050\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759534835815\n",
      "\n",
      " Epoch 9051\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912837982178\n",
      "\n",
      " Epoch 9052\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45614576339722\n",
      "\n",
      " Epoch 9053\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819425582886\n",
      "\n",
      " Epoch 9054\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844268798828\n",
      "\n",
      " Epoch 9055\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813369750977\n",
      "\n",
      " Epoch 9056\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893335342407\n",
      "\n",
      " Epoch 9057\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578800201416\n",
      "\n",
      " Epoch 9058\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577865600586\n",
      "\n",
      " Epoch 9059\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765447616577\n",
      "\n",
      " Epoch 9060\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899677276611\n",
      "\n",
      " Epoch 9061\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628929138184\n",
      "\n",
      " Epoch 9062\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801591873169\n",
      "\n",
      " Epoch 9063\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829820632935\n",
      "\n",
      " Epoch 9064\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821714401245\n",
      "\n",
      " Epoch 9065\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629453659058\n",
      "\n",
      " Epoch 9066\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820188522339\n",
      "\n",
      " Epoch 9067\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818758010864\n",
      "\n",
      " Epoch 9068\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4570984840393\n",
      "\n",
      " Epoch 9069\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45949840545654\n",
      "\n",
      " Epoch 9070\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832920074463\n",
      "\n",
      " Epoch 9071\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631551742554\n",
      "\n",
      " Epoch 9072\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580078125\n",
      "\n",
      " Epoch 9073\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802402496338\n",
      "\n",
      " Epoch 9074\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768165588379\n",
      "\n",
      " Epoch 9075\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901250839233\n",
      "\n",
      " Epoch 9076\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572868347168\n",
      "\n",
      " Epoch 9077\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927858352661\n",
      "\n",
      " Epoch 9078\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859432220459\n",
      "\n",
      " Epoch 9079\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752620697021\n",
      "\n",
      " Epoch 9080\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827674865723\n",
      "\n",
      " Epoch 9081\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45615339279175\n",
      "\n",
      " Epoch 9082\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823001861572\n",
      "\n",
      " Epoch 9083\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599838256836\n",
      "\n",
      " Epoch 9084\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45737743377686\n",
      "\n",
      " Epoch 9085\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864152908325\n",
      "\n",
      " Epoch 9086\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912027359009\n",
      "\n",
      " Epoch 9087\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793581008911\n",
      "\n",
      " Epoch 9088\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866346359253\n",
      "\n",
      " Epoch 9089\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804595947266\n",
      "\n",
      " Epoch 9090\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45639848709106\n",
      "\n",
      " Epoch 9091\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803451538086\n",
      "\n",
      " Epoch 9092\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800828933716\n",
      "\n",
      " Epoch 9093\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45973110198975\n",
      "\n",
      " Epoch 9094\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865631103516\n",
      "\n",
      " Epoch 9095\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458083152771\n",
      "\n",
      " Epoch 9096\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849561691284\n",
      "\n",
      " Epoch 9097\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630025863647\n",
      "\n",
      " Epoch 9098\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803546905518\n",
      "\n",
      " Epoch 9099\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802354812622\n",
      "\n",
      " Epoch 9100\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45452451705933\n",
      "\n",
      " Epoch 9101\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748519897461\n",
      "\n",
      " Epoch 9102\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906209945679\n",
      "\n",
      " Epoch 9103\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810508728027\n",
      "\n",
      " Epoch 9104\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893430709839\n",
      "\n",
      " Epoch 9105\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803737640381\n",
      "\n",
      " Epoch 9106\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577283859253\n",
      "\n",
      " Epoch 9107\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575924873352\n",
      "\n",
      " Epoch 9108\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897579193115\n",
      "\n",
      " Epoch 9109\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562520980835\n",
      "\n",
      " Epoch 9110\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799160003662\n",
      "\n",
      " Epoch 9111\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828485488892\n",
      "\n",
      " Epoch 9112\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819044113159\n",
      "\n",
      " Epoch 9113\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45626735687256\n",
      "\n",
      " Epoch 9114\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458251953125\n",
      "\n",
      " Epoch 9115\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575777053833\n",
      "\n",
      " Epoch 9116\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860719680786\n",
      "\n",
      " Epoch 9117\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747232437134\n",
      "\n",
      " Epoch 9118\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814895629883\n",
      "\n",
      " Epoch 9119\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917987823486\n",
      "\n",
      " Epoch 9120\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588041305542\n",
      "\n",
      " Epoch 9121\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897150039673\n",
      "\n",
      " Epoch 9122\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820045471191\n",
      "\n",
      " Epoch 9123\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.455069065094\n",
      "\n",
      " Epoch 9124\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828676223755\n",
      "\n",
      " Epoch 9125\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862150192261\n",
      "\n",
      " Epoch 9126\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609283447266\n",
      "\n",
      " Epoch 9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807218551636\n",
      "\n",
      " Epoch 9128\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834589004517\n",
      "\n",
      " Epoch 9129\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810079574585\n",
      "\n",
      " Epoch 9130\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45664072036743\n",
      "\n",
      " Epoch 9131\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873880386353\n",
      "\n",
      " Epoch 9132\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918035507202\n",
      "\n",
      " Epoch 9133\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873355865479\n",
      "\n",
      " Epoch 9134\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590482711792\n",
      "\n",
      " Epoch 9135\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798921585083\n",
      "\n",
      " Epoch 9136\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45593404769897\n",
      "\n",
      " Epoch 9137\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827102661133\n",
      "\n",
      " Epoch 9138\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860052108765\n",
      "\n",
      " Epoch 9139\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741128921509\n",
      "\n",
      " Epoch 9140\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45614004135132\n",
      "\n",
      " Epoch 9141\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814752578735\n",
      "\n",
      " Epoch 9142\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842504501343\n",
      "\n",
      " Epoch 9143\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748615264893\n",
      "\n",
      " Epoch 9144\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888900756836\n",
      "\n",
      " Epoch 9145\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901012420654\n",
      "\n",
      " Epoch 9146\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814752578735\n",
      "\n",
      " Epoch 9147\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4560136795044\n",
      "\n",
      " Epoch 9148\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580283164978\n",
      "\n",
      " Epoch 9149\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876121520996\n",
      "\n",
      " Epoch 9150\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808267593384\n",
      "\n",
      " Epoch 9151\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866060256958\n",
      "\n",
      " Epoch 9152\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616436004639\n",
      "\n",
      " Epoch 9153\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913362503052\n",
      "\n",
      " Epoch 9154\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457688331604\n",
      "\n",
      " Epoch 9155\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800065994263\n",
      "\n",
      " Epoch 9156\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861053466797\n",
      "\n",
      " Epoch 9157\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581069946289\n",
      "\n",
      " Epoch 9158\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45641994476318\n",
      "\n",
      " Epoch 9159\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807075500488\n",
      "\n",
      " Epoch 9160\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754337310791\n",
      "\n",
      " Epoch 9161\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876026153564\n",
      "\n",
      " Epoch 9162\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583969116211\n",
      "\n",
      " Epoch 9163\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45464992523193\n",
      "\n",
      " Epoch 9164\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575457572937\n",
      "\n",
      " Epoch 9165\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589672088623\n",
      "\n",
      " Epoch 9166\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583477973938\n",
      "\n",
      " Epoch 9167\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903778076172\n",
      "\n",
      " Epoch 9168\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45831489562988\n",
      "\n",
      " Epoch 9169\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901536941528\n",
      "\n",
      " Epoch 9170\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45773887634277\n",
      "\n",
      " Epoch 9171\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576563835144\n",
      "\n",
      " Epoch 9172\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589958190918\n",
      "\n",
      " Epoch 9173\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907640457153\n",
      "\n",
      " Epoch 9174\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813322067261\n",
      "\n",
      " Epoch 9175\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574146270752\n",
      "\n",
      " Epoch 9176\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887565612793\n",
      "\n",
      " Epoch 9177\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897674560547\n",
      "\n",
      " Epoch 9178\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581298828125\n",
      "\n",
      " Epoch 9179\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609045028687\n",
      "\n",
      " Epoch 9180\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804643630981\n",
      "\n",
      " Epoch 9181\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880937576294\n",
      "\n",
      " Epoch 9182\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810985565186\n",
      "\n",
      " Epoch 9183\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586935043335\n",
      "\n",
      " Epoch 9184\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562349319458\n",
      "\n",
      " Epoch 9185\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914459228516\n",
      "\n",
      " Epoch 9186\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770740509033\n",
      "\n",
      " Epoch 9187\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800876617432\n",
      "\n",
      " Epoch 9188\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586329460144\n",
      "\n",
      " Epoch 9189\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809984207153\n",
      "\n",
      " Epoch 9190\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45640087127686\n",
      "\n",
      " Epoch 9191\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809412002563\n",
      "\n",
      " Epoch 9192\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457594871521\n",
      "\n",
      " Epoch 9193\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893049240112\n",
      "\n",
      " Epoch 9194\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758867263794\n",
      "\n",
      " Epoch 9195\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45501804351807\n",
      "\n",
      " Epoch 9196\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823669433594\n",
      "\n",
      " Epoch 9197\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848512649536\n",
      "\n",
      " Epoch 9198\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45975351333618\n",
      "\n",
      " Epoch 9199\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877599716187\n",
      "\n",
      " Epoch 9200\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851373672485\n",
      "\n",
      " Epoch 9201\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917081832886\n",
      "\n",
      " Epoch 9202\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837450027466\n",
      "\n",
      " Epoch 9203\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573860168457\n",
      "\n",
      " Epoch 9204\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45526170730591\n",
      "\n",
      " Epoch 9205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817375183105\n",
      "\n",
      " Epoch 9206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576678276062\n",
      "\n",
      " Epoch 9207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45862436294556\n",
      "\n",
      " Epoch 9208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635223388672\n",
      "\n",
      " Epoch 9209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813465118408\n",
      "\n",
      " Epoch 9210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850801467896\n",
      "\n",
      " Epoch 9211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821809768677\n",
      "\n",
      " Epoch 9212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45794439315796\n",
      "\n",
      " Epoch 9213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813989639282\n",
      "\n",
      " Epoch 9214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584732055664\n",
      "\n",
      " Epoch 9215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770645141602\n",
      "\n",
      " Epoch 9216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861339569092\n",
      "\n",
      " Epoch 9217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564733505249\n",
      "\n",
      " Epoch 9218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580397605896\n",
      "\n",
      " Epoch 9219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839357376099\n",
      "\n",
      " Epoch 9220\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810174942017\n",
      "\n",
      " Epoch 9221\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891857147217\n",
      "\n",
      " Epoch 9222\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919609069824\n",
      "\n",
      " Epoch 9223\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826864242554\n",
      "\n",
      " Epoch 9224\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834302902222\n",
      "\n",
      " Epoch 9225\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859336853027\n",
      "\n",
      " Epoch 9226\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45496273040771\n",
      "\n",
      " Epoch 9227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458176612854\n",
      "\n",
      " Epoch 9228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781993865967\n",
      "\n",
      " Epoch 9229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872449874878\n",
      "\n",
      " Epoch 9230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45918798446655\n",
      "\n",
      " Epoch 9231\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824527740479\n",
      "\n",
      " Epoch 9232\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759153366089\n",
      "\n",
      " Epoch 9233\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586730003357\n",
      "\n",
      " Epoch 9234\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45474624633789\n",
      "\n",
      " Epoch 9235\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457594871521\n",
      "\n",
      " Epoch 9236\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45941925048828\n",
      "\n",
      " Epoch 9237\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874071121216\n",
      "\n",
      " Epoch 9238\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923376083374\n",
      "\n",
      " Epoch 9239\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582290649414\n",
      "\n",
      " Epoch 9240\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873403549194\n",
      "\n",
      " Epoch 9241\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45782899856567\n",
      "\n",
      " Epoch 9242\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852375030518\n",
      "\n",
      " Epoch 9243\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45778131484985\n",
      "\n",
      " Epoch 9244\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882415771484\n",
      "\n",
      " Epoch 9245\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45487880706787\n",
      "\n",
      " Epoch 9246\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750379562378\n",
      "\n",
      " Epoch 9247\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853614807129\n",
      "\n",
      " Epoch 9248\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745849609375\n",
      "\n",
      " Epoch 9249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762014389038\n",
      "\n",
      " Epoch 9250\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45898389816284\n",
      "\n",
      " Epoch 9251\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45655679702759\n",
      "\n",
      " Epoch 9252\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818614959717\n",
      "\n",
      " Epoch 9253\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841455459595\n",
      "\n",
      " Epoch 9254\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742797851562\n",
      "\n",
      " Epoch 9255\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780992507935\n",
      "\n",
      " Epoch 9256\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45617723464966\n",
      "\n",
      " Epoch 9257\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906066894531\n",
      "\n",
      " Epoch 9258\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877838134766\n",
      "\n",
      " Epoch 9259\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45834064483643\n",
      "\n",
      " Epoch 9260\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890712738037\n",
      "\n",
      " Epoch 9261\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580807685852\n",
      "\n",
      " Epoch 9262\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4559383392334\n",
      "\n",
      " Epoch 9263\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811223983765\n",
      "\n",
      " Epoch 9264\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840120315552\n",
      "\n",
      " Epoch 9265\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620155334473\n",
      "\n",
      " Epoch 9266\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801115036011\n",
      "\n",
      " Epoch 9267\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835304260254\n",
      "\n",
      " Epoch 9268\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45705461502075\n",
      "\n",
      " Epoch 9269\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45912218093872\n",
      "\n",
      " Epoch 9270\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792245864868\n",
      "\n",
      " Epoch 9271\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585280418396\n",
      "\n",
      " Epoch 9272\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813179016113\n",
      "\n",
      " Epoch 9273\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630884170532\n",
      "\n",
      " Epoch 9274\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819854736328\n",
      "\n",
      " Epoch 9275\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761299133301\n",
      "\n",
      " Epoch 9276\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45903253555298\n",
      "\n",
      " Epoch 9277\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715141296387\n",
      "\n",
      " Epoch 9278\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630359649658\n",
      "\n",
      " Epoch 9279\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887422561646\n",
      "\n",
      " Epoch 9280\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857810974121\n",
      "\n",
      " Epoch 9281\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809650421143\n",
      "\n",
      " Epoch 9282\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865869522095\n",
      "\n",
      " Epoch 9283\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576210975647\n",
      "\n",
      " Epoch 9284\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897197723389\n",
      "\n",
      " Epoch 9285\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45483589172363\n",
      "\n",
      " Epoch 9286\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576678276062\n",
      "\n",
      " Epoch 9287\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588394165039\n",
      "\n",
      " Epoch 9288\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845937728882\n",
      "\n",
      " Epoch 9289\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45713567733765\n",
      "\n",
      " Epoch 9290\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643281936646\n",
      "\n",
      " Epoch 9291\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810842514038\n",
      "\n",
      " Epoch 9292\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575366973877\n",
      "\n",
      " Epoch 9293\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919275283813\n",
      "\n",
      " Epoch 9294\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45687294006348\n",
      "\n",
      " Epoch 9295\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747756958008\n",
      "\n",
      " Epoch 9296\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856380462646\n",
      "\n",
      " Epoch 9297\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580888748169\n",
      "\n",
      " Epoch 9298\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45983648300171\n",
      "\n",
      " Epoch 9299\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869302749634\n",
      "\n",
      " Epoch 9300\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804738998413\n",
      "\n",
      " Epoch 9301\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458655834198\n",
      "\n",
      " Epoch 9302\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4567494392395\n",
      "\n",
      " Epoch 9303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896005630493\n",
      "\n",
      " Epoch 9304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913791656494\n",
      "\n",
      " Epoch 9305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866823196411\n",
      "\n",
      " Epoch 9306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45733499526978\n",
      "\n",
      " Epoch 9307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45624780654907\n",
      "\n",
      " Epoch 9308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815086364746\n",
      "\n",
      " Epoch 9309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818376541138\n",
      "\n",
      " Epoch 9310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45627021789551\n",
      "\n",
      " Epoch 9311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821523666382\n",
      "\n",
      " Epoch 9312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761919021606\n",
      "\n",
      " Epoch 9313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902013778687\n",
      "\n",
      " Epoch 9314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817613601685\n",
      "\n",
      " Epoch 9315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45719194412231\n",
      "\n",
      " Epoch 9316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913171768188\n",
      "\n",
      " Epoch 9317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811605453491\n",
      "\n",
      " Epoch 9318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870923995972\n",
      "\n",
      " Epoch 9319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4561996459961\n",
      "\n",
      " Epoch 9320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590802192688\n",
      "\n",
      " Epoch 9321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587664604187\n",
      "\n",
      " Epoch 9322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762014389038\n",
      "\n",
      " Epoch 9323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588451385498\n",
      "\n",
      " Epoch 9324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753479003906\n",
      "\n",
      " Epoch 9325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45506763458252\n",
      "\n",
      " Epoch 9326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45814752578735\n",
      "\n",
      " Epoch 9327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583683013916\n",
      "\n",
      " Epoch 9328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596939086914\n",
      "\n",
      " Epoch 9329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864963531494\n",
      "\n",
      " Epoch 9330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45938539505005\n",
      "\n",
      " Epoch 9331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833730697632\n",
      "\n",
      " Epoch 9332\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746517181396\n",
      "\n",
      " Epoch 9333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874977111816\n",
      "\n",
      " Epoch 9334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45624256134033\n",
      "\n",
      " Epoch 9335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811557769775\n",
      "\n",
      " Epoch 9336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581093788147\n",
      "\n",
      " Epoch 9337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45703315734863\n",
      "\n",
      " Epoch 9338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772886276245\n",
      "\n",
      " Epoch 9339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889472961426\n",
      "\n",
      " Epoch 9340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45656728744507\n",
      "\n",
      " Epoch 9341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807695388794\n",
      "\n",
      " Epoch 9342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798921585083\n",
      "\n",
      " Epoch 9343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880889892578\n",
      "\n",
      " Epoch 9344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783233642578\n",
      "\n",
      " Epoch 9345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850372314453\n",
      "\n",
      " Epoch 9346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825958251953\n",
      "\n",
      " Epoch 9347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45485210418701\n",
      "\n",
      " Epoch 9348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744943618774\n",
      "\n",
      " Epoch 9349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864534378052\n",
      "\n",
      " Epoch 9350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45997953414917\n",
      "\n",
      " Epoch 9351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45866394042969\n",
      "\n",
      " Epoch 9352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847702026367\n",
      "\n",
      " Epoch 9353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787811279297\n",
      "\n",
      " Epoch 9354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810127258301\n",
      "\n",
      " Epoch 9355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4559473991394\n",
      "\n",
      " Epoch 9356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813465118408\n",
      "\n",
      " Epoch 9357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768547058105\n",
      "\n",
      " Epoch 9358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863628387451\n",
      "\n",
      " Epoch 9359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820951461792\n",
      "\n",
      " Epoch 9360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45485544204712\n",
      "\n",
      " Epoch 9361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752286911011\n",
      "\n",
      " Epoch 9362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860576629639\n",
      "\n",
      " Epoch 9363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45621013641357\n",
      "\n",
      " Epoch 9364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45917320251465\n",
      "\n",
      " Epoch 9365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882654190063\n",
      "\n",
      " Epoch 9366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804214477539\n",
      "\n",
      " Epoch 9367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868444442749\n",
      "\n",
      " Epoch 9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756673812866\n",
      "\n",
      " Epoch 9369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897817611694\n",
      "\n",
      " Epoch 9370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45486783981323\n",
      "\n",
      " Epoch 9371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821714401245\n",
      "\n",
      " Epoch 9372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904111862183\n",
      "\n",
      " Epoch 9373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849084854126\n",
      "\n",
      " Epoch 9374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45965909957886\n",
      "\n",
      " Epoch 9375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886325836182\n",
      "\n",
      " Epoch 9376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45777750015259\n",
      "\n",
      " Epoch 9377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851278305054\n",
      "\n",
      " Epoch 9378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768594741821\n",
      "\n",
      " Epoch 9379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45527982711792\n",
      "\n",
      " Epoch 9380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819807052612\n",
      "\n",
      " Epoch 9381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770502090454\n",
      "\n",
      " Epoch 9382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847225189209\n",
      "\n",
      " Epoch 9383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743799209595\n",
      "\n",
      " Epoch 9384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638227462769\n",
      "\n",
      " Epoch 9385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809316635132\n",
      "\n",
      " Epoch 9386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754957199097\n",
      "\n",
      " Epoch 9387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458664894104\n",
      "\n",
      " Epoch 9388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820713043213\n",
      "\n",
      " Epoch 9389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45635890960693\n",
      "\n",
      " Epoch 9390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904731750488\n",
      "\n",
      " Epoch 9391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767784118652\n",
      "\n",
      " Epoch 9392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799922943115\n",
      "\n",
      " Epoch 9393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899868011475\n",
      "\n",
      " Epoch 9394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759439468384\n",
      "\n",
      " Epoch 9395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886945724487\n",
      "\n",
      " Epoch 9396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906209945679\n",
      "\n",
      " Epoch 9397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825576782227\n",
      "\n",
      " Epoch 9398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634460449219\n",
      "\n",
      " Epoch 9399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790243148804\n",
      "\n",
      " Epoch 9400\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828247070312\n",
      "\n",
      " Epoch 9401\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732545852661\n",
      "\n",
      " Epoch 9402\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45517635345459\n",
      "\n",
      " Epoch 9403\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827913284302\n",
      "\n",
      " Epoch 9404\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857572555542\n",
      "\n",
      " Epoch 9405\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609617233276\n",
      "\n",
      " Epoch 9406\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813179016113\n",
      "\n",
      " Epoch 9407\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837497711182\n",
      "\n",
      " Epoch 9408\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815944671631\n",
      "\n",
      " Epoch 9409\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571442604065\n",
      "\n",
      " Epoch 9410\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45924282073975\n",
      "\n",
      " Epoch 9411\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854377746582\n",
      "\n",
      " Epoch 9412\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45922327041626\n",
      "\n",
      " Epoch 9413\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585690498352\n",
      "\n",
      " Epoch 9414\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586353302002\n",
      "\n",
      " Epoch 9415\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793056488037\n",
      "\n",
      " Epoch 9416\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609331130981\n",
      "\n",
      " Epoch 9417\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815420150757\n",
      "\n",
      " Epoch 9418\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772695541382\n",
      "\n",
      " Epoch 9419\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851469039917\n",
      "\n",
      " Epoch 9420\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732593536377\n",
      "\n",
      " Epoch 9421\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642042160034\n",
      "\n",
      " Epoch 9422\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581356048584\n",
      "\n",
      " Epoch 9423\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758771896362\n",
      "\n",
      " Epoch 9424\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896577835083\n",
      "\n",
      " Epoch 9425\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832443237305\n",
      "\n",
      " Epoch 9426\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4546537399292\n",
      "\n",
      " Epoch 9427\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749998092651\n",
      "\n",
      " Epoch 9428\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910453796387\n",
      "\n",
      " Epoch 9429\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596586227417\n",
      "\n",
      " Epoch 9430\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861196517944\n",
      "\n",
      " Epoch 9431\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843410491943\n",
      "\n",
      " Epoch 9432\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589614868164\n",
      "\n",
      " Epoch 9433\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839500427246\n",
      "\n",
      " Epoch 9434\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588098526001\n",
      "\n",
      " Epoch 9435\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791053771973\n",
      "\n",
      " Epoch 9436\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857381820679\n",
      "\n",
      " Epoch 9437\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573802947998\n",
      "\n",
      " Epoch 9438\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638847351074\n",
      "\n",
      " Epoch 9439\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807838439941\n",
      "\n",
      " Epoch 9440\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749473571777\n",
      "\n",
      " Epoch 9441\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861864089966\n",
      "\n",
      " Epoch 9442\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810461044312\n",
      "\n",
      " Epoch 9443\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45669221878052\n",
      "\n",
      " Epoch 9444\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820808410645\n",
      "\n",
      " Epoch 9445\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45607614517212\n",
      "\n",
      " Epoch 9446\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818948745728\n",
      "\n",
      " Epoch 9447\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599347114563\n",
      "\n",
      " Epoch 9448\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835876464844\n",
      "\n",
      " Epoch 9449\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792484283447\n",
      "\n",
      " Epoch 9450\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860385894775\n",
      "\n",
      " Epoch 9451\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579906463623\n",
      "\n",
      " Epoch 9452\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45638799667358\n",
      "\n",
      " Epoch 9453\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804357528687\n",
      "\n",
      " Epoch 9454\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747995376587\n",
      "\n",
      " Epoch 9455\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863246917725\n",
      "\n",
      " Epoch 9456\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811605453491\n",
      "\n",
      " Epoch 9457\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574499130249\n",
      "\n",
      " Epoch 9458\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892286300659\n",
      "\n",
      " Epoch 9459\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822763442993\n",
      "\n",
      " Epoch 9460\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872688293457\n",
      "\n",
      " Epoch 9461\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593415260315\n",
      "\n",
      " Epoch 9462\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45585680007935\n",
      "\n",
      " Epoch 9463\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45783042907715\n",
      "\n",
      " Epoch 9464\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856618881226\n",
      "\n",
      " Epoch 9465\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817804336548\n",
      "\n",
      " Epoch 9466\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868158340454\n",
      "\n",
      " Epoch 9467\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45765590667725\n",
      "\n",
      " Epoch 9468\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45880508422852\n",
      "\n",
      " Epoch 9469\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45630502700806\n",
      "\n",
      " Epoch 9470\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811605453491\n",
      "\n",
      " Epoch 9471\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584231376648\n",
      "\n",
      " Epoch 9472\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571943283081\n",
      "\n",
      " Epoch 9473\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591703414917\n",
      "\n",
      " Epoch 9474\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849514007568\n",
      "\n",
      " Epoch 9475\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632219314575\n",
      "\n",
      " Epoch 9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813131332397\n",
      "\n",
      " Epoch 9477\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581503868103\n",
      "\n",
      " Epoch 9478\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761442184448\n",
      "\n",
      " Epoch 9479\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909023284912\n",
      "\n",
      " Epoch 9480\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4547290802002\n",
      "\n",
      " Epoch 9481\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748853683472\n",
      "\n",
      " Epoch 9482\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 9483\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45993566513062\n",
      "\n",
      " Epoch 9484\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868635177612\n",
      "\n",
      " Epoch 9485\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791673660278\n",
      "\n",
      " Epoch 9486\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458731174469\n",
      "\n",
      " Epoch 9487\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45643854141235\n",
      "\n",
      " Epoch 9488\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579381942749\n",
      "\n",
      " Epoch 9489\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829153060913\n",
      "\n",
      " Epoch 9490\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45732069015503\n",
      "\n",
      " Epoch 9491\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4577169418335\n",
      "\n",
      " Epoch 9492\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45756912231445\n",
      "\n",
      " Epoch 9493\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45896434783936\n",
      "\n",
      " Epoch 9494\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45624303817749\n",
      "\n",
      " Epoch 9495\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803594589233\n",
      "\n",
      " Epoch 9496\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833730697632\n",
      "\n",
      " Epoch 9497\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582314491272\n",
      "\n",
      " Epoch 9498\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628547668457\n",
      "\n",
      " Epoch 9499\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458251953125\n",
      "\n",
      " Epoch 9500\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757961273193\n",
      "\n",
      " Epoch 9501\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861530303955\n",
      "\n",
      " Epoch 9502\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746850967407\n",
      "\n",
      " Epoch 9503\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45606756210327\n",
      "\n",
      " Epoch 9504\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804691314697\n",
      "\n",
      " Epoch 9505\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835447311401\n",
      "\n",
      " Epoch 9506\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45970726013184\n",
      "\n",
      " Epoch 9507\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865297317505\n",
      "\n",
      " Epoch 9508\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789289474487\n",
      "\n",
      " Epoch 9509\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761156082153\n",
      "\n",
      " Epoch 9510\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576325416565\n",
      "\n",
      " Epoch 9511\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888805389404\n",
      "\n",
      " Epoch 9512\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45755004882812\n",
      "\n",
      " Epoch 9513\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885848999023\n",
      "\n",
      " Epoch 9514\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45662355422974\n",
      "\n",
      " Epoch 9515\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801448822021\n",
      "\n",
      " Epoch 9516\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45838785171509\n",
      "\n",
      " Epoch 9517\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4570746421814\n",
      "\n",
      " Epoch 9518\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45647192001343\n",
      "\n",
      " Epoch 9519\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810079574585\n",
      "\n",
      " Epoch 9520\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580307006836\n",
      "\n",
      " Epoch 9521\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45768976211548\n",
      "\n",
      " Epoch 9522\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45901870727539\n",
      "\n",
      " Epoch 9523\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631504058838\n",
      "\n",
      " Epoch 9524\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805406570435\n",
      "\n",
      " Epoch 9525\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828819274902\n",
      "\n",
      " Epoch 9526\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821285247803\n",
      "\n",
      " Epoch 9527\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45460748672485\n",
      "\n",
      " Epoch 9528\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754909515381\n",
      "\n",
      " Epoch 9529\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45911979675293\n",
      "\n",
      " Epoch 9530\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4596643447876\n",
      "\n",
      " Epoch 9531\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881462097168\n",
      "\n",
      " Epoch 9532\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805025100708\n",
      "\n",
      " Epoch 9533\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45772647857666\n",
      "\n",
      " Epoch 9534\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762252807617\n",
      "\n",
      " Epoch 9535\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589614868164\n",
      "\n",
      " Epoch 9536\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4562668800354\n",
      "\n",
      " Epoch 9537\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806694030762\n",
      "\n",
      " Epoch 9538\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833730697632\n",
      "\n",
      " Epoch 9539\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822286605835\n",
      "\n",
      " Epoch 9540\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45629978179932\n",
      "\n",
      " Epoch 9541\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458261013031\n",
      "\n",
      " Epoch 9542\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758819580078\n",
      "\n",
      " Epoch 9543\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860719680786\n",
      "\n",
      " Epoch 9544\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745801925659\n",
      "\n",
      " Epoch 9545\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812177658081\n",
      "\n",
      " Epoch 9546\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910835266113\n",
      "\n",
      " Epoch 9547\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873975753784\n",
      "\n",
      " Epoch 9548\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589467048645\n",
      "\n",
      " Epoch 9549\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875597000122\n",
      "\n",
      " Epoch 9550\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45490169525146\n",
      "\n",
      " Epoch 9551\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759057998657\n",
      "\n",
      " Epoch 9552\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857334136963\n",
      "\n",
      " Epoch 9553\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628309249878\n",
      "\n",
      " Epoch 9554\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897817611694\n",
      "\n",
      " Epoch 9555\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760011672974\n",
      "\n",
      " Epoch 9556\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45789670944214\n",
      "\n",
      " Epoch 9557\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893430709839\n",
      "\n",
      " Epoch 9558\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752954483032\n",
      "\n",
      " Epoch 9559\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45881414413452\n",
      "\n",
      " Epoch 9560\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996427536011\n",
      "\n",
      " Epoch 9561\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843505859375\n",
      "\n",
      " Epoch 9562\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579963684082\n",
      "\n",
      " Epoch 9563\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864343643188\n",
      "\n",
      " Epoch 9564\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800399780273\n",
      "\n",
      " Epoch 9565\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45471620559692\n",
      "\n",
      " Epoch 9566\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45742845535278\n",
      "\n",
      " Epoch 9567\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897054672241\n",
      "\n",
      " Epoch 9568\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899105072021\n",
      "\n",
      " Epoch 9569\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822858810425\n",
      "\n",
      " Epoch 9570\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45632743835449\n",
      "\n",
      " Epoch 9571\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803117752075\n",
      "\n",
      " Epoch 9572\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45748662948608\n",
      "\n",
      " Epoch 9573\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45888710021973\n",
      "\n",
      " Epoch 9574\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45724105834961\n",
      "\n",
      " Epoch 9575\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796966552734\n",
      "\n",
      " Epoch 9576\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45927476882935\n",
      "\n",
      " Epoch 9577\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870780944824\n",
      "\n",
      " Epoch 9578\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45618009567261\n",
      "\n",
      " Epoch 9579\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807838439941\n",
      "\n",
      " Epoch 9580\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835161209106\n",
      "\n",
      " Epoch 9581\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45736932754517\n",
      "\n",
      " Epoch 9582\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829725265503\n",
      "\n",
      " Epoch 9583\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45592021942139\n",
      "\n",
      " Epoch 9584\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45793867111206\n",
      "\n",
      " Epoch 9585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861339569092\n",
      "\n",
      " Epoch 9586\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580307006836\n",
      "\n",
      " Epoch 9587\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858907699585\n",
      "\n",
      " Epoch 9588\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45631408691406\n",
      "\n",
      " Epoch 9589\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817232131958\n",
      "\n",
      " Epoch 9590\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816326141357\n",
      "\n",
      " Epoch 9591\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757579803467\n",
      "\n",
      " Epoch 9592\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45909929275513\n",
      "\n",
      " Epoch 9593\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45472621917725\n",
      "\n",
      " Epoch 9594\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826768875122\n",
      "\n",
      " Epoch 9595\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904111862183\n",
      "\n",
      " Epoch 9596\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846033096313\n",
      "\n",
      " Epoch 9597\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900201797485\n",
      "\n",
      " Epoch 9598\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812129974365\n",
      "\n",
      " Epoch 9599\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962476730347\n",
      "\n",
      " Epoch 9600\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586067199707\n",
      "\n",
      " Epoch 9601\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775079727173\n",
      "\n",
      " Epoch 9602\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45775890350342\n",
      "\n",
      " Epoch 9603\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743179321289\n",
      "\n",
      " Epoch 9604\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905876159668\n",
      "\n",
      " Epoch 9605\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634412765503\n",
      "\n",
      " Epoch 9606\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813941955566\n",
      "\n",
      " Epoch 9607\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45813083648682\n",
      "\n",
      " Epoch 9608\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749378204346\n",
      "\n",
      " Epoch 9609\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45615720748901\n",
      "\n",
      " Epoch 9610\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791864395142\n",
      "\n",
      " Epoch 9611\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871448516846\n",
      "\n",
      " Epoch 9612\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812463760376\n",
      "\n",
      " Epoch 9613\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45857238769531\n",
      "\n",
      " Epoch 9614\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634317398071\n",
      "\n",
      " Epoch 9615\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806503295898\n",
      "\n",
      " Epoch 9616\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45753288269043\n",
      "\n",
      " Epoch 9617\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876026153564\n",
      "\n",
      " Epoch 9618\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766735076904\n",
      "\n",
      " Epoch 9619\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45497465133667\n",
      "\n",
      " Epoch 9620\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821189880371\n",
      "\n",
      " Epoch 9621\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45846223831177\n",
      "\n",
      " Epoch 9622\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4595856666565\n",
      "\n",
      " Epoch 9623\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45868110656738\n",
      "\n",
      " Epoch 9624\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787000656128\n",
      "\n",
      " Epoch 9625\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870018005371\n",
      "\n",
      " Epoch 9626\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4564642906189\n",
      "\n",
      " Epoch 9627\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792818069458\n",
      "\n",
      " Epoch 9628\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45833683013916\n",
      "\n",
      " Epoch 9629\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802879333496\n",
      "\n",
      " Epoch 9630\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565806388855\n",
      "\n",
      " Epoch 9631\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45873689651489\n",
      "\n",
      " Epoch 9632\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591760635376\n",
      "\n",
      " Epoch 9633\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45790195465088\n",
      "\n",
      " Epoch 9634\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45900630950928\n",
      "\n",
      " Epoch 9635\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45728397369385\n",
      "\n",
      " Epoch 9636\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45562696456909\n",
      "\n",
      " Epoch 9637\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576268196106\n",
      "\n",
      " Epoch 9638\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856094360352\n",
      "\n",
      " Epoch 9639\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563856124878\n",
      "\n",
      " Epoch 9640\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916557312012\n",
      "\n",
      " Epoch 9641\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45771789550781\n",
      "\n",
      " Epoch 9642\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803356170654\n",
      "\n",
      " Epoch 9643\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861530303955\n",
      "\n",
      " Epoch 9644\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45780611038208\n",
      "\n",
      " Epoch 9645\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 9646\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45697689056396\n",
      "\n",
      " Epoch 9647\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573860168457\n",
      "\n",
      " Epoch 9648\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584846496582\n",
      "\n",
      " Epoch 9649\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45804357528687\n",
      "\n",
      " Epoch 9650\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45481252670288\n",
      "\n",
      " Epoch 9651\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749139785767\n",
      "\n",
      " Epoch 9652\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893716812134\n",
      "\n",
      " Epoch 9653\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581527709961\n",
      "\n",
      " Epoch 9654\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908880233765\n",
      "\n",
      " Epoch 9655\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45828247070312\n",
      "\n",
      " Epoch 9656\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905017852783\n",
      "\n",
      " Epoch 9657\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808124542236\n",
      "\n",
      " Epoch 9658\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869159698486\n",
      "\n",
      " Epoch 9659\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45549726486206\n",
      "\n",
      " Epoch 9660\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45711517333984\n",
      "\n",
      " Epoch 9661\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45766687393188\n",
      "\n",
      " Epoch 9662\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4590196609497\n",
      "\n",
      " Epoch 9663\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45624828338623\n",
      "\n",
      " Epoch 9664\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801830291748\n",
      "\n",
      " Epoch 9665\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45826625823975\n",
      "\n",
      " Epoch 9666\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45976781845093\n",
      "\n",
      " Epoch 9667\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870447158813\n",
      "\n",
      " Epoch 9668\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808744430542\n",
      "\n",
      " Epoch 9669\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45845603942871\n",
      "\n",
      " Epoch 9670\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800065994263\n",
      "\n",
      " Epoch 9671\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620536804199\n",
      "\n",
      " Epoch 9672\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810556411743\n",
      "\n",
      " Epoch 9673\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812129974365\n",
      "\n",
      " Epoch 9674\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45452880859375\n",
      "\n",
      " Epoch 9675\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574966430664\n",
      "\n",
      " Epoch 9676\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45908117294312\n",
      "\n",
      " Epoch 9677\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819473266602\n",
      "\n",
      " Epoch 9678\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572377204895\n",
      "\n",
      " Epoch 9679\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45943403244019\n",
      "\n",
      " Epoch 9680\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.46024131774902\n",
      "\n",
      " Epoch 9681\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45878267288208\n",
      "\n",
      " Epoch 9682\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4576187133789\n",
      "\n",
      " Epoch 9683\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819520950317\n",
      "\n",
      " Epoch 9684\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45580863952637\n",
      "\n",
      " Epoch 9685\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579586982727\n",
      "\n",
      " Epoch 9686\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45758724212646\n",
      "\n",
      " Epoch 9687\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892763137817\n",
      "\n",
      " Epoch 9688\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4572868347168\n",
      "\n",
      " Epoch 9689\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798873901367\n",
      "\n",
      " Epoch 9690\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907497406006\n",
      "\n",
      " Epoch 9691\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810842514038\n",
      "\n",
      " Epoch 9692\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895147323608\n",
      "\n",
      " Epoch 9693\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45914459228516\n",
      "\n",
      " Epoch 9694\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45852088928223\n",
      "\n",
      " Epoch 9695\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45462417602539\n",
      "\n",
      " Epoch 9696\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819330215454\n",
      "\n",
      " Epoch 9697\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4599380493164\n",
      "\n",
      " Epoch 9698\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458664894104\n",
      "\n",
      " Epoch 9699\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843601226807\n",
      "\n",
      " Epoch 9700\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628929138184\n",
      "\n",
      " Epoch 9701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815849304199\n",
      "\n",
      " Epoch 9702\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805072784424\n",
      "\n",
      " Epoch 9703\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45762825012207\n",
      "\n",
      " Epoch 9704\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820236206055\n",
      "\n",
      " Epoch 9705\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45840072631836\n",
      "\n",
      " Epoch 9706\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45620822906494\n",
      "\n",
      " Epoch 9707\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.458749294281\n",
      "\n",
      " Epoch 9708\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757818222046\n",
      "\n",
      " Epoch 9709\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45787286758423\n",
      "\n",
      " Epoch 9710\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854759216309\n",
      "\n",
      " Epoch 9711\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764350891113\n",
      "\n",
      " Epoch 9712\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853233337402\n",
      "\n",
      " Epoch 9713\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642566680908\n",
      "\n",
      " Epoch 9714\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801162719727\n",
      "\n",
      " Epoch 9715\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836448669434\n",
      "\n",
      " Epoch 9716\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806550979614\n",
      "\n",
      " Epoch 9717\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45473623275757\n",
      "\n",
      " Epoch 9718\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45741033554077\n",
      "\n",
      " Epoch 9719\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902156829834\n",
      "\n",
      " Epoch 9720\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598913192749\n",
      "\n",
      " Epoch 9721\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892906188965\n",
      "\n",
      " Epoch 9722\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792007446289\n",
      "\n",
      " Epoch 9723\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45853900909424\n",
      "\n",
      " Epoch 9724\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759725570679\n",
      "\n",
      " Epoch 9725\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586968421936\n",
      "\n",
      " Epoch 9726\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45470237731934\n",
      "\n",
      " Epoch 9727\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752143859863\n",
      "\n",
      " Epoch 9728\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589352607727\n",
      "\n",
      " Epoch 9729\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815896987915\n",
      "\n",
      " Epoch 9730\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45734643936157\n",
      "\n",
      " Epoch 9731\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45923614501953\n",
      "\n",
      " Epoch 9732\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45602941513062\n",
      "\n",
      " Epoch 9733\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767784118652\n",
      "\n",
      " Epoch 9734\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872259140015\n",
      "\n",
      " Epoch 9735\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.456289768219\n",
      "\n",
      " Epoch 9736\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45899057388306\n",
      "\n",
      " Epoch 9737\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45761823654175\n",
      "\n",
      " Epoch 9738\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788431167603\n",
      "\n",
      " Epoch 9739\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45940828323364\n",
      "\n",
      " Epoch 9740\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4587516784668\n",
      "\n",
      " Epoch 9741\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810747146606\n",
      "\n",
      " Epoch 9742\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586706161499\n",
      "\n",
      " Epoch 9743\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573187828064\n",
      "\n",
      " Epoch 9744\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45884370803833\n",
      "\n",
      " Epoch 9745\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45902299880981\n",
      "\n",
      " Epoch 9746\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850419998169\n",
      "\n",
      " Epoch 9747\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.454749584198\n",
      "\n",
      " Epoch 9748\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751762390137\n",
      "\n",
      " Epoch 9749\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947217941284\n",
      "\n",
      " Epoch 9750\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883321762085\n",
      "\n",
      " Epoch 9751\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4593300819397\n",
      "\n",
      " Epoch 9752\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821285247803\n",
      "\n",
      " Epoch 9753\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45747232437134\n",
      "\n",
      " Epoch 9754\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45832443237305\n",
      "\n",
      " Epoch 9755\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45584869384766\n",
      "\n",
      " Epoch 9756\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836400985718\n",
      "\n",
      " Epoch 9757\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723962783813\n",
      "\n",
      " Epoch 9758\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45800542831421\n",
      "\n",
      " Epoch 9759\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904111862183\n",
      "\n",
      " Epoch 9760\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811223983765\n",
      "\n",
      " Epoch 9761\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45856142044067\n",
      "\n",
      " Epoch 9762\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45947360992432\n",
      "\n",
      " Epoch 9763\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45572328567505\n",
      "\n",
      " Epoch 9764\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821189880371\n",
      "\n",
      " Epoch 9765\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781087875366\n",
      "\n",
      " Epoch 9766\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45848369598389\n",
      "\n",
      " Epoch 9767\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45628881454468\n",
      "\n",
      " Epoch 9768\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45808362960815\n",
      "\n",
      " Epoch 9769\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45863580703735\n",
      "\n",
      " Epoch 9770\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4573016166687\n",
      "\n",
      " Epoch 9771\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45895147323608\n",
      "\n",
      " Epoch 9772\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580659866333\n",
      "\n",
      " Epoch 9773\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849847793579\n",
      "\n",
      " Epoch 9774\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4579668045044\n",
      "\n",
      " Epoch 9775\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45484733581543\n",
      "\n",
      " Epoch 9776\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746040344238\n",
      "\n",
      " Epoch 9777\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45890855789185\n",
      "\n",
      " Epoch 9778\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45991086959839\n",
      "\n",
      " Epoch 9779\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45871782302856\n",
      "\n",
      " Epoch 9780\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849943161011\n",
      "\n",
      " Epoch 9781\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45661354064941\n",
      "\n",
      " Epoch 9782\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861291885376\n",
      "\n",
      " Epoch 9783\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591064453125\n",
      "\n",
      " Epoch 9784\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45797824859619\n",
      "\n",
      " Epoch 9785\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45609045028687\n",
      "\n",
      " Epoch 9786\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45822238922119\n",
      "\n",
      " Epoch 9787\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4575514793396\n",
      "\n",
      " Epoch 9788\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851802825928\n",
      "\n",
      " Epoch 9789\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45559787750244\n",
      "\n",
      " Epoch 9790\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4571123123169\n",
      "\n",
      " Epoch 9791\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829343795776\n",
      "\n",
      " Epoch 9792\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45637845993042\n",
      "\n",
      " Epoch 9793\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820188522339\n",
      "\n",
      " Epoch 9794\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45841789245605\n",
      "\n",
      " Epoch 9795\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746994018555\n",
      "\n",
      " Epoch 9796\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588770866394\n",
      "\n",
      " Epoch 9797\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45650434494019\n",
      "\n",
      " Epoch 9798\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457998752594\n",
      "\n",
      " Epoch 9799\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582462310791\n",
      "\n",
      " Epoch 9800\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45962190628052\n",
      "\n",
      " Epoch 9801\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45722818374634\n",
      "\n",
      " Epoch 9802\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580602645874\n",
      "\n",
      " Epoch 9803\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45886325836182\n",
      "\n",
      " Epoch 9804\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45750570297241\n",
      "\n",
      " Epoch 9805\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4588394165039\n",
      "\n",
      " Epoch 9806\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634984970093\n",
      "\n",
      " Epoch 9807\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805501937866\n",
      "\n",
      " Epoch 9808\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45839977264404\n",
      "\n",
      " Epoch 9809\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807027816772\n",
      "\n",
      " Epoch 9810\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45663595199585\n",
      "\n",
      " Epoch 9811\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875215530396\n",
      "\n",
      " Epoch 9812\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45919513702393\n",
      "\n",
      " Epoch 9813\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45860385894775\n",
      "\n",
      " Epoch 9814\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45889949798584\n",
      "\n",
      " Epoch 9815\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45803689956665\n",
      "\n",
      " Epoch 9816\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45600032806396\n",
      "\n",
      " Epoch 9817\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4580307006836\n",
      "\n",
      " Epoch 9818\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45718812942505\n",
      "\n",
      " Epoch 9819\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45749092102051\n",
      "\n",
      " Epoch 9820\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss :  82.45910406112671\n",
      "\n",
      " Epoch 9821\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45616149902344\n",
      "\n",
      " Epoch 9822\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806455612183\n",
      "\n",
      " Epoch 9823\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45836019515991\n",
      "\n",
      " Epoch 9824\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806837081909\n",
      "\n",
      " Epoch 9825\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892238616943\n",
      "\n",
      " Epoch 9826\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45781946182251\n",
      "\n",
      " Epoch 9827\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45597696304321\n",
      "\n",
      " Epoch 9828\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45842027664185\n",
      "\n",
      " Epoch 9829\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45709037780762\n",
      "\n",
      " Epoch 9830\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811605453491\n",
      "\n",
      " Epoch 9831\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45542669296265\n",
      "\n",
      " Epoch 9832\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45801544189453\n",
      "\n",
      " Epoch 9833\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45851278305054\n",
      "\n",
      " Epoch 9834\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45885944366455\n",
      "\n",
      " Epoch 9835\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45820474624634\n",
      "\n",
      " Epoch 9836\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894479751587\n",
      "\n",
      " Epoch 9837\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817470550537\n",
      "\n",
      " Epoch 9838\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850229263306\n",
      "\n",
      " Epoch 9839\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45798254013062\n",
      "\n",
      " Epoch 9840\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45653581619263\n",
      "\n",
      " Epoch 9841\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810794830322\n",
      "\n",
      " Epoch 9842\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45757675170898\n",
      "\n",
      " Epoch 9843\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876693725586\n",
      "\n",
      " Epoch 9844\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45816564559937\n",
      "\n",
      " Epoch 9845\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45730257034302\n",
      "\n",
      " Epoch 9846\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897340774536\n",
      "\n",
      " Epoch 9847\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806455612183\n",
      "\n",
      " Epoch 9848\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864725112915\n",
      "\n",
      " Epoch 9849\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45618963241577\n",
      "\n",
      " Epoch 9850\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45904874801636\n",
      "\n",
      " Epoch 9851\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764780044556\n",
      "\n",
      " Epoch 9852\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45795488357544\n",
      "\n",
      " Epoch 9853\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586501121521\n",
      "\n",
      " Epoch 9854\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45815706253052\n",
      "\n",
      " Epoch 9855\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45894193649292\n",
      "\n",
      " Epoch 9856\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45843458175659\n",
      "\n",
      " Epoch 9857\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45633316040039\n",
      "\n",
      " Epoch 9858\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825481414795\n",
      "\n",
      " Epoch 9859\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764589309692\n",
      "\n",
      " Epoch 9860\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45929765701294\n",
      "\n",
      " Epoch 9861\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745038986206\n",
      "\n",
      " Epoch 9862\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45821046829224\n",
      "\n",
      " Epoch 9863\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877408981323\n",
      "\n",
      " Epoch 9864\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819139480591\n",
      "\n",
      " Epoch 9865\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45910215377808\n",
      "\n",
      " Epoch 9866\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799112319946\n",
      "\n",
      " Epoch 9867\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45854568481445\n",
      "\n",
      " Epoch 9868\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4563102722168\n",
      "\n",
      " Epoch 9869\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809268951416\n",
      "\n",
      " Epoch 9870\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844173431396\n",
      "\n",
      " Epoch 9871\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45715379714966\n",
      "\n",
      " Epoch 9872\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45887517929077\n",
      "\n",
      " Epoch 9873\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45817565917969\n",
      "\n",
      " Epoch 9874\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45599555969238\n",
      "\n",
      " Epoch 9875\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812606811523\n",
      "\n",
      " Epoch 9876\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45767831802368\n",
      "\n",
      " Epoch 9877\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825719833374\n",
      "\n",
      " Epoch 9878\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45462131500244\n",
      "\n",
      " Epoch 9879\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811939239502\n",
      "\n",
      " Epoch 9880\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45837831497192\n",
      "\n",
      " Epoch 9881\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45627880096436\n",
      "\n",
      " Epoch 9882\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802879333496\n",
      "\n",
      " Epoch 9883\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835542678833\n",
      "\n",
      " Epoch 9884\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876693725586\n",
      "\n",
      " Epoch 9885\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802736282349\n",
      "\n",
      " Epoch 9886\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45823097229004\n",
      "\n",
      " Epoch 9887\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45634078979492\n",
      "\n",
      " Epoch 9888\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45788669586182\n",
      "\n",
      " Epoch 9889\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45829820632935\n",
      "\n",
      " Epoch 9890\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45694541931152\n",
      "\n",
      " Epoch 9891\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45913648605347\n",
      "\n",
      " Epoch 9892\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45791053771973\n",
      "\n",
      " Epoch 9893\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45850610733032\n",
      "\n",
      " Epoch 9894\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581184387207\n",
      "\n",
      " Epoch 9895\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45622730255127\n",
      "\n",
      " Epoch 9896\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45812797546387\n",
      "\n",
      " Epoch 9897\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45760107040405\n",
      "\n",
      " Epoch 9898\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4589672088623\n",
      "\n",
      " Epoch 9899\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45727491378784\n",
      "\n",
      " Epoch 9900\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45987224578857\n",
      "\n",
      " Epoch 9901\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45869493484497\n",
      "\n",
      " Epoch 9902\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792961120605\n",
      "\n",
      " Epoch 9903\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45870780944824\n",
      "\n",
      " Epoch 9904\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45642566680908\n",
      "\n",
      " Epoch 9905\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45792961120605\n",
      "\n",
      " Epoch 9906\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45825910568237\n",
      "\n",
      " Epoch 9907\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45746660232544\n",
      "\n",
      " Epoch 9908\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45515489578247\n",
      "\n",
      " Epoch 9909\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4582405090332\n",
      "\n",
      " Epoch 9910\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4578309059143\n",
      "\n",
      " Epoch 9911\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45876455307007\n",
      "\n",
      " Epoch 9912\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45723962783813\n",
      "\n",
      " Epoch 9913\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45621824264526\n",
      "\n",
      " Epoch 9914\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45906162261963\n",
      "\n",
      " Epoch 9915\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45872974395752\n",
      "\n",
      " Epoch 9916\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806550979614\n",
      "\n",
      " Epoch 9917\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45861864089966\n",
      "\n",
      " Epoch 9918\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45743131637573\n",
      "\n",
      " Epoch 9919\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45905256271362\n",
      "\n",
      " Epoch 9920\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45611333847046\n",
      "\n",
      " Epoch 9921\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802927017212\n",
      "\n",
      " Epoch 9922\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45835399627686\n",
      "\n",
      " Epoch 9923\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805597305298\n",
      "\n",
      " Epoch 9924\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45711898803711\n",
      "\n",
      " Epoch 9925\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45935726165771\n",
      "\n",
      " Epoch 9926\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45847272872925\n",
      "\n",
      " Epoch 9927\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45644235610962\n",
      "\n",
      " Epoch 9928\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45805788040161\n",
      "\n",
      " Epoch 9929\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45751762390137\n",
      "\n",
      " Epoch 9930\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45892524719238\n",
      "\n",
      " Epoch 9931\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754480361938\n",
      "\n",
      " Epoch 9932\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45500755310059\n",
      "\n",
      " Epoch 9933\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45819044113159\n",
      "\n",
      " Epoch 9934\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45844459533691\n",
      "\n",
      " Epoch 9935\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45972299575806\n",
      "\n",
      " Epoch 9936\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45879125595093\n",
      "\n",
      " Epoch 9937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4591908454895\n",
      "\n",
      " Epoch 9938\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4581732749939\n",
      "\n",
      " Epoch 9939\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.457688331604\n",
      "\n",
      " Epoch 9940\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584550857544\n",
      "\n",
      " Epoch 9941\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4547381401062\n",
      "\n",
      " Epoch 9942\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4574122428894\n",
      "\n",
      " Epoch 9943\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45893096923828\n",
      "\n",
      " Epoch 9944\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45827531814575\n",
      "\n",
      " Epoch 9945\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45460653305054\n",
      "\n",
      " Epoch 9946\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45754051208496\n",
      "\n",
      " Epoch 9947\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45864772796631\n",
      "\n",
      " Epoch 9948\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45998620986938\n",
      "\n",
      " Epoch 9949\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45883178710938\n",
      "\n",
      " Epoch 9950\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849561691284\n",
      "\n",
      " Epoch 9951\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45619058609009\n",
      "\n",
      " Epoch 9952\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45810508728027\n",
      "\n",
      " Epoch 9953\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45752763748169\n",
      "\n",
      " Epoch 9954\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45897006988525\n",
      "\n",
      " Epoch 9955\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811462402344\n",
      "\n",
      " Epoch 9956\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45716142654419\n",
      "\n",
      " Epoch 9957\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45907783508301\n",
      "\n",
      " Epoch 9958\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45811033248901\n",
      "\n",
      " Epoch 9959\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45611143112183\n",
      "\n",
      " Epoch 9960\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4583797454834\n",
      "\n",
      " Epoch 9961\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4598560333252\n",
      "\n",
      " Epoch 9962\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4585313796997\n",
      "\n",
      " Epoch 9963\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45796012878418\n",
      "\n",
      " Epoch 9964\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45859718322754\n",
      "\n",
      " Epoch 9965\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45799779891968\n",
      "\n",
      " Epoch 9966\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45466947555542\n",
      "\n",
      " Epoch 9967\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45744800567627\n",
      "\n",
      " Epoch 9968\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45882511138916\n",
      "\n",
      " Epoch 9969\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770502090454\n",
      "\n",
      " Epoch 9970\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45877265930176\n",
      "\n",
      " Epoch 9971\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4565167427063\n",
      "\n",
      " Epoch 9972\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45802593231201\n",
      "\n",
      " Epoch 9973\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45824718475342\n",
      "\n",
      " Epoch 9974\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45745515823364\n",
      "\n",
      " Epoch 9975\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45764064788818\n",
      "\n",
      " Epoch 9976\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.456223487854\n",
      "\n",
      " Epoch 9977\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45891380310059\n",
      "\n",
      " Epoch 9978\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45858573913574\n",
      "\n",
      " Epoch 9979\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45806312561035\n",
      "\n",
      " Epoch 9980\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45865201950073\n",
      "\n",
      " Epoch 9981\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45759344100952\n",
      "\n",
      " Epoch 9982\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4559736251831\n",
      "\n",
      " Epoch 9983\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45809841156006\n",
      "\n",
      " Epoch 9984\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45716381072998\n",
      "\n",
      " Epoch 9985\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45984411239624\n",
      "\n",
      " Epoch 9986\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45874738693237\n",
      "\n",
      " Epoch 9987\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4584231376648\n",
      "\n",
      " Epoch 9988\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45916891098022\n",
      "\n",
      " Epoch 9989\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45849752426147\n",
      "\n",
      " Epoch 9990\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45740842819214\n",
      "\n",
      " Epoch 9991\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45807266235352\n",
      "\n",
      " Epoch 9992\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45593976974487\n",
      "\n",
      " Epoch 9993\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45818901062012\n",
      "\n",
      " Epoch 9994\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45996713638306\n",
      "\n",
      " Epoch 9995\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45735597610474\n",
      "\n",
      " Epoch 9996\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.4586009979248\n",
      "\n",
      " Epoch 9997\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45770263671875\n",
      "\n",
      " Epoch 9998\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45875263214111\n",
      "\n",
      " Epoch 9999\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  82.45475816726685\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    \n",
    "    print(\"\\n Epoch\", epoch)\n",
    "    \n",
    "    batch_size = 50\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    for b in range(0, train_input.size()[0], batch_size):\n",
    "        output = model.forward(train_input[b:b+batch_size,:])\n",
    "        batch_loss = loss.forward(output, train_target[b:b+batch_size,:])\n",
    "        train_loss += batch_loss\n",
    "        model.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        _, pred = torch.max(output,1)\n",
    "        _, target = torch.max(train_target[b:b+batch_size],1)\n",
    "        \n",
    "        train_accuracy += torch.sum(pred==target)\n",
    "        \n",
    "    print(\"\\nTraining accuracy : \", train_accuracy/train_target.size()[0])      \n",
    "    print(\"\\nTraining loss : \", train_loss)\n",
    "    loss_list.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAF1CAYAAADr6FECAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8M3MknDgm5kl8QWLMvHmnra3vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f612fccd358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npP4/8UB4sUbz4s8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f612a27f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(test_input[:,:])\n",
    "_, pred = torch.max(output,1)\n",
    "_, target = torch.max(test_target,1)\n",
    "        \n",
    "test_accuracy = torch.sum(pred==target)\n",
    "print (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 25])\n",
      "torch.Size([25, 25])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "param = model.params[1]\n",
    "print (param[0][0].size())\n",
    "print (param[1][0].size())\n",
    "#.add_(- self.lr * param[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 24 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0\n",
       "[torch.FloatTensor of size 25x25]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(param[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LNGfSSVHMGvSTV3P8HxnVQsE79dSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f612a2235c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected r_ [1000], ta [1000] and tb [1000 x 2] to have the same number of elements, but got 1000, 1000 and 2000 elements respectively at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorMath.c:3051",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-65d5688fa7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected r_ [1000], ta [1000] and tb [1000 x 2] to have the same number of elements, but got 1000, 1000 and 2000 elements respectively at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorMath.c:3051"
     ]
    }
   ],
   "source": [
    "test_output = model.forward(test_input)\n",
    "_, pred = torch.max(test_output,1)\n",
    "\n",
    "torch.sum(pred == test_target.type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(train_input)\n",
    "print(output)\n",
    "train_loss = loss.forward(output,train_target)\n",
    "print(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_input\n",
    "x = Lin1.forward(x)\n",
    "x = act1.forward(x)\n",
    "#x = Lin2.forward(x)\n",
    "#x = act2.forward(x)\n",
    "x = Lin3.forward(x)\n",
    "x = act3.forward(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = loss.backward()\n",
    "dx = act3.backward(dx)\n",
    "dx = Lin3.backward(dx)\n",
    "#dx = act2.backward(dx)\n",
    "#dx = Lin2.backward(dx)\n",
    "#dx = act1.backward(dx)\n",
    "#dx = Lin1.backward(dx)\n",
    "print(dx)\n",
    "\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.reset_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lin3.dl_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
