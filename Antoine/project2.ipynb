{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input_ = Tensor(nb, 2).uniform_(0,1)\n",
    "    disk_center = Tensor(nb, 2).fill_(0.5)\n",
    "    #ones_ = torch.ones(nb,2)\n",
    "    R = 1/math.sqrt(2*math.pi) # Radius of the disk\n",
    "    target = (R - (disk_center - input_).pow(2).sum(1).sqrt()).sign()#.long()\n",
    "    target.add_(1).div_(2) # to transform [-1,1] into [0,1]\n",
    "    return input_, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mini_batch_size = 100\n",
    "print (train_input.size(), train_target.size())\n",
    "print(train_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples:        torch.Size([1000, 2])\n",
      "#true_samples:   torch.Size([483, 2])\n",
      "#false_samples:  torch.Size([517, 2])\n",
      "torch.Size([1000, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAF1CAYAAADr6FECAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsfXucXVV1/3ffO4+8BYZAyEAIBISAUSARHaQwJBgppQpFi7WYFGziCFGgUDA8JLwSbatNFawTFGSwtcov1aJi1UAGkbmWJFJBQJQIDSEJyMgjicnkcffvj33P3HNPzmO/9z53zvfzOZ+Ze+85+6y999prr73W2msTSikKFChQoEDzo+SagAIFChQoYAeFwC9QoECBEYJC4BcoUKDACEEh8AsUKFBghKAQ+AUKFCgwQlAI/AIFChQYISgEfpOBEPIVQsgNmsqaQgjZRggp1z73E0L+VkfZtfJ+SAiZr6s8gffeSgh5lRCyxfa7fQIh5G8IIT8TuP8FQsiZJmkqYBaFwM8RagNuByFkKyHkdULIACGkhxAy3I+U0h5K6S2cZaUOXkrpBkrpOErpXg20LyGEfCNS/p9SSu9RLVuQjsMAXAngOErpJJvv1g3dE7BOEEIoIeQo13QUaEQh8POHP6eUjgdwOIDPArgGwNd0v4QQ0qK7TE9wOIBBSukrrglJQxO3fwGHKAR+TkEpfYNSej+ACwDMJ4S8DQAIIV8nhNxa+/9AQsj3a6uBPxBCHiGElAgh9wKYAuB7NZPN1YSQqTWt7GOEkA0AHgp9FxY+0wghjxFC3iCE/Bch5IDau7oJIRvDNAarCELIWQCuBXBB7X2/rP0+rKHW6LqeEPJ/hJBXCCF9hJC31H4L6JhPCNlQM8dcl9Q2hJC31J7/fa2862vlnwngJwAm1+j4esLzVxNCNhNCNhFC/jasrRJC2gkh/1Sj4+WaCW10uA0IIVfW6rCZEHJRqFyeZ6+pmZruJoTsX+u/3xNCXqv9f2jt/tsA/AmA22t1ub32/bGEkJ/U+vtZQshfht7fQQi5nxDyJiHkMQDTktqwdv9Ha+03GG1vQsjJhJBKjbc2E0JuJ4S01X77ae22X9ZouyCtLgUsglJaXDm5ALwA4MyY7zcA+ETt/68DuLX2/zIAXwHQWrv+BACJKwvAVAAUQB+AsQBGh75rqd3TD+AlAG+r3bMSwDdqv3UD2JhEL4Alwb2h3/sB/G3t/4sBPAfgSADjAPwngHsjtN1Zo+sdAIYATE9opz4A/wVgfO3Z3wD4WBKdkWfPArAFwPEAxgC4t/buo2q/LwdwP4ADauV/D8CyUNl7ANxca++zAfwRwP4Cz34OQHutnh0Azq/RMR7AfQC+G9d+tc9jAbwI4CIALQBOAvAqgONrv/8HgG/X7ntbrS9/ltAOxwHYBuC0Gj1fqNEX9OdMAO+uvWcqgGcAXB56frjNap9T61JclmSIawKKS6CzkgX+zwFcV/v/66gL/Jtrgu+orLJQF6pHxnwXFvifDf1+HIBdAMpQF/gPArgk9NsxAHaHBAoFcGjo98cAfDimXmWwyeC40HcfB9Bf+38fOiPP34WaEK59PioQXgAIgO0ApoV+7wLwfKjsHUF71b57pSYYeZ7dBWBUCm0nAHgtrv1qny8A8EjkmV4AN9baZTeAY0O/LUWywP8MgP8IfR5bo28f/qv9fjmA74Q+Nwj8rLoUl52rsBM2BzoB/CHm+38EE7Q/JoQAwApK6WczynpR4Pf/A9NkD+QjMxWTa+WFy24BcHDou3BUzR/BVgJRHAigLaasTgE61oY+h+s7EUxDXVdrT4AJ8nLonkFK6Z4YOnme/T2ldOfwj4SMAfDPYKuO/WtfjyeElGm8I/1wAO8ihLwe+q4FbJUysfZ/tP+SMDl8L6V0OyFkMETbW8G0/lm1erUAWJdUmERdChhAYcPPOQgh7wQTZvuE11FKt1JKr6SUHgngzwH8HSFkTvBzQpFZ6VMPC/0/BUxrfBVMex0ToqsMJmR4y90EJrDCZe8B8HLGc1G8WqMpWtZLnM9vBhC2LYfr+yqYBn88pXS/2vUWSmncxBNHV9az0Ta6Emyl8y5K6QQw8wrAJoq4+18E8HCo/P0oi7L6BIDfg7VntP+SsDl8b01gd4R+/1cAvwZwdI22a0N0xSGrLgUsoBD4OQUhZAIh5Bwwu+w3KKVPxtxzDiHkKMJUyjcB7K1dABOkR0q8+kJCyHE1AXAzgP9X09B+A2AUIeTPCCGtAK4Hs/0GeBnAVBIKIY3gmwCuIIQcQQgZB2Zu+FZEW85EjZZvA7iNEDKeEHI4gL8D8I30J4fxbQAXEUKm1+r4mVDZVTA/wj8TQg4CAEJIJyHkfRx0yTw7HmySeJ0w5/iNkd+jffh9AG+tOVtba9c7CSHTa+3ynwCWEELGEEKOA5C2B+L/ATiHEHJqzRl7MxrlxXgwntpGCDkWwCcyaMuqSwELKAR+/vA9QshWMG3uOrBl9UUJ9x4NYBWY860C4MuU0v7ab8sAXF+LsrhK4P33gvkJtgAYBeBTAIsaAnAJgK+CadPbAYSjdu6r/R0khPwipty7amX/FMDzAHYC+KQAXWF8svb+34GtfP69Vn4mKKU/BPBFAKvBnMiV2k9Dtb/X1L7/OSHkTbD2PYaTLtFnl4M5b18F89P8d+T3fwHwwVrUyxcppVsBzAXwYbAV0xbUncAAsAjMvLQFrA/vTnoxpfQpAJeCtd1mAK+hsT+vAvARAFvBJrJvRYpYAuCeGn/9JUddClhAELFRoECBGBBCpgP4FYB20dVGgQK+odDwCxSIgBByHiGkjRCyP5iG/L1C2BdoBmQKfELIXbVNJL9K+J0QQr5ICHmOEPIEIeQk/WQWKGAVHwdzcq4H83lE7dMFCuQSmSYdQshpYDbgPkrp22J+PxvMZno2gHcB+BdK6bsM0FqgQIECBRSQqeFTSn+K+BjvAB8AmwwopfTnAPYjhByii8ACBQoUKKAHOmz4nWjczLER/JtcChQoUKCAJejYaRu3cSLWTkQIWQhgIQCMHTt25rHHHqvh9W6xZQvwUmhLT2cnMClnSXe3bweefRagFCAEOOYYYOxY11TpxfbtwNatwPjx4nXzsY+z6qNSX9fIO+2mx9K6detepZROzL4zBjz5F8Bymfwq4bdeAH8V+vwsgEOyypw5cyZtBgwMUDp6NKXlMvs7MOCaInEsXcroB9jfpUtdU6QXSX00MMDqmtVnrvo4ib4sevLMk2m08/aXS9gYSwDWUoe5dO4HsIgQ8h9gTts3KKWbNZSbC3R1AQ8+CPT3A93d7HPe0N0NtLUBu3axv93dfM9VKvmod38/q9vevexvfz/7fs6cep0ffDC5Di76eMUKYNEiRnN7eyN9cfUJ05T1u89Ior1S4e8vHpjiXdmxZAuZAp8Q8k2wTH4HEpbv/EawhFmglH4FwANgETrPgSWKStr12bTo6srPgIqDjEDTPQBNIm4QigpFm31cqQCXXgrsqUX+Dw010pcmVCoVYMMGoFxLyeaj0EkTtkl1U53Ewu8EzPGu7wpgpsCnlP5Vxu8UbAt2LlGpAH197P958/zrIFsQFWh50iKTBqGvmlh/P1Ct1j+Xy430JdUnmISHhpj9+M//HLj6ar/6JUtRSKqbiuYcfef8+fK8y7My8FoBlLUFqV7HHjvTuT1uYIDStjZmbwMobW/32z5oEqL2UdN2Yhv2Wl9twkHblkqUtrRQ2tvL99zSpeyZgJ9bW/2rW5KNm6cvZPsr+s6eHjne9cU3AgUbvjOBT8hM5w23dCmlhNQHCCHxThZfBYMuyDKyqXbxZWC5hEzbDgywCSLg51LJPwd8XN/aUB7i3inavr4EN6gIfGcHoFBq3xwQXY51dwOtrYwGIH6pmCdbtSxkzTPB0rVSAZYtU7NZhvsmT+aiAG+++SZeeeUV7N69u+H7oSFg505g1CjmfOXFfvsB557L/n/mGf5nHn0U+ENtmyQhwMEH8z9vA/vtBwwMNLbJG28A//mf9XsIiadZpS2j7wTE2/dP/xQ46aR6yKWJtm1tbcVBBx2ECRMm6C24BmcCnxCgVLJnP00S3P396Tb8PAofHoQFrE77qMyEGC1j+XJ/7etxePPNN/Hyyy+js7MTo0ePRnCi1bZtwG9+A7S0MJv8YYcB43iOSlHEtm31OHaR98k+p4qgnapVJhPe+tZ93y/SlibrYbJsSil27NiB9etfQqUCzJgxQbuscSbwjzmGCVjTnuxAsG3YEC+4sxwsPoVZZTmMeEPNwgK2XAYuvpgJ2cFB8f7QMSFGyxgcdBPpIBuq98orr6CzsxNjxoxp+H7r1rrztVpln1WEBK+wGTdO/D08QtcUxo1j70urG29bmq6HTNvyghCCanUMdu3qxJgxmzBnzgTtFgVnAn/sWGDxYrPviAq2llptRQS3L2FWWZq0iKYdFrB79wK9vWypGzwjIvh0TIjhMlpa2OQMmOePMGRWKkE7/emf7sbo0aP3+X38eCZ0AuEzfrw8fSYEWXgC0T05iSJLkPK2pet6qGLrVoDS0TjggN1GLAq5P8Q8TTiFBRsALFgATJkiLrh9CLPSudkmELA7dwbuPbkNSYCeCTEoo68PuOsu4M47gXvusesvEV2phEMgTzwR6OwkmBjZ7M6jufLCxGohPIEcdpi+yckEeNtS5yTrAox+YszcnWuBn6WVRbXPPMfZZ2nSIpp2WMDefTfb4JO1ISltYtUxIQb+lGDVYdtfEtd+WcrE0FBdCG/YAIweva8g4jUBZJlrdAuy6ASyZ4++yUkXom3C05Y6J1kVWmUR0L9rlxmFJ9cnXsUJpzACwXbLLfmPrsmqi2hdu7qAf/1XYPXqxmcCwVcuNwq+OXOAG25gfyuV9LJlEfduW4i2H5Be5+7u+m5WgK2Stm5tvGfbNmDzZvY3Ddu2sYRbL73E/sbdHwiCzk495pxgAgFYAEUQqXbIIellT506Fbfeemtq2f39/SCEYOPGjan3EULwjW/Eny0frEBeeon9zWrDMMaNq9eDl5YsfP3rX0dLS7x+rEJrHMaNA97yFjPyKtcafnd33Wvf0hIvIHwwx+hCVl1k6hp9Js5Es2yZnGNW1Alq0l/Cu0MSYPc99ljd5BVX564u4PbbWQoEYF+tW8TmPjjI3gOwv4OD8ffqdBgGE8jgIPDqq8Dvf8/+z5pM1qxZ0+CcPuqoo3DhhRdiyZIlwjRs3rwZ++23X+xvukxYp5xyCjZv3oyDDjpI/GFO5MlvkGuBDzQOlAJqCAvFsMNUxjEbF2rJEwVkYoLmdciG7fLh1AalEjPZVCqNzy1cCMyYwTTkqKDMgxAYNy5wErLPPHROjDoqFDApJce0LhNWW1tb6nsAYNeuXWhra5N7AfLlN8i9SWfv3vomrqhJpwA/0sw2MqaxsLltaIhpwqZNQjy0xJn+oveFhT0h7POdd8bT3tXFlt9RIRk2mWQJgY4O9p7gfR0dApVTwKpVqzB1ajuGhv4IANi9eyeOOGIUTj311OF7Vq9ejZaWFrz55psAgMMPn4prrrkV27YB3d3dWL9+PW666SYQQkAIwQsvvDD87DPPPIPTTjsNY8aMwXHHHYcf/ehHDe+PmnQIIfjyl7+Mj370ozjkkPF4//sPw3e/+w+Zq47169fjQx/6EA444ACMGTMGb3/72/H9738fwL4mneDzD37wA5x66qkYNWoUVqxYAQBYt24dzjrrLEyYMAHjxo3DySefjP/5n/9JfO+6deswd+5cTJo0DnPnTsT11/8Fduz4P46Wd4dcC3yXNl/bCHazmhKWPP6QxYv5te9w3xDCnIJZAtcUePkkuC8sqFta9t0VzgMRm/u4cWxfSmcnMP31CsZ9Sbyjef0FYbznPe8BIQS///0j6OwEBgcfxfjx4/HYY49hW62ghx56CLNmzcKECROwbRuwezfw5pvMXNXX95+YOnUqrrzySmzevBmbN2/GYYcdNlz+VVddhWuvvRa//OUvMWvWLFxwwQXYuPH1VDpvuukmnHbaafjf//1fXH313+O2267BmjWrE+uwZcsWnHLKKXjttddw//3348knn8Qtt9yCUildtF155ZW4+uqr8cwzz+Dcc8/FU089hdNOOw37778/HnroITz++OO44oorUA3P/iGsXfs0TjvtdMyc2YW1a9fiBz94CHv2lPGRj7wXTz65U9mObwyyORlUL10HoMTlxGi23Dc2csuYeMfAAEtU1dpaz+/S1uamr0QOO1m6lCUsC/5mtcvTTz+tj0iJTti6ldJ16yhds4b93bqV/5Wnn346/fu//3tKKaXXXnstvfjii+n06dPpD37wA0oppaeccgpdvHgxpZTSTZsoPeSQw2lPzy10zRr2edq0afTGG29sKHP16tUUAF25cuXwd5s3b6YA6Je+9N/DdAKg99577/A9AOgnP/nJhrKOOeYY+ulPfzqR/uuvv54efPDBdNu2bbG/B7S8+OKLDZ/7+voa7rvwwgvp29/+drp3797Ycu6++25aLpcppax9zzlnPn3vey8Ybu9Nmyh99NGdtL19NP3Hf/wO3bQpkWQupPEU8phLRxRJTreozTdshy2XmWNt4ULb1IqDdz+BqXBFEw7TINQyUJIIYbt6o+l8beQp4vUNxN03Y4aljXeSHa3iL5g9ezbuv/9+AEyb/+QnP4lRo0bhoYcewmmnnYY1a9bgpptuAtBoluKxVZ9wwgnD/0+aNAnlchmDgy8P05n1DAB0dnbi5ZdfTnzHunXrcMopp2Cs4DmCJ5988j7lnHXWWZkrA4C171NPrcHGjc/h1FPHgZC66W/Xrp3YuPG33trxcyHww4KhpQW46KLkmPpwfHS1ymzHM2b4Hakjup9A1XTFO3nqQNxeiAA2JjIdsBbpJdnRKk7D2bNn46abbsKGDRuwbt06zJ49G+3t7bj11lsxZ84clEolvOc97wHAJpHWVmDCBL7Q0DhHKKVM0ifJ1egzLN1AwuwQukcUcRMEbznjx7N6nH32R3HRRZ/G1Kksc8D27ew67LAO7xz0AZwLfJ5wubhUAEk7MYP46LDG46sgCZAl+HRq37q0at6QyzTafcpT5AUkO1pls9G73vUujB49GjfffDOOPvpoTJo0CWeccQYuuOAC3HfffXj3u9/dkDaCkMZ3tLW1YW+wlZ0DkyYxX4UuDXjmzJm48847sX37dmEtP1rOqlWrUK1WM7X8ceOAd797Fn796ycwe/Y0jB8vPuG4glOnLe+GnkAwBBNwNBVAGEF8dEsL0yLa2/0XJDxORVGnaRLiJhdRh7DoRqwk2ptpY5w2SHZ0eLNRGqLO3dbWVpx66qm45557MHv2bADAAQccgBkzZuDee+8d/i4JRxxxBB599FFs2LABr776aqY2PmoUozPAzp2ZVUvFJZdcgmq1ig984AN49NFH8fzzz+P73/8+fvjDHwqVs2jR1fjNb36LCy74a6xduxbr16/Hvffeh+99rxLrgP3MZ67Fc889g56eC/HYY4/h+eefx+rVq3HZZZfhd7/7nVqlDMKpwOcNlwsEw8c/zhdtsXAh8NOfArfealaQ6IqcsSn4opNLR4f4LlrefuOB6kRmOnqpmZC0I3TOnDnYs2dPg3CfPXv2Pt/F4aabbsIbb7yBY445BhMnTsSGIPMdBx0AsGVLcsTOtm3MPBs5YqABhxxyCH72s59h/PjxOPvss3H88cfjuuuuY6c7cWLbNqC1dQa+8pV+bNjwe5x++uk44YQT8LnP/RP+8IcyfvObfSem6dOnY2BgANu2bcP73vc+HHfccViwYAF27NiRuJnMBxCRhtGJWbNm0S99aa10hkKXmSsDOvJ6MEr0sJEbbmDCu1xmk05Wlkpf6u4LHc888wymT59u/8UciGbEfOml+m+dnUzbtp0Hf/PmeDqidNtK1xxHD5BNo0mk8RQhZB2ldJZMuU5t+DImS19SJeTF4RiHaBuK2tFNpkAQQZ77wAZ4MmK6yIPP42S2uVM5TA8hzBw8enR+ds+KwLnT1hcBHkXSSiL4vqOjORyOssLbh34rnL7p4MmIuXmz/RQQPE5mm+kKxo1jk+GGDcw/+OKLjD7fsofqgHOB7yMqFeCMM+qCZPXqeopgmfwwvsMH4S0DX1YaviJOaEYTsEXvaWlhk0CWkFM1A2UlgrOd5njPnn1zCvE4wfOGphH4Om37fX3MWQSwv3199U1E0aP4bJ7KFIWuIw9d0JYX5LkePEIzfE9LC9Nus8w7tsxAJo8TjCJPCdBU0BQC35bzzicTgs4jD23Tlpf3xG34O/HEfK3qeA8NETHv2LKv23Qm80yOrg5514lcJ08LoDNMEGC7QYO4//DuUJ/ixrPqrLtNdNKWl/eEyx8aYhv+Pv5x4Prr3WT9NA3eDJ8imUBloftQER6k7WVwQY8JNIWGr1vzDsw3ttIPyCCrzi5XI7bebfo9Qfnhs3+BIGeKn1FBKloor93chn3dt/MEfKNHFk7j8NeuXautvDzbWmVR2PDNv6dSqR+uvmcPUK1SlAhFexvFg6vL6OryJw7fRYilCWzbVj+Ji1I/6mKrbYMJ++WXn8GOHdNjeTu3cfjNgkAoAHYPSs9abehejYgIV1srISPvCVW0C0DXlH7M+9I56H98Ajq++jkM7t0f3fRRdGEZAH+0i2bQQsOClRBg4kQWAu26HjZWNeG6v/oqcO65TMmIRgQqQTavsuqlKx8+pXbyxae9u62tnu+9vb158vCHodLGuTqfIFzR9nbWuUGle3rY/wD7u3QppVRjPnxFqOTFN0XPpk3JdNx444102rRpDd9t2sToD65vfpPlr//1r180Suvhhx9Ob7nlFuVyEMnxL4Jw3X/4w6cpIYzVSiV2pkTAhsD4Z6ik3C2cthreHc714eJEJxuQbWPRRGvOEa3o7t31/wGvj1gTOWVLN4466qiGg8x5nJxXXXUVfv7znzd8F3YIEwK88Qb7/3e/M+soXbNmDa644gpzL+BAuO5AndVKpXqmYMaGE6Td5E1h0rHpoIyaNbq7WY7wsDywJQds2uhl2zh36Q/CFQ2fbxiEa82bx9fojmL4bMSu81SNx7w0btw4jIt8GTadBGMqrQxdyDqcXfWgcx5E90SsXl3f1X/55fWxt2PHm1ulXyK7NFC9skw6omYAG2aDJLNGcJRfT489s0VvL6UtLWy5195u592ixwQODLg1t0kjWoGMSu9j0vHNtpKCXbt20WuuuYZOnjyZtra20unTp9N/+7d/a7gHITNFULV3vnMOPeec+XTrVnZMIoCG61e/ep7+/Oe76Ec+cgU96KBO2tbWRg8+eBJ9//svGG6OwKQTNv188YtfpJ2dnXT06NF0zpy59Kab7qEA6AMPvDj83Nq1a+l73/teOnbsWHrggQfS8847j77wwgup9dy9eze96aab6JFHHknb2tro5MmT6aJFi4Z/j5p0Dj/8cHrdddfRT3ziE/SAAw6gs2bNqtV/K73sssvooYceStva2ujhhx9Ob7vttti2Cu7/1Kc+RSdPnkxHjx5NTzjhhIajH5MQ5qmofIHCEYdeCnxfhcTSpbEmXOsYGGg8JxaglBCz592GZV6aDIzru1zZ8CWwj8CPGqIFDji13VZXXXUVPeCAA+i3v/1t+uyzz9LbbruNEkLoqlWrhu8JC7Ggau985xz6Z382n27aROng4CCdOnUqvfLKK+nmzZvp5s2b6Z49e+jSpZ+nhxzSSR94YDV9+un/o319j9Errvjn4TnwxhtvpEceOW14bvz8579Ly+Uy/fznP0+fffZZ+tWvfpVOnHhQgw3/qaeeomPHjqWf+cxn6DPPPEOfeOIJ+sEPfpAeffTRdMeOHYn1nDdvHp04cSLt6+ujzz33HK1UKvQLX/jC8O9xAn/8+PH0xhtvpM8++yx96qmnaLVapaeffjo94ogj6He+8x26fv16+vDDD9MVK1bEtlW1WqXd3d309NNPp4888ghdv3497e3tpa2trfRb31qVqgcEPBU3nppO4PsiWKMwPRHxDvalS5lmHxb4ptoqWuesQ70b+q5UpUvnrtbbUB7OHro0fNuKzvbt22lbWxu94447Gr4/99xz6RlnnDH8OUvDpzT+MPNPfepT9IwzzqDVajV2Drzxxhvp1KnThr97xzveQ8877yMNZVx55ZUNh5DPnz+fXnDBBQ337Ny5k44ePZp+5zvfia3nb3/7WwqA3nfffYltESfwZ8+ePfx561ZKv/WtVRQAXbNmTWI54bZavXo1bW9vp6+//npDOe9//0X09NM/kMoaAU/FyUIVge/Mabt9e/LBFVknQLk69ELHTtsk2kWcm93d7CSvUom1UUuLvB8xqy2jNviVK9Odt8N9V6Joq+5A9yqN21JXrABOP93/ra6S3lPbwQfPPfccdu3ahdNOO63h+9NPPx1PPfVU7DNB1drb2dm2aVW76KKL8OSTT+Koo47C9df3YPXqldi9e1fD7txSqe6ofP75p3Hqqac0lHHqqac2fF6zZg2+853vDNv/x40bh46ODuzcuRO//e1vY+n4xS9+AQCYO3duMrExCA46DxzQP/vZOkyYsD+OPZYvBH7NmjXYtWsXOjs7h2k9+OBxeOCBb2DDht8O+yXSwHMangicOW2ffZYJt7gcKGlZEF0feqES951Gu4hzM9o+wfOizluetow6a88/H3jkkWTn7TBtSx5G96rr0VV9FNhVVvfWVirsRPo9e9jnoSG/PcBh7ymnA9fV7ujo4d2U0obvCCHMHFDDuHFAqbQbra3p5Z5wwgl4/vnn8ZOf/ASrV6/G8uWX4c47b0B//88xbtyEWtl1R2W5DIwalX4+bLVaxUc/+lF8+tOf3ue3jo6OrKoKITgjN+yAJoRgcJDPH1+tVvGWt7wFa9asGf5u+3bghReAcrmNKy2F7oywzgQ+penCLUmw5i7qI4Q02kUHe7R9ZNqApy3jGG7GjHQG7OoCupa0A4/8ggl7HdKrv78+6gAmHTwLi4yFwBZN2+mejzrqKLS3t+Phhx/G8ccfP/z9T3/604bPBx10EDZt2jT8eWhoCE8//TSOOOKI4e+SDjMfN24czjvvPJx33nm49tprccghh2DduocqfFTcAAAgAElEQVQxefKfh+5h13HHHYdHH30Ul1xyyfBvjz76aEN5s2bNwhNPPIFp06btM1El4aSTTgIA/PjHP8YHP/hBrmfCCMIljz12Jt544w/46U/XYvr0WZk7bmfNmoXXX38dO3fuxNve9rbh76dNEwvg0rm50JnAJ4Q1oqgsUNGCXKdfSKPdRW533raMm1wy6dNdocCONTTEGOf22/Mx0wtuf7WZq2nMmDH41Kc+hRtuuAETJ07ECSecgPvuuw//9V//hZ/85CfD95155pn4yle+gtNOOw3jx4/Hbbfdhl3hmEk0HmY+ZswYHHDAAVi69PPYf//JOPnkE3DggWPwzW9+E+VyGW9961tj6bnyyivxoQ99CCeffDLOPvts/OxnP8O9997bcM+1116Lk08+GRdeeCEuu+wyTJw4ES+88AK++93v4rLLLsORRx65T7lHHXUU/vqv/xqXXHIJdu7cia6uLvzhD3/AwMAALrvsssx2CsxYkybNxj33/AkWL74AV1zxBRx11Nvx7LObMDj4DBYt+tt9nps9ezbOPPNM/MVf/AU+97nP4R3veAdee+01DAwMYNSoUViwYEHmu7VD1viveh177Exp35uM386XyB/ffI6+0ZMKT4lN3WmrM0Qza+uqRBk8YZmbN2+m55xzDh0/fjw99NBD6Ze//GU6Z84cOn/+/OF71qxZQ0866SQ6atSo4bDMa6/9Cj322JPo2LHj6dixY+msWbPod7/73eFn4nbaLl++nE6ePJmOGjWKzpkzh379619vcNpu3Urpgw8+Qc8++/10v/32o6NGjaLTpk2jCxYsoIODg4nV3rVrF73++uvp4YcfTltbW2lnZye97LLLhn+Pc9rG7bzdtOlNesEFi2hHxyTa0tJKJ0+eShctWjbcJYiEZf7xj3+k11xzDZ06dSptbW2lBx98MH3f+95HH3zwwURaKU3nKSg4bZsmeVoWli0TP6y7QAEeZCZPk9mEFX1GR/Yui9nVeA4qF4UvyeG2bQM2bQLefLP+ne5Dzk0dYt4UqRV4oNvbrQNxETI8EUiuopScw1TFTTdoWqL1OMTlJYgzDYlCRxmciKZI2LVLPTWCRfJTMW4cMHmy+TMBTMCL1Ao2bOu+nX8aFyEDZEfNuI5ScgZTFfexQeMkm44z+Cye4xfYvYM0x7//PftfRSv36RhC22fu6oJzgW9zvPlyeAmQHHOdFTWT5yglJfT3M4dttao3JNPHBk06fVxGwkRNQxal1Lhx7FWB1Vg1H45O8nWkOrJ55q4uOBf4Po43G0iKkMmKmvHpXF2r6Oho1Hp1xVzbbFBeKZMk2UQlTJLR26KU0q2V6yDfF1+ACzgX+KbGW5KZyIb5iOcdSSamLLOTb6YpaxgcbJQcg4N6yrXVoKJSRodk8+BEFB9NHx40izM4F/gmxluSmciG+ahSAc44o/6O1avThT7vhrOse1zvMTCOIA7fhCauwdZHI7tT94ELKePQ6B1dzPgkUH3yBQQIt9fYseYiJ50LfEB8vGUJtyQzkQ3zUV8fMzED7G9fn3kBbHwi82E28WlpE2mP1tZW7NixA2PGjEl+xoWUcaRe+2gyEXFl2D7KINpeU6bsQGtW3gpJeCHww+A5mFs0/0ugDIqaj3yQczwwOpH5FMXig9c9pj0OOv54vPTSS+js7MTo0aPjNX1Xto009dqQZNOxmNFJmogrw8VkVW8vimp1B9avfwnTpx9s5F1eCXwe2SKb/yXte1la4nDiiemfTcCo37GZveoyM3pMe0yoPbtp0ybsDp93mYTXX5elWB+GhoCXX2YhNIQABx/MTGaaih4crBfd0iJWZd2kvfFG4/t37QLe8hb1e8P07twJjBolR2fQXnv3Aq+91opp0w7GhAkTxAvigewWXdUrLh8+Tx58kykSwjv3ZXPyh3PVl0r2cvkbyzrgS04K3ZCtV7O0R5jBCWHHKWmECj/qPg9DpMtEu1cXO4i0F5rlABTexjMh3EQP+uAtJ6/yoAGmZhObuXGi71KRKp7m9BHCwAA7GzM4PaetzZv6mBhDIl0mcq+Lw5qaRuBT6m4s9fQwRSfccbK0NIM8MA6bM2PSuYuyM3pa5+ap8+OY3hPkpRldKHgqAt8rGz7gxi9XqQB3313fERikWpelhee5vDiEjcGmbyDuXYsXi0f9ZDl2fHJw82DePOCee4xvOqtUWLTali3ApEnstTKhx7pp0jH+wn7Bjo76jnlfu907ge8C/f31g5QIAS6+2Dyz5UkuKCNudNnc4Rq8a2iIdXCwS1dUqmRNUnlzcFsIda1UWNHh9Pl33eW2aXSPv+DZPIzpEZMtMw3hTJqjRjENxCSS8ug0JZIO6w2EjcoBwbzo6gKWL2cdXK0Cl18ulxkzK+WqjylZs9DVxVY7htq/vx+IBi7t3g0sWeIu26uJ8ZeXMc2l4RNCzgLwLwDKAL5KKf1s5PcpAO4BsF/tnk9TSh/QTKtWRJVOm3t6RlQ+nDSt16b9bnCQCftqVU37nj+f/Y2zS/i0OcwWMmwj3d1Aa2ujhk8psGoVOxvZhSZsYvzlZkxnGfnBBPh6AEcCaAPwSwDHRe5ZAeATtf+PA/BCVrlJTlsb8CGSxqpTivdlNsKfgrJ53qWTHtVO94FpfANnmwwMMP/wuedSevLJ9bBlWT+xDrYwxeo2xjRMRukA6ALwo9DnxQAWR+7pBXBN6P6BrHJdCnwXoVTOIBLramODA++7XMfmRaHKNHkJOxGBRJv4Nu/msVtUBD6PSacTwIuhzxsBvCtyzxIAPyaEfBLAWABn8q8x7CMPyy9tUTz9/Xx55E06HKOmG553maBHxYSkwjTN6qWXaBNVq5dOtvClW2xG7PEI/LgUgNF0bn8F4OuU0s8TQroA3EsIeRultNpQECELASwEgClTpsjQq4ygcZcvZ2ZdH02tWhmRN4+8i6gZ14n/RUaaiqTKW/QOLyTbxNW8G0alwhzHgS7kqltsTzo8An8jgMNCnw8FsClyz8cAnAUAlNIKIWQUgAMBvBK+iVK6Aszej1mzZjVMGrby1Ms2rs1ZWKt84M0jb9PhyPMu0/TIMIOspMrDklIWaW1iYNDoYIug6wNhXyq56xbrukCWzQdsUvgdgCNQd9oeH7nnhwD+pvb/dLAJgaSVG7bhq/j1RCBrhk3aqGnK9qfVTtkMzkYTjW3LkRPQ3tubP2OxCjzmu3DXl0qUzp3rjjyZZoJJGz6ldA8hZBGAH4FF7NxFKX2KEHJz7cX3A7gSwJ2EkCvAzD1/UyOMC0kxrHGHfCfN7DzKhKyiFaWvr69xg6LuZVisFiOrLeU9VNDUmteWycgHI7ELeGzGinb9kiUj6JgH2ZlC9crS8KMKWE9P8kwomg1PVNEKyi+VKG1tZeFlVqN8PNaWjMOkJm46RGNEhYNF4DnP+hqdw0MX8p5LJ2mWC8/CQLLCIKJMyJhhg42al17K3vHAAyzHd0Cjcdufx9qScZjUxE1v/Gpm230cXO5mFISLnF1ZsLEg9ELgA/t2QJRfgOQ8TzbGVXCgQ7XK5O6CBcCUKZZ4eaQJjjA8FxypiGPiZcvyVw8eJEmrZqunQdjQ67wR+HGI8kvSuLchE6IylyfjnzYES4yVK4Hzzx95gyjPgiOgvdnt+SN5FaoJNvQ6rwV+FGnj3nR0mFNFs1JhCb927WIJSGbM8Hcwjfi8zwlodoHoYBXabKxmQ8bkSuCHwdvZ4ZjbUgm44w5g4UK5d/IomkaYMC/CwqYWm7fRniUQ81afKCxrRM26YDK9mM2lwBfp7P5+dsBwYH9ftMicgmyMCX214UeFVNrEpFOg5XG0pwnEPNYnDhZNb1k6kC52y/s8HEUuBb6IwtvRUT/JCmDPJN2v2rlGFHFfc0HECamkiUm3QMvLiieKJIGY1/o4RJoOpIvdmmUeDiOXAl9E4R0cZIccBUI/OL4wCh2dG6Wro0MxKMNnjosTUknHBuoQaOHZ2NcVTxgi2kMe6uMZ0hZMuuZPnnJytwKQDeBXvVTTI4ukeA82TbW0sB3ucdC1Rya8k15534nPG3dEd7vpzonr684ZSuXq66o+PrejJHTt+coqx9XeMpjMh2/qspkPn/esDZ2dp0VWe75bUUhYuMxFzwtdws/niToM3/lLAbq6Mq2cnh5KCbHfzSNW4OtWTnw6YMkIUXmFDcGk8x29vSwHR6mkrmIWqR+8xMAApe3trOkAStva8qHh59KGD/Cbt0VTnuuyw2mLUsvzpiNdyGpMHYZUXYbfYM/E3r0sDnj5cn89hoXvQBr9/cCePex/QoCLL9bbPaZ8A7kV+LwOFZc+z0JWa0RSY+rqZF3CL2DMapVJgqTzB3jLCadozZIAolIiz2krHCNu570umJRb3gv8JB7mGZ8jPtpNh5rAU4aue2Sgq5Oz4uRtR9yEyymXgbvvZiplkgSQlRKFViIFk3OlUbklawtSvXhs+Dxe8jQTZxP7pOxUXtdh4yY7wnQnu4y4Ccrp6cm2tbvyIBbQjiyWQ7Pa8LNmuizlRHUW9jbGlkeb06Em8JSh6x5ZmDZLyNCuS2sOyqlUklPFAuz3u+6qbzZpaSns8TmGSZb2WuDrWB3Ljj3X9v9U8AghHY3HU4aue1SQ1ckqM7cPjs0sCdDfz3gBYH6Diy7yiFkLyMCUpc1rge/Sp+S1/Z9HCOloPJ4yeCNoeFJDmFhSqc7cvjg20ySASQ9iFN4ue9WxYkU9A7lsgkXvIWsLUr1sbrySgff2/zzE59vcjZuEkRJrboMfdPaRZ/zb21uPqQeSd+T7ADSrDd8lfFHsEpGH6AqRZZKpJZVuk4yvGq4oP8jUQ+deBc/spStX7vtZp5bvC9uMOIFvciOWL53qDUSErSlbuc6Z20NBJQXZeujeq+CRvfT884Ef/7jxsyyicsAntnEm8Ldvt3+8p8mG11a2rVnDxntEhK3JJZWu1ZCHgkoKsvXQ1Uc+OMIjCLR5VRt+nBzwim1kbUGqFyEzrdvHTZpzc5UszXsHhQB02IJFU6/60m6ydfehHnG0h7/zzMbPizg5oLu5kcfkacBM63407/f/2HIwNosjU7TRe3spnTu30SOXVEaSwOFNvaoirGykd/VNoIbr097OspH5MrEKQJSdZJBLge9Cw6fULJ8rl11o+GIQmbiSwjB0q2Q6BDHP880yaQcI7xQmJNe7hk3PpSoC35kN/5hjWLiwbQenyeAW5bJthQZ5H4LECRFbcFIYRlwZKkZX0WdFzgWWrbvvqFRYriAa2ilMCGuDHNbN5wA6ZwJ/7Fh2Il7TIzyggWwhy8MtOhyuPnMlL0QmrqQwjKQyZIWpiCAWORc4imaZtIF9cw1/7GNMG2yGunmGEReWaRXhAV0uM2ZOy3goWqbrGK+AHtWBKVtGXPxbUjlB2MXXvgZMngzMmFH/LTr5qQhTkWfjtPmkc4GT3tUMwjBup3Cz1M03yNqCVC/fd9qGIW2TC9tZddklfbLd2srIyfMczyHCun0XOpyzzeBL0QHfnMgeA3m04ecFSgp1NKd5WMPnNRNEtVafbLc6Aoxly4g+t3Kl3aydOlZaMiuJZt3d56FG34xNnSuB76IDlGREdEAHBYoM7jih4oPttlIBNmxgExlgNiNn9L39/UBHR+Nz558PPPKIvayduiYPEUGXxA/NKJkcwzfLqS7kRuDr7ACrBxjF2Yd5kSRUdGpDMsIi3BktLcCCBXW7qyhEJrAoE0QzcM6YoZbZUwQ8jKFbEMfxA9CckskxvNodqxHeCPyssSHSAWlliU4cThVq0+Yb2Vk03BkAMGWKWsPwTmBRJhgcbAz14ilHdbIMM1dWWmjdglh3COlIWRlI1JN36JlqQmNdI2v8V73CTludp+Rl3Sfi83TmR7K1xVzWAezK2ejaySnyflPO9Sg/6HJ659FZanhHclbxMkXrIBl5d9ryKClx5vC45GtZZYnM3E5WynEvNrVhQXYF4WrZ49p/IaJNm1IRdYWQ5t1mwTtAFeqZtRgULdoCydmQnSlUL1ENn3cG5F0tZM2yzqIfbb+4CIfjx8AAy/NCCPvLw6imD5qXhe8aflbb8Y4Tg/UULVoXyci7hi+qpKTNgDxl8ZhxnUU/2n6xjE17pNh+40Bp4980BG1bqcgtR03C9WopDTyqsOiO5L4+7ST29/Od3ClLcpY1QwqyM4XqpbLxymaOMec2fN/gu2ZoEjKrr7RVgSkjcN4hogo7SGutmltPpPvi3oW8a/iisKWcONsL4uEmlGHIGC51dFRSOTZXGzKrr74+YGiI/T80xD6LLEfDaNbg8ChEVGGZ6C7FlVRScTysKDq0kyJxZZFLgT+SLQpCMNFQqsnBZOgIyhkaYhu9br+d5caxLQBNaBoiEiDvjlZe6G5nzWbSuOJMsaJuC2/uBP5IUXKUYaqhRAajLgHV38+EfbXKrksvrW+ysi0ARVW0efOAu+4Cdu8GSiXgxBPF3heetH1KqxEHnQqGjlUu754JCdKixS1bZoYVtesYsrYg1UvWhu9T7jAh2La9+tBQumynAwOUtrbS4cNLSiUzZ8fJ0MXTp1dfzWgmRD1WnjeQWyev8b5TJILJNCzzhs3XIY8nXskK/KBhSyVKW1oaT6vzFi4Ek2thGKZDh/Dp7WUdXiqZOztOBCI7AeMmKx7IOol5+13nxqWennodAfbZJRwoPLZYUUXg586k09XFQqEWLWLLp8svZ9+nhUY5t/kneV5kiOKtjC9hd7oc0AsXxufKceXg5jUn9ffXU1AAzKzDm3dHxoTDS5fuXUBbtqR/tg0H5i+fYy0C5E7gA0y4B+bcoSFm0qU0nm+9sPlHma+jQ44omURAvnOgCHyqT5JAiUtn3d7e6HCO1iGpX2UmbV5BxyvIecubNCn9s204VnicK5kJyKXAD/NgqcR4tlqN51svAhuizCdLlBeVKQAgXqDIprPO2kko0se8gk52F1BSeWHndGsr+2waWVLVkYLghZKZgFwK/DAPdnQws04S33oT2BBlPhmivKlMAQD79mmS4M4SPLr7lUfQiWjAvOX199tTaz2Wqj7rZbkU+EAjD6alQffFlN0AWaK8rEwTQvaMANkDYVz1q24N2KZG7bFU9VkvI8zpax+zZs2ia9eudfLuAjmELaOojOYYPRDmoovkD4QpwAePNXygkV0BvaxLCFlHKZ0l82xuNfwCivDVqxQHm4NbRnMMPwOoHwhjGnnq+yQE4XorV7LjLT2rR7DY8W1eKgT+SIRvXJgFm8t3mfW47BreheDNW98noVKpO+8eeYTZdR3WI6krfbM8ORP427drTPnpCnnVlHzjwijiQhttGUVl7Okyz8iajlT5zUTfuxgHafWwTE9aV4ZZt6WFuXkqFYfDTXbHlupFyEznm0CV4MtOVhnoTHmge2thEm1xR/v5kiZYhhbRnaA6+0wn37oaB2l8YpieaHdndeXAANt43Namhyzkcactpf4qmFzwXUtOg46oEFOmgb4+YOdOxiBJoY02zRJZ2qIsLaKrFl38pjsiyNU4SKqHYXriujurK4OI1b173YsLZwKfELZpSnWF7syq4nPsFQ9UQ+hMmQbuvrt+mlS5HN+u4Xfv3NmYY14neIS5bDuICl6d/KYzfNLlOIirR1LuYk1Cor+/nrh1aIh9Xrw4uyu9EReySwPV69hjZyqvyI2s3kSW5z6ZFUSgg24TjR9eGxOSnIAryMwYJOpqazPTBzxmF14TlA74ym++0RWmRzOf9vY25ogTSd6oq5kwkrJlhqE9IV6e7fK80FlHE2l4eWnr6WGTgslsiCIZMaP+BVt85Juw9Q2KQiLOXl8q0eHEp3Pn2m96FYHPZdIhhJwF4F8AlAF8lVL62Zh7/hLAEgAUwC8ppR/RtgxJgOjhS5mrurj1Wl7s8rzQaYoxsVOT98DpefOAe+7Rs0ZOYg5eswtvigXdaJYQS5NQsKUk2euDXHjVKrBqFYsKzU3TZ80IYEJ+PYAjAbQB+CWA4yL3HA3gcQD71z4flFWuDg2fUr0pvZXWa3mB76sY3fncdb6PtzydIRlp8OGQG0rdrDIsmF6TmndggGn2gaZvu+lhWMM/GcBzlNLfAQAh5D8AfADA06F7FgC4g1L6Wm0SeUV9KuIDj5LJrXANDjJPcrXK/g4OGqA4BBceZ9/z8YhoxzpWGDq18WiKhQULzKZY8MET6GKVkXTGcRIk+SSpebu6gCVLmGbv3AkrCB6B3wngxdDnjQDeFbnnrQBACHkUbEWwhFL639GCCCELASwEgClTpsjQKwXucRGs12z0osvluM0kV6IwKcR0HTKSBNspFnyYvF2EZYZNr+EzjjW/N615fWh6GfAIfBLzXTTjWguYWacbwKEAHiGEvI1S+nrDQ5SuALACYMnThKkVhPAZxrZ6sVJhKkLAtKIDRcfKwNddwqb6QOchI0lwoXG7nrxd1Lm7m2n21Sr7XK0am2jSmtd100shy+YDoAvAj0KfFwNYHLnnKwD+JvT5QQDvTCtXlw0/Cd6aqsOH8gauftWDrWVp8K5xDMKWvXskRs1EwyBF6y/zTNIZxzmBCpvAZFgmmPb+OwBHoO60PT5yz1kA7qn9fyCYCagjrVzTAl9qfNsYrGHCZOK6os+ffDJzEprc1p932HSkjmTIKBIqyoeHk6vWIJIEGBX4rHycDeA3YNE619W+uxnA+2v/EwBfAHPkPgngw1lleqfhm9R6VTaCJMV4BysEmc1HI0nDD9e1vV18cizADxlFQuYZTwS97PYLVX1LReBzxeFTSh8A8EDku8+E/qcA/q52eQEe02yDGduU8ynOdsxrM047I3XJEuAnP6mnIdi929y2fp8g6nuw7UgdybCRWtqTvQdxZPCKEKfBVbIzheplWsPPwj6zce8TZrReFRNOmipgK72AT7BtMiggDl6bhmzmU0/MkXFk2NpCgjxmy3SNfWbjwRno0qH1JuVyl9mal6YKdHUBq1fXd6WmxXv7GpEjCplVWJ5XM3kDD5+lRUvxwIe9BwlkiLCaswgf2ZlC9fJOw9eh+CUVqrI1T9Ve2UwabjPVpdlg2oCtGglkAK7IQKHhi8OI4pekgfJszUvL5+JbGmNXKLR1fxHls76+ffupUmFHPpXL7DOvhh63Kli82Ew9BJDHOPwRIfBNydJ9kGWCSRJWJh1RniyBtSFPo0zGlJZX81uYz8pldq7Bnj11fgbk0040k9IiCN3s0PQC36pTP0sDTRJWJhm60IrdQPbMWg8iUKQQ5rMNG4A772zkZ4A/WsrlmcYewQQ7NL3At64cBEK9UuE/pd00Q+dJK24WyDBe3jXZMO/Hpa7m4fG0UOQmV1qi85wJdvBa4OtYzmiVpbwEhZm2XAYuvjh9+aqLoSsVvqidZgdvtIhJAWIjJt1XJPEzD4+n+cGamJ9lzsqVgqy3V/XKitJR3ZDK+xs3RAgKRyIEx/XZOPmora3+zvZ251EMTsDTT7aifWzlleEpr7fXi8iWTNgKZvcMabn3o1VEs0TphJUukeVMlq1Li3IgQlAwNe/cWU9+YHqJ3t/PdtsGyKNJQAd4+klmrSyzIpBhvOD+wO6t0n/hvPHBGQ/t7X77BnhXu3n2d8QgLfe+zmp5I/Cj/bd8Of9yJikirKODnWGiZdUusr4KmLavj0Ur7N4NEMIIMoXubqC1ldEH5NskoAKefvJ5O7/qu+K0pnAa4TwoAjxSLu/+jghsuSm8EfjR/hsc3LcBkpSs8PhtaQHuuotFhGlVakR7JGDaE08EFi1iFbv8cv6DGkQ1ysDLkwcbvkn7OU8/ifalTeGi8q44ramlpR4ZA7DPzaAINIu/IwQrbgpZW5DqFbXhZ5nueH5fupQlQwybz51nAJbNBtisO0p5O5L3exuw2R8q74rjtZ4e5kMKfEk9PeZoD8NGfzWRDV8EMJ0e2cQV57RN6z9euRnNHuz8fASZAexJgigjyEoIF3Rea2v9EHkfJkCbwkX2XXHtxNt2OuvnQ381MVQEvjcmHSDdX8W7gguv1rXa8GUhY5yTsTH7GqMssommvz/+rNI0M4etutsMC5R9l2g4ZNB2HR3M3CjjN4hrfx/6i4fOkQjZmUL1StLwZVb7TQneyvqsTaUlk0sy27S21m1xpVJj3tlSiR1r55PmH6bdd+aMJiAL2i44KlAmoVl7OzMVhcOA0/rdRX/5xCcagGbR8LP8VU2+96IRvJX1OVohKXyquzs++VVXF3D77Uyzr1aZtz3QyJYv39f5zVN3G5qdixBB0XpFaZw/v952pRLbIEiImAO0r4+tyAD2t6+vzrdxqwpXvOrzGLEMrwR+EzrezcN2o4kImqyEWnHPL1xYF+bh8KyVK9mADYcWZtXdliC2JVBUTDBRGoHGtlu+XK/9M05hSeovH3c9W4BItcP3KkF2aaB6Je20zcPKeBi+EGuLDpmlcVz4lKjZIM0Lr8PTrwobJoPwO1pbxU0wSQ5d1bMW2tqYSYf3xLXoO33e9WwQvBvCg03Swb1sM/0Rr1BJueudwM8NmswuyAUVASrbXipHRNoOpzQpUKLt0NIiXi8TNKqW2cwRaSlIOiIxy8XCrpmUNoMNPzeoVNiBJkFEyUixC6osjWW3EkbfuWSJWGoDW1kWTTuYou0gY4IxQaNqmbbMLZ5F6USr3dGR7WIJxL0KCoEvirj8JFmM6hmzSUNVgMrmlrH9Th9hc/IShQp/26iXZac6T3NEq83jYnn8ceYGGxpSEPuySwPVy6VJR2kVKmpicG368cx2WSADeesvXfxtst4WzUayzcHrYhkYoBTo3EgLkw4flCd7URODzggO1VA800m/fNQ+84Q8ZoDUwd+m620xSke2OZIWOtFn2eeXtsjSN+IEvjJ/ii5BdTGbzKCwGS6YN0HFA9uTWB7jxVX524Y/LLr9vr+//r1mqLq5THd3rgS+NydgifSMLhulzCYjW5pNHgVVFlxMYp7Gi3cHXyUAACAASURBVKdChb9l/GEqdALKfZolg2Saw6peIWsLUr1Ebfg6TeF5M5NSSvnyToikMbBJWx7hKlxQR2y8a+bmpUEl5FYGin1qgs1lykSzpFZIg04lUnjp5IN9Okt1SGogG+tEXrXGh3ZMgqvVURQq/eWDaU2EBpWQWxko9qmJhaztxXFuBL6z1a4PgyhAmjBwbQ7IElQ+tWMUSbT5GgaZBB9MayI02G5jxfeZGGK2h21uBL6z8efDIOKBqi3VdMP63I79/XU78tCQ3dWRTrie9GVosN3GCu8zIYNsy7XcCHxArK+0yTAfBhEvZJjZlubtczt2dDSe+/r66/Zp0MGwPqxKfKDBIJKGmOreM1vNlCuBzwutMqzJGdia5u1zOw4OstTAwQbGL3wBOPdc/TQmSQWdDOvDqsQHGizCZ2tlFE0p8LXLsGZmYJ2aN0/Mmo/t2N3NDvfevZt9rlb1T3xpUsFnc1eBTOSp+0quCTCBQIaVy/5ZD7xDoHnfcouaahIItBtuYH8rFb10mkRXFzt4paWFafrlMjPz6EScVAhQMGyuIdN9lQqwbJn9YdKUGr7P1gMvoUPzFlVzfAvRXLiQ/b300sZTtQA9dKatpAqGjYdvPJIA0e6TNQEFzQGMHytNrGwAv+qV+3z4PsLlphuRHSS+btQKb8whhNJzz9VLpw+bovKCpHOMmwAy+7/CQwY4aS9t9o1XBTLg2nMkoub4avQMbPl79zIH7ve+x/7qyvHiqw9DB3Rr4+FQ2WqVnWc8Y0ZTtJ+M2yw8ZAAQ2Xd7I/Bzsnrjg4vK+CBEeQWar4dedHUBF10E9PbWT5uQOdx7pMGEshH1oezd649ioIg43SiLVcNDZu9e5Dsfvq8rfCm4qozKe12YGky/U1di8t7ewgwTRly/ydookto16ANC6ua13AuGZPCyatBkwPhnqKTc9ULgN9Wxli4rEz0Uk0dQNdVsG4Lq+bsjUcj39rIEZkn28rQEfSI8lHW/rqRqhvpRd7GirAqF5GleCPymkjk+VEaEhqaabUOw0Q8+TAy6aOjtpaFTsuOFfhqviNCRxXM6+s5Q/4tq4zyvFSVVReB7YcNvqqg005XhsUvz2vMrFWDDBmanBprLTm2jH3jt1qZ8Ojpt5ytX7vs5CFUNkBVayvvuLB+Ojr4z5NPiKVa0W6zKP9mZQvU69tiZzpWj3EFEvci6L3xPezulPT12/Q1xne+DxswL3pWRyZWGztUZj4ZPqb4+8tWHo6FY04tm5NGkQ8hM7WOgGeRIKkQ4KavSLg/40GEHdg1eek22s+5Db7Js+HmDIxu+aVbOpcAHZmodA7mRIypMqLMyustStd/m0ZfAU2/TDBilwTuGH5kwqWSqCHxnNnxC9B5hmWRb8yE8fRgqNtfADrx8OcvuqGrs02U4FK1Tkv3W5/TJSYizW0ft9artLJqQziuGH7ngYQ0nkJ0pVC/dNvxAsYnuxPZK4ZHVYr2qRAQ6Y7Bd2t5U3z0wwPwgbW16UzGI9rvPvDKCobNbkEcNf+xYYPFifeV1dTHld9GixtxXSgqW7ilZVotV0dpMqxUydUqK6HCVekA12iV4fufOek59Hdq1bL/Pn8/+zptXaPcWER1q4c++LLy8CMvUhcHBeuoN5XO8TWwXl519ZCcKG/l1miGmVjXTZ/B8IOx1pWIQ7fdof8+bp/Z+Hnhhp3CPaNMvX86UzvBnHyyWTSXwtZqBTU3JMrOPrFC1pVbkPSmYCOPETaLh51taWD4eHdq1aL/bViPj2iKgw9UeFEeINv3KlY2fBwflhrD2KsvaglQvU+mRtZmBm8EW2gx1sAXekMSoz6Knh30Xzbnjwh+hu79FQ3t7eszxm+e8HCWvt9fcZmHkMSwzmlrByzh5bwkTQDPUwTREhEl0w1qck9alcNK5MUpk897o0UzgmwqtzUHYblyErEpXJFVZReA7N+nwmJmdreTybqoAmqMOpiFiCgmbWTZsAO68069YYF39zVOHqMnpySdZrDWl+g3VOQjbjTa9amimkSrLzhSqV6Dh28ijVIADI3klIMtkudntJwHROiTFReumKcc8KhtlG60y8qzhR2exjg52uG80AMJ1OFNTw/VpWaLIUpNWrGBes/PP3zcBWBxkneJJz8mU55tDUtZhXK2yKKXBQTM0+dA2kpCRZbqr7Fzgh/mqo6MxlCkaAGFiJefbOOOGTsLzNKtmTU4rVgAf/zj7/8c/BtavBz73uexyZUeWjhEZrlO5DFx8sb4YehU+0ZkBs4BSdLU2GcWzDABwFoBnATwH4NMp930QAAUwK6vMuCidJPNOsKzRffhQblfeJqIxTEZX2DwtYu5c2pD1sVSy37Gi7Rmuk84TnmwzeM5NLjYg2kRxXQiTJh1CSBnAHQDeC2AjgDWEkPsppU9H7hsP4FMA/kd28kmaAYNZTbfVIU+KbQN0E25q85QJU1GWmnT++UyzD0CpnY5V2VYZ1CnYqUup2526ssiTycXR0l60ieK6UAU8Jp2TATxHKf0dABBC/gPABwA8HbnvFgD/AOAqWWLS5I4J3s3tKtQE4SYGq4lOy5qcFi5kZpx/+icmOEeNMtuxlQrQ1wfcdRerp8y2yqBOfX3A3XcDe/boWfPnlsENI25brI6EhAagvQuzlgBgZpqvhj5/FMDtkXtOBLCy9n8/Ekw6ABYCWAtg7ZQpU4SXQiZWp1Kr0CBRls1DQ+Jo8H353Azx6FnvGD26fth22Mwk+34da36V8nTS5iuiZ+a2tnpt1402O0xuvALwoRiB/6XQ51JNyE+lGQI/fMnstPWC3wYG2IabYIC3tXnJJN7Ai04zBFO2d1kaTG5I4t2IlYe+DtelpYUJfY83dEWhIvB5TDobARwW+nwogE2hz+MBvA1APyEEACYBuJ8Q8n5K6Vq+dUY84lKLO19xBWaKALt3m7ON5jaEKAQvOs0QTOXQkaXBpNkmyzyXp9DetNDAJjd78Qj8NQCOJoQcAeAlAB8G8JHgR0rpGwAODD4TQvoBXKVD2HvJP8EAGxpin1tbzTCJtw1QYBg+ZAq1RUPWxJK3CIiwIjJjhrH2062zVSoA0DlJ9vlMgU8p3UMIWQTgRwDKAO6ilD5FCLkZbGlxv+zL0+At/3R1AatXMwcbYE6j87YBCjTAhxWMDRqyJpY8O4gNtZ9unS0oD5jUKVsG18YrSukDAB6IfPeZhHu7ZYkJw2v+sTHAVBugGcxBBfxCGt/rXmk0Af/q1tmi1mQZON9pmwQfVstOmU6lAQpzUAEXCCaESqUxP4oomoR/s9LGyJa3YwelsjR5K/ABx6tlH5hOpAFUz1OzPbk1gQZXIAY6xk2TmDOz0sbIZLp48EHglFNe3pR9dzy8Fvg6ICpXhu/f8Ft05YXpKhXgjDPq3PTFL4qd4BTd8GN6cvNhMi1gBjqEtdf2XDEEOtuyZXrmMPbMS1tk6WlqgS8qVxrub/lrPFi+C134mTzT2dJi+/rqUUNDQ8Djj/OZg0wdvp2FJtHgCsRAh7D2wp6rF77MYU0t8EXlSsP9KKN/wT3omvLvckznWovlMQcFFQ6Eva7Dt7NgkvsLU5EYdLeXLmHtQ/STRngzh8nu2FK9gp22JjfnyZ7hoGWXtc0j2QYG2I5fQsR2/oYr3NaWnSrC5DZ9HWXnNv2pIxTtlUsgrwegmFaCRWdV4Vk4TTuyuYbr6mJ08BAepZm3wiY7S1fZhalIDEV7JSIYJh0d3uZVk4PsTKF6zZw5k1sJ9jJFRx5zi6hodDpXLKYOvy40VjE0Q3sZGGPh0xqD/Go+NQ/yquHzKMGuTeGJSNOOwlr04sX63qlqb1XR6HRuBIvSAehZDXljKM0J8t5ehoRDwJ7VKvtcrTbPAsipwOfhN29XnUkCMGDCoSGgVALuuIPvXNUw4gS7DuZWEdo6N4JF88XPm8cuHYLHtbMvb05j1+2lAkPCIZwuq1plwzjn0aHDcB6lk8VvvoQz7YMkAdjfX+eUahVYtIglZxLZQBUn2HUwt6pGJyscorQPDiYf/p1neLsc1QifJjRDwiG6YaqZbPjOBX4WvF51xgnA7m6mEgTrwb17xYRzkmDXxdwuNLo42vOsWSbB2+WoJvg2oRkUDs3InoAnAj9LachV43d1MTPOokVs4Le3iwnnJMHu9cwXQlxn+k67Lq3V2+WoJiRNaCLtZyLu3zd+8hmy3l7VKxyHn/dAgVioRA/4Ft3Dg+DYx7a2fHWmbgbMY9/xIq6tRNrP1WBvsj5BXqN0AHerYOOmSBXNw6XWItMwrlI0ZNHEUw/dDNjMGmfcSk0kSYyLwe6bGcoxnAt8F6vgggcSINswrlI0JEGkHqIM6JPTMoBNmqITmkj7uRjsze5XEYRzga/DvCvK7yOKB0QaR7ZhwgPZ1dmuQL2uGzbw18OX3caycE2TSPu58OUITDJNu7s2DFlbkOoV2PBVIWMWlE094y2SbJS6kgnx2EBd20mjeYHa2/Xbim3mR8ozTb4g4Mne3kzedLW7VmbYIM82fFXIKqWENP7Ngo8reQDpGp5o48RpYOHy07R317brcF0BYMECYMqU5A6T6VAfo3Bs0uTtIIiB4MrHxe5aJ4sz2ZlC9bKl4cfNoKJKkdeRREmVCaJmVDXdcPkAWxZ51wjUXrSIrqyeOldDNlZXXg+CGAgOclUNX6YLwiSWSpTOncv3PEayhp9mFkyaQUWVIq9t/nGVCVe8XGbarqxNPSg/iMCh1MNGgJh9WKVDVVcyutU6W1q314MgBoKDXGV3rWyXRlM4rFoFPPKIYU1fdqZQvXRp+GlIm+RFZmTvlZtoZXTbdX2LsVfVaF1mOjWZdbTQ8Bthya+UtsjmcX3NnVtfWfCwBBQ0/KYW+Dp51LVPsgFZxJganD40gq66pdXFpHDTWbZth60P/e8hbO9HawqBnxZooqrMmeBRZ7zPyx3NOjhtCDmRd8i0s66+yaPW3aSIdmlPD3N3ifgJeVki9wI/LRrQxMpbZbzF+kJ7n7AnXEU5qdlgQ8hFQzyTjn70QeA268SeYwwMMPkQOL10h37nXuAnKVRZipbMeFMN0Bg9ui5vAUrLpSpd2nKDWRND+J62tvrL29tH5kC3FZWSFeWU5xh4HrOgrxOJz7TRRrYghLGRTqgIfC+idJIc6lmOdpnAAZVgg9gMAuU96N77EFBViF7gdfP399fjzAlhMfE+R0qYgo2Y/+AMgj17kpklKULKVaw677uz+I3nd5d19G23cwRRtpg3zzVFdXgh8JMi6rIi7WT2nKjsUwk/Wy4DF18MzDvx1+i6/BfArvK+J1/pTmngMyf5BFvpjqMMCmQLI1PCUkQQZvFb2u+uBW4OwkO9zgYuuzRQvXRuvLJtw9/n2eiXvb2Utrby795Ic2JEX+b5ctY5dIdm9fQk2/CjMGGD5IWoozlrt2LS7zbMWK4iqHIC5N2G31QYGKC0paVuZy+V+AZFlMkLxk5GmkDQJZBMOIhMCktRekVs+NH/TfIlb6SGyETcZFAR+F6YdPKIxJV5f389IQfAbD88dqOoXToHS1cnyDIp6MotI9P+JmyQvBC1I2T5QYLf49rbpL2Ct93vuYf9fs89XtrxfUUh8CWQKnO6u9mxhkND7Gzb229XS2kwNMQctB0dGmuQY2QJBFUDajhHblg4d3Swwz54UgDrSMUsAxPO7Lj2XrzYnIDlmRQLZUgaTSvwVXxjWc+m8puuQd3VBSxfXj8b9/LLgRkz7BwYIAsb7+ERCLKCLzqTL1/Okqp0dLD21+Go5KHNp6yUtjOE8owfH7OW5gWytiDVy6QNX0esfZYJ0Yp5XUcyIFvE2vQ5mHJcy24I0Umrbd8N7/4P3wIFBGgKbuVIi58LoLDhN0JHrH3as9bCrpI0GZ0heLpgc5ltKg5fdkNIEmTi2W22Iy8f6WpvnSsXTpqCKgYZKUslZnEdqWZ/ZwJ/+3Y+k6gMdMXapz1r5byPpJlFRCjYWv42wzJbdkNIEmTi2W22o87JJUuYO4rfD6po82ATn+FM4D/7LHDDDWb6XmR8xp1jqUN716bMxM0s3d0s+qdazY4CsrUc8Xq3iQCSZnKZGT5NeCcJW5vtqGty4RHmjhyt0ZzzpVJ+9REdcCbwKTXb97y+saTl3uLF8u+O5X9odsSJnNFoZTmi8B6fnJQ6kSa804RttB1NtY+uyYVHmOucXGLoTWqicBV1HU5eqQB9fex/2XOFnEHW+K96ETLT+Z6i6Ol9uvbD7OPj63lBbw73np78Ju2KQtXDnmcvHK/D1PcNeLw0qvZXwntsxwuYzITJA+TRaXvMMWx2dKnUmVru7aPM4GH15Wz02MKWWtflfX0qu9TXaRN2FbbKsyLKQ8w570pBdaWZ0BY2myh4V4Ddu/d1zfi8WHUm8MeOVTOb6ICJ5V603O5uoAtHA/coLmfDXA2wc2qnTPGXs3ghu9TXNcptORNVDz713Rluw2yY0BY2myisJAJAa6tc8JwrNGVYpghM8WljuRpspXGZMn3jpjTwGFlF2sZlCgWb74m2D2AuvM139TSBV2z6ubu6gNWr4234eViMNeXGKxPwwlzsBRESMGVk1dEeedqYZpLWZtg45xhBE5ZKLH9ib6+Z9yCPNvw8wZulWtpyxGftzJTqo2N5lqewVZMqpC311JvBpB9dXfqyoZhC7gS+C7nm/VItHF9aKgF33AEsXOiaqjpEzS+2O9n3sNUAJo3Vtgzh3g8mNQwOsgAQXzd45Urgu1IOvPeb9ffXQ42qVaZi+KRaBNptYPhMQ1wnA/6uXmzC5GrE1kpHZjBxKAA2dASed3gvK2RtQaqXjA3f5pnRceeRODc7JhEhe+iK6ntFy+CxEff01E+JL5fZZ9/j0KPwglk8hkj7cPCNDfeDyDtMdz+a1YYfnVFtzZ5JKwmnymXa8qari5lxAuNhe7u+xtG1rOJZylcqwN1310+JL5fZ3zyZAJrYRq0NIoOJg29sWIlE3uFcVqSg5JqAJATj5oYb2N9Kpb7qvOUWs+MornNlUKmwCLpKxQJRCxcCDz8M3Hqr3sbR1RjBbF0uJ8/W/f3Anj3sf0Jqp8TPy37OJaKdrKu9ZN/fbODgGx7WskBGPiC7NFC9skw6Ns03UXgTQWfzLNE0GnQeCp51jirvYe4+II5e2+GNps+Xtd3uce/koMMGqb6wIZrxEHPXKURUO1d5wkoSJi44TtTmqpovJS+nVSR1sq1+snUoelubnQPDXQ/6nEBF4Htrw7e5ey7p/U4j6OJMAybPEk0Db2Oo2K/DDpvubnd2cJFwj7hOthlSatKpFea/vXuB3l7zB4Y3ecimD/BW4AP7yhmf9xZFoTxheR/fFQPZARudKObP1z/weZhHdMKKS3tgc6IyqRUF/LdzZz2ZrGkhbIHn8yRDTMBrgR/uHCB/wQ9KqwTXSxwZqCRCC/YRDA0BW7awDWSU6hn4vIJcZsIKd/KyZfY1VJPJoIK9E3ffzZzpphUPwzyf5wCqqCyUhbcC34bS5z18ju+Kg+yA7ehoPIPuBz9gHV0qsb3qqm3AK8hVNcw8rsrSEPDfvHn2FI8Qz+vWxmXmcx9WBNHM6MARU2TL8lbgRzsHcD+WfOh87yEzSQ0OMuFerbJwzD17mHZPCPtNFbyCWFXDNKGh+sB0DhSPqJALInRVyOjoEFs4+rIiiLpTgAMmShfG49kFcBaAZwE8B+DTMb//HYCnATwB4EEAh2eVKROl4zIsqgggMIhoREh7u77TwXwI7ZR99whmuuhpdISos4NoJkuXoeFhBLQHG9CBmZSaitIhhJQB3AHgvQA2AlhDCLmfUvp06LbHAcyilP6REPIJAP8A4ALpWQjJypIrJacIIDCIOOenilare6u0ipatoiaOYKbT7TMOmjJYRPIsHH2x0EXdKUNDlEoXljUjAOgC8KPQ58UAFqfcfyKAR7PKzWM+/BGhbPmyu0QFOlUz1Y5XoWXEMF08BgZY+L+uBZ9MU/o2HAYGKAU6N1KDcfidAF4Mfd4I4F0p938MwA8l5h6voWKe9cEMywVfjJaq0KmaqWrZKrTkMVJLI3T6jHmbUubYYR6oyoDGKJ2XtkgTkjUjAPgQgK+GPn8UwJcS7r0QwM8BtCf8vhDAWgBrp0yZYmwG1D0jq5SZKyXNF6OlDuhiBF15NnxSEwvEwtRYHRhgrilC2F9VVw4w/hlqUMPfCOCw0OdDAWyK3kQIORPAdQBOp5QOJUwuKwCsAIBZs2bJ26ESYEJBVS3TKzNslprhi9FSB3SpZjq07ICWINHZCNTW87DKNTVW+/rqkYa7drHPojIkvE0FmDBelhYegb8GwNGEkCMAvATgwwA+Er6BEHIigF4AZ1FKX5ElhgdpjGOiw1yu6OMgPXB4Zq4k4ZaH0RqFTpp1TB7NYi6TgGjVXbGbylg1SXN0m0o9pawEeJYBAM4G8BsA6wFcV/vuZgDvr/2/CsDLAP63dt2fVaaM0zZryWViSebTij5Ki1B+MVlzjY82qayMij7SLNP+TWIKEql6Wtf5mhGTRy61tzOTTnu7nN+/VKqHpwJHvEINmnRAKX0AwAOR7z4T+v9M6RlHAFnatsjqm3dG1rmiV0W4/kND7LyTapVTYVRJeyCyxDGtniUdgej7tmzR9s/riiCm/0WqnsRutpojKLO/v/FzGnjk0urV8sOiuxtoaWFlM/16/wPFSghBdqZQvWQ1fBXnR7gc3xRAHoTpbmmpz/rcCrsJ9UX2XlnEqYvR73w9FlGk/fPoQE/pf96qJxVhqzlkWNgG24dP/gROqlKTGr5PIKTxrwyimvKSJezyXYEKrzY6OoDLLxdU2GWWGiJLHBse6qi62NEBPP44U4EAtg9/yxbgfe8DJk1S34+vEyLqY5Za7KNfJaX/eVkvid1sxRPIsLCN6Nl581h26hpt5jZembpcHmIe3mYdnPnd3h5/xgPPDn1Xu/i9M/HaWjqFD0kJp2Q491xKW1sDNUjOYGoSou2T1MGiqy5bTGK4/23Z8H1cHFJar79KWGauBL7OzhgYoHTu3LrQj8vXEeckzTrRLu6epkPayLMpYKIawNy54XUv+9+2KSSt/ro0Ft5yXEgv77QQcfheBTTjiVdxK1adS6euLmbGeeSR5Hwd0eXdypXx51Nn3ZOHFKzcyPKe2cysGF3nn39+vdMA+3sJstpG1wlZvPYN3SY2HlodZNbUjSaoQiK8FPhp40bGi56EcFKiu+5i4yI8fuLkySOP7DvOsu5JGycrVgCXXsqibdrbcxCM4dNOsjgNYMYM4B/+Adi0CfjYx+zSJhpGBsiFnvBqPjoN3wbCZGTmulwpRwZQqQBA5yTpAmSXBqpXZ+fMxCVT2orV5PbnJHOpig0/K644bHIulXIQjOGzkZNSt/SJbpSwEXqiyz6hmVZfo2F44cLsE9TfaHpkU3jpJaYwxCkKaYqJKQUzaRkX/T7uvrR70k696+8PDjRgKJU8zmYQqFYdHSzOHfArAiaA6RVImoqZFkYlyui6oMs+0d2NSvlU9Fffg+7yo+hSpDWum4Lvk7R3HV2rY4XgaotE2FopDdmZQvUCZmb6m1QDFHxAloYfRAu1tvIdysD7Tq3aR1xYk6+Nb5JBRMoWcaz67CGsYWCA0tHte2iZ7KWj2/cokysT7JDV/FlNqYs1XG2RqGv48nH4TgW+61QFtmAzqMWIvIseP+T7ZiBTDKIrR0AOYULIhbtJdX7kaW7dYd2mujZLXqjkw3cm8NNs+LqRtwlCBUa0jzxp+CahK44+h7Ah5EyfM6OrDgMDbM9OsG9HZzfz0Ig8hmVOmmTH7pXXlCRZSLJFxm1EVc7IG7VNDw7yFdhsIRVZ0TGmTs/wAKZ3k0ZZTDQKj9cdoup+isqTE0/MdtWIwHgQnOxMoXrZOuJQJUmkr8oZry1T9yYwoTZpMpNGJpqsvq74X6UZs0whJuz3c+fqXVGb1vBLGucOLxHM/OUyfyBEMIvfcAP7y2Jf7SA4IyPtnUkRDgG6uoDFi5kinnafKF1CbZJFpAnwNJ4pxCVockGHBrjkfxW2CfieN8JHBlF5cv75jZ+DFbVsmwUrnVtuMWON8HLjFdAYBchrQYiDzFLU5t6ixrMq+cxPvMtXp0e72j49y7XtLqhvcDTRqlVsB14ObYgu99aZYhtd5Sbt9eONxOV9h7H2ll0aqF5pJh3XPkKdzh2RMLGeHrEgEN50s86OdlV5ueizPqQTHhhoTNDkcyRTClxbp0yZk0ybqWyxIBRMOl4KfB+iAFWZgzdMLDypmUrjrlPoW7Hrykgc11LKNzoU4bMPy1fY6noVge+lSSe6Oi6V7OfBUllWVSrMhBvQn7Qsjp5VeeKJLHpAZySETkuHtaATGZuCqO3OVASRjeToFsDT180WhKWKPHS9lwJfNgrQBwQCNm2yCgbKhg3s9+C+wUH9QtWnXGfckDW48jaeaXu/iZnRM+nq2mXiK3yPxPVS4AP+N1wSAgEbCPEzz2w8TSs8UFpa2BXN0qkTtn2nWmBaVcrbLOihdM1bE+qCZ/OuMLwV+AHy1sBRARs9OjE8UABgwQJgyhRz9cvDMjMWJmf8vM2CBqWr7PjKWxPqgIfzrjC8Fvh5bOAsARsdKKoJJ0fImRR84JVeeZsFOaWrqPBWGV/RJgQ07Oj2HE2xqpH19qpePDttfYi0ozQ+YsFmxGFaOSLp103CaVRHkNykrc1clkzXISsZNMhEiIjmgjO9i9V3mNoFLAo0W1hmAB8YKY4GH+iitHHAlkqUtrT4ce6H1fYIXh4+y1anduBLZ2dARjnirVrWfb4oZjYgI7h1s5CKwPc6tYLpbcY8iFvGucgaEIfwNu9ymTmKXdDktD2Cl1PKPhOi16jsS2dnQCaFCO/4ymoCmXfnFWnpG5LgEwt5bcMH3Nufk8ynPjis0g5YMkETb4ZOq+0RfnlLC3DRRVpP4qp0nIN+sgPdpYfQZTaTbQAADHFJREFU1fYL9tlDW7WsW4JnfGX1b95cIjzQGSzik4Ob0EAzsoxZs2bRtWvXOnm3KOI6X8ZBZnpAyL6D57ksB5/TaCpDLx+u8xBFW3kPll+xAZd/aVquggh0IW/RciowESyis/0IIesopbOkHpa1BalettIj+wCfzcC8tI0kO20A06lwbcCH4IK8wXdeR7OlVvANqrOzz+FcvLT5tCy1hWidzz+fJcDMSxuoaKp5DInWhWbm9ULgZ0B10AT2dV8ZiJe5m9FOm4W0VLh5aAMVRcNnJcU0RHhdRhnMesak+WxECnyRBpVl/OhEsXy5nzmBRqIgF0HUqek6iEAEKpqqi+MMdPOgSpm8yeNElUEeX5jJldWIE/iiDSrL+NGJYnCQhXP5CFPMXcAtVCZzm4qAKSepaX6VUQaznjG9svJG4NuKAhBtUFnGN6khuYiYGMlL/DxDZUViazVjgrds8KvMGM96xvTKyguBb1N7lGlQGcY3pSG50rSb2ZHlGiMp5DEOYd4ql1na8EpFrS14+FWl3YNnRU21WXLB+MpKNrxH9QqHZdoOg8pzuJnLkLE8t5ssTNc5fJxnayvLh5RnyLZXkA6pvV1f+LKp/D+uw6yR97BM29pjnhxvUZhoK5Ekk3ltNxnYsgMHh+VUq8Cll7JIoDy2s2r2zf5+YM8efWaYNH4dqRFMXgj8IlKkEWkCWHdbFc7YZNiyAwd5kAD2N08CJIys9spSLGwofjpCpfNs3vRC4AMjT3tMAo8A1tlWedZWTMPGwO7qAm6/nWn21SrQ3p4vARJGWnvx8rVJxU9XqLROOm37b7wR+AUYbAvgPGsrpmFr5blwYfaGrjw4dtPai5evTSp+OkOlddDpYnVdCHzPYFoARwVH2iDNg5AxDZGBbWqjjy9mN5XT1XxQLHygIQwnq2tZb6/qNZKSp0WRFclgKjJEJLog6d6RGKnDg7S2VW0zH5J56YhM8YF3fKAhTItMmyLvUTojCbpt9KbSRMTdC+jRNJtx5ZDUtjq0cx80Ux3aqG5zjQwf+eQrdBGsMuIFvm3ho3MZZzJNRNy9Omj3xTyhG0ltq0tQuo5i82HSCYOXj8JROb7msrJJT24Fvo6OdCF8dA4cUWEiIjiS7k2LwujrY/+nHTjVrFFBSe0l299xvhYTUSu8k4gPk04YPHwUjO9gn0OpxKKgXCoZzle3srYg1UvFhh/enRgc4C1jV9RpGxWxy8sehBx9xsWOvyQ62tro8Bni7e3yB2LroMc3JNGY9r3pfg36jBD2V/Yd0TrY6g+eNgqPbxPn24sijmaZ9oKCDT+XAl9XR+oaWFnlqL7HpENQB5YuZYIj6AtC0vtCF82ut7jLIiuNgA0nbU9P4/jp6REvI9r+vb12+yOLj3p7KW1pqfOmrGKoC9F+7ekpnLZcCJbJ4aVa2nI5aRmla5matbxUNWOkPe+DE6q7G2htZbQB2aYLXTT7Zh4SORt4504maoF9affNXp6EaPuvXGm3P7JCWS+/nMmHlhbgiiuA/fZza44K76oul9l3tvk3lwI/LKizbPhZdnodwsd0ylPfBUBXF+sLHhu+TvjULrz+oEBIBsKekH1pt2EvnzcP+NrXgN272WQ9b172M9EJLdr+uo+AVLF3B+1crbI23m8/P86jIKT+98QT7fNvLgU+wC+obWiBWQNUdQBHJ7ggRNK1Zh9GtD9sOKd8ciRm8VlcDpdyGbj44vgJ0sbKrVRigqdUyr43aUIzdQQkz8lQae/xSRkI0N/PksNRyv4ODjrgX1lbkOpleuNVYN+zbVc0CV9t1nGOOx/pNIksP0vU1u2D30XET2B781fa+3j5ywf/Vhi6xgVGmg0/C3k5T1YUYS1yaAhYsoRdru3WUU3MB9u67fC3tNVGtD18OO5SVAO2rTGnvY+Xv3zwb4Xhw4q0KQW+jwNMB6LO6lWrmM3UZFxxluCMG3yul9OuNnf5mEeGN2ABAJYtS+5n28Iq7X1x7ek8vp0Tzich2aWB6mXSpNPMJoWBAUrnzq3vQTC5vOZpRx9z7viQeyYKF+0hYvrI23iJ7mvJG/0qQGHSaUSgHQRRIyahS7MQOXVqyRK1aAjed/Esnbu6mMls5UoWpeFDuKjrFUYcXLQHr+nDtglOx5gJt+eyZXy7bsPvlKEhL6uIVMjOFKqXDaetjd2KNjZuJT0je3aoasbMuHtKJbbJxZczWX1z2LmAjxq+iXeJbnyUCeTwaRWBQsPfFza0Fl3vkClHVmMUeReP3ba/v/FM1kWL/DiT1bmt1AMkrb7i7rNlnzcxLrPo17FBzIdABB3gEviEkLMA/AuAMoCvUko/G/m9HUAfgJkABgFcQCl9QS+pYrCxrNf1DpsmCNF3ZQnO7m4Wxx2cybp3r18mgaZYhksi2G26axczAaZNxLYmSFO8nka/jg1iPpoJpZC1BAAT8usBHAmgDcAvARwXuecSAF+p/f9hAN/KKleXSSdt6W5jWa8zL4xqObxl6G6X3l5KW1vt5CrRbZJqZvjovKbUnQNbNcmbL2ZCmEyeBqALwI9CnxcDWBy550cAumr/twB4FQBJK1eHwB/pAzoM121hazCICDFfBZ4tuOaJAmagIvB5TDqdAF4Mfd4I4F1J91BK9xBC3gDQURP8xtAsdjUdcN0WPpoEmmYZLgkfNvoU8AuETRgpNxDyIQDvo5T+be3zRwGcTCn9ZOiep2r3bKx9Xl+7ZzBS1kIAC2sf3wbgV2rkjx8LHP1WAAQABX77G2DrdrUyneBAKE+OI6ktxo8FJowH3tyaXUeRe72DBr5oGhRtUccxlNLxMg/yaPgbARwW+nwogE0J92wkhLQAeAuAP0QLopSuALACAAghaymls2SIbjYUbVFH0RZ1FG1RR9EWdRBC1so+y5EnD2sAHE0IOYIQ0gbmlL0/cs/9AObX/v8ggIdo1tKhQIECBQpYRaaGX7PJLwJzzJYB3EUpfYoQcjOY8+B+AF8DcC8h5Dkwzf7DJokuUKBAgQLi4IrDp5Q+AOCByHefCf2/E8CHBN+9QvD+ZkbRFnUUbVFH0RZ1FG1Rh3RbZDptCxQoUKBAc4DHhl+gQIECBZoAxgU+IeQsQsizhJDnCCGfjvm9nRDyrdrv/0MImWqaJlfgaIu/I4Q8TQh5ghDyICHkcBd02kBWW4Tu+yAhhBJCmjZCg6ctCCF/WeONpwgh/26bRlvgGCNTCCGrCSGP18bJ2S7oNA1CyF2EkFcI+f/t3TtoFFEUxvH/EQUR4wOCICKkMaCkMQSJjQ8iFimSWggSCRYpLESsLBTsFBEEwUejNopaaBDESomIayWICEKIIQiCFpom+P4s7kTDusleAzMT75wfLMyys8PJYfbs5N65Z63hresWnMvy9MLMOqMOvNAVWzEPcmrL8D8+InOxG1iRbQ9XORfZfi3AKFADusqOu8TzYhPwHFibPV9Xdtwl5uISMJxtbwEmyo47p1zsADqBl3O83gvcJ6y76QaexRw37yv8bcCYpHFJX4EbQH/dPv3A1Wz7NtBjNvPb7klpmgtJDyVNZ09rhDUPKYo5LwBOAqeAz0UGV7CYXBwEzkv6CCDpfcExFiUmFwJWZdur+XtNUBIkjdJgLdMs/cA1BTVgjZmtb3bcvAt+o7YMG+baR9J3YKYtQ2picjHbEOEbPEVNc2FmW4GNku4VGVgJYs6LdqDdzJ6YWS3rXpuimFycAAbM7C3hzsFDVNO/1hMg/9+0bXSlXn9bUMw+KYj+O81sAOgCduYaUXnmzYWZLQHOAoNFBVSimPNiKWFYZxfhv77HZtYh6VPOsRUtJhf7gCuSzpjZdsL6nw5JP/MPb1FZUN3M+wr/X9oyMF9bhgTE5AIz2wMcA/okfSkotqI1y0ULodfSIzObIIxRjiQ6cRv7Gbkr6ZukN8BrwhdAamJyMQTcBJD0FFhO6LNTNVH1pF7eBd/bMvzRNBfZMMZFQrFPdZwWmuRC0pSkVkltktoI8xl9khbcQ2QRi/mM3CFM6GNmrYQhnvFCoyxGTC4mgR4AM9tMKPgfCo1ycRgB9md363QDU5LeNXtTrkM68rYMv0Xm4jSwEriVzVtPSuorLeicROaiEiJz8QDYa2avgB/AUdV1ok1BZC6OAJfN7DBhCGMwxQtEM7tOGMJrzeYrjgPLACRdIMxf9AJjwDRwIOq4CebKOedcA77S1jnnKsILvnPOVYQXfOecqwgv+M45VxFe8J1zriK84DvnXEV4wXfOuYrwgu+ccxXxC1EnaJCEP/tbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe515f7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_data(input_, target_, figure_size = 6):\n",
    "    input_true = torch.Tensor(0,2)\n",
    "    input_false = torch.Tensor(0,2)\n",
    "    for i,x in enumerate(input_):\n",
    "        if target_[i] == 0 :\n",
    "            input_false = torch.cat((input_false, input_[i,:].view(-1,2)),0 )\n",
    "        else :\n",
    "            input_true = torch.cat( (input_true, input_[i,:].view(-1,2)),0 )\n",
    "    print ('#samples:       ',input_.size())\n",
    "    print ('#true_samples:  ',input_true.size())\n",
    "    print ('#false_samples: ',input_false.size())\n",
    "    p1 = plt.figure(1,figsize=(figure_size,figure_size))\n",
    "    plt.plot(input_true[:,0].numpy(),input_true[:,1].numpy(),'r.',label='within circle')\n",
    "    plt.plot(input_false[:,0].numpy(),input_false[:,1].numpy(),'b.',label='outside circle')\n",
    "    plt.xlim(0,1), plt.ylim(0,1)\n",
    "    plt.legend(fontsize='x-large')\n",
    "    plt.title('Distribution of generated data')\n",
    "    \n",
    "    \n",
    "plot_data(train_input, train_target)\n",
    "train_target = torch.cat((1-train_target.unsqueeze(1), train_target.unsqueeze(1)),1)\n",
    "print(train_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1494 -1.0864\n",
       " 1.1466 -0.3749\n",
       "-0.9017 -1.0002\n",
       "       â‹®        \n",
       " 1.3303 -0.4098\n",
       "-0.8269 -1.7028\n",
       " 0.2946  1.2616\n",
       "[torch.FloatTensor of size 1000x2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, std = train_input.mean(),train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "mu, std = test_input.mean(),test_input.std()\n",
    "test_input.sub_(mu).div_(std)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param ( self ) :\n",
    "        return [] \n",
    "    \n",
    "    def zero_grad ( self ) :\n",
    "        pass\n",
    "    \n",
    "    def reset_params( self ) :\n",
    "        pass\n",
    "    \n",
    "\n",
    "class Optimizer(object):\n",
    "    def step(self, Sequential, lr, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "    def __init__(self, Sequential, lr):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Sequential = Sequential\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        for param in self.Sequential.params:\n",
    "            param[0][0].add_(- self.lr * param[1][0])\n",
    "            param[0][1].add_(- self.lr * param[1][1])\n",
    "        \n",
    "        self.Sequential.zero_grad()\n",
    "\n",
    "class SGDmomOptimizer(Optimizer):\n",
    "    \n",
    "    def __init__(self, Sequential, lr, gamma):\n",
    "        super().__init__()\n",
    "        self.Sequential = Sequential\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self._initialize_u()\n",
    "        \n",
    "    def step(self):\n",
    "        for i,param in enumerate(self.Sequential.params):\n",
    "            for j in range(2):\n",
    "                param[0][j].sub_(self.lr * (self.gamma * self.u[2*i+j] +  param[1][j]))\n",
    "                self.u[2*i+j] = param[0][j]\n",
    "            \n",
    "    def _initialize_u(self):\n",
    "        self.u = []\n",
    "        for param in self.Sequential.params:\n",
    "            self.u.append(torch.zeros_like(param[0][0]))\n",
    "            self.u.append(torch.zeros_like(param[0][1]))\n",
    "\n",
    "class AdamOptimizer(Optimizer):\n",
    "    def __init__(self, Sequential, lr, b1=0.9, b2=0.999):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Sequential = Sequential\n",
    "        self.lr = lr\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self._initialize_m()\n",
    "        self._initialize_v()\n",
    "        \n",
    "    def step(self):\n",
    "        for i,param in enumerate(self.Sequential.params):\n",
    "            for j in range(2):\n",
    "                self.m[2*i+j] = self.b1*self.m[2*i+j] + (1-self.b1)*param[1][j]\n",
    "                self.v[2*i+j] = self.b2*self.v[2*i+j] + (1-self.b2)*param[1][j]**2\n",
    "                \n",
    "                mhat = (1/(1-self.b1))*self.m[2*i+j]\n",
    "                vhat = (1/(1-self.b2))*self.v[2*i+j]\n",
    "                \n",
    "                div = torch.sqrt(vhat)+torch.Tensor(vhat.size()).normal_(mean = 0, std = 1e-6)\n",
    "                \n",
    "                param[0][j].sub_(self.lr * mhat/div)\n",
    "\n",
    "            \n",
    "    def _initialize_m(self):\n",
    "        self.m = []\n",
    "        for param in self.Sequential.params:\n",
    "            self.m.append(torch.zeros_like(param[0][0]))\n",
    "            self.m.append(torch.zeros_like(param[0][1]))\n",
    "            \n",
    "    def _initialize_v(self):\n",
    "        self.v = []\n",
    "        for param in self.Sequential.params:\n",
    "            self.v.append(torch.zeros_like(param[0][0]))\n",
    "            self.v.append(torch.zeros_like(param[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weights = torch.Tensor(out_features, in_features).normal_(mean=0, std = 1)\n",
    "        self.bias = torch.Tensor(out_features).uniform_(0,0)\n",
    "        \n",
    "        self.dl_dw = torch.Tensor(out_features, in_features)\n",
    "        self.dl_db = torch.Tensor(out_features)\n",
    "        self.zero_grad()\n",
    "        \n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        if(x.size()[1]!=self.in_features):\n",
    "            raise TypeError('Size of x should correspond to size of linear module')\n",
    "        return torch.mm(x,self.weights.t()) + self.bias.expand(x.size()[0], self.out_features)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        self.dl_db = torch.mean(d_dx,0)\n",
    "        self.dl_dw = torch.mm(d_dx.t(), self.x)\n",
    "        return torch.mm(d_dx,self.weights)\n",
    "        \n",
    "    def param(self):\n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "        return self.params\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.dl_db.zero_()\n",
    "        self.dl_dw.zero_()\n",
    "        \n",
    "    def reset_params(self):\n",
    "        self.weights.normal_(mean=0, std = 1)\n",
    "        self.bias.uniform_(0,0)\n",
    "        self.zero_grad()\n",
    "        self.params = [(self.weights, self.bias),(self.dl_dw, self.dl_db)]\n",
    "               \n",
    "        \n",
    "class Sequential(Module):\n",
    "    def __init__(self, modules, loss):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.modules = modules\n",
    "        self.loss = loss\n",
    "        self.params = []\n",
    "        self.param()\n",
    "        \n",
    "    def add(self, new_modules):\n",
    "        self.modules.append(new_modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.modules:\n",
    "            x = module.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "        d_dx = self.loss.backward()  \n",
    "        for module in reversed(self.modules):\n",
    "            d_dx = module.backward(d_dx)\n",
    "        self.param()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for module in self.modules:\n",
    "            module.zero_grad()\n",
    "\n",
    "    def param(self):\n",
    "        self.params = []\n",
    "        for module in self.modules:\n",
    "            if(module.params):\n",
    "                self.params.append(module.param())\n",
    "                \n",
    "    def reset_params(self):\n",
    "        for module in self.modules:\n",
    "            module.reset_params()\n",
    "                \n",
    "            \n",
    "class LeakyReLU(Module):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x*((x>0).type(torch.FloatTensor)+self.alpha*(x<0).type(torch.FloatTensor))\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx*((self.x>0).type(torch.FloatTensor)+self.alpha*(self.x<0).type(torch.FloatTensor))\n",
    "        \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x*(x>0).type(torch.FloatTensor)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx*(self.x>0).type(torch.FloatTensor)\n",
    "        \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "    \n",
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return 0.5*(1+x.tanh())\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return 0.5*d_dx*(1-torch.tanh(self.x)**2)\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "class Sigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    def backward(self, d_dx):\n",
    "        return d_dx * (torch.sigmoid(self.x*(1-torch.sigmoid(self.x))))\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n",
    "    \n",
    "class LossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        return torch.dist(y,t,p=2)\n",
    "    \n",
    "    def backward(self):\n",
    "        return 2*(self.y-self.t)\n",
    "    \n",
    "    def param(self):\n",
    "        return self.params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lin1 = Linear(2,20)\n",
    "Lin2 = Linear(20,20)\n",
    "Lin3 = Linear(20,2)\n",
    "act1 = LeakyReLU(0.1)\n",
    "act2 = LeakyReLU(0.1)\n",
    "act3 = Sigmoid()\n",
    "layers = [\n",
    "    Lin1,\n",
    "    act1,\n",
    "    Lin2,\n",
    "    act2,\n",
    "    Lin3,\n",
    "    act3]\n",
    "loss = LossMSE()\n",
    "model = Sequential(layers, loss)\n",
    "#optim = SGDOptimizer(model, 0.005)\n",
    "optim = SGDmomOptimizer(model, 0.0005, 0.2)\n",
    "#optim = AdamOptimizer(model, 0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0\n",
      "\n",
      "Training accuracy :  0.532\n",
      "\n",
      "Training loss :  131.1823878288269\n",
      "\n",
      " Epoch 1\n",
      "\n",
      "Training accuracy :  0.54\n",
      "\n",
      "Training loss :  129.71935749053955\n",
      "\n",
      " Epoch 2\n",
      "\n",
      "Training accuracy :  0.536\n",
      "\n",
      "Training loss :  129.24590969085693\n",
      "\n",
      " Epoch 3\n",
      "\n",
      "Training accuracy :  0.535\n",
      "\n",
      "Training loss :  128.6265368461609\n",
      "\n",
      " Epoch 4\n",
      "\n",
      "Training accuracy :  0.536\n",
      "\n",
      "Training loss :  127.71462869644165\n",
      "\n",
      " Epoch 5\n",
      "\n",
      "Training accuracy :  0.526\n",
      "\n",
      "Training loss :  126.64767932891846\n",
      "\n",
      " Epoch 6\n",
      "\n",
      "Training accuracy :  0.53\n",
      "\n",
      "Training loss :  125.80502319335938\n",
      "\n",
      " Epoch 7\n",
      "\n",
      "Training accuracy :  0.505\n",
      "\n",
      "Training loss :  124.99357414245605\n",
      "\n",
      " Epoch 8\n",
      "\n",
      "Training accuracy :  0.519\n",
      "\n",
      "Training loss :  123.95222663879395\n",
      "\n",
      " Epoch 9\n",
      "\n",
      "Training accuracy :  0.534\n",
      "\n",
      "Training loss :  122.59071445465088\n",
      "\n",
      " Epoch 10\n",
      "\n",
      "Training accuracy :  0.534\n",
      "\n",
      "Training loss :  121.31862688064575\n",
      "\n",
      " Epoch 11\n",
      "\n",
      "Training accuracy :  0.535\n",
      "\n",
      "Training loss :  120.57196950912476\n",
      "\n",
      " Epoch 12\n",
      "\n",
      "Training accuracy :  0.542\n",
      "\n",
      "Training loss :  119.97764205932617\n",
      "\n",
      " Epoch 13\n",
      "\n",
      "Training accuracy :  0.567\n",
      "\n",
      "Training loss :  118.1589241027832\n",
      "\n",
      " Epoch 14\n",
      "\n",
      "Training accuracy :  0.617\n",
      "\n",
      "Training loss :  114.51327085494995\n",
      "\n",
      " Epoch 15\n",
      "\n",
      "Training accuracy :  0.616\n",
      "\n",
      "Training loss :  113.63690757751465\n",
      "\n",
      " Epoch 16\n",
      "\n",
      "Training accuracy :  0.623\n",
      "\n",
      "Training loss :  113.0916862487793\n",
      "\n",
      " Epoch 17\n",
      "\n",
      "Training accuracy :  0.636\n",
      "\n",
      "Training loss :  112.64883661270142\n",
      "\n",
      " Epoch 18\n",
      "\n",
      "Training accuracy :  0.636\n",
      "\n",
      "Training loss :  112.23705863952637\n",
      "\n",
      " Epoch 19\n",
      "\n",
      "Training accuracy :  0.642\n",
      "\n",
      "Training loss :  111.81328678131104\n",
      "\n",
      " Epoch 20\n",
      "\n",
      "Training accuracy :  0.646\n",
      "\n",
      "Training loss :  111.38364315032959\n",
      "\n",
      " Epoch 21\n",
      "\n",
      "Training accuracy :  0.657\n",
      "\n",
      "Training loss :  110.92327833175659\n",
      "\n",
      " Epoch 22\n",
      "\n",
      "Training accuracy :  0.668\n",
      "\n",
      "Training loss :  110.41715288162231\n",
      "\n",
      " Epoch 23\n",
      "\n",
      "Training accuracy :  0.681\n",
      "\n",
      "Training loss :  109.87255811691284\n",
      "\n",
      " Epoch 24\n",
      "\n",
      "Training accuracy :  0.689\n",
      "\n",
      "Training loss :  109.29770374298096\n",
      "\n",
      " Epoch 25\n",
      "\n",
      "Training accuracy :  0.698\n",
      "\n",
      "Training loss :  108.70750141143799\n",
      "\n",
      " Epoch 26\n",
      "\n",
      "Training accuracy :  0.706\n",
      "\n",
      "Training loss :  108.09703016281128\n",
      "\n",
      " Epoch 27\n",
      "\n",
      "Training accuracy :  0.707\n",
      "\n",
      "Training loss :  107.39711570739746\n",
      "\n",
      " Epoch 28\n",
      "\n",
      "Training accuracy :  0.706\n",
      "\n",
      "Training loss :  106.47964000701904\n",
      "\n",
      " Epoch 29\n",
      "\n",
      "Training accuracy :  0.704\n",
      "\n",
      "Training loss :  105.05731105804443\n",
      "\n",
      " Epoch 30\n",
      "\n",
      "Training accuracy :  0.704\n",
      "\n",
      "Training loss :  101.75763273239136\n",
      "\n",
      " Epoch 31\n",
      "\n",
      "Training accuracy :  0.705\n",
      "\n",
      "Training loss :  96.67411279678345\n",
      "\n",
      " Epoch 32\n",
      "\n",
      "Training accuracy :  0.715\n",
      "\n",
      "Training loss :  94.85667514801025\n",
      "\n",
      " Epoch 33\n",
      "\n",
      "Training accuracy :  0.72\n",
      "\n",
      "Training loss :  93.44290661811829\n",
      "\n",
      " Epoch 34\n",
      "\n",
      "Training accuracy :  0.729\n",
      "\n",
      "Training loss :  92.09247636795044\n",
      "\n",
      " Epoch 35\n",
      "\n",
      "Training accuracy :  0.735\n",
      "\n",
      "Training loss :  90.69716811180115\n",
      "\n",
      " Epoch 36\n",
      "\n",
      "Training accuracy :  0.742\n",
      "\n",
      "Training loss :  89.00762557983398\n",
      "\n",
      " Epoch 37\n",
      "\n",
      "Training accuracy :  0.75\n",
      "\n",
      "Training loss :  86.95396447181702\n",
      "\n",
      " Epoch 38\n",
      "\n",
      "Training accuracy :  0.759\n",
      "\n",
      "Training loss :  84.87976217269897\n",
      "\n",
      " Epoch 39\n",
      "\n",
      "Training accuracy :  0.769\n",
      "\n",
      "Training loss :  82.547443151474\n",
      "\n",
      " Epoch 40\n",
      "\n",
      "Training accuracy :  0.783\n",
      "\n",
      "Training loss :  79.66525840759277\n",
      "\n",
      " Epoch 41\n",
      "\n",
      "Training accuracy :  0.805\n",
      "\n",
      "Training loss :  76.57736349105835\n",
      "\n",
      " Epoch 42\n",
      "\n",
      "Training accuracy :  0.815\n",
      "\n",
      "Training loss :  74.20783591270447\n",
      "\n",
      " Epoch 43\n",
      "\n",
      "Training accuracy :  0.824\n",
      "\n",
      "Training loss :  72.44033217430115\n",
      "\n",
      " Epoch 44\n",
      "\n",
      "Training accuracy :  0.841\n",
      "\n",
      "Training loss :  70.95019173622131\n",
      "\n",
      " Epoch 45\n",
      "\n",
      "Training accuracy :  0.85\n",
      "\n",
      "Training loss :  69.67982625961304\n",
      "\n",
      " Epoch 46\n",
      "\n",
      "Training accuracy :  0.86\n",
      "\n",
      "Training loss :  68.50615525245667\n",
      "\n",
      " Epoch 47\n",
      "\n",
      "Training accuracy :  0.866\n",
      "\n",
      "Training loss :  67.403005361557\n",
      "\n",
      " Epoch 48\n",
      "\n",
      "Training accuracy :  0.871\n",
      "\n",
      "Training loss :  66.39669013023376\n",
      "\n",
      " Epoch 49\n",
      "\n",
      "Training accuracy :  0.879\n",
      "\n",
      "Training loss :  65.45981574058533\n",
      "\n",
      " Epoch 50\n",
      "\n",
      "Training accuracy :  0.883\n",
      "\n",
      "Training loss :  64.57931637763977\n",
      "\n",
      " Epoch 51\n",
      "\n",
      "Training accuracy :  0.885\n",
      "\n",
      "Training loss :  63.765124797821045\n",
      "\n",
      " Epoch 52\n",
      "\n",
      "Training accuracy :  0.888\n",
      "\n",
      "Training loss :  62.97142434120178\n",
      "\n",
      " Epoch 53\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  62.236735582351685\n",
      "\n",
      " Epoch 54\n",
      "\n",
      "Training accuracy :  0.895\n",
      "\n",
      "Training loss :  61.5209174156189\n",
      "\n",
      " Epoch 55\n",
      "\n",
      "Training accuracy :  0.893\n",
      "\n",
      "Training loss :  60.82085633277893\n",
      "\n",
      " Epoch 56\n",
      "\n",
      "Training accuracy :  0.894\n",
      "\n",
      "Training loss :  60.16966986656189\n",
      "\n",
      " Epoch 57\n",
      "\n",
      "Training accuracy :  0.9\n",
      "\n",
      "Training loss :  59.51976275444031\n",
      "\n",
      " Epoch 58\n",
      "\n",
      "Training accuracy :  0.902\n",
      "\n",
      "Training loss :  58.87885332107544\n",
      "\n",
      " Epoch 59\n",
      "\n",
      "Training accuracy :  0.904\n",
      "\n",
      "Training loss :  58.26648020744324\n",
      "\n",
      " Epoch 60\n",
      "\n",
      "Training accuracy :  0.907\n",
      "\n",
      "Training loss :  57.65045642852783\n",
      "\n",
      " Epoch 61\n",
      "\n",
      "Training accuracy :  0.913\n",
      "\n",
      "Training loss :  57.04094958305359\n",
      "\n",
      " Epoch 62\n",
      "\n",
      "Training accuracy :  0.914\n",
      "\n",
      "Training loss :  56.457733392715454\n",
      "\n",
      " Epoch 63\n",
      "\n",
      "Training accuracy :  0.916\n",
      "\n",
      "Training loss :  55.89156675338745\n",
      "\n",
      " Epoch 64\n",
      "\n",
      "Training accuracy :  0.92\n",
      "\n",
      "Training loss :  55.333101987838745\n",
      "\n",
      " Epoch 65\n",
      "\n",
      "Training accuracy :  0.923\n",
      "\n",
      "Training loss :  54.81812858581543\n",
      "\n",
      " Epoch 66\n",
      "\n",
      "Training accuracy :  0.924\n",
      "\n",
      "Training loss :  54.316410779953\n",
      "\n",
      " Epoch 67\n",
      "\n",
      "Training accuracy :  0.924\n",
      "\n",
      "Training loss :  53.84165048599243\n",
      "\n",
      " Epoch 68\n",
      "\n",
      "Training accuracy :  0.928\n",
      "\n",
      "Training loss :  53.368879318237305\n",
      "\n",
      " Epoch 69\n",
      "\n",
      "Training accuracy :  0.929\n",
      "\n",
      "Training loss :  52.90242052078247\n",
      "\n",
      " Epoch 70\n",
      "\n",
      "Training accuracy :  0.929\n",
      "\n",
      "Training loss :  52.45411801338196\n",
      "\n",
      " Epoch 71\n",
      "\n",
      "Training accuracy :  0.932\n",
      "\n",
      "Training loss :  52.022175550460815\n",
      "\n",
      " Epoch 72\n",
      "\n",
      "Training accuracy :  0.935\n",
      "\n",
      "Training loss :  51.60993933677673\n",
      "\n",
      " Epoch 73\n",
      "\n",
      "Training accuracy :  0.936\n",
      "\n",
      "Training loss :  51.23939299583435\n",
      "\n",
      " Epoch 74\n",
      "\n",
      "Training accuracy :  0.936\n",
      "\n",
      "Training loss :  50.873724579811096\n",
      "\n",
      " Epoch 75\n",
      "\n",
      "Training accuracy :  0.936\n",
      "\n",
      "Training loss :  50.47665309906006\n",
      "\n",
      " Epoch 76\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  50.11760497093201\n",
      "\n",
      " Epoch 77\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  49.76430654525757\n",
      "\n",
      " Epoch 78\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  49.426151633262634\n",
      "\n",
      " Epoch 79\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  49.0873806476593\n",
      "\n",
      " Epoch 80\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  48.7664932012558\n",
      "\n",
      " Epoch 81\n",
      "\n",
      "Training accuracy :  0.937\n",
      "\n",
      "Training loss :  48.47061848640442\n",
      "\n",
      " Epoch 82\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  48.16484820842743\n",
      "\n",
      " Epoch 83\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  47.805614590644836\n",
      "\n",
      " Epoch 84\n",
      "\n",
      "Training accuracy :  0.938\n",
      "\n",
      "Training loss :  47.34057664871216\n",
      "\n",
      " Epoch 85\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  46.967100739479065\n",
      "\n",
      " Epoch 86\n",
      "\n",
      "Training accuracy :  0.939\n",
      "\n",
      "Training loss :  46.71359944343567\n",
      "\n",
      " Epoch 87\n",
      "\n",
      "Training accuracy :  0.94\n",
      "\n",
      "Training loss :  46.46167504787445\n",
      "\n",
      " Epoch 88\n",
      "\n",
      "Training accuracy :  0.941\n",
      "\n",
      "Training loss :  46.215219259262085\n",
      "\n",
      " Epoch 89\n",
      "\n",
      "Training accuracy :  0.941\n",
      "\n",
      "Training loss :  45.98051476478577\n",
      "\n",
      " Epoch 90\n",
      "\n",
      "Training accuracy :  0.941\n",
      "\n",
      "Training loss :  45.741427540779114\n",
      "\n",
      " Epoch 91\n",
      "\n",
      "Training accuracy :  0.943\n",
      "\n",
      "Training loss :  45.51371717453003\n",
      "\n",
      " Epoch 92\n",
      "\n",
      "Training accuracy :  0.944\n",
      "\n",
      "Training loss :  45.26517915725708\n",
      "\n",
      " Epoch 93\n",
      "\n",
      "Training accuracy :  0.946\n",
      "\n",
      "Training loss :  45.06641697883606\n",
      "\n",
      " Epoch 94\n",
      "\n",
      "Training accuracy :  0.947\n",
      "\n",
      "Training loss :  44.856744050979614\n",
      "\n",
      " Epoch 95\n",
      "\n",
      "Training accuracy :  0.948\n",
      "\n",
      "Training loss :  44.64949417114258\n",
      "\n",
      " Epoch 96\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  44.458901166915894\n",
      "\n",
      " Epoch 97\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  44.24908113479614\n",
      "\n",
      " Epoch 98\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  44.044148564338684\n",
      "\n",
      " Epoch 99\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  43.84983813762665\n",
      "\n",
      " Epoch 100\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  43.683966875076294\n",
      "\n",
      " Epoch 101\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  43.53064966201782\n",
      "\n",
      " Epoch 102\n",
      "\n",
      "Training accuracy :  0.949\n",
      "\n",
      "Training loss :  43.36619758605957\n",
      "\n",
      " Epoch 103\n",
      "\n",
      "Training accuracy :  0.95\n",
      "\n",
      "Training loss :  43.19473659992218\n",
      "\n",
      " Epoch 104\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  43.0737601518631\n",
      "\n",
      " Epoch 105\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  42.841174840927124\n",
      "\n",
      " Epoch 106\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  42.72978222370148\n",
      "\n",
      " Epoch 107\n",
      "\n",
      "Training accuracy :  0.953\n",
      "\n",
      "Training loss :  42.56818652153015\n",
      "\n",
      " Epoch 108\n",
      "\n",
      "Training accuracy :  0.954\n",
      "\n",
      "Training loss :  42.38296961784363\n",
      "\n",
      " Epoch 109\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  42.22273910045624\n",
      "\n",
      " Epoch 110\n",
      "\n",
      "Training accuracy :  0.955\n",
      "\n",
      "Training loss :  42.03187167644501\n",
      "\n",
      " Epoch 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  41.85770535469055\n",
      "\n",
      " Epoch 112\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  41.64848601818085\n",
      "\n",
      " Epoch 113\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  41.48436141014099\n",
      "\n",
      " Epoch 114\n",
      "\n",
      "Training accuracy :  0.956\n",
      "\n",
      "Training loss :  41.3300883769989\n",
      "\n",
      " Epoch 115\n",
      "\n",
      "Training accuracy :  0.957\n",
      "\n",
      "Training loss :  41.213505268096924\n",
      "\n",
      " Epoch 116\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  41.05925118923187\n",
      "\n",
      " Epoch 117\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  40.929428935050964\n",
      "\n",
      " Epoch 118\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  40.785430908203125\n",
      "\n",
      " Epoch 119\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  40.65838074684143\n",
      "\n",
      " Epoch 120\n",
      "\n",
      "Training accuracy :  0.958\n",
      "\n",
      "Training loss :  40.529292583465576\n",
      "\n",
      " Epoch 121\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  40.4082555770874\n",
      "\n",
      " Epoch 122\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  40.28908407688141\n",
      "\n",
      " Epoch 123\n",
      "\n",
      "Training accuracy :  0.96\n",
      "\n",
      "Training loss :  40.18215751647949\n",
      "\n",
      " Epoch 124\n",
      "\n",
      "Training accuracy :  0.961\n",
      "\n",
      "Training loss :  40.061177492141724\n",
      "\n",
      " Epoch 125\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  39.955530643463135\n",
      "\n",
      " Epoch 126\n",
      "\n",
      "Training accuracy :  0.962\n",
      "\n",
      "Training loss :  39.83811056613922\n",
      "\n",
      " Epoch 127\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  39.74536943435669\n",
      "\n",
      " Epoch 128\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  39.63879108428955\n",
      "\n",
      " Epoch 129\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  39.51150894165039\n",
      "\n",
      " Epoch 130\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  39.40709459781647\n",
      "\n",
      " Epoch 131\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  39.30827069282532\n",
      "\n",
      " Epoch 132\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  39.19622886180878\n",
      "\n",
      " Epoch 133\n",
      "\n",
      "Training accuracy :  0.963\n",
      "\n",
      "Training loss :  39.09166777133942\n",
      "\n",
      " Epoch 134\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  38.98950719833374\n",
      "\n",
      " Epoch 135\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  38.89724326133728\n",
      "\n",
      " Epoch 136\n",
      "\n",
      "Training accuracy :  0.964\n",
      "\n",
      "Training loss :  38.80431067943573\n",
      "\n",
      " Epoch 137\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  38.70352923870087\n",
      "\n",
      " Epoch 138\n",
      "\n",
      "Training accuracy :  0.965\n",
      "\n",
      "Training loss :  38.622931122779846\n",
      "\n",
      " Epoch 139\n",
      "\n",
      "Training accuracy :  0.966\n",
      "\n",
      "Training loss :  38.523959040641785\n",
      "\n",
      " Epoch 140\n",
      "\n",
      "Training accuracy :  0.967\n",
      "\n",
      "Training loss :  38.42369997501373\n",
      "\n",
      " Epoch 141\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  38.331886529922485\n",
      "\n",
      " Epoch 142\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  38.227601408958435\n",
      "\n",
      " Epoch 143\n",
      "\n",
      "Training accuracy :  0.968\n",
      "\n",
      "Training loss :  38.136247634887695\n",
      "\n",
      " Epoch 144\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  38.03335344791412\n",
      "\n",
      " Epoch 145\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  37.92845070362091\n",
      "\n",
      " Epoch 146\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  37.837159514427185\n",
      "\n",
      " Epoch 147\n",
      "\n",
      "Training accuracy :  0.969\n",
      "\n",
      "Training loss :  37.724329590797424\n",
      "\n",
      " Epoch 148\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.61735928058624\n",
      "\n",
      " Epoch 149\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.51922428607941\n",
      "\n",
      " Epoch 150\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.44172275066376\n",
      "\n",
      " Epoch 151\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.35326528549194\n",
      "\n",
      " Epoch 152\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.26834011077881\n",
      "\n",
      " Epoch 153\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.175814390182495\n",
      "\n",
      " Epoch 154\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.0932914018631\n",
      "\n",
      " Epoch 155\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  37.04671108722687\n",
      "\n",
      " Epoch 156\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  36.95642173290253\n",
      "\n",
      " Epoch 157\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  36.85183310508728\n",
      "\n",
      " Epoch 158\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.78028929233551\n",
      "\n",
      " Epoch 159\n",
      "\n",
      "Training accuracy :  0.97\n",
      "\n",
      "Training loss :  36.70233237743378\n",
      "\n",
      " Epoch 160\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.61347770690918\n",
      "\n",
      " Epoch 161\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.53139400482178\n",
      "\n",
      " Epoch 162\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.464611649513245\n",
      "\n",
      " Epoch 163\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  36.37963926792145\n",
      "\n",
      " Epoch 164\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  36.288286566734314\n",
      "\n",
      " Epoch 165\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.20411932468414\n",
      "\n",
      " Epoch 166\n",
      "\n",
      "Training accuracy :  0.971\n",
      "\n",
      "Training loss :  36.07593131065369\n",
      "\n",
      " Epoch 167\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  35.888898730278015\n",
      "\n",
      " Epoch 168\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  35.75723695755005\n",
      "\n",
      " Epoch 169\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  35.60727822780609\n",
      "\n",
      " Epoch 170\n",
      "\n",
      "Training accuracy :  0.973\n",
      "\n",
      "Training loss :  35.50725698471069\n",
      "\n",
      " Epoch 171\n",
      "\n",
      "Training accuracy :  0.974\n",
      "\n",
      "Training loss :  35.40034508705139\n",
      "\n",
      " Epoch 172\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.31846380233765\n",
      "\n",
      " Epoch 173\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.26433992385864\n",
      "\n",
      " Epoch 174\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.21742606163025\n",
      "\n",
      " Epoch 175\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  35.165414214134216\n",
      "\n",
      " Epoch 176\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.130818367004395\n",
      "\n",
      " Epoch 177\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.09544658660889\n",
      "\n",
      " Epoch 178\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  35.045172333717346\n",
      "\n",
      " Epoch 179\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  34.988401889801025\n",
      "\n",
      " Epoch 180\n",
      "\n",
      "Training accuracy :  0.975\n",
      "\n",
      "Training loss :  34.917744159698486\n",
      "\n",
      " Epoch 181\n",
      "\n",
      "Training accuracy :  0.976\n",
      "\n",
      "Training loss :  34.843353152275085\n",
      "\n",
      " Epoch 182\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  34.78245162963867\n",
      "\n",
      " Epoch 183\n",
      "\n",
      "Training accuracy :  0.977\n",
      "\n",
      "Training loss :  34.73902463912964\n",
      "\n",
      " Epoch 184\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.6796692609787\n",
      "\n",
      " Epoch 185\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  34.59662055969238\n",
      "\n",
      " Epoch 186\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  34.54468321800232\n",
      "\n",
      " Epoch 187\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  34.45986711978912\n",
      "\n",
      " Epoch 188\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.39930438995361\n",
      "\n",
      " Epoch 189\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.36725640296936\n",
      "\n",
      " Epoch 190\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.31146025657654\n",
      "\n",
      " Epoch 191\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.263219118118286\n",
      "\n",
      " Epoch 192\n",
      "\n",
      "Training accuracy :  0.978\n",
      "\n",
      "Training loss :  34.21862757205963\n",
      "\n",
      " Epoch 193\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  34.16876018047333\n",
      "\n",
      " Epoch 194\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  34.13416874408722\n",
      "\n",
      " Epoch 195\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  34.08850169181824\n",
      "\n",
      " Epoch 196\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  34.04790914058685\n",
      "\n",
      " Epoch 197\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  34.00713551044464\n",
      "\n",
      " Epoch 198\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  33.961684823036194\n",
      "\n",
      " Epoch 199\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.93287515640259\n",
      "\n",
      " Epoch 200\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.8933961391449\n",
      "\n",
      " Epoch 201\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.84623575210571\n",
      "\n",
      " Epoch 202\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.81749927997589\n",
      "\n",
      " Epoch 203\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.78173613548279\n",
      "\n",
      " Epoch 204\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.737162828445435\n",
      "\n",
      " Epoch 205\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.70361530780792\n",
      "\n",
      " Epoch 206\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.66143262386322\n",
      "\n",
      " Epoch 207\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.636741161346436\n",
      "\n",
      " Epoch 208\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.58556032180786\n",
      "\n",
      " Epoch 209\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.54549026489258\n",
      "\n",
      " Epoch 210\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.52299439907074\n",
      "\n",
      " Epoch 211\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.480061650276184\n",
      "\n",
      " Epoch 212\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.45908319950104\n",
      "\n",
      " Epoch 213\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.43535137176514\n",
      "\n",
      " Epoch 214\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.415329933166504\n",
      "\n",
      " Epoch 215\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.37362813949585\n",
      "\n",
      " Epoch 216\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.35012078285217\n",
      "\n",
      " Epoch 217\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.32019400596619\n",
      "\n",
      " Epoch 218\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.281084179878235\n",
      "\n",
      " Epoch 219\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  33.23956656455994\n",
      "\n",
      " Epoch 220\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  33.21289622783661\n",
      "\n",
      " Epoch 221\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.191736698150635\n",
      "\n",
      " Epoch 222\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.169679403305054\n",
      "\n",
      " Epoch 223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  33.11854410171509\n",
      "\n",
      " Epoch 224\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  33.09596657752991\n",
      "\n",
      " Epoch 225\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  33.06912314891815\n",
      "\n",
      " Epoch 226\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  33.039997816085815\n",
      "\n",
      " Epoch 227\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  32.99070060253143\n",
      "\n",
      " Epoch 228\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  32.96353566646576\n",
      "\n",
      " Epoch 229\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  32.93545937538147\n",
      "\n",
      " Epoch 230\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  32.905434012413025\n",
      "\n",
      " Epoch 231\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.883816838264465\n",
      "\n",
      " Epoch 232\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.865816593170166\n",
      "\n",
      " Epoch 233\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.8448680639267\n",
      "\n",
      " Epoch 234\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.81605684757233\n",
      "\n",
      " Epoch 235\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  32.78655242919922\n",
      "\n",
      " Epoch 236\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  32.741528391838074\n",
      "\n",
      " Epoch 237\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.73200714588165\n",
      "\n",
      " Epoch 238\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  32.70740485191345\n",
      "\n",
      " Epoch 239\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.69285070896149\n",
      "\n",
      " Epoch 240\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.67288792133331\n",
      "\n",
      " Epoch 241\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.658955335617065\n",
      "\n",
      " Epoch 242\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.64676129817963\n",
      "\n",
      " Epoch 243\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.61540699005127\n",
      "\n",
      " Epoch 244\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.605347633361816\n",
      "\n",
      " Epoch 245\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.58127558231354\n",
      "\n",
      " Epoch 246\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  32.50962197780609\n",
      "\n",
      " Epoch 247\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  32.40617835521698\n",
      "\n",
      " Epoch 248\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.33268392086029\n",
      "\n",
      " Epoch 249\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.31087517738342\n",
      "\n",
      " Epoch 250\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.30416250228882\n",
      "\n",
      " Epoch 251\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.296483278274536\n",
      "\n",
      " Epoch 252\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.270551562309265\n",
      "\n",
      " Epoch 253\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.247830629348755\n",
      "\n",
      " Epoch 254\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.21459484100342\n",
      "\n",
      " Epoch 255\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.205126881599426\n",
      "\n",
      " Epoch 256\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.16549873352051\n",
      "\n",
      " Epoch 257\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.144996881484985\n",
      "\n",
      " Epoch 258\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.11862885951996\n",
      "\n",
      " Epoch 259\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.10531294345856\n",
      "\n",
      " Epoch 260\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.08060622215271\n",
      "\n",
      " Epoch 261\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.07062911987305\n",
      "\n",
      " Epoch 262\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.056134939193726\n",
      "\n",
      " Epoch 263\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.04452443122864\n",
      "\n",
      " Epoch 264\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.04781150817871\n",
      "\n",
      " Epoch 265\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.02956247329712\n",
      "\n",
      " Epoch 266\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  32.008190751075745\n",
      "\n",
      " Epoch 267\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.997750878334045\n",
      "\n",
      " Epoch 268\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.97373342514038\n",
      "\n",
      " Epoch 269\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.96286952495575\n",
      "\n",
      " Epoch 270\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.858592867851257\n",
      "\n",
      " Epoch 271\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.812100648880005\n",
      "\n",
      " Epoch 272\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.790432453155518\n",
      "\n",
      " Epoch 273\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.781465649604797\n",
      "\n",
      " Epoch 274\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.77654731273651\n",
      "\n",
      " Epoch 275\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.767940759658813\n",
      "\n",
      " Epoch 276\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.756534457206726\n",
      "\n",
      " Epoch 277\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.753572583198547\n",
      "\n",
      " Epoch 278\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.754276156425476\n",
      "\n",
      " Epoch 279\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.748399257659912\n",
      "\n",
      " Epoch 280\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.74140167236328\n",
      "\n",
      " Epoch 281\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.7324116230011\n",
      "\n",
      " Epoch 282\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.722423553466797\n",
      "\n",
      " Epoch 283\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.71792995929718\n",
      "\n",
      " Epoch 284\n",
      "\n",
      "Training accuracy :  0.979\n",
      "\n",
      "Training loss :  31.715478658676147\n",
      "\n",
      " Epoch 285\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.702706456184387\n",
      "\n",
      " Epoch 286\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.701531529426575\n",
      "\n",
      " Epoch 287\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.691179752349854\n",
      "\n",
      " Epoch 288\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.690887451171875\n",
      "\n",
      " Epoch 289\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.681309580802917\n",
      "\n",
      " Epoch 290\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.674240589141846\n",
      "\n",
      " Epoch 291\n",
      "\n",
      "Training accuracy :  0.98\n",
      "\n",
      "Training loss :  31.666417360305786\n",
      "\n",
      " Epoch 292\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.660940885543823\n",
      "\n",
      " Epoch 293\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.65338635444641\n",
      "\n",
      " Epoch 294\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.653166890144348\n",
      "\n",
      " Epoch 295\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.63829529285431\n",
      "\n",
      " Epoch 296\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.634414672851562\n",
      "\n",
      " Epoch 297\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.624930500984192\n",
      "\n",
      " Epoch 298\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.619391918182373\n",
      "\n",
      " Epoch 299\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.612947583198547\n",
      "\n",
      " Epoch 300\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.604137301445007\n",
      "\n",
      " Epoch 301\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.604664206504822\n",
      "\n",
      " Epoch 302\n",
      "\n",
      "Training accuracy :  0.981\n",
      "\n",
      "Training loss :  31.59878432750702\n",
      "\n",
      " Epoch 303\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.58986186981201\n",
      "\n",
      " Epoch 304\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.58533275127411\n",
      "\n",
      " Epoch 305\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.582237720489502\n",
      "\n",
      " Epoch 306\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.57514452934265\n",
      "\n",
      " Epoch 307\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.571558594703674\n",
      "\n",
      " Epoch 308\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.56588101387024\n",
      "\n",
      " Epoch 309\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.55670416355133\n",
      "\n",
      " Epoch 310\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.553953647613525\n",
      "\n",
      " Epoch 311\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.545194268226624\n",
      "\n",
      " Epoch 312\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.54459035396576\n",
      "\n",
      " Epoch 313\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.531212091445923\n",
      "\n",
      " Epoch 314\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.535261631011963\n",
      "\n",
      " Epoch 315\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.527029037475586\n",
      "\n",
      " Epoch 316\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.522944927215576\n",
      "\n",
      " Epoch 317\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.52104616165161\n",
      "\n",
      " Epoch 318\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.516279458999634\n",
      "\n",
      " Epoch 319\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.512685298919678\n",
      "\n",
      " Epoch 320\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.504801154136658\n",
      "\n",
      " Epoch 321\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.500705003738403\n",
      "\n",
      " Epoch 322\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.49908471107483\n",
      "\n",
      " Epoch 323\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.491431951522827\n",
      "\n",
      " Epoch 324\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.48402512073517\n",
      "\n",
      " Epoch 325\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.484318256378174\n",
      "\n",
      " Epoch 326\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.47743284702301\n",
      "\n",
      " Epoch 327\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.473286032676697\n",
      "\n",
      " Epoch 328\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.46457529067993\n",
      "\n",
      " Epoch 329\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.465648770332336\n",
      "\n",
      " Epoch 330\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.459946155548096\n",
      "\n",
      " Epoch 331\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.457603931427002\n",
      "\n",
      " Epoch 332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.4498553276062\n",
      "\n",
      " Epoch 333\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.45312476158142\n",
      "\n",
      " Epoch 334\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.440725684165955\n",
      "\n",
      " Epoch 335\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.442991495132446\n",
      "\n",
      " Epoch 336\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.436764001846313\n",
      "\n",
      " Epoch 337\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.43260407447815\n",
      "\n",
      " Epoch 338\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.42642629146576\n",
      "\n",
      " Epoch 339\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.426978707313538\n",
      "\n",
      " Epoch 340\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.4248389005661\n",
      "\n",
      " Epoch 341\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.417033553123474\n",
      "\n",
      " Epoch 342\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.410320162773132\n",
      "\n",
      " Epoch 343\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.419785976409912\n",
      "\n",
      " Epoch 344\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.40946674346924\n",
      "\n",
      " Epoch 345\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.401400685310364\n",
      "\n",
      " Epoch 346\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.40614879131317\n",
      "\n",
      " Epoch 347\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.3988116979599\n",
      "\n",
      " Epoch 348\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.39817786216736\n",
      "\n",
      " Epoch 349\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.395504117012024\n",
      "\n",
      " Epoch 350\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.388452887535095\n",
      "\n",
      " Epoch 351\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.389477252960205\n",
      "\n",
      " Epoch 352\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.391180276870728\n",
      "\n",
      " Epoch 353\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.38563346862793\n",
      "\n",
      " Epoch 354\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.38401484489441\n",
      "\n",
      " Epoch 355\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.38301658630371\n",
      "\n",
      " Epoch 356\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.38334083557129\n",
      "\n",
      " Epoch 357\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.377984166145325\n",
      "\n",
      " Epoch 358\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.37595498561859\n",
      "\n",
      " Epoch 359\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.371038675308228\n",
      "\n",
      " Epoch 360\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.373300313949585\n",
      "\n",
      " Epoch 361\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.373184323310852\n",
      "\n",
      " Epoch 362\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.361231565475464\n",
      "\n",
      " Epoch 363\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.371182441711426\n",
      "\n",
      " Epoch 364\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.366288900375366\n",
      "\n",
      " Epoch 365\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.36058509349823\n",
      "\n",
      " Epoch 366\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.35864794254303\n",
      "\n",
      " Epoch 367\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.362479329109192\n",
      "\n",
      " Epoch 368\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.349859833717346\n",
      "\n",
      " Epoch 369\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.359267115592957\n",
      "\n",
      " Epoch 370\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.35146951675415\n",
      "\n",
      " Epoch 371\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.344915866851807\n",
      "\n",
      " Epoch 372\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.34849488735199\n",
      "\n",
      " Epoch 373\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.342114806175232\n",
      "\n",
      " Epoch 374\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.34883964061737\n",
      "\n",
      " Epoch 375\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.346190810203552\n",
      "\n",
      " Epoch 376\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.333183765411377\n",
      "\n",
      " Epoch 377\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.33943486213684\n",
      "\n",
      " Epoch 378\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.32970881462097\n",
      "\n",
      " Epoch 379\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.337724447250366\n",
      "\n",
      " Epoch 380\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.330178141593933\n",
      "\n",
      " Epoch 381\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.33038878440857\n",
      "\n",
      " Epoch 382\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.33195209503174\n",
      "\n",
      " Epoch 383\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.324503660202026\n",
      "\n",
      " Epoch 384\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.324617624282837\n",
      "\n",
      " Epoch 385\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.320325136184692\n",
      "\n",
      " Epoch 386\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.317942261695862\n",
      "\n",
      " Epoch 387\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.32017958164215\n",
      "\n",
      " Epoch 388\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.314779043197632\n",
      "\n",
      " Epoch 389\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.321404814720154\n",
      "\n",
      " Epoch 390\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.31260311603546\n",
      "\n",
      " Epoch 391\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.303045630455017\n",
      "\n",
      " Epoch 392\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.30840575695038\n",
      "\n",
      " Epoch 393\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.30068874359131\n",
      "\n",
      " Epoch 394\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.303303360939026\n",
      "\n",
      " Epoch 395\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.30257284641266\n",
      "\n",
      " Epoch 396\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.29174554347992\n",
      "\n",
      " Epoch 397\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.297000885009766\n",
      "\n",
      " Epoch 398\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.289239168167114\n",
      "\n",
      " Epoch 399\n",
      "\n",
      "Training accuracy :  0.982\n",
      "\n",
      "Training loss :  31.295721292495728\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(400):\n",
    "    \n",
    "    print(\"\\n Epoch\", epoch)\n",
    "    \n",
    "    batch_size = 50\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    for b in range(0, train_input.size()[0], batch_size):\n",
    "        output = model.forward(train_input[b:b+batch_size,:])\n",
    "        batch_loss = loss.forward(output, train_target[b:b+batch_size,:])\n",
    "        train_loss += batch_loss\n",
    "        model.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        _, pred = torch.max(output,1)\n",
    "        _, target = torch.max(train_target[b:b+batch_size],1)\n",
    "        \n",
    "        train_accuracy += torch.sum(pred==target)\n",
    "        \n",
    "    print(\"\\nTraining accuracy : \", train_accuracy/train_target.size()[0])      \n",
    "    print(\"\\nTraining loss : \", train_loss)\n",
    "    loss_list.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efe4bb026a0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAH4hJREFUeJzt3Xl4XfV95/H3V7vkRZvlfZGNbYxjNiMcCARInAVoGlMaEmbS4hJSMjOEJJOmhTTPk7TpZB7SdpqGJzM0nhACaUJZEgqTUIiBJASIARuD8S55k2XtkrXYkqzlfuePe2RkI8myru6iez6v59Fzz/3d373new/mfO75nc3cHRERCZ+MZBcgIiLJoQAQEQkpBYCISEgpAEREQkoBICISUgoAEZGQUgCIiISUAkBEJKTOGABm9kMzazSz7UPaSsxso5lVBo/FQbuZ2b1mVmVm28xs9ZD3rA/6V5rZ+vh8HRERGSs705nAZnYVcAx4yN1XBW1/D7S6+z1mdjdQ7O53mdn1wJ3A9cB7ge+6+3vNrATYDFQADmwBLnH3o6PNe8aMGV5eXh7TFxQRCZstW7Y0u3vZmfplnamDu79oZuWnNa8DrgmmHwR+A9wVtD/k0VTZZGZFZjYn6LvR3VsBzGwjcC3w8GjzLi8vZ/PmzWcqUUREhjCzQ2PpN959ALPcvQ4geJwZtM8DDg/pVxO0jdQuIiJJMtE7gW2YNh+l/d0fYHa7mW02s81NTU0TWpyIiLxjvAHQEAztEDw2Bu01wIIh/eYDtaO0v4u7b3D3CnevKCs74xCWiIiM03gD4Clg8Eie9cCTQ9pvCY4GugxoD4aIngU+YmbFwRFDHwnaREQkSc64E9jMHia6E3eGmdUA3wDuAR41s9uAauCmoPvTRI8AqgK6gFsB3L3VzP4OeD3o983BHcIiIpIcZzwMNJkqKipcRwGJiJwdM9vi7hVn6qczgUVEQuqMQ0Aicip3p/V4LwODW88Or+xrYX/TsTG9Pzc7k09duoCIO5lmlEzJwR0e2XyYurZuAFbOnc7qRcUAFOXnkJN15t9q3b0DdJ7oG9+XAkoKcsjKjO03obvTcryXyAgjC30DzjPb62nv6o1pPmGwfPY0PnbB3LjOQwEgQnTFtaO2g/buPmZNz2PpzKknX9vb0Mkbh47yYmUTkQg0dPawtbpt2M+x4Q54fte84B+e3XPy+cULi8jOyOC1g8PvFpsxNYfLlpRyTtlU3J01i0tPmc/+pmP8Zk8Tv6tspncgMrYvPIy5hXncuXYZC0sKxvQdNu1voarx1NA70tbN20faz/j+sSynsPvYBXPjHgDaByChVt/ewzPb6/jVzgZe2ddysr28tIAMMwbcOdTSBURXkNPyssnOMj66cjbFU3JO9p9XnM81y8uwMazZfru3iQ0v7mPtilkcO9HPszvq6R9wrjt/Nl9cu4yIw3O7GmjqPIG78/zuRt6uaafleC9m0ZXv6cxgXlE+n7v6nGFPujmTgYjz8zdqeKvmzCvvofNcWjaVjCHfOTc7g2tXzWZ6XvaI77t4YRHvmVs4jiplrMa6D0ABIGmno6ePTDO6egcwgx+9fJDmYyfYVtNO30CES4KhlZ6+AZ7ZUU9PX4SSKTnc8YGlnD+vkE37W6gc8st2xexpXLF0BhfMKyQjIzk/XXv7IzR29uAOde09p7xWkJPJzOm55GZmUlgw8or3TNydt4+009M3tq2I2dPzWFh65q0FSTwFgIRG/0CEv/vFTnbXd/JfrjmHbzy5g9q2bvojTnamEfHoMErplFyyM436jndWoJcvKeWODyylfMYUsmMc/xZJFWMNAO0DkJTh7jR2nqA/4hw93suzO+pHHNPeWdtBR08/dW3ddPT00dMXISvDuPWB6KkmK2ZP4/3LZtDdN8CtVyzmnLKpw36OSJgpACSpunr7eeDlg2w5dPTkMM2gDGPEX+XFBTkUFWSzcu50lpZN5fz5hVx+TikPvXKI5bOn8fEL47vzTCQdKAAkriIRp7tvgKxMIzcrk/6BCD39Ef7x2T3sazrG7vpOmjpPsGL2NPKyM/nLj55L2dRcMjKMq5eXUTYt96zm95WPnhunbyKSfhQAMuEaOnp463AbG3c28HJVM7XtPWRmGFcuncEb1Ufp7Ok/2ffS8mLu+/RqKspLklixSDgpAGRC/GZPI/+66RBTc7P45dt19A0403KzOG/udG55XznVrV28VNnM5UtKqSgvZm5RPn9w/pwxHTYpIvGhAJAxO9E/gGFkZhhPvnnk5Ak/PX0RHnm9mml52Rw70c8nK+Zz7ao5rCkvIT8nM8lVi8hIFAAyqs6ePr75/3YyLS+bn71RQ4bBtLxsqlu7mJKTefK4+KuWl/F/Pr2anMyMmC8nICKJoQCQd3mpsplnd9Tz5uE2+gYi7K7vBKIr+fzsDDp7+rn7uhVct2q2hnBEJjEFgJxid30H6x94jYGIs2zmVE70R/j+n17CpeUllAy59IGITH4KgJDatL+F771QRUPHqZcVqG3rZnpeFs99+WpKp57dIZgiMrkoAEKm5dgJ/urxbTy/u5E5hXlcvLDolNcvWVTMn1+1RCt/kRBQAITIjtp2/uLRtzjQfJy7rl3BrVeUk5eto3REwkoBkObau/t4bPNhWo738tArB8nLzuT7f3oJ15w7M9mliUiSKQDSTENHDw+8fJDsTKOy4Ri/399Ce3cfmRnG0rKpPHTbGmZNz0t2mSKSAhQAk1BlQye/3dtEZ08/z2yvp6d/4ORr9e099A1EiDjMnJbLmsUlfOlDy3QDDhF5FwXAJPO7yib+7IHXGYhE7+Nw8cIizpsz7eTrRefmcOsV5WRmGLOn5+mkLBEZkQJgEunpG+BrT2xnUWkBP/3sZUzNy2Jqrv4Tisj4aO0xSfx2bxPffW4v1a1d/PSz72V2ocbxRSQ2CoBJ4Bfbavn8T7eSlWF89srFvG/pjGSXJCJpQAGQwgYizjPb67nr8W0smzmVX37h/eRkaUxfRCaGAiCF3f2zbTy2pQaAL6xdppW/iEwoBUCKenV/C49tqeGzVy7mL689l9wsnbErIhNLPylT1Pd+XcWMqbl85aNa+YtIfCgAUtC/bz3C7yqb+cyVulaPiMSPhoBSzHefq+Q7z+1lzeISPnPF4mSXIyJpTFsAKSQScX686SBXLS/joc+s0a9/EYkrBUAK2Xq4jeZjvfzx6nla+YtI3MUUAGb2RTPbbmY7zOxLQVuJmW00s8rgsThoNzO718yqzGybma2eiC+QTja8uI+87AxdqllEEmLcAWBmq4A/B9YAFwIfM7NlwN3A8+6+DHg+eA5wHbAs+LsduC+GutPOjzcd4tkdDdz5wWUU5mcnuxwRCYFYtgDOAza5e5e79wO/Bf4IWAc8GPR5ELghmF4HPORRm4AiM5sTw/zTxn+8XcfXn9zOh86byeeuWpLsckQkJGIJgO3AVWZWamYFwPXAAmCWu9cBBI+D4xnzgMND3l8TtJ3CzG43s81mtrmpqSmG8iaPf3h2DyvnTOd7/3m1Lt8sIgkz7rWNu+8Cvg1sBJ4B3gL6R3mLDfcxw3zuBnevcPeKsrKy8ZaX8tydZ3fU88q+ZvY3H+dTly7Qjl8RSaiYzgNw9/uB+wHM7H8S/VXfYGZz3L0uGOJpDLrXEN1CGDQfqI1l/pPZD353gG89vevk8w+dNyuJ1YhIGMV6FNDM4HEhcCPwMPAUsD7osh54Mph+CrglOBroMqB9cKgobHr6Brj3hUouWlDEBfMLuefG85lblJ/sskQkZGI9E/hnZlYK9AF3uPtRM7sHeNTMbgOqgZuCvk8T3U9QBXQBt8Y470lr484GOnv6+cpHzuXKZbq2v4gkR6xDQO8fpq0FWDtMuwN3xDK/dNDbH+G7z1eysKSAy88pTXY5IhJiuhZQArk7f/3E21Q1HuOBP7uUzIzh9ouLiCSGjjlMoE37W3l8Sw2f/8BSPrBCZ/uKSHIpABLoB7/bz4ypOXz+g0uTXYqIiAIgUXr7I7xU1cwfXjhXx/uLSEpQACTIjtp2TvRHuLS8JNmliIgACoCE2XLoKACXLCpOciUiIlEKgAR5YXcji2dMYdb0vGSXIiICKAAS4khbN7/f38K6i+YmuxQRkZMUAAnw9LY63OHGi+cnuxQRkZMUAAmwcWcDK2ZPY2FpQbJLERE5SQEQZ21dvWw+1MqHV+pqnyKSWhQAcfb2kXYiDpct0XV/RCS1KADibPuRDgDeM3d6kisRETmVAiDOtte2M68on6KCnGSXIiJyCgVAnO2s7WDVPP36F5HUowCIo86ePg40H2fV3MJklyIi8i4KgDjaVdcJwKp5CgARST0KgDjafqQd0A5gEUlNCoA42lnXwYypuczU9X9EJAUpAOLoyNFuFunsXxFJUQqAOGro6GF2oX79i0hqUgDEibtT197DbA3/iEiKUgDESUd3P919A8zRFoCIpCgFQJzUd/QAaAhIRFKWAiBO6tq7ATQEJCIpSwEQJ7Vt2gIQkdSmAIiTPfUdTMnJZG5hfrJLEREZlgIgTnbUdrBy7nQyMizZpYiIDEsBEAcDEWdnXQfv0UXgRCSFKQDi4EDzcbp6B3QNIBFJaQqAONhRG70InK4CKiKpTAEQBztqO8jJymDpzKnJLkVEZEQxBYCZ/Xcz22Fm283sYTPLM7PFZvaqmVWa2SNmlhP0zQ2eVwWvl0/EF0hFO2rbWTF7GtmZylcRSV3jXkOZ2TzgC0CFu68CMoGbgW8D33H3ZcBR4LbgLbcBR919KfCdoF9a2lXXyco5Gv8XkdQW60/ULCDfzLKAAqAO+CDwePD6g8ANwfS64DnB62vNLO2OkewbiNB6vFcngIlIyht3ALj7EeAfgWqiK/52YAvQ5u79QbcaYF4wPQ84HLy3P+hfOt75p6qjx3sBKJ2am+RKRERGF8sQUDHRX/WLgbnAFOC6Ybr64FtGeW3o595uZpvNbHNTU9N4y0ualsEAmJKT5EpEREYXyxDQh4AD7t7k7n3Az4H3AUXBkBDAfKA2mK4BFgAErxcCrad/qLtvcPcKd68oKyuLobzkaDmmABCRySGWAKgGLjOzgmAsfy2wE/g18Imgz3rgyWD6qeA5wesvuPu7tgAmu5bjJwAonaoAEJHUFss+gFeJ7sx9A3g7+KwNwF3Al82siugY//3BW+4HSoP2LwN3x1B3ynpnC0D7AEQktWWducvI3P0bwDdOa94PrBmmbw9wUyzzmwxaj/eSmWEU5mcnuxQRkVHpTKUJ1nL8BMUFOboKqIikPAXABGs+1qsdwCIyKSgAJtiRo93MLdJJYCKS+hQAE8jdOdzaxcKSgmSXIiJyRgqACdTe3UfniX4WKABEZBJQAEyg6tYuAAWAiEwKCoAJdDIAihUAIpL6FAAT6FDL4BZAfpIrERE5MwXABNpR286Cknym5ekkMBFJfQqACbSjtoNVc3UfYBGZHBQAE6Sjp49DLV26EbyITBoKgAmys7YDgJVzdStIEZkcFAATZPuRdgANAYnIpKEAmCA7azuYNT2Xsmm6DLSITA4KgAmyvbad9+jXv4hMIgqACXDsRD9Vjce0A1hEJhUFwATYfLCViMOa8pJklyIiMmYKgAnw6oFWsjKM1YuKkl2KiMiYKQAmwKv7W7hgfiEFOTHdYVNEJKEUADHq7h1gW007axaXJrsUEZGzogCI0RvVR+mPOO9dovF/EZlcFAAxemVfM5kZRsWi4mSXIiJyVhQAMXp+VyMVi4p1BVARmXQUADE43NrF7vpOPrxyVrJLERE5awqAGLx6oBWAq5eXJbkSEZGzpwCIwbaaNqbkZHJO2dRklyIictYUADHYVtPOqnmFZGRYsksRETlrCoBx6ukbYGddBxfM1/V/RGRyUgCM03O7Gujtj3D18pnJLkVEZFwUAOP071uPMKcwj8vP0RnAIjI5KQDGwd3ZfOgoVy8vI1Pj/yIySSkAxqG+o4e2rj7Om6P7/4rI5DXuADCzc83szSF/HWb2JTMrMbONZlYZPBYH/c3M7jWzKjPbZmarJ+5rxJe78+vdjTzyejU9fQPsqoveAF4BICKT2bivX+zue4CLAMwsEzgCPAHcDTzv7veY2d3B87uA64Blwd97gfuCx5T3q50NfO7HWwD4yavVLCwpAGDFnGnJLEtEJCYTNQS0Ftjn7oeAdcCDQfuDwA3B9DrgIY/aBBSZ2ZwJmn9cvbi3iam5Wfzzpy5i+5F2frGtjhsvnsd0Xf9HRCaxibqDyc3Aw8H0LHevA3D3OjMbPE5yHnB4yHtqgra6CaohbrZWt3HRgiJuuHgeaxaX0N03oLN/RWTSi3kLwMxygI8Dj52p6zBtPszn3W5mm81sc1NTU6zlxez4iX5213ewemH0do9zi/K18heRtDARQ0DXAW+4e0PwvGFwaCd4bAzaa4AFQ943H6g9/cPcfYO7V7h7RVlZ8i+y9lZNGxGHixfqev8ikl4mIgD+E+8M/wA8BawPptcDTw5pvyU4GugyoH1wqCiVba1uA+CiBbrhu4ikl5j2AZhZAfBh4HNDmu8BHjWz24Bq4Kag/WngeqAK6AJujWXeibK1+ihLZkyheEpOsksREZlQMQWAu3cBpae1tRA9Kuj0vg7cEcv8Es3d2VrdxjXn6no/IpJ+dCbwKKpbu2g53svqRRr+EZH0owAYxRvVRwG4eIF2AItI+lEAjGJrdRsFOZmcO1tn/IpI+lEAjGJvQycrZk/TFT9FJC0pAEZxsLmL8hlTkl2GiEhcKABG0N07QH1HD+WlCgARSU8KgBFUt3YBsKi0IMmViIjEhwJgBAdbjgOwWENAIpKmFAAjONAcDYBFGgISkTSlABjB3oZOZk3PpTBf1/wXkfSkABhBZcMxls/S8f8ikr4UAMOIRJyqxmMsnanr/otI+lIADONIWzfdfQPaAhCRtKYAGMbehk4Als/SFoCIpC8FwDD2NhwDYOlMbQGISPpSAAyjsqGT2dPzdASQiKQ1BcAwKhuPsUzDPyKS5hQAp2k93sue4CqgIiLpTAFwmod+f5De/gifrFiQ7FJEROJKATCEu/PE1iO8f9kMlukQUBFJcwqAIV490Mqhli6uXTU72aWIiMSdAiCwu76DmzdsAmDtillJrkZEJP4UAIHtRzoA+B83rGJ2YV6SqxERiT8FQOBQy3EyM4xPXaqdvyISDgqAwIHm48wvzic7U4tERMJBa7vAoZYu3fxFREJFAUD08M+DLccp1/1/RSREFADAvqbjdPb0c96c6ckuRUQkYUIfAD19Azy25TAAV5wzI8nViIgkTugD4IGXD/L93+6nMD+bhRoCEpEQCX0A1LV3A3DPjecnuRIRkcQKfQD09keYOS2X686fk+xSREQSKvQB0NM3QF52ZrLLEBFJuJgCwMyKzOxxM9ttZrvM7HIzKzGzjWZWGTwWB33NzO41syoz22ZmqyfmK8Smu2+AfAWAiIRQrFsA3wWecfcVwIXALuBu4Hl3XwY8HzwHuA5YFvzdDtwX47wnRE9fhLzs0G8IiUgIjXvNZ2bTgauA+wHcvdfd24B1wINBtweBG4LpdcBDHrUJKDKzpA+8d2sISERCKpafvkuAJuABM9tqZj8wsynALHevAwgeZwb95wGHh7y/JmhLqhMKABEJqVgCIAtYDdzn7hcDx3lnuGc4Nkybv6uT2e1mttnMNjc1NcVQ3tj09EW0D0BEQimWAKgBatz91eD540QDoWFwaCd4bBzSf+i1lucDtad/qLtvcPcKd68oKyuLobyxiQ4BaR+AiITPuNd87l4PHDazc4OmtcBO4ClgfdC2HngymH4KuCU4GugyoH1wqCiZdBioiIRVVozvvxP4iZnlAPuBW4mGyqNmdhtQDdwU9H0auB6oArqCvkmnncAiElYxBYC7vwlUDPPS2mH6OnBHLPOLhxN9EQWAiIRSqAe/ByJO74B2AotIOIU6AHr6BgC0E1hEQinUa77BAMjP0RaAiIRPqAOge3ALIEsBICLhE+oA6OmLAJCnLQARCaGQB8DgFkCoF4OIhFSo13zaByAiYRbyAAiGgHQYqIiEUKgD4NiJfgCdByAioRTqAGjr6gWgeEpOkisREUm8UAfA0a4+AIoLspNciYhI4oU6ANq6esnJytAQkIiEUsgDoI/igmzMhrtXjYhIegt1ABzt6qW4QOP/IhJOoQ6Atq4+CvM1/i8i4RTqANAWgIiEWcgDoI/iKdoCEJFwCm0AuDttXb0UaQtAREIqbQOgu3eAt2vaR3y99Xgv/RGnVCeBiUhIpW0AfPuZ3fzh915iV13HsK+/dqAVgIsWFCWyLBGRlJG2AbD1cBsA3/rlLr7+5HYaO3pOef3lfc1MycnkQgWAiIRUVrILiIeBiLO/8RgAL1U181JVM4tKp3DblYvZU9/JnQ+/QVXjMT68chbZmWmbgSIio0rLtV9lYyedJ/r5p09eyGt/vZb87EzeOtxGe3cfv9/XzN6GY9x0yQLuufGCZJcqIpI0abkFUJifzV98eDmXn1PKzOl5VJQX89RbtTy7o54/uWwR+dmZ3PPH5+sSECISamkZAHMK87lz7bKTz6cHZ/ue6I9Qc7SL+cX5WvmLSOil5RDQ6f7kvYtOTh9sjgaAiEjYhSIALj+nlG+uew8Q3T+woKQgyRWJiCRfKAIAOHnGb8TRFoCICCEKgKF3/VpQrC0AEZHQBEBR/juXfJivABARCVEADN0CKNEQkIhIaAKgOLjo27TcLN0ERkSEGAPAzA6a2dtm9qaZbQ7aSsxso5lVBo/FQbuZ2b1mVmVm28xs9UR8gbGakpNJdqYxT+cAiIgAE7MF8AF3v8jdK4LndwPPu/sy4PngOcB1wLLg73bgvgmY95iZGUUFOToEVEQkEI8zgdcB1wTTDwK/Ae4K2h9ydwc2mVmRmc1x97o41DCsr3xkOQtLpiRqdiIiKS3WAHDgV2bmwPfdfQMwa3Cl7u51ZjYz6DsPODzkvTVBW8IC4FOXLkzUrEREUl6sAXCFu9cGK/mNZrZ7lL7DDbz7uzqZ3U50iIiFC7XCFhGJl5j2Abh7bfDYCDwBrAEazGwOQPDYGHSvARYMeft8oHaYz9zg7hXuXlFWVhZLeSIiMopxB4CZTTGzaYPTwEeA7cBTwPqg23rgyWD6KeCW4Gigy4D2RI7/i4jIqWIZApoFPBEcUpkF/NTdnzGz14FHzew2oBq4Kej/NHA9UAV0AbfGMG8REYnRuAPA3fcDFw7T3gKsHabdgTvGOz8REZlYoTkTWERETqUAEBEJKQWAiEhIWXRoPjWZWRNwKIaPmAE0T1A5E0l1nR3VdXZU19lL1drGW9cidz/jcfQpHQCxMrPNQ65RlDJU19lRXWdHdZ29VK0t3nVpCEhEJKQUACIiIZXuAbAh2QWMQHWdHdV1dlTX2UvV2uJaV1rvAxARkZGl+xaAiIiMIC0DwMyuNbM9we0n7z7zO+Jay5hvm5mAWn5oZo1mtn1IW9Jv4TlCXX9jZkeC5fammV0/5LWvBnXtMbOPxqmmBWb2azPbZWY7zOyLQXtSl9codSV1eQXzyTOz18zsraC2vw3aF5vZq8Eye8TMcoL23OB5VfB6eYLr+pGZHRiyzC4K2hP2bz+YX6aZbTWzXwTPE7e83D2t/oBMYB+wBMgB3gJWJrGeg8CM09r+Hrg7mL4b+HaCarkKWA1sP1MtRC/c9x9E7+NwGfBqguv6G+Arw/RdGfw3zQUWB/+tM+NQ0xxgdTA9DdgbzDupy2uUupK6vIJ5GTA1mM4GXg2WxaPAzUH7vwD/NZj+b8C/BNM3A48kuK4fAZ8Ypn/C/u0H8/sy8FPgF8HzhC2vdNwCWANUuft+d+8F/o3o7ShTyTqit8skeLwhETN19xeB1jHWcvIWnu6+CSiy4D4PCaprJOuAf3P3E+5+gOjVZdfEoaY6d38jmO4EdhG9g11Sl9codY0kIcsrqMfd/VjwNDv4c+CDwONB++nLbHBZPg6sNbPhbhwVr7pGkrB/+2Y2H/gD4AfBcyOByysdA2CkW08my+BtM7dY9G5ncNptM4GZI747/kaqJRWW4+eDTfAfDhkmS3hdwab2xUR/OabM8jqtLkiB5RUMZ7xJ9EZQG4lucbS5e/8w8z9ZW/B6O1CaiLrcfXCZfStYZt8xs9zT6xqm5on2z8BfAZHgeSkJXF7pGABjuvVkAl3h7quB64A7zOyqJNZyNpK9HO8DzgEuInrf6P8VtCe0LjObCvwM+JK7d4zWdZi2RNaVEsvL3Qfc/SKid/xbA5w3yvwTVtvpdZnZKuCrwArgUqAEuCuRdZnZx4BGd98ytHmUeU94XekYAGO69WSi+NndNjMZYrqFZ7y4e0PwP20E+L+8M2yRsLrMLJvoSvYn7v7zoDnpy2u4ulJheQ3l7m3Ab4iOoReZ2eC9R4bO/2RtweuFjH0oMNa6rg2G09zdTwAPkPhldgXwcTM7SHSo+oNEtwgStrzSMQBeB5YFe9JziO4seSoZhdjZ3zYzGVLyFp6njbn+EdHlNljXzcEREYuBZcBrcZi/AfcDu9z9n4a8lNTlNVJdyV5eQQ1lZlYUTOcDHyK6j+LXwCeCbqcvs8Fl+QngBQ/2cCagrt1DgtyIjrMPXWZx/2/p7l919/nuXk50PfWCu3+aRC6vidybnSp/RPfi7yU6/vi1JNaxhOgRGG8BOwZrITpu9zxQGTyWJKieh4kOD/QR/TVx20i1EN3c/N/BMnwbqEhwXT8O5rst+Ic/Z0j/rwV17QGui1NNVxLdvN4GvBn8XZ/s5TVKXUldXsF8LgC2BjVsB74+5P+D14jugH4MyA3a84LnVcHrSxJc1wvBMtsO/CvvHCmUsH/7Q2q8hneOAkrY8tKZwCIiIZWOQ0AiIjIGCgARkZBSAIiIhJQCQEQkpBQAIiIhpQAQEQkpBYCISEgpAEREQur/Ay3RNzkKcah5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe4ba63978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efe4ba14978>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe515f7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on test set : 97.4%\n"
     ]
    }
   ],
   "source": [
    "test_output = model.forward(test_input)\n",
    "_, test_pred = torch.max(test_output,1)\n",
    "\n",
    "test_accuracy = torch.sum(test_pred == test_target.type(torch.LongTensor))\n",
    "print(\"Accuracy of model on test set : {}%\".format(test_accuracy/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
